{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to MkDocs\n\n\nnanocosmos documentation - visit \nnanocosmos.de\n.\n\n\nDocs\n\n\nTest\n\n* see index in the left\n\n\nUnder\n\n\nTest", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome_to_mkdocs", 
            "text": "nanocosmos documentation - visit  nanocosmos.de .", 
            "title": "Welcome to MkDocs"
        }, 
        {
            "location": "/#docs", 
            "text": "Test \n* see index in the left", 
            "title": "Docs"
        }, 
        {
            "location": "/#under", 
            "text": "Test", 
            "title": "Under"
        }, 
        {
            "location": "/about/", 
            "text": "About nanocosmos", 
            "title": "About"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/", 
            "text": "nanoStream Live Video Encoder\n\n\nWebcaster / Browser based Live Encoder\nVersion 4.0\nCompatible to NPAPI, ActiveX and Chrome Extension\n(c) 2015 nanocosmos gmbh\nhttp://www.nanocosmos.net\n\n\nWork in Progress\n\n\nNANO.NanoStream\n\n\n\n\n\n\nDescription\n\n\n\n\nUse the \nNANO.NanoStream\n API to communicate with the plugin. It provide async functions and events to handle devices, configs, preview and broadcast. Use the functions with callbacks to retrieve necessary informations and data for the encoder lifecycle and the usage with frontend javascript code.\n\n\n\n\n\n\n\n\nBrowser\n\n\n\n\nChrome, Firefox, Internet Explorer, Safari\n\n\n\n\n\n\n\n\nOS\n\n\n\n\nWindows Support for NPAPI / Chrome\n\n\nMacOS Support only for NPAPI (Chrome not supported yet)\n\n\n\n\n\n\n\n\nAvailability\n\n\n\n\nSince nanoStream 4.0\n\n\n\n\n\n\n\n\nNanoStream Summary\n\n\n\n\n\n\nAPI Methods (async with callbacks)\n\n\n\n\nGetAudioDeviceConfig\n\n\nGetAudioDevices\n\n\nGetAudioLevels\n\n\nGetConfig\n\n\nGetInputs\n\n\nGetOutputs\n\n\nGetVideoDeviceConfig\n\n\nGetVideoDevices\n\n\nGetWindows\n\n\nSaveXmlProfile\n\n\nSetAudioVolume\n\n\nSetConfigs\n\n\nSetInputs\n\n\nSetOutputs\n\n\nSetPictureInPictureSize\n\n\nSetVideoMixingMode\n\n\nSetXmlProfile\n\n\nStartBroadcast\n\n\nStartPreview\n\n\nStopBroadcast\n\n\nStopPreview\n\n\nInit\n\n\n\n\n\n\n\n\nHelper Methods (sync)\n\n\n\n\nDetectBrowser\n\n\nInstallExtensionInline\n\n\nInstallExtensionWebstore\n\n\nFireEvent\n\n\n\n\n\n\n\n\nEvents\n\n\n\n\nonError\n\n\nonNotifyEvent\n\n\nonStopEvent\n\n\nonSupported\n\n\nonUnsupported\n\n\n\n\n\n\n\n\nAPI Methods (async with callbacks)\n\n\nGetAudioDeviceConfig\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetAudioDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn object with all possible config parameters of the the audio device by index will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetAudioDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n index\n\n\nThe index of the audio device\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: string, // the device name\n                            \nindex\n: integer, // the device index\n                            \noptions\n: [ // array with options\n                                {\n                                    \nsamplerates\n: [ // array available samplerates \n                                        integer,\n                                        integer,\n                                        ...\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: \nMikrofon (HD Pro Webcam C920)\n,\n                            \nindex\n: 2,\n                            \noptions\n: [\n                                {\n                                    \nsamplerates\n: [\n                                        22050,\n                                        24000,\n                                        44100,\n                                        48000\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n:\nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \nparams\n: [\n                    index\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var index = 0;\n    var message = NANO.NanoStream.GetAudioDeviceConfig(\n        index,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i \n options.length; i += 1) {\n                console.log(\nFound options \n + i + \n for audio device '\n + device.id + \n' with index = \n + device.index);\n                var samplerates = options[i].samplerates;\n                for (var j = 0; j \n samplerates.length; j += 1) {\n                    console.log(\nAvailable samplerate: \n + samplerates[j]);                \n                }\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetAudioDevices\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetAudioDevices(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn array object with all available audio devices will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetAudioDevices(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetAudioDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \naudio\n: [ // array with device objects\n                                {\n                                    \nid\n: string, // the device name\n                                    \nindex\n: integer // the device index\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetAudioDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \naudio\n: [\n                                {\n                                    \nid\n: \nMikrofon (HD Pro Webcam C920)\n,\n                                    \nindex\n: 0\n                                },\n                                {\n                                    \nid\n: \nnanocosmos Live Audio Capture\n,\n                                    \nindex\n: 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetAudioDevices\n,\n                \ndata\n: {\n                    \nvalue\n: string // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetAudioDevices\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.GetAudioDevices(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var devices = message.data.value.devices.audio;\n            for (var i = 0; i \n devices.length; i += 1) {\n                console.log(\nFound audio device '\n + devices[i].id + \n' with index = \n + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetAudioLevels\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetAudioLevels(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn array object with the current audio levels (stereo) will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetAudioLevels(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetAudioLevels\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nlevels\n: [\n                            integer,\n                            integer\n                        ]\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetAudioLevels\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nlevels\n: [\n                            14326,\n                            13954\n                        ]\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetAudioLevels\n,\n                \ndata\n: {\n                    \nvalue\n: string // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetAudioLevels\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    NANO.NanoStream.GetAudioLevels(function success(message) {\n        var levels = message.data.value.levels;\n        var reference = 32768.0;\n        var left = Math.round(levels[0] / reference * 100) / 100;\n        var right = Math.round(levels[1] / reference * 100) / 100;\n        console.log(\nAudio level left: \n + left);\n        console.log(\nAudio level right: \n + right);\n    }, null);\n\n\n\n\nup\n\n\n\n\nGetConfig\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetConfig(\nstring\n key, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method gets the value from a defined key of the advanced configuration.\n\n\nNOTE: see possible advanced configuration \nhere\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetConfig(\nstring\n key, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nstring\n key\n\n\nThe key of the key value pair\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nkey\n: string, // the key of the key value pair\n                        \nvalue\n: string // the value of the key value pair\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nkey\n: \nVideoMixerMode\n,\n                        \nvalue\n: \n0\n\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetConfig\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetConfig\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var key = \nVideoMixerMode\n;\n    var message = NANO.NanoStream.GetConfig(\n        key,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nConfig pair: \n + message.data.value.key + \n,\n + message.data.value.value);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetInputs\n\n\nGetOutputs\n\n\nGetVideoDeviceConfig\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetVideoDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn object with all possible config parameters of the the video device by index will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetVideoDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n index\n\n\nThe index of the video device\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: string, // the device name\n                            \nindex\n: integer, // the device index\n                            \noptions\n: [ // array with options\n                                { // the option object with an available resolution\n                                    \ncolorspaces\n: [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                            \nframerates\n: [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                            \nid\n: string, // the name of the colorspace\n                                            \nindex\n: integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                    \nresolution\n: { // the resolution object\n                                        \nheight\n: integer, // the height\n                                        \nwidth\n: integer // the width\n                                    }\n                                },\n                                { // the option object with an available resolution\n                                    \ncolorspaces\n: [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                            \nframerates\n: [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                            \nid\n: string, // the name of the colorspace\n                                            \nindex\n: integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                    \nresolution\n: { // the resolution object\n                                        \nheight\n: integer, // the height\n                                        \nwidth\n: integer // the width\n                                    }\n                                },\n                                ... // more objects\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: \nLogitech HD Pro Webcam C920\n,\n                            \nindex\n: 1,\n                            \noptions\n: [\n                                {\n                                    \ncolorspaces\n: [\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nMJPG\n,\n                                            \nindex\n: 0\n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nRGB24\n,\n                                            \nindex\n: 1\n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nI420\n,\n                                            \nindex\n: 2\n                                        }\n                                    ],\n                                    \nresolution\n: {\n                                        \nheight\n: 360,\n                                        \nwidth\n: 640\n                                    }\n                                },\n                                {\n                                    \ncolorspaces\n: [\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nMJPG\n,\n                                            \nindex\n: 0 \n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nRGB24\n,\n                                            \nindex\n: 1 \n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nI420\n,\n                                            \nindex\n: 2 \n                                        }\n                                    ],\n                                    \nresolution\n: {\n                                        \nheight\n: 720,\n                                        \nwidth\n: 1280\n                                    }\n                                }\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: \nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \nparams\n: [\n                    index\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var index = 0;\n    var message = NANO.NanoStream.GetVideoDeviceConfig(\n        index,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i \n options.length; i += 1) {\n                console.log(\nFound options \n + i + \n for audio device '\n + device.id + \n' with index = \n + device.index);\n                var width = options[i].resolution.width;\n                var height = options[i].resolution.height;\n                console.log(\nAvailable resolution: \n + width + \nx\n + height);\n                var colorspaces = options[i].colorspaces;\n                for (var j = 0; j \n colorspaces.length; j += 1) {\n                    var name = colorspaces[j].id;\n                    var index = colorspaces[j].index;\n                    console.log(\nAvailable colorspace for resolution \n + width + \nx\n + height + \n: name = \n + name + \n, index = \n + index);\n                    for (var k = 0; k \n colorspaces[j].framerates.length; k += 1) {\n                        console.log(\nAvailable framerate for \n + width + \nx\n + height + \n, \n + name + \n: \n + colorspaces[j].framerates[k]);\n                    }\n                }\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetVideoDevices\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetVideoDevices(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn array object with all available video devices will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetVideoDevices(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetVideoDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \nvideo\n: [ // array with device objects\n                                {\n                                    \nid\n: string, // the device name\n                                    \nindex\n: integer // the device index\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetVideoDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \nvideo\n: [\n                                {\n                                    \nid\n: \nMikrofon (HD Pro Webcam C920)\n,\n                                    \nindex\n: 0\n                                },\n                                {\n                                    \nid\n: \nnanocosmos Live Video Capture\n,\n                                    \nindex\n: 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetVideoDevices\n,\n                \ndata\n: {\n                    \nvalue\n: string // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetVideoDevices\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.GetVideoDevices(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var devices = message.data.value.devices.video;\n            for (var i = 0; i \n devices.length; i += 1) {\n                console.log(\nFound video device '\n + devices[i].id + \n' with index = \n + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetWindows\n\n\nSaveXmlProfile\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method saves an \nXML\n profile to a defined path.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nstring\n path\n\n\nThe path to save the profile to\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSaveXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSaveXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSaveXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSaveXmlProfile\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var path = \nC:\\profile.xml\n;\n    var message = NANO.NanoStream.SaveXmlProfile(\n        path,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nProfile saved\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetAudioVolume\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method sets the audio volume in a range between 0 and 100.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n volume\n\n\nThe volume to set in a range between 0 and 100\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetAudioVolume\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetAudioVolume\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetAudioVolume\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetAudioVolume\n,\n                \nparams\n: [\n                    integer\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var volume = 50;\n    var message = NANO.NanoStream.SetAudioVolume(\n        volume,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nVolume set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetConfigs\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetConfigs(\nobject\n \nnanoConfigObject\n, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\n\n\nThis method sets multiple key value pairs for advanced configuration.\n\n\n\n\n\n\nNOTE: see possible advanced configurations \nhere\n\n\n\n\n\n\nNOTE: it\ns necesary to use the \nNANO.Config\n class to generate the needed object \nnanoConfigObject\n\n\n\n\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetConfigs(\nobject\n \nnanoConfigObject\n, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nobject\n \nnanoConfigObject\n\n\nThe object with one or multiple key value pairs\n\n\nNOTE: see the description to the usage of this object \nhere\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetConfigs\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetConfigs\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n            \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetConfigs\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetConfigs\n,\n                \nparams\n: [ object ]                \n            }\n\n\n\n\nExamples\n\n\n\n\nlow latency configuration\n\n\n\n\n    var config = new NANO.Config();\n    config.AddConfig(\nH264Profile\n, \nBaseline\n); // Baseline Profile supported by most devices and players\n    config.AddConfig(\nH264IFrameDistance\n, \n50\n); // Moderate GOP length\n    config.AddConfig(\nH264PFrameDistance\n, \n1\n); // No B-frames \n    //(optional)\n    //config.AddConfig(\nH264VlcMode\n, \n1\n); // CAVLC entropy coding mode\n    //config.AddConfig(\nRateControl\n, \n1\n); // Strict constant bitrate\n    var nanoConfigObject = config.GetConfig(); // returns the well json parsed object we need to pass\n    var message = NANO.NanoStream.SetConfigs(\n        nanoConfigObject,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nConfiguration set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetInputs\n\n\nSetOutputs\n\n\nSetPictureInPictureSize\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method sets the picture in picture size in a range between 0 and 3.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n size\n\n\nThe picture in picture size to set in a range between 0 and 3\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \nparams\n: [\n                    integer\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var size = 2;\n    var message = NANO.NanoStream.SetPictureInPictureSize(\n        size,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nPicture in picture size set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetVideoMixingMode\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method sets the video mix mode.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n mode\n\n\nThe video mix mode to set\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \nparams\n: [\n                    integer\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var mode = 0;\n    var message = NANO.NanoStream.SetVideoMixingMode(\n        mode,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nVideo mix mode set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetXmlProfile\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method loads an \nXML\n profile from a defined path.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nstring\n path\n\n\nThe path to load the profile from\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetXmlProfile\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var path = \nC:\\profile.xml\n;\n    var message = NANO.NanoStream.SetXmlProfile(\n        path,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nProfile loaded\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStartBroadcast\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StartBroadcast(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the broadcast and/or recording.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StartBroadcast(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartBroadcast(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartBroadcast(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStartBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: float\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStartBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: 30\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStartBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStartBroadcast\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StartBroadcast(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nBroadcast started with framerate \n + message.data.value.framerate);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStartPreview\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StartPreview(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the preview.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StartPreview(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartPreview(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartPreview(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStartPreview\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: float\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStartPreview\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: 30\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStartPreview\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStartPreview\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StartPreview(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nPreview started with framerate \n + message.data.value.framerate);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStopBroadcast\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StopBroadcast(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the preview.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StopBroadcast(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopBroadcast(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopBroadcast(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStopBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: string           \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStopBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n            \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStopBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStopBroadcast\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StopBroadcast(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nBroadcast stopped\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStopPreview\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StopPreview(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the preview.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StopPreview(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopPreview(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopPreview(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStopPreview\n,\n                \ndata\n: {\n                    \nvalue\n: string            \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStopPreview\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStopPreview\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStopPreview\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StopPreview(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nPreview stopped\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nInit\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.Init(\nstring\n elementId, \nstring\n license, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method embeds the plugin into an container element (div) and initilize the plugin.\n\n\nCall this method after \nNANO.NanoStream.DetectBrowser()\n and before any other API call.\n\n\n\n\nParameters\n\n\n\n\nstring\n elementId\n\n\nThe id of the div element where to embed the plugin into\n\n\n\n\n\n\nstring\n license\n\n\nThe license string\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nInit\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nInit\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nInit\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ncode\n: integer, // the error code\n                        \nerror\n: string // the error message\n                    }\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nInit\n,\n                \nparams\n: [\n                    string,\n                    string\n                ]\n            }\n\n\n\n\nExample (with all possible errors)\n\n\n    var elementId = \nvideo-container\n; // an existing div element with this id\n    var license = \nnlic::...\n; // an valid nanostream license string\n    var message = NANO.NanoStream.Init(\n        elementId,\n        license,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nNanoStream plugin successfully embedded and ready!\n);\n        },\n        function error(message) {\n            if (message.type === \nnanoextensioncheck\n) { // only chrome\n                if (message.data.value.code === 0) { // extension not installed or unavailable\n                    // DO STUFF\n                    var result = confirm(\nYou using chrome browser, but don't have installed your extension!\\r\\nDo you want to install it now?\n);\n                    if (result) {\n                        NANO.NanoStream.InstallExtensionInline();\n                    }\n                } else if (message.data.value.code === 1) { // extension installation finished (not really an error, but passed within the handler)\n                    // DO STUFF\n                    console.log(\nExtension now installed\n);\n                }\n            } else if (message.type === \nnanoversioncheck\n) { // only chrome\n                if (message.data.value.code === 0) { // native version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 1) { // extension version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 2) { // lib version outdated\n                    alert(message.data.value.error);\n                }\n            } else {\n                if (message.data.value.code === 100) { // error initialization\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 101) { // error setting license\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 102) { // error connecting to the native plugin (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 103) { // error connecting to the extension (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 104) { // error passing parameters / wrong parameters\n                    alert(message.data.value.error);\n                } else { // error embedding plugin\n                    if (message.data.value.code === 0) { // plugin found but no version\n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -1) { // general no plugins available (unsupported browser) \n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -2) { // plugin not found / not installed / not activated\n                        alert(message.data.value.error);\n                    } else {\n                        alert(\nUnknown Error Init: code = \n + message.data.value.code + \n, error = '\n + message.data.value.error + \n'\n);\n                    }\n                }\n            }\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nHelper Methods (sync)\n\n\nDetectBrowser\n\n\nFireEvent\n\n\nInstallExtensionInline\n\n\nInstallExtensionWebstore\n\n\nEvents\n\n\nonError\n\n\nonNotifyEvent\n\n\nonStopEvent\n\n\nonSupported\n\n\nonUnsupported\n\n\nNANO Config", 
            "title": "Web api"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nanostream_live_video_encoder", 
            "text": "Webcaster / Browser based Live Encoder\nVersion 4.0\nCompatible to NPAPI, ActiveX and Chrome Extension\n(c) 2015 nanocosmos gmbh\nhttp://www.nanocosmos.net  Work in Progress", 
            "title": "nanoStream Live Video Encoder"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nanonanostream", 
            "text": "Description   Use the  NANO.NanoStream  API to communicate with the plugin. It provide async functions and events to handle devices, configs, preview and broadcast. Use the functions with callbacks to retrieve necessary informations and data for the encoder lifecycle and the usage with frontend javascript code.     Browser   Chrome, Firefox, Internet Explorer, Safari     OS   Windows Support for NPAPI / Chrome  MacOS Support only for NPAPI (Chrome not supported yet)     Availability   Since nanoStream 4.0", 
            "title": "NANO.NanoStream"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nanostream_summary", 
            "text": "API Methods (async with callbacks)   GetAudioDeviceConfig  GetAudioDevices  GetAudioLevels  GetConfig  GetInputs  GetOutputs  GetVideoDeviceConfig  GetVideoDevices  GetWindows  SaveXmlProfile  SetAudioVolume  SetConfigs  SetInputs  SetOutputs  SetPictureInPictureSize  SetVideoMixingMode  SetXmlProfile  StartBroadcast  StartPreview  StopBroadcast  StopPreview  Init     Helper Methods (sync)   DetectBrowser  InstallExtensionInline  InstallExtensionWebstore  FireEvent     Events   onError  onNotifyEvent  onStopEvent  onSupported  onUnsupported", 
            "title": "NanoStream Summary"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#api_methods_async_with_callbacks", 
            "text": "", 
            "title": "API Methods (async with callbacks)"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getaudiodeviceconfig", 
            "text": "up to summary  object  NANO.NanoStream.GetAudioDeviceConfig( integer  index,  function  successCallback,  function  errorCallback)", 
            "title": "GetAudioDeviceConfig"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description", 
            "text": "An object with all possible config parameters of the the audio device by index will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetAudioDeviceConfig( integer  index,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters", 
            "text": "integer  index  The index of the audio device    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetAudioDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id : string, // the device name\n                             index : integer, // the device index\n                             options : [ // array with options\n                                {\n                                     samplerates : [ // array available samplerates \n                                        integer,\n                                        integer,\n                                        ...\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetAudioDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id :  Mikrofon (HD Pro Webcam C920) ,\n                             index : 2,\n                             options : [\n                                {\n                                     samplerates : [\n                                        22050,\n                                        24000,\n                                        44100,\n                                        48000\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status : COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetAudioDeviceConfig ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetAudioDeviceConfig ,\n                 params : [\n                    index\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example", 
            "text": "var index = 0;\n    var message = NANO.NanoStream.GetAudioDeviceConfig(\n        index,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i   options.length; i += 1) {\n                console.log( Found options   + i +   for audio device '  + device.id +  ' with index =   + device.index);\n                var samplerates = options[i].samplerates;\n                for (var j = 0; j   samplerates.length; j += 1) {\n                    console.log( Available samplerate:   + samplerates[j]);                \n                }\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getaudiodevices", 
            "text": "up to summary  object  NANO.NanoStream.GetAudioDevices( function  successCallback,  function  errorCallback)", 
            "title": "GetAudioDevices"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_1", 
            "text": "An array object with all available audio devices will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetAudioDevices( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_1", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetAudioDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             audio : [ // array with device objects\n                                {\n                                     id : string, // the device name\n                                     index : integer // the device index\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetAudioDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             audio : [\n                                {\n                                     id :  Mikrofon (HD Pro Webcam C920) ,\n                                     index : 0\n                                },\n                                {\n                                     id :  nanocosmos Live Audio Capture ,\n                                     index : 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetAudioDevices ,\n                 data : {\n                     value : string // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_1", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetAudioDevices ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_1", 
            "text": "var message = NANO.NanoStream.GetAudioDevices(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var devices = message.data.value.devices.audio;\n            for (var i = 0; i   devices.length; i += 1) {\n                console.log( Found audio device '  + devices[i].id +  ' with index =   + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getaudiolevels", 
            "text": "up to summary  object  NANO.NanoStream.GetAudioLevels( function  successCallback,  function  errorCallback)", 
            "title": "GetAudioLevels"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_2", 
            "text": "An array object with the current audio levels (stereo) will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetAudioLevels( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_2", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetAudioLevels ,\n                 data : {\n                     value : {\n                         levels : [\n                            integer,\n                            integer\n                        ]\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetAudioLevels ,\n                 data : {\n                     value : {\n                         levels : [\n                            14326,\n                            13954\n                        ]\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetAudioLevels ,\n                 data : {\n                     value : string // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_2", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetAudioLevels ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_2", 
            "text": "NANO.NanoStream.GetAudioLevels(function success(message) {\n        var levels = message.data.value.levels;\n        var reference = 32768.0;\n        var left = Math.round(levels[0] / reference * 100) / 100;\n        var right = Math.round(levels[1] / reference * 100) / 100;\n        console.log( Audio level left:   + left);\n        console.log( Audio level right:   + right);\n    }, null);  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getconfig", 
            "text": "up to summary  object  NANO.NanoStream.GetConfig( string  key,  function  successCallback,  function  errorCallback)", 
            "title": "GetConfig"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_3", 
            "text": "This method gets the value from a defined key of the advanced configuration.  NOTE: see possible advanced configuration  here  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetConfig( string  key,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_3", 
            "text": "string  key  The key of the key value pair    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetConfig ,\n                 data : {\n                     value : {\n                         key : string, // the key of the key value pair\n                         value : string // the value of the key value pair\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetConfig ,\n                 data : {\n                     value : {\n                         key :  VideoMixerMode ,\n                         value :  0 \n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetConfig ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_3", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetConfig ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_3", 
            "text": "var key =  VideoMixerMode ;\n    var message = NANO.NanoStream.GetConfig(\n        key,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Config pair:   + message.data.value.key +  ,  + message.data.value.value);\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getinputs", 
            "text": "", 
            "title": "GetInputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getoutputs", 
            "text": "", 
            "title": "GetOutputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getvideodeviceconfig", 
            "text": "up to summary  object  NANO.NanoStream.GetVideoDeviceConfig( integer  index,  function  successCallback,  function  errorCallback)", 
            "title": "GetVideoDeviceConfig"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_4", 
            "text": "An object with all possible config parameters of the the video device by index will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetVideoDeviceConfig( integer  index,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_4", 
            "text": "integer  index  The index of the video device    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetVideoDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id : string, // the device name\n                             index : integer, // the device index\n                             options : [ // array with options\n                                { // the option object with an available resolution\n                                     colorspaces : [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                             framerates : [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                             id : string, // the name of the colorspace\n                                             index : integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                     resolution : { // the resolution object\n                                         height : integer, // the height\n                                         width : integer // the width\n                                    }\n                                },\n                                { // the option object with an available resolution\n                                     colorspaces : [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                             framerates : [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                             id : string, // the name of the colorspace\n                                             index : integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                     resolution : { // the resolution object\n                                         height : integer, // the height\n                                         width : integer // the width\n                                    }\n                                },\n                                ... // more objects\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetVideoDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id :  Logitech HD Pro Webcam C920 ,\n                             index : 1,\n                             options : [\n                                {\n                                     colorspaces : [\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  MJPG ,\n                                             index : 0\n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  RGB24 ,\n                                             index : 1\n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  I420 ,\n                                             index : 2\n                                        }\n                                    ],\n                                     resolution : {\n                                         height : 360,\n                                         width : 640\n                                    }\n                                },\n                                {\n                                     colorspaces : [\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  MJPG ,\n                                             index : 0 \n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  RGB24 ,\n                                             index : 1 \n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  I420 ,\n                                             index : 2 \n                                        }\n                                    ],\n                                     resolution : {\n                                         height : 720,\n                                         width : 1280\n                                    }\n                                }\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type :  nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetVideoDeviceConfig ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_4", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetVideoDeviceConfig ,\n                 params : [\n                    index\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_4", 
            "text": "var index = 0;\n    var message = NANO.NanoStream.GetVideoDeviceConfig(\n        index,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i   options.length; i += 1) {\n                console.log( Found options   + i +   for audio device '  + device.id +  ' with index =   + device.index);\n                var width = options[i].resolution.width;\n                var height = options[i].resolution.height;\n                console.log( Available resolution:   + width +  x  + height);\n                var colorspaces = options[i].colorspaces;\n                for (var j = 0; j   colorspaces.length; j += 1) {\n                    var name = colorspaces[j].id;\n                    var index = colorspaces[j].index;\n                    console.log( Available colorspace for resolution   + width +  x  + height +  : name =   + name +  , index =   + index);\n                    for (var k = 0; k   colorspaces[j].framerates.length; k += 1) {\n                        console.log( Available framerate for   + width +  x  + height +  ,   + name +  :   + colorspaces[j].framerates[k]);\n                    }\n                }\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getvideodevices", 
            "text": "up to summary  object  NANO.NanoStream.GetVideoDevices( function  successCallback,  function  errorCallback)", 
            "title": "GetVideoDevices"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_5", 
            "text": "An array object with all available video devices will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetVideoDevices( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_5", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetVideoDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             video : [ // array with device objects\n                                {\n                                     id : string, // the device name\n                                     index : integer // the device index\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetVideoDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             video : [\n                                {\n                                     id :  Mikrofon (HD Pro Webcam C920) ,\n                                     index : 0\n                                },\n                                {\n                                     id :  nanocosmos Live Video Capture ,\n                                     index : 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetVideoDevices ,\n                 data : {\n                     value : string // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_5", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetVideoDevices ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_5", 
            "text": "var message = NANO.NanoStream.GetVideoDevices(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var devices = message.data.value.devices.video;\n            for (var i = 0; i   devices.length; i += 1) {\n                console.log( Found video device '  + devices[i].id +  ' with index =   + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getwindows", 
            "text": "", 
            "title": "GetWindows"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#savexmlprofile", 
            "text": "up to summary  object  NANO.NanoStream.SaveXmlProfile( string  path,  function  successCallback,  function  errorCallback)", 
            "title": "SaveXmlProfile"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_6", 
            "text": "This method saves an  XML  profile to a defined path.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SaveXmlProfile( string  path,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SaveXmlProfile( string  path,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SaveXmlProfile( string  path,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_6", 
            "text": "string  path  The path to save the profile to    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SaveXmlProfile ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SaveXmlProfile ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SaveXmlProfile ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_6", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SaveXmlProfile ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_6", 
            "text": "var path =  C:\\profile.xml ;\n    var message = NANO.NanoStream.SaveXmlProfile(\n        path,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Profile saved );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setaudiovolume", 
            "text": "up to summary  object  NANO.NanoStream.SetAudioVolume( integer  volume,  function  successCallback,  function  errorCallback)", 
            "title": "SetAudioVolume"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_7", 
            "text": "This method sets the audio volume in a range between 0 and 100.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetAudioVolume( integer  volume,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetAudioVolume( integer  volume,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetAudioVolume( integer  volume,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_7", 
            "text": "integer  volume  The volume to set in a range between 0 and 100    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetAudioVolume ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetAudioVolume ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetAudioVolume ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_7", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetAudioVolume ,\n                 params : [\n                    integer\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_7", 
            "text": "var volume = 50;\n    var message = NANO.NanoStream.SetAudioVolume(\n        volume,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Volume set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setconfigs", 
            "text": "up to summary  object  NANO.NanoStream.SetConfigs( object   nanoConfigObject ,  function  successCallback,  function  errorCallback)", 
            "title": "SetConfigs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_8", 
            "text": "This method sets multiple key value pairs for advanced configuration.    NOTE: see possible advanced configurations  here    NOTE: it s necesary to use the  NANO.Config  class to generate the needed object  nanoConfigObject    The error callback parameters is optional. If no callback should be used, pass  null   e.g.  object  NANO.NanoStream.SetConfigs( object   nanoConfigObject ,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_8", 
            "text": "object   nanoConfigObject  The object with one or multiple key value pairs  NOTE: see the description to the usage of this object  here    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetConfigs ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetConfigs ,\n                 data : {\n                     value :  noreturnvalue             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetConfigs ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_8", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetConfigs ,\n                 params : [ object ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#examples", 
            "text": "low latency configuration       var config = new NANO.Config();\n    config.AddConfig( H264Profile ,  Baseline ); // Baseline Profile supported by most devices and players\n    config.AddConfig( H264IFrameDistance ,  50 ); // Moderate GOP length\n    config.AddConfig( H264PFrameDistance ,  1 ); // No B-frames \n    //(optional)\n    //config.AddConfig( H264VlcMode ,  1 ); // CAVLC entropy coding mode\n    //config.AddConfig( RateControl ,  1 ); // Strict constant bitrate\n    var nanoConfigObject = config.GetConfig(); // returns the well json parsed object we need to pass\n    var message = NANO.NanoStream.SetConfigs(\n        nanoConfigObject,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Configuration set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Examples"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setinputs", 
            "text": "", 
            "title": "SetInputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setoutputs", 
            "text": "", 
            "title": "SetOutputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setpictureinpicturesize", 
            "text": "up to summary  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  function  successCallback,  function  errorCallback)", 
            "title": "SetPictureInPictureSize"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_9", 
            "text": "This method sets the picture in picture size in a range between 0 and 3.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_9", 
            "text": "integer  size  The picture in picture size to set in a range between 0 and 3    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetPictureInPictureSize ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetPictureInPictureSize ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetPictureInPictureSize ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_9", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetPictureInPictureSize ,\n                 params : [\n                    integer\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_8", 
            "text": "var size = 2;\n    var message = NANO.NanoStream.SetPictureInPictureSize(\n        size,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Picture in picture size set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setvideomixingmode", 
            "text": "up to summary  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  function  successCallback,  function  errorCallback)", 
            "title": "SetVideoMixingMode"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_10", 
            "text": "This method sets the video mix mode.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_10", 
            "text": "integer  mode  The video mix mode to set    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetVideoMixingMode ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetVideoMixingMode ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetVideoMixingMode ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_10", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetVideoMixingMode ,\n                 params : [\n                    integer\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_9", 
            "text": "var mode = 0;\n    var message = NANO.NanoStream.SetVideoMixingMode(\n        mode,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Video mix mode set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setxmlprofile", 
            "text": "up to summary  object  NANO.NanoStream.SetXmlProfile( string  path,  function  successCallback,  function  errorCallback)", 
            "title": "SetXmlProfile"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_11", 
            "text": "This method loads an  XML  profile from a defined path.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetXmlProfile( string  path,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetXmlProfile( string  path,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetXmlProfile( string  path,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_11", 
            "text": "string  path  The path to load the profile from    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetXmlProfile ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetXmlProfile ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetXmlProfile ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_11", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetXmlProfile ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_10", 
            "text": "var path =  C:\\profile.xml ;\n    var message = NANO.NanoStream.SetXmlProfile(\n        path,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Profile loaded );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#startbroadcast", 
            "text": "up to summary  object  NANO.NanoStream.StartBroadcast( function  successCallback,  function  errorCallback)", 
            "title": "StartBroadcast"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_12", 
            "text": "This method will start the broadcast and/or recording.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StartBroadcast( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StartBroadcast( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StartBroadcast( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_12", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StartBroadcast ,\n                 data : {\n                     value : {\n                         framerate : float\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StartBroadcast ,\n                 data : {\n                     value : {\n                         framerate : 30\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StartBroadcast ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_12", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StartBroadcast ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_11", 
            "text": "var message = NANO.NanoStream.StartBroadcast(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Broadcast started with framerate   + message.data.value.framerate);\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#startpreview", 
            "text": "up to summary  object  NANO.NanoStream.StartPreview( function  successCallback,  function  errorCallback)", 
            "title": "StartPreview"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_13", 
            "text": "This method will start the preview.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StartPreview( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StartPreview( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StartPreview( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_13", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StartPreview ,\n                 data : {\n                     value : {\n                         framerate : float\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StartPreview ,\n                 data : {\n                     value : {\n                         framerate : 30\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StartPreview ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_13", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StartPreview ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_12", 
            "text": "var message = NANO.NanoStream.StartPreview(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Preview started with framerate   + message.data.value.framerate);\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#stopbroadcast", 
            "text": "up to summary  object  NANO.NanoStream.StopBroadcast( function  successCallback,  function  errorCallback)", 
            "title": "StopBroadcast"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_14", 
            "text": "This method will start the preview.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StopBroadcast( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StopBroadcast( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StopBroadcast( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_14", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StopBroadcast ,\n                 data : {\n                     value : string           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StopBroadcast ,\n                 data : {\n                     value :  noreturnvalue             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StopBroadcast ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_14", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StopBroadcast ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_13", 
            "text": "var message = NANO.NanoStream.StopBroadcast(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Broadcast stopped );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#stoppreview", 
            "text": "up to summary  object  NANO.NanoStream.StopPreview( function  successCallback,  function  errorCallback)", 
            "title": "StopPreview"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_15", 
            "text": "This method will start the preview.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StopPreview( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StopPreview( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StopPreview( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_15", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StopPreview ,\n                 data : {\n                     value : string            \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StopPreview ,\n                 data : {\n                     value :  noreturnvalue \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StopPreview ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_15", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StopPreview ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_14", 
            "text": "var message = NANO.NanoStream.StopPreview(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Preview stopped );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#init", 
            "text": "up to summary  object  NANO.NanoStream.Init( string  elementId,  string  license,  function  successCallback,  function  errorCallback)", 
            "title": "Init"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_16", 
            "text": "This method embeds the plugin into an container element (div) and initilize the plugin.  Call this method after  NANO.NanoStream.DetectBrowser()  and before any other API call.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_16", 
            "text": "string  elementId  The id of the div element where to embed the plugin into    string  license  The license string    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  Init ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  Init ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  Init ,\n                 data : {\n                     value : {\n                         code : integer, // the error code\n                         error : string // the error message\n                    }\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_16", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  Init ,\n                 params : [\n                    string,\n                    string\n                ]\n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_with_all_possible_errors", 
            "text": "var elementId =  video-container ; // an existing div element with this id\n    var license =  nlic::... ; // an valid nanostream license string\n    var message = NANO.NanoStream.Init(\n        elementId,\n        license,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( NanoStream plugin successfully embedded and ready! );\n        },\n        function error(message) {\n            if (message.type ===  nanoextensioncheck ) { // only chrome\n                if (message.data.value.code === 0) { // extension not installed or unavailable\n                    // DO STUFF\n                    var result = confirm( You using chrome browser, but don't have installed your extension!\\r\\nDo you want to install it now? );\n                    if (result) {\n                        NANO.NanoStream.InstallExtensionInline();\n                    }\n                } else if (message.data.value.code === 1) { // extension installation finished (not really an error, but passed within the handler)\n                    // DO STUFF\n                    console.log( Extension now installed );\n                }\n            } else if (message.type ===  nanoversioncheck ) { // only chrome\n                if (message.data.value.code === 0) { // native version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 1) { // extension version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 2) { // lib version outdated\n                    alert(message.data.value.error);\n                }\n            } else {\n                if (message.data.value.code === 100) { // error initialization\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 101) { // error setting license\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 102) { // error connecting to the native plugin (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 103) { // error connecting to the extension (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 104) { // error passing parameters / wrong parameters\n                    alert(message.data.value.error);\n                } else { // error embedding plugin\n                    if (message.data.value.code === 0) { // plugin found but no version\n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -1) { // general no plugins available (unsupported browser) \n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -2) { // plugin not found / not installed / not activated\n                        alert(message.data.value.error);\n                    } else {\n                        alert( Unknown Error Init: code =   + message.data.value.code +  , error = '  + message.data.value.error +  ' );\n                    }\n                }\n            }\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example (with all possible errors)"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#helper_methods_sync", 
            "text": "", 
            "title": "Helper Methods (sync)"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#detectbrowser", 
            "text": "", 
            "title": "DetectBrowser"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#fireevent", 
            "text": "", 
            "title": "FireEvent"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#installextensioninline", 
            "text": "", 
            "title": "InstallExtensionInline"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#installextensionwebstore", 
            "text": "", 
            "title": "InstallExtensionWebstore"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#events", 
            "text": "", 
            "title": "Events"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onerror", 
            "text": "", 
            "title": "onError"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onnotifyevent", 
            "text": "", 
            "title": "onNotifyEvent"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onstopevent", 
            "text": "", 
            "title": "onStopEvent"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onsupported", 
            "text": "", 
            "title": "onSupported"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onunsupported", 
            "text": "", 
            "title": "onUnsupported"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nano_config", 
            "text": "", 
            "title": "NANO Config"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/", 
            "text": "This is Markdown.\nvergleiche\nhttp://www.nanocosmos.de/v4/documentation/nanostream_sdk_for_ios_-_developer_documentation\n\n\nnanoStream SDK for iOS - Developer Manual\n\n\nPurpose\n\n\nThis documentation is about the nanoStream Live Video Streaming SDK for iOS and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.\n\n\nRequirements\n\n\n\n\nApple Mac with MacOS 10.9 with XCode 6 or higher\n\n\nApple iPhone with iOS 7 or later (min. iOS 8.1 recommended)\n\n\n\n\nGetting Started\n\n\nPreparation\n\n\nAdd the library \nlibnanostreamAVC.a\n as dependency (Link Binary With Libraries) to your project.\nFurther required dependencies:\n\n\n\n\nlibc++.dylib\n\n\nlibstdc++.dylib\n\n\nAVFoundation.framework\n\n\nAccelerate.framework\n\n\nCoreGraphics.framework\n\n\nCoreMedia.framework\n\n\nCoreVideo.framework\n\n\nFoundation.framework\n\n\nSystemConfiguration.framework\n\n\nVideoToolbox.framework (link as Optional, not as Required)\n\n\nAudioToolbox.framework\n\n\n\n\nInclude the header \nlibnanostreamAVC.h\n in your source code.\n\n\nCheck library version\n\n\nint version = [nanostreamAVC getVersion];\nif(version!=NANOSTREAM_AVC_VERSION)\n{\n    // Handle header and library version mismatch\n}\n\n\n\n\n\nInitialize the library\n\n\nImplement the interface \nnanostreamEventListener\n in your class:\n\n\n@interface SampleLiveViewController : UIViewController \nnanostreamEventListener\n\n...\n@property (nonatomic, strong) nanostreamAVC *nAVC;\n@property (nonatomic, strong) IBOutlet UIView *previewView;\n...\n@end\n\n@implementation SampleLiveViewController\n...\n-(void)nanostreamEventHandlerWithType:(nanostreamEvent)type andLevel:(int)level andDescription:(NSString *)description\n{\n    switch (type) {\n        case StreamStarted:\n            break;\n        case StreamStopped:\n            break;\n        case StreamError:\n            NSLog(@\nnanostreamEventHandlerWithType: StreamError: %@\n, description);\n            break;\n        case StreamErrorConnect:\n            NSLog(@\nnanostreamEventHandlerWithType: StreamErrorConnect: %@\n, description);\n            break;\n        case StreamConnectionStatus:\n            NSLog(@\nnanostreamEventHandlerWithType: RtmpConnectionStatus %@\n, description);\n            break;\n        case GeneralError:\n            break;\n        default:\n            break;\n    }\n}\n...\n@end\n\n\n\n\nConfigure the settings object for the library:\n\n\nnanostreamAVCSettings *nAVCSettings = [[nanostreamAVCSettings alloc] init];\n\n// set the rtmp url, you want to stream to\n[nAVCSettings setUrl: @\nrtmp://localhost/live\n];\n[nAVCSettings setStreamId: @\nmyStream\n];\n\n// set the video settings\n[nAVCSettings setVideoResolution: Resolution640x480];\n[nAVCSettings setVideoBitrate: 512];\n[nAVCSettings setKeyFramerate: 60];\n[nAVCSettings setOrientation: AVCaptureVideoOrientationLandscapeRight];\n[nAVCSettings setCropMode: NoCrop];\n[nAVCSettings setFramerate: 30];\n[nAVCSettings setH264Level: Baseline30];\n\n// set the audio settings\n[nAVCSettings setInitialVolume: 1.0];\n[nAVCSettings setAudioMonoStereo: Stereo];\n[nAVCSettings setAudioSamplerate: 44100.0f];\n\n\n\n\nThen the library itself can be initialized:\n\n\n// nAVC and previewView are properties of the controller class in this example\nself.nAVC = [[nanostreamAVC alloc] initWithSettings: nAVCSettings\n                                          uiPreview: self.previewView\n                                      errorListener: self];\n\n// set the license key (required for streaming)\n[self.nanostream setLicense: @\nnlic:1.2:LiveEnc:1.1:LvApp=1.....288\n];\n\n\n\n\nStart a stream\n\n\n// Start broadcast asynchronously with completion handler\n[self.nAVC start:^(bool success)\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        if (success)\n        {\n            // Handle succesful stream start\n            ...\n        }\n        else\n        {\n            // Handle failure\n            ...\n        }\n    }\n}\n\n\n\n\nStop a running stream\n\n\nIf the parameter \nblocking\n of the stop method is set to YES, all the remaining data (to this moment) will be sent before stopping the stream.\nIf set to NO, the stream will stop immediately, discarding the remaining data.\n\n\n// Stop broadcast asynchronously with completion handler\n[self.nAVC stop:YES withCompletion:^\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        // Handle stream stop\n    }\n}\n\n\n\n\nAdvanced Settings/Usage\n\n\nOrientation\n\n\nThe orientation of the stream can be set to portrait or landscape with the property \norientation\n of the settings object.\n\n\nAs of version 4.4.0.6 the orientation can also be changed after the initialization with the property \norientation\n of the nanostreamAVC object itself.\n\n\nImportant:\n The orientation change will only affect the stream, but not the preview. The orientation for the preview has to be managed on the application level. This can be achieved by using e.g. \nCGAffineTransformMakeRotation\n (https://developer.apple.com/library/mac/documentation/GraphicsImaging/Reference/CGAffineTransform/).\n\n\nStream Type\n\n\nThe SDK supports different streaming modes:\n\n\n\n\nVideo and Audio\n\n\nVideo only\n\n\nAudio only\n\n\n\n\nYou can configure the mode with the property \nstreamType\n of the settings object.\n\n\nServer Authentication\n\n\nIn case authentication is required, the credentials can be set with the method\n\n\n-(void) setAuthentication: (NSString*) user withPassword: (NSString*) password;\n\n\n\n\nThe method has to be invoked before a stream is started.\n\n\nFor example:\n\n\n// set up nAVC object\n...\n[nAVC setAuthentication: @\nMyUser\n withPassword: @\nMyPassword\n];\n...\n// start the stream\n\n\n\n\nCropping\n\n\nThe stream can be transformed to a different format than the input from the camera.\n\n\nThe following example shows how to crop the format to 16:9.\n\n\n[nAVCSettings setCropMode: CropTo16By9];\n\n\n\n\nLocal Recording\n\n\nIt is possible to make a local copy of the stream, on the iOS device.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string \nMP4=2\n.\n\n\nNSString *homeDirectory = [NSHomeDirectory() stringByAppendingPathComponent:@\nDocuments\n];\nNSDateFormatter *dateFormatter=[[NSDateFormatter alloc] init];\n[dateFormatter setDateFormat:@\nyyyy-MM-dd_HH-mm-ss\n];\nNSString *locStr = [homeDirectory stringByAppendingPathComponent: [[dateFormatter stringFromDate:[NSDate date]] stringByAppendingString: @\n.mp4\n]];\n\n[nAVCSettings setLocalRecordingMode:AVCRecordingModeDoubleAtLeastOneMbit];\n[nAVCSettings setLocalRecordingPath:locStr];\n\n\n\n\nThere are three modes available:\n\n\n\n\nAVCRecordingModeStartBitrate: uses the video bitrate set with nanostreamAVCSettings\n\n\nAVCRecordingModeDoubleAtLeastOneMbit: uses double the video bitrate, but at least 1Mbps\n\n\nAVCRecordingMode720p2Mbit: independent of the set video bitrate, always uses 2Mbps and a resolution of 1280x720\n\n\n\n\nThe bitrate for the recording remains constant during a stream. The adaptive bitrate mechanism only influences the bitrate for the stream, but not the bitrate for the recording.\n\n\nThe bitrate for the recording also depends on the video material. If there is a lot of movement in the video the bitrate will be higher than for recordings with little to no movement.\n\n\nAdaptive Bitrate\n\n\nBy using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth.\nThere are two modes available:\n\n\n\n\nAdaptiveBitrateControlModeQualityDegrade: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.\n\n\nAdaptiveBitrateControlModeFrameDrop: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.\n\n\n\n\nMake sure to set the ABC settings before a stream is started.\n\n\n[self.nAVC setAdaptiveBitrateControlMode: AdaptiveBitrateControlModeQualityDegrade];\n\nAdaptiveBitrateControlSettings abr;\nabr.minimumBitrate = 100000;  // 100kb\nabr.minimumFramerate = 15;\nabr.maxPercentBitrateChange = 50;  // if the bitrate drops to less than 50% of the previous bitrate, all buffered data will be discarded\n\n[self.nAVC setAdaptiveBitrateControlSettings: abr];\n\n\n\n\nPossible properties:\n\n\n\n\n\n\n\n\nproperty\n\n\ndefault values\n\n\nrange of values\n\n\noptional\n\n\n\n\n\n\n\n\n\n\nminimumBitrate\n\n\n5000 (50 kb)\n\n\n50000 - 10 000 000\n\n\nYES\n\n\n\n\n\n\nminimumFramerate\n\n\n15 (fps)\n\n\n5 - 60\n\n\nYES\n\n\n\n\n\n\nmaxPercentBitrateChange\n\n\n50 (%)\n\n\n0 - 100\n\n\nYES\n\n\n\n\n\n\n\n\n_\n\n\nFor more information look here http://www.nanocosmos.de/v4/documentation/live_video_encoder_-_adaptive_bitrate#abc_modes\n\n\nMeasuring the available bandwidth\n\n\nFor measuring the available bandwidth you can use the method \nrunBandwidthCheck\n. After the check finished, the result can be used to set the bitrate for the nanostreamAVC object.\n\n\nThe check measures the bandwidth by running a test stream to the server.\n\n\nNSXBandwidthCheckSettings *bwSettings = [[NSXBandwidthCheckSettings alloc] init];\n// the URL settings are identical to the URL settings for the nanostreamAVCSettings\n// for testing the bandwidth it is advised to use the same server you want to stream to\n// you might want to use a stream id different from the stream id for the actual stream, to distinguish between a bandwidth check and a real stream\nbwSettings.url = @\nrtmp://localhost/live\n;\nbwSettings.streamId = @\nbwcheck\n;\n// the maxium bitrate that should be tested - if this value is lower than the actual bandwidth, the result will be similar to the maximum bitrate\nbwSettings.maxBitrate = 5000000;  // 5Mb\n\n[self.nAVC runBandwidthCheck: bwSettings withCompletionBlock:^(NSXBandwidthCheckResult* measuredBandwidth){\n    NSLog(@\nmeasuredBandwidth: avg=%i, median=%i, min=%i, max=%i, runTimeMs=%i\n, (int)measuredBandwidth.avgBitrate, (int)measuredBandwidth.medianBitrate, (int)measuredBandwidth.minBitrate, (int)measuredBandwidth.maxBitrate, (int)measuredBandwidth.runTimeMs);\n}];\n\n\n\n\nThe default run time is 10 seconds. The run time can be changed with the property \nrunTime\n.\nIf the bandwidth check should be stopped before it finished on itself, the method \nstopBandwidthCheck\n can be used. This will force the bandwidth check to stop and return the result based on the collected information up to this point.\n\n\n[self.nAVC stopBandwidthCheck];    // stop bw check if still running\n\n\n\n\nThe result of the bandwidth check can be used as bitrate setting for library object. At the moment it is not possible to change the video bitrate after the initialization of the library object, thus the object need to be re-initialized. (This will change in future releases.)\n\n\nSnaphot from the current stream\n\n\nTo get a snaphot (image) of the current preview/stream, the method \ngrabStillImageWithCompletionBlock\n can be used.\n\n\n[self.nAVC grabStillImageWithCompletionBlock:^(UIImage *image, NSError *error) {\n    // do something with the image\n}];\n\n\n\n\nOverlay/Watermark\n\n\nIt is possible to use an overlay (image, text, or both) for a stream. Notice that the CPU usage will be increased slightly when an overlay is used.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string \nOVL=1\n.\n\n\nThe easiest way to use an overlay is to use the class \nAVCFullImageOverlay\n:\n\n\nUIImage *overlayImg = [UIImage imageNamed:@\nbutton\n];  // uses an image from the bundle resources, named \nbutton\n\n\nUIGraphicsBeginImageContextWithOptions(CGSizeMake(640, 480), NO, 1.0);  // assuming the video resolution is set to \nResolution640x480\n\n[overlayImg drawInRect:CGRectMake(200, 200, 240, 80) blendMode:kCGBlendModeNormal alpha:0.5];\nUIFont *font = [UIFont boldSystemFontOfSize:20];\n[[UIColor whiteColor] set];\nNSString *text = @\nWatermark\n;\n[text drawInRect:CGRectMake(200, 300, 100, 50) withFont:font];\nUIImage *finalOverlayImage = UIGraphicsGetImageFromCurrentImageContext();\nUIGraphicsEndImageContext();\n\n[self.nAVC setOverlay: [[AVCFullImageOverlay alloc] initWithImage: finalOverlayImage]];\n\n\n\n\nNotice that the final output resolution can be different, if an option like cropping is used.\nIn this case it is better to implement your own overlay class, which is shown in the following example:\n\n\n@interface NSXWatermark : NSObject \nAVCOverlay\n\n\n@property (assign) AVCOverlayRawBuffer buffer;\n\n@end\n\n@implementation NSXWatermark\n\n@synthesize imageSize;\n@synthesize overlayBoundingRect;\n\n-(AVCOverlayRawBuffer)overlayImageWithStreamTime:(NSTimeInterval)time\n{\n    if (self.buffer.buffer == NULL) {\n        UIImage *image = [NSXWatermark generateWatermarkWithSize:self.imageSize inBoundingRect:self.overlayBoundingRect];\n        self.buffer = [NSXWatermark makeBufferFromUIImage:image];\n    }\n\n    return self.buffer;\n}\n\n+(UIImage *)generateWatermarkWithSize:(CGSize)size inBoundingRect:(CGRect)boundingRect\n{\n    UIImage *watermarkImage = ...  // use your desired UIImage here\n    CGFloat padding = 10.0;\n    CGSize overlaySize = watermarkImage.size;\n\n    CGFloat height = size.height / 3;\n    if (overlaySize.height \n height) {\n        overlaySize.width = height;\n        overlaySize.height = height;\n    }\n\n    CGFloat boundingMaxX = boundingRect.origin.x + boundingRect.size.width;\n    CGFloat boundingMaxY = boundingRect.origin.y + boundingRect.size.height;\n\n    CGRect overlayRect = CGRectMake(boundingMaxX - overlaySize.width, boundingMaxY - overlaySize.height, overlaySize.width, overlaySize.height);\n\n    //  CGRect overlayRect = CGRectMake(size.width - overlaySize.width, size.height - overlaySize.height, overlaySize.width, overlaySize.height);\n    CGRect realRect =  AVMakeRectWithAspectRatioInsideRect(watermarkImage.size, overlayRect);\n\n    realRect.origin.y -= padding;\n    realRect.origin.x -= padding;\n\n    UIGraphicsBeginImageContext(size);\n    [watermarkImage drawInRect:realRect];\n\n    UIImage *overlayImage = UIGraphicsGetImageFromCurrentImageContext();\n\n    UIGraphicsEndImageContext();\n\n    return overlayImage;\n}\n\n+(AVCOverlayRawBuffer)makeBufferFromUIImage:(UIImage *)image\n{\n    CGImageRef rawPic = [image CGImage];\n\n    CGDataProviderRef inProvider = CGImageGetDataProvider(rawPic);\n    CFDataRef inBitmapData = CGDataProviderCopyData(inProvider);\n\n    size_t inBitmapDataBytesPerRow = CGImageGetBytesPerRow(rawPic);\n\n    UInt8 *buffer = (UInt8*)CFDataGetBytePtr(inBitmapData);\n\n    AVCOverlayRawBuffer rawBuf;\n    rawBuf.buffer = buffer;\n    rawBuf.bytesPerRow = (int)inBitmapDataBytesPerRow;\n    rawBuf.bufferType = AVCOverlayBufferTypeBGRA;\n    return rawBuf;\n}\n@end\n\n\n\n\ninitWithSession\n\n\nInstead of letting the SDK manage the video and audio input, you can also do that yourself. This is helpful to supply video and audio samples which are not coming from the standard input devices. Or to modify video and/or audio samples before they are used for the stream.\n\n\nThe SDK provides a separate init method \ninitWithSession\n.\n\n\nAn example for a custom capture session, which supplies CVPixelBufferRef\ns to the SDK:\n\n\n@interface CustomCaptureSession : AVCaptureSession\n...\n@end\n\n@implementation CustomCaptureSession\n\n-(void) addOutput:(AVCaptureOutput )output\n{\n    if ([output isKindOfClass:[AVCaptureVideoDataOutput class]]) {\n        self.myVideoOutput = (AVCaptureVideoDataOutput)output;\n    }else if([output isKindOfClass:[AVCaptureAudioDataOutput class]])\n    {\n        //self.myAudioOutput = (AVCaptureAudioDataOutput*)output; // if you want to use a custom audio capture device\n        [super addOutput: output]; // uses the standard microphone of the iOS device\n    }\n}\n\n-(void) addInput:(AVCaptureInput *)input\n{\n    [super addInput:input]; // this is required, because nanostreamAVC checks the available inputs\n}\n\n-(void) startRunning\n{\n    [super startRunning];\n}\n\n// this method has to be called periodically - e.g. with CADisplayLink\n-(void) supplyCMSampleBufferRef\n{\n    CVPixelBufferRef buffer = [self getCVPixelBufferRef]; // get the CVPixelBufferRef from somewhere\n\n    CMSampleBufferRef newSampleBuffer = NULL;\n    CMSampleTimingInfo timingInfo = kCMTimingInfoInvalid;\n    timingInfo.duration = CMTimeMake(33, 1000);    // assuming 30fps, change if otherwise\n    timingInfo.decodeTimeStamp = CMTimeMake(ts, 1000);    // timestamp information required\n    timingInfo.presentationTimeStamp = timingInfo.decodeTimeStamp;\n\n    CMVideoFormatDescriptionRef videoInfo = NULL;\n    CMVideoFormatDescriptionCreateForImageBuffer(NULL, buffer, \nvideoInfo);\n\n    CMSampleBufferCreateForImageBuffer(kCFAllocatorDefault,buffer,true,NULL,NULL,videoInfo,\ntimingInfo,\nnewSampleBuffer);\n\n    // the following line submits the new CMSampleBufferRef to the nanostreamAVC lib\n    [self.myVideoOutput.sampleBufferDelegate captureOutput:self.myVideoOutput didOutputSampleBuffer:newSampleBuffer fromConnection:nil];\n\n    CFRelease(videoInfo);\n    CFRelease(buffer);\n    CFRelease(newSampleBuffer);\n\n}\n\n@end\n\n// you need to use initWithSession for nanostreamAVC to use your custom session\n...\nsession = [[CustomCaptureSession alloc] init];\n\n// Add input nodes\nif(videoInput != nil)\n{\n    [session addInput: videoInput];\n}\n\nif(audioInput != nil)\n{\n    [session addInput: audioInput]; // if the stream is video only, don't add an audioInput\n}\n\n[session startRunning];\n\n...\nself.stream = [[nanostreamAVC alloc] initWithSession: session settings: nAVCSettings errorListener: self];\n...\n\n\n\n\nPossible Issues\n\n\nGeneral\n\n\nFor older versions of the sdk, without support for arm64, architecture in Xcode has to be set to armv7 and/or armv7s. This works also for newer iOS-Devcies like iPhone 5s.\nThis is not required for newer sdk versions, which also support arm64.\n\n\nCompiler/Linker\n\n\nlibstdc++\n\n\nIf there are linker errors with \nstd::\n: \nsymbol(s) not found for architecture\n, make sure that you added the libraries \nlibstdc++.dylib\n and \nlibc++.dylib\n to your project.\n\n\nDue to a bug in Xcode, depending on the selected Base SDK and deployment target, there might be still linker errors regarding \nstd\n. In this case you need to add a specific version of the libstdc++ to your project, e.g.: libstdc++-6.0.9.dylib instead of libstdc++.dylib\n\n\nUndefined Symbols for Parrot \n DJI\n\n\nThe following part is only relevant for SDK versions from 3.3.x to 4.1.x.\n\nAs of version 4.2.x the drone dependencies are removed from the standard SDK package.\n\n\nIt might be possible that there are linker errors for the classes\n\n\n\n\nParrotBebopCaptureSession or\n\n\nDJIPhantom2CaptureSession\n\n\n\n\nGenerally, if the Parrot \n DJI extensions are not used, the symbols should be stripped automatically by Xcode and you do not need to link the frameworks.\nHowever this is not the case when the linker flag \n-ObjC\n is used in the app project. This causes the linker to load all symbols included in all linked object files (including the Parrot \n DJI symbols). This prevents the automatic stripping.\n\n\nTo use our library without Parrot \n DJI, either remove the \n-ObjC\n linker flag from the project or replace the \n-ObjC\n linker flag with the \n-force_load\n flag for each library that you want to use. Do not use \n-force_load\n with libnanostreamAVC.a.\nFor examples see http://stackoverflow.com/questions/11254269/using-the-force-load-linker-flag-with-restkit-ios\n\n\nBreakpoints\n\n\nIf you debug your application, it is possible that breakpoints are being hit due to internal exceptions. Exceptions on the SDK level are handled in the SDK and do not affect the workflow of your application.\n\n\nYou can prevent the breakpoint from pausing the workflow of your application, if you use the right settings for the breakpoint.\nThe default setting is most likely that every exception causes a break.\nTo change that, use the settings from the following screenshot:\n\n\n\n\nThis way only Objective-C exceptions will be catched and C++ exceptions will be ignored.\n\n\nCrashes\n\n\nCALayerGetDelegate / CALayerGetSuperlayer / Other CALayer\n\n\nIf there are crashes occurring in your app that include above symbols in the stack trace and are otherwise not obvious, check to see if you added a subviews to the preview view. The UIView instance that is passed to\n\n\n[RtmpSourceCaptureSession initWithPreview:andStatusListener:andLogLevel:]\n\n\n\n\nand\n\n\n[nanostreamAVC initWithSettings:uiPreview:errorListener:]\n\n\n\n\ncannot contain any subviews (UIButtons or otherwise).\n\n\nLogging Information\n\n\nIf you encounter a problem with the nanostreamAVC library and you want to report the problem, log files will help us to comprehend the problem.\n\n\nPlease use the following steps to create the log files:\n\n\n\n\nenable logging for the library with the method \nSetLogLevel\n, use LogLevelVerbose:\n\n\n\n\nobjc\n  [self.nAVC SetLogLevel: LogLevelVerbose];  // set the log level before the method \"start\" is invoked\n\n\n\n\ntry to reproduce the problem\n\n\ndownload the app container (for your app) from the iOS device with Xcode, as explained here: https://developer.apple.com/library/ios/recipes/xcode_help-devices_organizer/articles/manage_containers.html\n\n\nin Finder right click on the downloaded container and select \nShow Package Contents\n\n\nsend us the logfiles located (in the container) in the folder \n/AppData/Library/Caches/Logs/\n\n\n\n\nCrash Logs\n\n\nIf you encounter a crash, please send us the crash log as explained in the following steps:\n\n\n\n\nPlug in the device and open Xcode\n\n\nChoose Window -\n Devices from the menu bar\n\n\nUnder the DEVICES section in the left column, choose the device\n\n\nTo see the device console, click the up-triangle at the bottom left of the right hand panel\n\n\nClick the down arrow on the bottom right to save the console as a file\n\n\nTo see crash logs, select the View Device Logs button under the Device Information section on the right hand panel\n\n\nFind your app in the Process column and select the Crash log to see the contents.\n\n\nTo save a crash log, right click the entry on the left column and choose \nExport Log\n\n\n\n\n(Taken from https://developer.apple.com/library/ios/qa/qa1747/_index.html)", 
            "title": "iOS api"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#nanostream_sdk_for_ios_-_developer_manual", 
            "text": "", 
            "title": "nanoStream SDK for iOS - Developer Manual"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#purpose", 
            "text": "This documentation is about the nanoStream Live Video Streaming SDK for iOS and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.", 
            "title": "Purpose"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#requirements", 
            "text": "Apple Mac with MacOS 10.9 with XCode 6 or higher  Apple iPhone with iOS 7 or later (min. iOS 8.1 recommended)", 
            "title": "Requirements"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#getting_started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#preparation", 
            "text": "Add the library  libnanostreamAVC.a  as dependency (Link Binary With Libraries) to your project.\nFurther required dependencies:   libc++.dylib  libstdc++.dylib  AVFoundation.framework  Accelerate.framework  CoreGraphics.framework  CoreMedia.framework  CoreVideo.framework  Foundation.framework  SystemConfiguration.framework  VideoToolbox.framework (link as Optional, not as Required)  AudioToolbox.framework   Include the header  libnanostreamAVC.h  in your source code.", 
            "title": "Preparation"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#check_library_version", 
            "text": "int version = [nanostreamAVC getVersion];\nif(version!=NANOSTREAM_AVC_VERSION)\n{\n    // Handle header and library version mismatch\n}", 
            "title": "Check library version"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#initialize_the_library", 
            "text": "Implement the interface  nanostreamEventListener  in your class:  @interface SampleLiveViewController : UIViewController  nanostreamEventListener \n...\n@property (nonatomic, strong) nanostreamAVC *nAVC;\n@property (nonatomic, strong) IBOutlet UIView *previewView;\n...\n@end\n\n@implementation SampleLiveViewController\n...\n-(void)nanostreamEventHandlerWithType:(nanostreamEvent)type andLevel:(int)level andDescription:(NSString *)description\n{\n    switch (type) {\n        case StreamStarted:\n            break;\n        case StreamStopped:\n            break;\n        case StreamError:\n            NSLog(@ nanostreamEventHandlerWithType: StreamError: %@ , description);\n            break;\n        case StreamErrorConnect:\n            NSLog(@ nanostreamEventHandlerWithType: StreamErrorConnect: %@ , description);\n            break;\n        case StreamConnectionStatus:\n            NSLog(@ nanostreamEventHandlerWithType: RtmpConnectionStatus %@ , description);\n            break;\n        case GeneralError:\n            break;\n        default:\n            break;\n    }\n}\n...\n@end  Configure the settings object for the library:  nanostreamAVCSettings *nAVCSettings = [[nanostreamAVCSettings alloc] init];\n\n// set the rtmp url, you want to stream to\n[nAVCSettings setUrl: @ rtmp://localhost/live ];\n[nAVCSettings setStreamId: @ myStream ];\n\n// set the video settings\n[nAVCSettings setVideoResolution: Resolution640x480];\n[nAVCSettings setVideoBitrate: 512];\n[nAVCSettings setKeyFramerate: 60];\n[nAVCSettings setOrientation: AVCaptureVideoOrientationLandscapeRight];\n[nAVCSettings setCropMode: NoCrop];\n[nAVCSettings setFramerate: 30];\n[nAVCSettings setH264Level: Baseline30];\n\n// set the audio settings\n[nAVCSettings setInitialVolume: 1.0];\n[nAVCSettings setAudioMonoStereo: Stereo];\n[nAVCSettings setAudioSamplerate: 44100.0f];  Then the library itself can be initialized:  // nAVC and previewView are properties of the controller class in this example\nself.nAVC = [[nanostreamAVC alloc] initWithSettings: nAVCSettings\n                                          uiPreview: self.previewView\n                                      errorListener: self];\n\n// set the license key (required for streaming)\n[self.nanostream setLicense: @ nlic:1.2:LiveEnc:1.1:LvApp=1.....288 ];", 
            "title": "Initialize the library"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#start_a_stream", 
            "text": "// Start broadcast asynchronously with completion handler\n[self.nAVC start:^(bool success)\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        if (success)\n        {\n            // Handle succesful stream start\n            ...\n        }\n        else\n        {\n            // Handle failure\n            ...\n        }\n    }\n}", 
            "title": "Start a stream"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#stop_a_running_stream", 
            "text": "If the parameter  blocking  of the stop method is set to YES, all the remaining data (to this moment) will be sent before stopping the stream.\nIf set to NO, the stream will stop immediately, discarding the remaining data.  // Stop broadcast asynchronously with completion handler\n[self.nAVC stop:YES withCompletion:^\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        // Handle stream stop\n    }\n}", 
            "title": "Stop a running stream"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#advanced_settingsusage", 
            "text": "", 
            "title": "Advanced Settings/Usage"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#orientation", 
            "text": "The orientation of the stream can be set to portrait or landscape with the property  orientation  of the settings object.  As of version 4.4.0.6 the orientation can also be changed after the initialization with the property  orientation  of the nanostreamAVC object itself.  Important:  The orientation change will only affect the stream, but not the preview. The orientation for the preview has to be managed on the application level. This can be achieved by using e.g.  CGAffineTransformMakeRotation  (https://developer.apple.com/library/mac/documentation/GraphicsImaging/Reference/CGAffineTransform/).", 
            "title": "Orientation"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#stream_type", 
            "text": "The SDK supports different streaming modes:   Video and Audio  Video only  Audio only   You can configure the mode with the property  streamType  of the settings object.", 
            "title": "Stream Type"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#server_authentication", 
            "text": "In case authentication is required, the credentials can be set with the method  -(void) setAuthentication: (NSString*) user withPassword: (NSString*) password;  The method has to be invoked before a stream is started.  For example:  // set up nAVC object\n...\n[nAVC setAuthentication: @ MyUser  withPassword: @ MyPassword ];\n...\n// start the stream", 
            "title": "Server Authentication"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#cropping", 
            "text": "The stream can be transformed to a different format than the input from the camera.  The following example shows how to crop the format to 16:9.  [nAVCSettings setCropMode: CropTo16By9];", 
            "title": "Cropping"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#local_recording", 
            "text": "It is possible to make a local copy of the stream, on the iOS device.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string  MP4=2 .  NSString *homeDirectory = [NSHomeDirectory() stringByAppendingPathComponent:@ Documents ];\nNSDateFormatter *dateFormatter=[[NSDateFormatter alloc] init];\n[dateFormatter setDateFormat:@ yyyy-MM-dd_HH-mm-ss ];\nNSString *locStr = [homeDirectory stringByAppendingPathComponent: [[dateFormatter stringFromDate:[NSDate date]] stringByAppendingString: @ .mp4 ]];\n\n[nAVCSettings setLocalRecordingMode:AVCRecordingModeDoubleAtLeastOneMbit];\n[nAVCSettings setLocalRecordingPath:locStr];  There are three modes available:   AVCRecordingModeStartBitrate: uses the video bitrate set with nanostreamAVCSettings  AVCRecordingModeDoubleAtLeastOneMbit: uses double the video bitrate, but at least 1Mbps  AVCRecordingMode720p2Mbit: independent of the set video bitrate, always uses 2Mbps and a resolution of 1280x720   The bitrate for the recording remains constant during a stream. The adaptive bitrate mechanism only influences the bitrate for the stream, but not the bitrate for the recording.  The bitrate for the recording also depends on the video material. If there is a lot of movement in the video the bitrate will be higher than for recordings with little to no movement.", 
            "title": "Local Recording"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#adaptive_bitrate", 
            "text": "By using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth.\nThere are two modes available:   AdaptiveBitrateControlModeQualityDegrade: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.  AdaptiveBitrateControlModeFrameDrop: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.   Make sure to set the ABC settings before a stream is started.  [self.nAVC setAdaptiveBitrateControlMode: AdaptiveBitrateControlModeQualityDegrade];\n\nAdaptiveBitrateControlSettings abr;\nabr.minimumBitrate = 100000;  // 100kb\nabr.minimumFramerate = 15;\nabr.maxPercentBitrateChange = 50;  // if the bitrate drops to less than 50% of the previous bitrate, all buffered data will be discarded\n\n[self.nAVC setAdaptiveBitrateControlSettings: abr];  Possible properties:     property  default values  range of values  optional      minimumBitrate  5000 (50 kb)  50000 - 10 000 000  YES    minimumFramerate  15 (fps)  5 - 60  YES    maxPercentBitrateChange  50 (%)  0 - 100  YES     _  For more information look here http://www.nanocosmos.de/v4/documentation/live_video_encoder_-_adaptive_bitrate#abc_modes", 
            "title": "Adaptive Bitrate"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#measuring_the_available_bandwidth", 
            "text": "For measuring the available bandwidth you can use the method  runBandwidthCheck . After the check finished, the result can be used to set the bitrate for the nanostreamAVC object.  The check measures the bandwidth by running a test stream to the server.  NSXBandwidthCheckSettings *bwSettings = [[NSXBandwidthCheckSettings alloc] init];\n// the URL settings are identical to the URL settings for the nanostreamAVCSettings\n// for testing the bandwidth it is advised to use the same server you want to stream to\n// you might want to use a stream id different from the stream id for the actual stream, to distinguish between a bandwidth check and a real stream\nbwSettings.url = @ rtmp://localhost/live ;\nbwSettings.streamId = @ bwcheck ;\n// the maxium bitrate that should be tested - if this value is lower than the actual bandwidth, the result will be similar to the maximum bitrate\nbwSettings.maxBitrate = 5000000;  // 5Mb\n\n[self.nAVC runBandwidthCheck: bwSettings withCompletionBlock:^(NSXBandwidthCheckResult* measuredBandwidth){\n    NSLog(@ measuredBandwidth: avg=%i, median=%i, min=%i, max=%i, runTimeMs=%i , (int)measuredBandwidth.avgBitrate, (int)measuredBandwidth.medianBitrate, (int)measuredBandwidth.minBitrate, (int)measuredBandwidth.maxBitrate, (int)measuredBandwidth.runTimeMs);\n}];  The default run time is 10 seconds. The run time can be changed with the property  runTime .\nIf the bandwidth check should be stopped before it finished on itself, the method  stopBandwidthCheck  can be used. This will force the bandwidth check to stop and return the result based on the collected information up to this point.  [self.nAVC stopBandwidthCheck];    // stop bw check if still running  The result of the bandwidth check can be used as bitrate setting for library object. At the moment it is not possible to change the video bitrate after the initialization of the library object, thus the object need to be re-initialized. (This will change in future releases.)", 
            "title": "Measuring the available bandwidth"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#snaphot_from_the_current_stream", 
            "text": "To get a snaphot (image) of the current preview/stream, the method  grabStillImageWithCompletionBlock  can be used.  [self.nAVC grabStillImageWithCompletionBlock:^(UIImage *image, NSError *error) {\n    // do something with the image\n}];", 
            "title": "Snaphot from the current stream"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#overlaywatermark", 
            "text": "It is possible to use an overlay (image, text, or both) for a stream. Notice that the CPU usage will be increased slightly when an overlay is used.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string  OVL=1 .  The easiest way to use an overlay is to use the class  AVCFullImageOverlay :  UIImage *overlayImg = [UIImage imageNamed:@ button ];  // uses an image from the bundle resources, named  button \n\nUIGraphicsBeginImageContextWithOptions(CGSizeMake(640, 480), NO, 1.0);  // assuming the video resolution is set to  Resolution640x480 \n[overlayImg drawInRect:CGRectMake(200, 200, 240, 80) blendMode:kCGBlendModeNormal alpha:0.5];\nUIFont *font = [UIFont boldSystemFontOfSize:20];\n[[UIColor whiteColor] set];\nNSString *text = @ Watermark ;\n[text drawInRect:CGRectMake(200, 300, 100, 50) withFont:font];\nUIImage *finalOverlayImage = UIGraphicsGetImageFromCurrentImageContext();\nUIGraphicsEndImageContext();\n\n[self.nAVC setOverlay: [[AVCFullImageOverlay alloc] initWithImage: finalOverlayImage]];  Notice that the final output resolution can be different, if an option like cropping is used.\nIn this case it is better to implement your own overlay class, which is shown in the following example:  @interface NSXWatermark : NSObject  AVCOverlay \n\n@property (assign) AVCOverlayRawBuffer buffer;\n\n@end\n\n@implementation NSXWatermark\n\n@synthesize imageSize;\n@synthesize overlayBoundingRect;\n\n-(AVCOverlayRawBuffer)overlayImageWithStreamTime:(NSTimeInterval)time\n{\n    if (self.buffer.buffer == NULL) {\n        UIImage *image = [NSXWatermark generateWatermarkWithSize:self.imageSize inBoundingRect:self.overlayBoundingRect];\n        self.buffer = [NSXWatermark makeBufferFromUIImage:image];\n    }\n\n    return self.buffer;\n}\n\n+(UIImage *)generateWatermarkWithSize:(CGSize)size inBoundingRect:(CGRect)boundingRect\n{\n    UIImage *watermarkImage = ...  // use your desired UIImage here\n    CGFloat padding = 10.0;\n    CGSize overlaySize = watermarkImage.size;\n\n    CGFloat height = size.height / 3;\n    if (overlaySize.height   height) {\n        overlaySize.width = height;\n        overlaySize.height = height;\n    }\n\n    CGFloat boundingMaxX = boundingRect.origin.x + boundingRect.size.width;\n    CGFloat boundingMaxY = boundingRect.origin.y + boundingRect.size.height;\n\n    CGRect overlayRect = CGRectMake(boundingMaxX - overlaySize.width, boundingMaxY - overlaySize.height, overlaySize.width, overlaySize.height);\n\n    //  CGRect overlayRect = CGRectMake(size.width - overlaySize.width, size.height - overlaySize.height, overlaySize.width, overlaySize.height);\n    CGRect realRect =  AVMakeRectWithAspectRatioInsideRect(watermarkImage.size, overlayRect);\n\n    realRect.origin.y -= padding;\n    realRect.origin.x -= padding;\n\n    UIGraphicsBeginImageContext(size);\n    [watermarkImage drawInRect:realRect];\n\n    UIImage *overlayImage = UIGraphicsGetImageFromCurrentImageContext();\n\n    UIGraphicsEndImageContext();\n\n    return overlayImage;\n}\n\n+(AVCOverlayRawBuffer)makeBufferFromUIImage:(UIImage *)image\n{\n    CGImageRef rawPic = [image CGImage];\n\n    CGDataProviderRef inProvider = CGImageGetDataProvider(rawPic);\n    CFDataRef inBitmapData = CGDataProviderCopyData(inProvider);\n\n    size_t inBitmapDataBytesPerRow = CGImageGetBytesPerRow(rawPic);\n\n    UInt8 *buffer = (UInt8*)CFDataGetBytePtr(inBitmapData);\n\n    AVCOverlayRawBuffer rawBuf;\n    rawBuf.buffer = buffer;\n    rawBuf.bytesPerRow = (int)inBitmapDataBytesPerRow;\n    rawBuf.bufferType = AVCOverlayBufferTypeBGRA;\n    return rawBuf;\n}\n@end", 
            "title": "Overlay/Watermark"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#initwithsession", 
            "text": "Instead of letting the SDK manage the video and audio input, you can also do that yourself. This is helpful to supply video and audio samples which are not coming from the standard input devices. Or to modify video and/or audio samples before they are used for the stream.  The SDK provides a separate init method  initWithSession .  An example for a custom capture session, which supplies CVPixelBufferRef s to the SDK:  @interface CustomCaptureSession : AVCaptureSession\n...\n@end\n\n@implementation CustomCaptureSession\n\n-(void) addOutput:(AVCaptureOutput )output\n{\n    if ([output isKindOfClass:[AVCaptureVideoDataOutput class]]) {\n        self.myVideoOutput = (AVCaptureVideoDataOutput)output;\n    }else if([output isKindOfClass:[AVCaptureAudioDataOutput class]])\n    {\n        //self.myAudioOutput = (AVCaptureAudioDataOutput*)output; // if you want to use a custom audio capture device\n        [super addOutput: output]; // uses the standard microphone of the iOS device\n    }\n}\n\n-(void) addInput:(AVCaptureInput *)input\n{\n    [super addInput:input]; // this is required, because nanostreamAVC checks the available inputs\n}\n\n-(void) startRunning\n{\n    [super startRunning];\n}\n\n// this method has to be called periodically - e.g. with CADisplayLink\n-(void) supplyCMSampleBufferRef\n{\n    CVPixelBufferRef buffer = [self getCVPixelBufferRef]; // get the CVPixelBufferRef from somewhere\n\n    CMSampleBufferRef newSampleBuffer = NULL;\n    CMSampleTimingInfo timingInfo = kCMTimingInfoInvalid;\n    timingInfo.duration = CMTimeMake(33, 1000);    // assuming 30fps, change if otherwise\n    timingInfo.decodeTimeStamp = CMTimeMake(ts, 1000);    // timestamp information required\n    timingInfo.presentationTimeStamp = timingInfo.decodeTimeStamp;\n\n    CMVideoFormatDescriptionRef videoInfo = NULL;\n    CMVideoFormatDescriptionCreateForImageBuffer(NULL, buffer,  videoInfo);\n\n    CMSampleBufferCreateForImageBuffer(kCFAllocatorDefault,buffer,true,NULL,NULL,videoInfo, timingInfo, newSampleBuffer);\n\n    // the following line submits the new CMSampleBufferRef to the nanostreamAVC lib\n    [self.myVideoOutput.sampleBufferDelegate captureOutput:self.myVideoOutput didOutputSampleBuffer:newSampleBuffer fromConnection:nil];\n\n    CFRelease(videoInfo);\n    CFRelease(buffer);\n    CFRelease(newSampleBuffer);\n\n}\n\n@end\n\n// you need to use initWithSession for nanostreamAVC to use your custom session\n...\nsession = [[CustomCaptureSession alloc] init];\n\n// Add input nodes\nif(videoInput != nil)\n{\n    [session addInput: videoInput];\n}\n\nif(audioInput != nil)\n{\n    [session addInput: audioInput]; // if the stream is video only, don't add an audioInput\n}\n\n[session startRunning];\n\n...\nself.stream = [[nanostreamAVC alloc] initWithSession: session settings: nAVCSettings errorListener: self];\n...", 
            "title": "initWithSession"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#possible_issues", 
            "text": "", 
            "title": "Possible Issues"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#general", 
            "text": "For older versions of the sdk, without support for arm64, architecture in Xcode has to be set to armv7 and/or armv7s. This works also for newer iOS-Devcies like iPhone 5s.\nThis is not required for newer sdk versions, which also support arm64.", 
            "title": "General"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#compilerlinker", 
            "text": "", 
            "title": "Compiler/Linker"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#libstdc", 
            "text": "If there are linker errors with  std:: :  symbol(s) not found for architecture , make sure that you added the libraries  libstdc++.dylib  and  libc++.dylib  to your project.  Due to a bug in Xcode, depending on the selected Base SDK and deployment target, there might be still linker errors regarding  std . In this case you need to add a specific version of the libstdc++ to your project, e.g.: libstdc++-6.0.9.dylib instead of libstdc++.dylib", 
            "title": "libstdc++"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#undefined_symbols_for_parrot_dji", 
            "text": "The following part is only relevant for SDK versions from 3.3.x to 4.1.x. \nAs of version 4.2.x the drone dependencies are removed from the standard SDK package.  It might be possible that there are linker errors for the classes   ParrotBebopCaptureSession or  DJIPhantom2CaptureSession   Generally, if the Parrot   DJI extensions are not used, the symbols should be stripped automatically by Xcode and you do not need to link the frameworks.\nHowever this is not the case when the linker flag  -ObjC  is used in the app project. This causes the linker to load all symbols included in all linked object files (including the Parrot   DJI symbols). This prevents the automatic stripping.  To use our library without Parrot   DJI, either remove the  -ObjC  linker flag from the project or replace the  -ObjC  linker flag with the  -force_load  flag for each library that you want to use. Do not use  -force_load  with libnanostreamAVC.a.\nFor examples see http://stackoverflow.com/questions/11254269/using-the-force-load-linker-flag-with-restkit-ios", 
            "title": "Undefined Symbols for Parrot &amp; DJI"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#breakpoints", 
            "text": "If you debug your application, it is possible that breakpoints are being hit due to internal exceptions. Exceptions on the SDK level are handled in the SDK and do not affect the workflow of your application.  You can prevent the breakpoint from pausing the workflow of your application, if you use the right settings for the breakpoint.\nThe default setting is most likely that every exception causes a break.\nTo change that, use the settings from the following screenshot:   This way only Objective-C exceptions will be catched and C++ exceptions will be ignored.", 
            "title": "Breakpoints"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#crashes", 
            "text": "", 
            "title": "Crashes"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#calayergetdelegate_calayergetsuperlayer_other_calayer", 
            "text": "If there are crashes occurring in your app that include above symbols in the stack trace and are otherwise not obvious, check to see if you added a subviews to the preview view. The UIView instance that is passed to  [RtmpSourceCaptureSession initWithPreview:andStatusListener:andLogLevel:]  and  [nanostreamAVC initWithSettings:uiPreview:errorListener:]  cannot contain any subviews (UIButtons or otherwise).", 
            "title": "CALayerGetDelegate / CALayerGetSuperlayer / Other CALayer"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#logging_information", 
            "text": "If you encounter a problem with the nanostreamAVC library and you want to report the problem, log files will help us to comprehend the problem.  Please use the following steps to create the log files:   enable logging for the library with the method  SetLogLevel , use LogLevelVerbose:   objc\n  [self.nAVC SetLogLevel: LogLevelVerbose];  // set the log level before the method \"start\" is invoked   try to reproduce the problem  download the app container (for your app) from the iOS device with Xcode, as explained here: https://developer.apple.com/library/ios/recipes/xcode_help-devices_organizer/articles/manage_containers.html  in Finder right click on the downloaded container and select  Show Package Contents  send us the logfiles located (in the container) in the folder  /AppData/Library/Caches/Logs/", 
            "title": "Logging Information"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#crash_logs", 
            "text": "If you encounter a crash, please send us the crash log as explained in the following steps:   Plug in the device and open Xcode  Choose Window -  Devices from the menu bar  Under the DEVICES section in the left column, choose the device  To see the device console, click the up-triangle at the bottom left of the right hand panel  Click the down arrow on the bottom right to save the console as a file  To see crash logs, select the View Device Logs button under the Device Information section on the right hand panel  Find your app in the Process column and select the Crash log to see the contents.  To save a crash log, right click the entry on the left column and choose  Export Log   (Taken from https://developer.apple.com/library/ios/qa/qa1747/_index.html)", 
            "title": "Crash Logs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/", 
            "text": "nanoStream MacOS API\n\n\nIntro\n\n\nThe nanoStream MacOS dylib API is a video capture and encoding software for streaming live video and audio to internet based media servers and other network clients.\n\n\nThe nanoStream MacOS dylib API supports internet broadcast streaming and local recording at the same time. A lots of video devices are supported, also Blackmagic devices. The resolution, frame rate, samplerate and more can be manipulated. For a full feature list and platform specific features look at the method list below.\n\n\nIt works perfectly together with internet streaming servers like Wowza Media Server and Flash Media Server, streaming to Mobile devices like iPhone, Silverlight and other playback clients is possible.\n\n\n\n\nNote: this is preliminary documentation, please contact us for further information or help.\n\n\n\n\nSetup:\n\n\nThe best way to start is using the C++ sample code included in the SDK.\n\n\nSystem Requirements:\n\n\nMac OSX 10.9 or newer, Windows 7 or newer\n\n\nHardware Requirements:\n\n\nIntel Core2 Duo or later\n\n\nRecommended for HD capture: Intel Core i7 or Xeon\n\n\n| \nMethod Name\n             | \nDescription\n                                     | libnanoStream.dylib Support | Mac Plugin Support | Mac Framework Support | ANE Support|\n| InitPlugin              | Initialization of the Plugin.                               |  nanoStream  |  initEncoder  |  init  |  \u2714  |\n| SetXml                  | deprecated - no functionality                          |  \u2718  |  \u2718  |  \u2718  |  \u2714  |\n| GetVersion              | Get version number of the SDK                                                                     |   \u2714  |    |    |  |\n| SetLicense              | Set license for nano SDK                               |  \u2714  |  \u2714  |  \u2714   |  \u2714  |\n| GetLicense              | Get the current license of the SDK                                                                     |  \u2714  |    |    |  |\n| SetConfig               | Set property over Identifier.                            |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| UpdatePreviewDimensions | Update preview dimensions of the bmp           |  \u2718  |  \u2718   |  \u2718   |  \u2714  |\n| GetPreviewDimensions              | Get the current preview dimensions                                                                      |  \u2714   |    |    |  |\n| GetPreviewImage              | Get the preview image                                                                     |  \u2714  |    |    |  |\n| GetPreviewFrame         | Get current preview Frame                       |  \u2718  |  \u2718  |  \u2718  |  \u2714  |\n| StartPreview            | Start the preview.                              |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| StopPreview             | Stop the preview.                              |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| StartBroadcast          | Start broadcasting.                             |  \u2714  |  \u2714  |  startStream  |  \u2714  |\n| StopBroadcast           | Stop broadcasting.                              |  \u2714  |  \u2714  |  stopStream  |  \u2714  |\n| GetNumberOfVideoSources | Count video sources with current settings       |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| GetNumberOfAudioSources | Count audio sources with current settings      |  \u2714   |  \u2714  |  \u2714  |  \u2714  |\n| GetVideoSource          | Get name of the video source as string.         |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| GetAudioSource          | Get name of the audio source as string.         |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoSource          | Set video source for preview or broadcasting    |  \u2714  |  VideoSource  |  \u2718   |  \u2714  |\n| SetVideoSourceFromURL   | URL to an mp4 file source or ramp source        |  \u2718  |  \u2718  |  \u2718  |  \u2714  |\n| SetAudioSource          | Set audio source for preview or broadcasting    |  \u2714  |  AudioSource  |  \u2718  |  \u2714  |\n| SetVideoWidth           | Set width of video in pixels                   |  \u2714  |  VideoWidth  |  \u2714  |  \u2714  |\n| GetVideoWidth           | Get width of video in pixels                   |  \u2714  |  VideoWidth  |    |    |\n| SetVideoHeight          | Set height of video in pixels                   |  \u2714  |  VideoHeight  |  \u2714  |  \u2714  |\n| GetVideoHeight          | Get height of video in pixels                   |  \u2714  |  VideoHeight  |   |   |\n| SetVideoResizeWidth     | Resize width of video in pixels                |  \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoResizeHeight    | Resize height of video in pixels               |  \u2718  |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoFramerate       | Set frame rate of video in frames per second    |  SetFramerate   |  VideoFrameRate  |  setFrameRate  |  \u2714  |\n| SetNumberOfChannels              | set channel number                                                                      |  \u2714   |    |    |  |\n| SetVideoBitrate         | Set bitrate of video in kbits per second        |  \u2714  |  \u2714  |  \u2714   |  \u2714  |\n| GetVideoBitrate              | Get the current video bitrate                                                                     |  \u2714  |    |    |  |\n| SetAudioBitrate         | Set bitrate of audio in kbits per second       |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| GetAudioBitrate              | Get the current audio bitrate                                                                     |  \u2714   |    |    |  |\n| SetAudioSamplerate      | Set the samplerate of the audio in Hertz        |  \u2714  |  \u2718  |  setSampleRate   |  \u2714  |\n| GetAudioLevel           | Get the audio level of a channel                |  \u2714  |  \u2714  |  \u2714   |  \u2714  |\n| SetAudioVolume          | Set audio volume                               |  \u2714  |  AudioVolume  |  \u2718  |  \u2714  |\n| SetAudioPreviewVolume   | Set audio volume of preview                    |  \u2714  |  AudioPreviewVolume  |  \u2718  |  \u2714  |\n| SetColorSpace           | Set the color space of an input source         |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| GetNumberOfColorspaces  | Get the count of color spaces                  |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| GetColorspace           | Get color space name as string                  |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| GetNumberOfResolutions  | Get count of available resolutions             |  \u2714   |  \u2714  |  \u2718  |  \u2714  |\n| GetResolution           | Get count of resolutions                       |  \u2714   |  \u2714  |  \u2718  |  \u2714  |\n| GetNumberOfFramerates   | Count of available frame rates as integer value |  GetNumberOfFrameRates  |  \u2714  |  \u2718  |  \u2714  |\n| GetFramerate            | Get the frame rate of a video source           |  \u2714   |  \u2714  |  getFrameRate  |  \u2714  |\n| SetDeinterlacing        | Set deinterlacing mode and method              |  \u2718   |  \u2718  |  \u2718  |  \u2714  |\n| GetNumberOfOutputs      | Get count of output sources                    |  \u2718  |  \u2714  |  \u2718  |  \u2714  |\n| AddOutput               | Add new output source with url                 |  \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetOutputUrl            | Set output source with url. Local or rtmp       |  \u2714   |  \u2714  |  setOutputUrl   |  \u2714  |\n| GetOutputUrl              |                                                                      |  \u2714  |    |    |  |\n| GetNumberOfOutputUrls              |                                                                      |  \u2714  |    |    |  |\n| AcceptDataInSampleBuffer              |                                                                      |  \u2714   |    |    |  |\n| AddSampleBuffer              |                                                                      |  \u2714  |    |    |  |\n| SetFilesourceFilename   | Set the filename of a local source            |  \u2718   |  \u2718  |  \u2718  |  \u2714  |\n| ClearOutputs            | Reset all output sources                      |   \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoEffect          | Add a video effect.                            |  \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetOverlay              | Add a overlay to the video                     |   \u2718   |  \u2718  |  \u2718  |  \u2714  |\n| ShowPropertyPage        | Show property page                            |   \u2718    |  \u2714  |  \u2718   |  \u2714  |\n| SetLog                  | Set log file path and log level.               |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| SetXmlProfile              |                                                                      |  \u2714   |    |    |  |\n| dispose():void          | Reset buffer                                  |  \u2718   |  \u2718  |  \u2718  |  \u2714  |\n\n\nMethod Description:\n\n\n===== Setup the Plugin =====\n\n\n==== InitPlugin ====\n\n\n=== Declaration ===\n\n\nInitPlugin(xmlPath:String):int\n\n\n=== Parameters ===\n\n\n\n\n\n\n\n\nxmlPath:String\n\n\nPath to the xml file with configuration information, can be local or a url.\n\n\n\n\n\n\n\n\n\n\n=== Return Value ===\n\n\n-1\n if the initialization failed\n\n\n=== Description ===\n\n\nInitialization of the plugin.\n\n\n=== Availability ===\n\n\nOn Windows and Mac OSX\n\n\n==== GetVersion ====\n\n\n=== Declaration ===\n\n\nGetVersion()\n\n\n=== Return Value ===\n\n\nVersion number as int value\n\n\n=== Description ===\n\n\nReturn the version number of the SDK as int value\n\n\n=== Availability ===\n\n\nOn Mac OSX\n==== SetLicense ====\n\n\n=== Declaration ===\n\n\nSetLicense(licenseStr:String):int\n\n\n=== Parameters ===\n\n\n| licenseStr:String | License String getting from nano. |\n\n\n=== Return Value ===\n\n\n-\n1\n if call failed\n\n\n=== Description ===\n\n\nSet license for nano SDK\n\n\n=== Availability ===\n\n\nOn Windows and Mac OSX\n\n\n==== GetLicense ====\n\n\n=== Declaration ===\n\n\nGetLicense()\n\n\n=== Return Value ===\n\n\nString represantation of the license\n\n\n=== Description ===\n\n\nGet license for nano SDK\n\n\n=== Availability ===\n\n\nOn Mac OSX\n\n\nSetConfig\n\n\nDeclaration\n\n\nSetConfig(property:String, value:String):int\n\n\nParameters\n\n\n| property:String | Property identifier as string. See property list for configuration on page 32. |\n| value:String    | Value for property as string representation.                                   |\n\n\nReturn Value\n\n\n1\n if call was successful, \n0\n otherwise\n\n\nDescription\n\n\nSet property over Identifier.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nPreview\n\n\nUpdatePreviewDimensions\n\n\nDeclaration\n\n\nUpdatePreviewDimensions():void\n\n\nDescription\n\n\nUpdates the preview with the current width and height.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetPreviewDimensions\n\n\n=== Declaration ===\n\n\nGetPreviewDimensions(long \nwidth, long \nheight, long *size)\n\n\n=== Parameters ===\n\n\n| width:long | Pointer to return the video width |\n| height:long | Pointer to return the video height |\n| size:long | Pointer to return the video size |\n\n\n=== Return Value ===\n\n\n1\n if call failed, \n0\n otherwise\n\n\n=== Description ===\n\n\nGet the current preview dimensions.\n\n\nGetPreviewImage\n\n\n=== Declaration ===\n\n\nGetPreviewImage(char *pixelBuffer, int size)\n\n\n=== Parameters ===\n\n\n| pixelBuffer:char | pixel buffer|\n| size:int | size |\n\n\n=== Return Value ===\n\n\n1\n if call failed, \n0\n otherwise\n\n\n=== Description ===\n\n\nGet the preview image.\n\n\nGetPreviewFrame\n\n\n=== Declaration ===\n\n\nGetPreviewFrame(options:int = GET_FRAME_BITMAP):Boolean\n\n\n=== Parameters ===\n\n\n| options:int | option as integer. Default is GET_FRAME_BITMAP = 2. A\\  Also possible: \\  GET_FRAME_RAW_BYTES:int = 4,\\  GET_POWER_OF_2_FRAME_BGRA_BYTES:int = 8 |\n\n\n=== Return Value ===\n\n\nTrue if new frame was received otherwise false\n\n\n=== Description ===\n\n\nGet current preview Frame.\n\n\nStartPreview\n\n\nDeclaration\n\n\nStartPreview():int\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nStart the preview.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nStopPreview\n\n\nDeclaration\n\n\nStopPreview():int\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nStop the preview.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nBroadcast\n\n\nStartBroadcast\n\n\nDeclaration\n\n\nStartBroadcast():int\n\n\nReturn Value\n\n\nERROR_SETUP_ENCODER_FAILED = -2\n\n\nERROR_RTMP_OUTPUT_SOURCE1_FAILED = 2\n\n\nERROR_RTMP_OUTPUT_SOURCE2_FAILED = 3\n\n\nDescription\n\n\nStart broadcasting.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nStopBroadcast\n\n\nDeclaration\n\n\nStopBroadcast():int\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nStop broadcasting.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nVideo Source \n Audio Source handling\n\n\nGetNumberOfVideoSources\n\n\nDeclaration\n\n\nGetNumberOfVideoSources():int\n\n\nReturn Value\n\n\nCount of all available video sources.\n\n\nDescription\n\n\nCount of all available video sources with current settings\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetNumberOfAudioSources\n\n\nDeclaration\n\n\nGetNumberOfAudioSources():int\n\n\nReturn Value\n\n\nCount of all available audio sources.\n\n\nDescription\n\n\nCount of all available audio sources with current settings\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetVideoSource\n\n\nDeclaration\n\n\nGetVideoSource(index:int):String\n\n\nParameters\n\n\n| index:int | Index of the video source. The index of the video source, from \n0 - GetNumberOfVideoSources -1\n |\n\n\nReturn Value\n\n\nVideo source name as string.\n\n\nDescription\n\n\nGet name of the video source as string. Call \nGetNumberOfVideoSources\n first.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetAudioSource\n\n\nDeclaration\n\n\nGetAudioSource(index:int):String\n\n\nParameters\n\n\n| index:int | Index of the audio source. The index of the audio source, from \n0 - GetNumberOfAudioSources -1\n |\n\n\nReturn Value\n\n\nAudio source name as string.\n\n\nDescription\n\n\nGet name of the audio source as string. Call \nGetNumberOfAudioSources\n first.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nSetVideoSource\n\n\nDeclaration\n\n\nSetVideoSource(index:int, mixSource:int, mixMode:int):int\n\n\nParameters\n\n\n| index:int     | Index of the video source. The index of the video source goes from \n0 - GetNumberOfVideoSources -1\n |\n| mixSource:int | set \n0\n to to set only the first video source. \n1\n to set a second video source |                                   \n\n|               | \n\u2014second video source only available on Microsoft Windows\n |\n| mixMode:int   | when mixSource \n1\n is set, the mix mode to combine two video sources can be chosen here. See available mix modes on page 33. |\n|               | \n\u2014only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet video source for preview or broadcasting over index. Call \nGetNumberOfVideoSources\n first. The mix source defines the video source you want set. The mixSource and mixMode is optional and only available on Microsoft Windows. There with you can combine two videos over the mixMode.\n\n\nAvailability\n\n\nOn Mac OSX only one video source can use. On Microsoft Windows up to two video sources can be used and be combined in different ways.\n\n\nSetVideoSourceFromURL\n\n\nDeclaration\n\n\nSetVideoSourceFromURL(url:String):int\n\n\nParameters\n\n\n| url:String | URL to use an mp4 file as video source. |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nURL to an mp4 file source to stream this file.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows\n\n\nSetAudioSource\n\n\nDeclaration\n\n\nSetAudioSource(index:int):int\n\n\nParameters\n\n\n| index:int | Index of the audio source. The index of the audio source, from \n0 - GetNumberOfAudioSources -1\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet audio source for preview or broadcasting over index. Call \nGetNumberOfAudioSources\n first.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX\n\n\nVideo Properties\n\n\nSetVideoWidth\n\n\nDeclaration\n\n\nSetVideoWidth(width:int, mixSource:int):int\n\n\nParameters\n\n\n| width:int | Width of the video in pixels as integer value |\n| mixSource:int | set \n0\n to to set only the first video source. \n1\n to set a second video source |\n|               | \n\u2014second video source only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet width of video in pixels. With mixSource the height for two video sources can be set.\n\n\nAvailability\n\n\nSet Width is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.\n\n\nSetVideoHeight\n\n\nDeclaration\n\n\nSetVideoHeight(height:int, mixSource:int):int\n\n\nParameters\n\n\n| height:int    | Height of the video in pixels as integer value                                      |\n| mixSource:int | set \n0\n to to set only the first video source. \n1\n to set a second video source |\n|           | \n\u2014second video source only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet height of video in pixels. With mixSource the height for two video sources can be set.\n\n\nAvailability\n\n\nSet Height is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.\n\n\nSetVideoResizeWidth\n\n\nDeclaration\n\n\nSetVideoResizeWidth(width:int, index:int):int\n\n\nParameters\n\n\n\n\n\n\n\n\nwidth:int\n\n\nresize width of the video in pixels as integer value\n\n\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nResize width of video in pixels.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows\n\n\nSetVideoResizeHeight\n\n\nDeclaration\n\n\nSetVideoResizeHeight(height:int, index:int):int\n\n\nParameters\n\n\n\n\n\n\n\n\nheight:int\n\n\nresize height of the video in pixels as integer value\n\n\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nResize height of video in pixels.\n\n\nAvailability\n\n\nOnly supported under Microsoft Windows\n\n\nSetVideoFramerate\n\n\nDeclaration\n\n\nSetVideoFramerate(framerate:Number, mixSource:int):int\n\n\nParameters\n\n\n| framerate:Number | Frame rate in frames per Second(FPS) as number value.                               |\n| mixSource:int    | set \n0\n to to set only the first video source. \n1\n to set a second video source |\n|    | \n\u2014second video source only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet frame rate of video in frames per second (FPS). With mixSource the frame rate for two video sources can be set under Microsoft Windows.\n\n\nAvailability\n\n\nSet video frame rate is supported under Mac OS X and Microsoft Windows. Mix Source is only available under Microsoft Windows.\n\n\n===== SetNumberOfChannels =====\n\n\n=== Declaration ===\n\n\nSetNumberOfChannels(int numOfChannels)\n\n\n=== Parameters ===\n\n\n| numOfChannels:int | Number of channels as int value |\n\n\n=== Description ===\n\n\nSet channel number\n\n\n=== Availability ===\n\n\nOn Mac OSX\n\n\nSetVideoBitrate\n\n\n=== Declaration ===\n\n\nSetVideoBitrate(bitrate:int, index:int):int\n\n\n=== Parameters ===\n\n\n| bitrate:int | Video bitrate as integer value. |\n| index:int   | index of output to set the bitrate for multiple encoders. |                                                      \n\n|              | \n\u2014set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.\n  |\n\n\n=== Return Value ===\n\n\n-\n1\n if call failed\n\n\n=== Description ===\n\n\nSet bitrate of video in kbits per second (kbits/s).\n\n\n=== Availability ===\n\n\nUnder Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.\n\n\nGetVideoBitrate\n\n\n=== Declaration ===\n\n\nGetVideoBitrate(int source)\n\n\n=== Parameters ===\n\n\n| index:int   | index of output to get the bitrate for multiple encoders. |                                                       \n\n|               | \n\u2014get different outputs is only available on Microsoft Windows. On Mac OS X there is only one source available.\n  |\n\n\n=== Return Value ===\n\n\nVideo bitrate as integer value.\n\n\n=== Description ===\n\n\nGet the current video bitrate.\n\n\n=== Availability ===\n\n\nUnder Mac OS X there is only one output available. Under Microsoft Windows several outputs are available over the index parameter.\n\n\nAudio Properties\n\n\nSetAudioBitrate\n\n\n=== Declaration ===\n\n\nSetAudioBitrate(bitrate:int, index:int):int\n\n\n=== Parameters ===\n\n\n| bitrate:int | Audio bitrate as integer value.  |\n| index:int   | index of output to set the bitrate for multiple encoders. |                                                       \n\n|               | \n\u2014set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.\n  |\n\n\n=== Return Value ===\n\n\n-\n1\n if call failed\n\n\n=== Description ===\n\n\nSet bitrate of audio in kbits per second (kbits/s).\n\n\n=== Availability ===\n\n\nUnder Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.\n\n\nGetAudioBitrate\n\n\n=== Declaration ===\n\n\nGetAudioBitrate(int source)\n\n\n=== Parameters ===\n\n\n| index:int   | index of output to get the bitrate for multiple encoders. |                                                       \n\n|               | \n\u2014Get different outputs is only available on Microsoft Windows. On Mac OS X there is only one source available.\n  |\n\n\n=== Return Value ===\n\n\nAudio bitrate as integer value.\n\n\n=== Description ===\n\n\nGet the current audio bitrate.\n\n\nSetAudioSamplerate\n\n\nDeclaration\n\n\nSetAudioSamplerate(samplerate:int):int\n\n\nParameters\n\n\n| samplerate:int | Samplerate of audio as integer value |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet the samplerate of the audio in Hertz (Hz).\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nGetAudioLevel\n\n\nDeclaration\n\n\nGetAudioLevel(channel:int):int\n\n\nParameters\n\n\n| channel:int | channel id as integer. |\n\n\nReturn Value\n\n\nAudiolevel as integer value.\n\n\nDescription\n\n\nGet the audio level of a channel.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetAudioVolume\n\n\nDeclaration\n\n\nSetAudioVolume(volume:int):int\n\n\nParameters\n\n\n| volume:int | volume as integer value |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet audio volume.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetAudioPreviewVolume\n\n\nDeclaration\n\n\nSetAudioPreviewVolume(volume:int):int\n\n\nParameters\n\n\n| volume:int | volume as integer value |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet audio volume of preview.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nColor Management\n\n\nSetColorSpace\n\n\nDeclaration\n\n\nSetColorSpace(index:int, mixSource:int):int\n\n\nParameters\n\n\n| index:int     | index of the input source. |\n| mixSource:int | set \n0\n to to set only the first mixed source. \n1\n to set a second mixed source |\n|       | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet the color space of an input source. Only the firtst source is supported under Mac OS X\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nGetNumberOfColorspaces\n\n\nDeclaration\n\n\nGetNumberOfColorspaces(width:int, height:int, mixSource:int):int\n\n\nParameters\n\n\n| width:int     | width of the video source  |\n| height:int    | height of the video source  |\n| mixSource:int | set \n0\n to to get the first mixed source. \n1\n to get the second mixed source |\n|  | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\nCount of color spaces as integer value.\n\n\nDescription\n\n\nGet the count of color spaces. Get the color space for the specified with and height.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX mix source is not supported.\n\n\nGetColorspace\n\n\nDeclaration\n\n\nGetColorspace(index:int, mixSource:int):String\n\n\nParameters\n\n\n| index:int     | Index of the color spaces. The index of the color spaces, from \n0 - GetNumberOfColorspaces -1\n |\n| mixSource:int | set \n0\n to to get the first mixed source. \n1\n to get the second mixed source |           \n\n|   | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\ncolor space name as String\n\n\nDescription\n\n\nGet color space name as string. First call \nGetNumberOfColorspaces.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nResolution \n Frame rate\n\n\nGetNumberOfResolutions\n\n\nDeclaration\n\n\nGetNumberOfResolutions(mixSource:int):int\n\n\nParameters\n\n\n| mixSource:int | set \n0\n to to get the first mixed source. \n1\n to get the second mixed source |\n|                 | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\nCount of resolutions as integer value.\n\n\nDescription\n\n\nGet count of resolutions.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nGetResolution\n\n\nDeclaration\n\n\nGetResolution(index:int, mixSource:int):Object\n\n\nParameters\n\n\n| index:int     | Index of the resolutions. The index of the resolutions, from \n0 - GetNumberOfResolutions -1\n |\n| mixSource:int | set \n0\n to to get the first mixed source. \n1\n to get the second mixed source  |           \n\n|                    | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\nGet resolution of video source. First call \nGetNumberOfResolutions.\n\n\nDescription\n\n\nGet count of resolutions.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nGetNumberOfFramerates\n\n\nDeclaration\n\n\nGetNumberOfFramerates(width:int, height:int, colorspace:String, mixSource:int):int\n\n\nParameters\n\n\n| width:int         | width of the video source  |\n| height:int        | height of the video source.                                                      |\n| colorspace:String | name of the color space get from GetColorspace                                   |\n| mixSource:int     | set \n0\n to to get the first mixed source. \n1\n to get the second mixed source |\n|        | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\nCount of available frame rates as integer value.\n\n\nDescription\n\n\nGet count of available frame rates.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nGetFramerate\n\n\nDeclaration\n\n\nGetFramerate(index:int, mixSource:int):Number\n\n\nParameters\n\n\n| index:int     | Index of the frame rate. The index of the frame rate, from \n0 - GetNumberOfFramerates -1\n |\n| mixSource:int | set \n0\n to to get the first mixed source. \n1\n to get the second mixed source  |        \n\n|     | \n\u2014second mixed source is only available on Microsoft Windows\n |\n\n\nReturn Value\n\n\nFrame rate (FPS) as number value.\n\n\nDescription\n\n\nGet the frame rate of a video source. Call \nGetNumberOfFramerates\n first.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nSetDeinterlacing\n\n\nDeclaration\n\n\nSetDeinterlacing(mode:int, method:int):int\n\n\nParameters\n\n\n| mode:int   | possible values: \n0\n=off, \n1\n=auto, \n2\n=on   \\  no auto mode for mac |\n| method:int | possible values: \n0\n=duplicate field/bob, \n1\n=blend, \n2\n=vertical filter, \n3\n=edge, 4=median, \n5\n=median2 |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet deinterlacing mode and method.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nOutputs\n\n\nGetNumberOfOutputs\n\n\nDeclaration\n\n\nGetNumberOfOutputs():int\n\n\nReturn Value\n\n\nCount of outputs as integer value.\n\n\nDescription\n\n\nGet count of outputs.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nAddOutput\n\n\nDeclaration\n\n\nAddOutput(url:String):int\n\n\nParameters\n\n\n| url:String | Url of outputs can be a local mp4 recording or a rtmp source. |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nAdd new output source with url.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nSetOutputUrl\n\n\nDeclaration\n\n\nSetOutputUrl(url:String, index:int):int\n\n\nParameters\n\n\n| url:String | Url of outputs can be a local mp4 recording or a rtmp server. |\n| index:int  | Index of the output.                                          |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet output with url. A local mp4 recording or a rtmp server.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nGetOutputUrl\n\n\nGetNumberOfOutputUrls\n\n\nAcceptDataInSampleBuffer\n\n\nSetFilesourceFilename\n\n\nDeclaration\n\n\nSetFilesourceFilename(url:String):int\n\n\nParameters\n\n\n| url:String | Url to the local file |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet the filename of a local source.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nClearOutputs\n\n\nDeclaration\n\n\nClearOutputs():int\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nReset all outputs except the first one.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nVideo Special\n\n\nSetVideoEffect\n\n\nDeclaration\n\n\nSetVideoEffect(mode:int):int\n\n\nParameters\n\n\n| mode:int | Mode of video effect. See possible overlay effects on page 33 |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nAdd a video effect. For overlay.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nSetOverlay\n\n\nDeclaration\n\n\nSetOverlay(url:String):int\n\n\nParameters\n\n\n| url:String | Url of the overlay source. Can be a locale path or server url to a png or txt file. Also can be a txt string. |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nAdd a overlay to the video.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nShowPropertyPage\n\n\nDeclaration\n\n\nShowPropertyPage(value:int):int\n\n\nParameters\n\n\n| value:int | \n1\n or \n0\n are possible values |\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nShow property page. Only used for Blackmagic devices.\n\n\nAvailability\n\n\nOnly supported under Microsoft Windows.\n\n\nLogging\n\n\nSetLog\n\n\nDeclaration\n\n\nSetLog(logFile:String, logLevel:int):int\n\n\nParameters\n\n\n\n\n\n\n\n\nlogFile:String\n\n\nlocal path for logfile as string.\n\n\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet log file path and log level.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetXmlProfile\n\n\ndispose\n\n\nDeclaration\n\n\ndispose():void\n\n\nDescription\n\n\nDestructor.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetConfig Properties\n\n\n| \nProperty name\n               | \nDescription\n                                                                                                              | \nValues\n                                                                                                                                               |  Mac Platform Support  | \n| license                                 | License string                                                                                                              |                                                                                                                                                                |                  \u2714                          |\n| XMLPath                              | Path to the XML file with configuration information                                                      |                                                                                                                                                                |                  \u2714                          |\n| RemoteControlPort              | Port number                                                                                                                 |                                                                                                                                                                |                  \u2714                          |\n| LiveSource                           |                                                                                                                                     |                                                                                                                                                               |                  \u2714                          |\n| RemoteIP                             |                                                                                                                                     |                                                                                                                                                               |                  \u2714                          |\n| AVOffsetMs              |                                                           |                                                                                                                                                                                                                                                     |                  \u2714                          |\n| ReconnectPeriod/ReconnectInterval              |                                                           |                                                                                                                                                                                                               |                  \u2714                          |\n| ReconnectAttempts              | Auto Reconnect No. of Attempts  | 5                                                                                                                                                                                                                                           |                  \u2714                          | \n| UseInternalReconnect              | Use RTMP Internal Reconnect of the RTMP Filter (do not stop encoder on network errors)  | 0 / 1                                                                                                                                          |                  \u2714                          |\n| UseUnlimitedReconnect              | Don\nt stop reconnecting after a specific number of failed attempts (encoder is not stopped)  | 0 / 1                                                                                                                                   |                  \u2714                          |\n| Auth              |  Authentication for RTMP and RTSP Push streaming                                                         | \u201cuser:password\u201d                                                                                                                                                      |                  \u2714                          | \n| RtmpUrlDelimiter              | Set delimiter for RTMP-url and streamname.                                                          | Example: \u201d+\u201c will split \n so that \u201cmyStream\u201d is the stream name.                   |                  \u2714                          | \n| DeinterlacingMode              | Deinterlacing Mode                                                          | 0=off, 1=auto (default), 2=on Note: for some capture devices you need to set this to \u201eon\u201c (2). (Resolutions 480i, 576i, 1080i)             |                  \u2714                          |\n| DeinterlacingMethod              | Deinterlacing Method                                                           | 0=duplicate field/bob, 1=blend, 2=vertical filter, 3=edge, 4=median, 5=median2                                                                          |                  \u2714                          |\n| RemoteSendAudioLevelInterval              |                                                           |                                                                                                                                                                                                                        |                  \u2714                          |\n| CaptureRegion              | Capture Region of the input source, example for a input resolution of 640\u00d7480: SetConfig(\u201cCaptureRegion\u201d, \u201c10,630,10,470\u201d) - discards 10 pixels on each side | left,right,top,bottom                    |                  \u2714                          |\n| RTMPPublishMode              | RTMP Publish/Live/Record on Server (VOD)                                                          | 1=record, 2=append, 0=live (default)                                                                                                             |                  \u2714                          | \n| VideoAudioInput              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          | \n| PreviewNoInvert              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          |\n| ScreenCapMode              | Screen Capture Desktop Mode                                                          | 0=Screen, 1=FollowMouse, 2=Region relative, 3=Region absolute, 4=Window, 5=Window overlapping                               |                  \u2714                          | \n| ScreenCapWindowIndex              |                                                           |                                                                                                                                                                                                                                   |                  \u2714                          | \n| ApplyDynamicSettings              |                                                           |                                                                                                                                                                                                                                       |                  \u2714                          | \n| Mp4RecordOnTheFlyChangeName |                                                                                                     |                                                                                                                                                                                        |        \u2714          | \n| Mp4RecordOnTheFlyControl    | If Mp4RecordOnTheFly is enabled, controls start/stop recording        | 0=stop, 1=start                                                                                                                                                               |        \u2714          | \n| AudioPreview                | Enables audio preview during preview or broadcast                                       | 0=no preview, 1=visual preview (default, requires filter AudioVolume), 2=visual and audible preview, 3=audible preview  |       \u2714          | \n| Mp4RecordOnTheFly           | Enables start/stop recording to local file while the broadcast is running  | 0=off (default), 1=on                                                                                                                                                        |      \u2714           | \n| H264Quality                 | H.264 Encoder Quality/Speed Ratio                                                                 | 0=worst/fastest 1=default 6=highest/slowest                                                                                                                 |      \u2714           | \n| H264IFrameDistance              | H.264 I Frame / GOP Length in Frames (100 Frames = 4 seconds for 25 fps)   | 100=default, 1 = I-Frame-Only                                                                                                                              |                  \u2714                          |\n| H264PFrameDistance             | H.264 P/B Frame Distance                                                                   | 3 1 = IP-Only (no B-Frames)                                                                                                                                             |                  \u2714                          | \n| H264Profile              | H.264 Encoding Profile                                                          | Baseline, Main, Extended, High Most compatible but lowest quality is Baseline, (no B-Frames, no CABAC VLC)                                           |                  \u2714                          | \n| H264Level              | H.264 Level                                                           | 10=1.0, 11=1.1, 12=1.2, 13=1.3, 20=2.0, 21=2.1, 22=2.2, 30=3.0, 31=3.1, 32=3.2, 40=4.0, 41=4.1, 42=4.2, 50=5.0, 51=5.1                                         |                  \u2714                          |\n| H264VlcMode              | H.264 VLC Mode (CAVLC/CABAC)                                                          | =CAVLC, 2=CABAC (not allowed in H.264 Baseline Profile)                                                                                                     |                  \u2714                          |\n| OutputFrameRate             | Video Output (Encoded) Frame Rate                                                           | 5,10,15,20,25,30, OR 23980 OR 29970                                                                                                                          |       \u2714          | \n| RTMPWriteTimecode           | Send timecodes in RTMP streams, If enabled RTMP timecodes are sent in addition to the always sent RTMP packet timestamps | 0=off (default), 1=on                                                                 |      \u2714           |\n| UseSystemTimeAsTimecode              | Send RTMP/MP4 timecodes as UTC system date time or stream time                                                          | 0=stream time (default), 1=UTC system date time                                       |                  \u2714                          | \n| TimecodeInterval            | RTMP/MP4 timecode interval in milliseconds                                                | Should be higher or equal to 1000 (1s)                                                                                                                          |        \u2714         |\n| TcpConnectTimeout              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          | \n| RTSPSinkMode              | Determines if the RTSPSink is running as a server (passive/pull) or as a streamer to a RTSP push capable server (active/push) | 1=server/pull (default), 2=streamer/push                                            |                  \u2714                          |\n\n| RTSPSDPFileFolder              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          | \n| RTSPStreamDescription              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          |\n| AudioVolumePerSoftware              | Control volume with the Audio Volume Filter                                                          | 0=off (default), 1=on                                                                                                                                                                                                                                             |                  \u2714                          | \n| AVFShowBlackmagicDevices    | use AVFoundation for BlackMagic devices                                                                                                                                 | 0=off (default), 1=on                                                                 |       \u2714          |\n| OverlayRect                 | Sets the dimensions for a given overlay-image.  | \u201cindex,left,top,right,bottom\u201d. index: the overlay-index, beginning with 0. left, top, right and bottom define a rectangle in screen-coordinates.           |        \u2714         |\n| OverlayAlpha                | Sets the alpha-value for overlays.   | Range: 0-1. 0.0 (not visable), 1 (fully visable).                                                                                                                                                                                 |       \u2714          |\n| OverlayTextColor            | Text Overlay Color | Must be a hexadecimal color-value in BGR-format, e.g.: \u201c0000FF\u201d (255 (0x0000FF) - red)                                                                                                                                     |       \u2714          | \n| OverlayBackgroundColor      |                         | Must be a hexadecimal color-value in BGR-format, e.g.: \u201c000000\u201d (0 (0x000000) - black).                                                                                                                                   |       \u2714          | \n| OverlaySkipColor            | Setting skipcolor to a specific value will result in this color to be rendered transparent in the overlays.              | Example: If OverlayBackgroundColor was set to blue (\u201cFF0000\u201d) setting OverlaySkipColor to blue as well will result in a transparent background. Parameter must be a hexadecimal color-value in BGR-format, e.g.: \u201cFF0000\u201d (blue). Disable: Setting OverlaySkipColor to \u201cFF000000\u201d (ABGR) will disable the usage of skipcolor.                                                                                                                                                 |       \u2714          | \n| AudioDelay                  | Streaming Audio Delay / Offset (ms) |                                                                                                                                                                                                                                                      |        \u2714         |\n| ShowPropertyPageForDevice   | Calls the propertypage for a given device.                                                                               | 0 for device with index: 0                                                                                                         |         \u2714        |\n| UseQuicktimeH264Encoder              |                                                           |                                                                                                                                                                                                                               |                  \u2714                          | \n| RotateDegrees              | set the degrees by which video should be rotated, only works if UseRotation is set to on, set before StartPreview or StartBroadcast | 0/90/180/270                                                                           |                  \u2714                          |\n\n\nMixmode\n\n\nNO_MIXING = 0 (if video mixing is not used)\n\n\nLEFT_RIGHT_FULL = 1\n\n\nLEFT_RIGHT_HALF = 2\n\n\nTOP_BOTTOM = 3\n\n\nINTERLACED_LINES = 4\n\n\nINTERLACED_COLUMN = 5\n\n\nANAGLYPH = 6\n\n\nPIC_IN_PIC_LEFT_TOP = 7\n\n\nPIC_IN_PIC_RIGHT_TOP = 8\n\n\nPIC_IN_PIC_LEFT_BOTTOM = 9\n\n\nPIC_IN_PIC_RIGHT_BOTTOM = 10\n\n\nVIDEO1_ONLY = 11\n\n\nVIDEO2_ONLY = 12\n\n\nREGION = 13\n\n\nMAX = 14\n\n\nOverlay Effects\n\n\nOverlay off = 0\n\n\nLeft Top = 1\n\n\nRight Top = 2\n\n\nLeft Bottom = 3\n\n\nRight bottom = 4\n\n\nFree Postion = 5", 
            "title": "MacOS api"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#nanostream_macos_api", 
            "text": "", 
            "title": "nanoStream MacOS API"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#intro", 
            "text": "The nanoStream MacOS dylib API is a video capture and encoding software for streaming live video and audio to internet based media servers and other network clients.  The nanoStream MacOS dylib API supports internet broadcast streaming and local recording at the same time. A lots of video devices are supported, also Blackmagic devices. The resolution, frame rate, samplerate and more can be manipulated. For a full feature list and platform specific features look at the method list below.  It works perfectly together with internet streaming servers like Wowza Media Server and Flash Media Server, streaming to Mobile devices like iPhone, Silverlight and other playback clients is possible.   Note: this is preliminary documentation, please contact us for further information or help.", 
            "title": "Intro"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setup", 
            "text": "The best way to start is using the C++ sample code included in the SDK.", 
            "title": "Setup:"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#system_requirements", 
            "text": "Mac OSX 10.9 or newer, Windows 7 or newer  Hardware Requirements:  Intel Core2 Duo or later  Recommended for HD capture: Intel Core i7 or Xeon  |  Method Name              |  Description                                      | libnanoStream.dylib Support | Mac Plugin Support | Mac Framework Support | ANE Support|\n| InitPlugin              | Initialization of the Plugin.                               |  nanoStream  |  initEncoder  |  init  |  \u2714  |\n| SetXml                  | deprecated - no functionality                          |  \u2718  |  \u2718  |  \u2718  |  \u2714  |\n| GetVersion              | Get version number of the SDK                                                                     |   \u2714  |    |    |  |\n| SetLicense              | Set license for nano SDK                               |  \u2714  |  \u2714  |  \u2714   |  \u2714  |\n| GetLicense              | Get the current license of the SDK                                                                     |  \u2714  |    |    |  |\n| SetConfig               | Set property over Identifier.                            |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| UpdatePreviewDimensions | Update preview dimensions of the bmp           |  \u2718  |  \u2718   |  \u2718   |  \u2714  |\n| GetPreviewDimensions              | Get the current preview dimensions                                                                      |  \u2714   |    |    |  |\n| GetPreviewImage              | Get the preview image                                                                     |  \u2714  |    |    |  |\n| GetPreviewFrame         | Get current preview Frame                       |  \u2718  |  \u2718  |  \u2718  |  \u2714  |\n| StartPreview            | Start the preview.                              |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| StopPreview             | Stop the preview.                              |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| StartBroadcast          | Start broadcasting.                             |  \u2714  |  \u2714  |  startStream  |  \u2714  |\n| StopBroadcast           | Stop broadcasting.                              |  \u2714  |  \u2714  |  stopStream  |  \u2714  |\n| GetNumberOfVideoSources | Count video sources with current settings       |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| GetNumberOfAudioSources | Count audio sources with current settings      |  \u2714   |  \u2714  |  \u2714  |  \u2714  |\n| GetVideoSource          | Get name of the video source as string.         |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| GetAudioSource          | Get name of the audio source as string.         |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoSource          | Set video source for preview or broadcasting    |  \u2714  |  VideoSource  |  \u2718   |  \u2714  |\n| SetVideoSourceFromURL   | URL to an mp4 file source or ramp source        |  \u2718  |  \u2718  |  \u2718  |  \u2714  |\n| SetAudioSource          | Set audio source for preview or broadcasting    |  \u2714  |  AudioSource  |  \u2718  |  \u2714  |\n| SetVideoWidth           | Set width of video in pixels                   |  \u2714  |  VideoWidth  |  \u2714  |  \u2714  |\n| GetVideoWidth           | Get width of video in pixels                   |  \u2714  |  VideoWidth  |    |    |\n| SetVideoHeight          | Set height of video in pixels                   |  \u2714  |  VideoHeight  |  \u2714  |  \u2714  |\n| GetVideoHeight          | Get height of video in pixels                   |  \u2714  |  VideoHeight  |   |   |\n| SetVideoResizeWidth     | Resize width of video in pixels                |  \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoResizeHeight    | Resize height of video in pixels               |  \u2718  |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoFramerate       | Set frame rate of video in frames per second    |  SetFramerate   |  VideoFrameRate  |  setFrameRate  |  \u2714  |\n| SetNumberOfChannels              | set channel number                                                                      |  \u2714   |    |    |  |\n| SetVideoBitrate         | Set bitrate of video in kbits per second        |  \u2714  |  \u2714  |  \u2714   |  \u2714  |\n| GetVideoBitrate              | Get the current video bitrate                                                                     |  \u2714  |    |    |  |\n| SetAudioBitrate         | Set bitrate of audio in kbits per second       |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| GetAudioBitrate              | Get the current audio bitrate                                                                     |  \u2714   |    |    |  |\n| SetAudioSamplerate      | Set the samplerate of the audio in Hertz        |  \u2714  |  \u2718  |  setSampleRate   |  \u2714  |\n| GetAudioLevel           | Get the audio level of a channel                |  \u2714  |  \u2714  |  \u2714   |  \u2714  |\n| SetAudioVolume          | Set audio volume                               |  \u2714  |  AudioVolume  |  \u2718  |  \u2714  |\n| SetAudioPreviewVolume   | Set audio volume of preview                    |  \u2714  |  AudioPreviewVolume  |  \u2718  |  \u2714  |\n| SetColorSpace           | Set the color space of an input source         |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| GetNumberOfColorspaces  | Get the count of color spaces                  |  \u2714  |  \u2714  |  \u2718  |  \u2714  |\n| GetColorspace           | Get color space name as string                  |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| GetNumberOfResolutions  | Get count of available resolutions             |  \u2714   |  \u2714  |  \u2718  |  \u2714  |\n| GetResolution           | Get count of resolutions                       |  \u2714   |  \u2714  |  \u2718  |  \u2714  |\n| GetNumberOfFramerates   | Count of available frame rates as integer value |  GetNumberOfFrameRates  |  \u2714  |  \u2718  |  \u2714  |\n| GetFramerate            | Get the frame rate of a video source           |  \u2714   |  \u2714  |  getFrameRate  |  \u2714  |\n| SetDeinterlacing        | Set deinterlacing mode and method              |  \u2718   |  \u2718  |  \u2718  |  \u2714  |\n| GetNumberOfOutputs      | Get count of output sources                    |  \u2718  |  \u2714  |  \u2718  |  \u2714  |\n| AddOutput               | Add new output source with url                 |  \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetOutputUrl            | Set output source with url. Local or rtmp       |  \u2714   |  \u2714  |  setOutputUrl   |  \u2714  |\n| GetOutputUrl              |                                                                      |  \u2714  |    |    |  |\n| GetNumberOfOutputUrls              |                                                                      |  \u2714  |    |    |  |\n| AcceptDataInSampleBuffer              |                                                                      |  \u2714   |    |    |  |\n| AddSampleBuffer              |                                                                      |  \u2714  |    |    |  |\n| SetFilesourceFilename   | Set the filename of a local source            |  \u2718   |  \u2718  |  \u2718  |  \u2714  |\n| ClearOutputs            | Reset all output sources                      |   \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetVideoEffect          | Add a video effect.                            |  \u2718   |  \u2714  |  \u2718  |  \u2714  |\n| SetOverlay              | Add a overlay to the video                     |   \u2718   |  \u2718  |  \u2718  |  \u2714  |\n| ShowPropertyPage        | Show property page                            |   \u2718    |  \u2714  |  \u2718   |  \u2714  |\n| SetLog                  | Set log file path and log level.               |  \u2714  |  \u2714  |  \u2714  |  \u2714  |\n| SetXmlProfile              |                                                                      |  \u2714   |    |    |  |\n| dispose():void          | Reset buffer                                  |  \u2718   |  \u2718  |  \u2718  |  \u2714  |", 
            "title": "System Requirements:"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#method_description", 
            "text": "===== Setup the Plugin =====  ==== InitPlugin ====  === Declaration ===  InitPlugin(xmlPath:String):int  === Parameters ===     xmlPath:String  Path to the xml file with configuration information, can be local or a url.      === Return Value ===  -1  if the initialization failed  === Description ===  Initialization of the plugin.  === Availability ===  On Windows and Mac OSX  ==== GetVersion ====  === Declaration ===  GetVersion()  === Return Value ===  Version number as int value  === Description ===  Return the version number of the SDK as int value  === Availability ===  On Mac OSX\n==== SetLicense ====  === Declaration ===  SetLicense(licenseStr:String):int  === Parameters ===  | licenseStr:String | License String getting from nano. |  === Return Value ===  - 1  if call failed  === Description ===  Set license for nano SDK  === Availability ===  On Windows and Mac OSX  ==== GetLicense ====  === Declaration ===  GetLicense()  === Return Value ===  String represantation of the license  === Description ===  Get license for nano SDK  === Availability ===  On Mac OSX", 
            "title": "Method Description:"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setconfig", 
            "text": "", 
            "title": "SetConfig"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration", 
            "text": "SetConfig(property:String, value:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters", 
            "text": "| property:String | Property identifier as string. See property list for configuration on page 32. |\n| value:String    | Value for property as string representation.                                   |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value", 
            "text": "1  if call was successful,  0  otherwise", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description", 
            "text": "Set property over Identifier.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#preview", 
            "text": "", 
            "title": "Preview"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#updatepreviewdimensions", 
            "text": "", 
            "title": "UpdatePreviewDimensions"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_1", 
            "text": "UpdatePreviewDimensions():void", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_1", 
            "text": "Updates the preview with the current width and height.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_1", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getpreviewdimensions", 
            "text": "=== Declaration ===  GetPreviewDimensions(long  width, long  height, long *size)  === Parameters ===  | width:long | Pointer to return the video width |\n| height:long | Pointer to return the video height |\n| size:long | Pointer to return the video size |  === Return Value ===  1  if call failed,  0  otherwise  === Description ===  Get the current preview dimensions.", 
            "title": "GetPreviewDimensions"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getpreviewimage", 
            "text": "=== Declaration ===  GetPreviewImage(char *pixelBuffer, int size)  === Parameters ===  | pixelBuffer:char | pixel buffer|\n| size:int | size |  === Return Value ===  1  if call failed,  0  otherwise  === Description ===  Get the preview image.", 
            "title": "GetPreviewImage"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getpreviewframe", 
            "text": "=== Declaration ===  GetPreviewFrame(options:int = GET_FRAME_BITMAP):Boolean  === Parameters ===  | options:int | option as integer. Default is GET_FRAME_BITMAP = 2. A\\  Also possible: \\  GET_FRAME_RAW_BYTES:int = 4,\\  GET_POWER_OF_2_FRAME_BGRA_BYTES:int = 8 |  === Return Value ===  True if new frame was received otherwise false  === Description ===  Get current preview Frame.", 
            "title": "GetPreviewFrame"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#startpreview", 
            "text": "", 
            "title": "StartPreview"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_2", 
            "text": "StartPreview():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_1", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_2", 
            "text": "Start the preview.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_2", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#stoppreview", 
            "text": "", 
            "title": "StopPreview"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_3", 
            "text": "StopPreview():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_2", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_3", 
            "text": "Stop the preview.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_3", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#broadcast", 
            "text": "", 
            "title": "Broadcast"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#startbroadcast", 
            "text": "", 
            "title": "StartBroadcast"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_4", 
            "text": "StartBroadcast():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_3", 
            "text": "ERROR_SETUP_ENCODER_FAILED = -2  ERROR_RTMP_OUTPUT_SOURCE1_FAILED = 2  ERROR_RTMP_OUTPUT_SOURCE2_FAILED = 3", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_4", 
            "text": "Start broadcasting.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_4", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#stopbroadcast", 
            "text": "", 
            "title": "StopBroadcast"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_5", 
            "text": "StopBroadcast():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_4", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_5", 
            "text": "Stop broadcasting.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_5", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#video_source_audio_source_handling", 
            "text": "", 
            "title": "Video Source &amp; Audio Source handling"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofvideosources", 
            "text": "", 
            "title": "GetNumberOfVideoSources"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_6", 
            "text": "GetNumberOfVideoSources():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_5", 
            "text": "Count of all available video sources.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_6", 
            "text": "Count of all available video sources with current settings", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_6", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofaudiosources", 
            "text": "", 
            "title": "GetNumberOfAudioSources"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_7", 
            "text": "GetNumberOfAudioSources():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_6", 
            "text": "Count of all available audio sources.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_7", 
            "text": "Count of all available audio sources with current settings", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_7", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getvideosource", 
            "text": "", 
            "title": "GetVideoSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_8", 
            "text": "GetVideoSource(index:int):String", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_1", 
            "text": "| index:int | Index of the video source. The index of the video source, from  0 - GetNumberOfVideoSources -1  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_7", 
            "text": "Video source name as string.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_8", 
            "text": "Get name of the video source as string. Call  GetNumberOfVideoSources  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_8", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getaudiosource", 
            "text": "", 
            "title": "GetAudioSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_9", 
            "text": "GetAudioSource(index:int):String", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_2", 
            "text": "| index:int | Index of the audio source. The index of the audio source, from  0 - GetNumberOfAudioSources -1  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_8", 
            "text": "Audio source name as string.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_9", 
            "text": "Get name of the audio source as string. Call  GetNumberOfAudioSources  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_9", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideosource", 
            "text": "", 
            "title": "SetVideoSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_10", 
            "text": "SetVideoSource(index:int, mixSource:int, mixMode:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_3", 
            "text": "| index:int     | Index of the video source. The index of the video source goes from  0 - GetNumberOfVideoSources -1  |\n| mixSource:int | set  0  to to set only the first video source.  1  to set a second video source |                                    \n|               |  \u2014second video source only available on Microsoft Windows  |\n| mixMode:int   | when mixSource  1  is set, the mix mode to combine two video sources can be chosen here. See available mix modes on page 33. |\n|               |  \u2014only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_9", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_10", 
            "text": "Set video source for preview or broadcasting over index. Call  GetNumberOfVideoSources  first. The mix source defines the video source you want set. The mixSource and mixMode is optional and only available on Microsoft Windows. There with you can combine two videos over the mixMode.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_10", 
            "text": "On Mac OSX only one video source can use. On Microsoft Windows up to two video sources can be used and be combined in different ways.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideosourcefromurl", 
            "text": "", 
            "title": "SetVideoSourceFromURL"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_11", 
            "text": "SetVideoSourceFromURL(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_4", 
            "text": "| url:String | URL to use an mp4 file as video source. |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_10", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_11", 
            "text": "URL to an mp4 file source to stream this file.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_11", 
            "text": "Only Supported under Microsoft Windows", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiosource", 
            "text": "", 
            "title": "SetAudioSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_12", 
            "text": "SetAudioSource(index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_5", 
            "text": "| index:int | Index of the audio source. The index of the audio source, from  0 - GetNumberOfAudioSources -1  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_11", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_12", 
            "text": "Set audio source for preview or broadcasting over index. Call  GetNumberOfAudioSources  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_12", 
            "text": "Under Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#video_properties", 
            "text": "", 
            "title": "Video Properties"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideowidth", 
            "text": "", 
            "title": "SetVideoWidth"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_13", 
            "text": "SetVideoWidth(width:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_6", 
            "text": "| width:int | Width of the video in pixels as integer value |\n| mixSource:int | set  0  to to set only the first video source.  1  to set a second video source |\n|               |  \u2014second video source only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_12", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_13", 
            "text": "Set width of video in pixels. With mixSource the height for two video sources can be set.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_13", 
            "text": "Set Width is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoheight", 
            "text": "", 
            "title": "SetVideoHeight"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_14", 
            "text": "SetVideoHeight(height:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_7", 
            "text": "| height:int    | Height of the video in pixels as integer value                                      |\n| mixSource:int | set  0  to to set only the first video source.  1  to set a second video source |\n|           |  \u2014second video source only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_13", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_14", 
            "text": "Set height of video in pixels. With mixSource the height for two video sources can be set.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_14", 
            "text": "Set Height is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoresizewidth", 
            "text": "", 
            "title": "SetVideoResizeWidth"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_15", 
            "text": "SetVideoResizeWidth(width:int, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_8", 
            "text": "width:int  resize width of the video in pixels as integer value", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_14", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_15", 
            "text": "Resize width of video in pixels.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_15", 
            "text": "Only Supported under Microsoft Windows", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoresizeheight", 
            "text": "", 
            "title": "SetVideoResizeHeight"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_16", 
            "text": "SetVideoResizeHeight(height:int, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_9", 
            "text": "height:int  resize height of the video in pixels as integer value", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_15", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_16", 
            "text": "Resize height of video in pixels.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_16", 
            "text": "Only supported under Microsoft Windows", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoframerate", 
            "text": "", 
            "title": "SetVideoFramerate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_17", 
            "text": "SetVideoFramerate(framerate:Number, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_10", 
            "text": "| framerate:Number | Frame rate in frames per Second(FPS) as number value.                               |\n| mixSource:int    | set  0  to to set only the first video source.  1  to set a second video source |\n|    |  \u2014second video source only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_16", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_17", 
            "text": "Set frame rate of video in frames per second (FPS). With mixSource the frame rate for two video sources can be set under Microsoft Windows.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_17", 
            "text": "Set video frame rate is supported under Mac OS X and Microsoft Windows. Mix Source is only available under Microsoft Windows.  ===== SetNumberOfChannels =====  === Declaration ===  SetNumberOfChannels(int numOfChannels)  === Parameters ===  | numOfChannels:int | Number of channels as int value |  === Description ===  Set channel number  === Availability ===  On Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideobitrate", 
            "text": "=== Declaration ===  SetVideoBitrate(bitrate:int, index:int):int  === Parameters ===  | bitrate:int | Video bitrate as integer value. |\n| index:int   | index of output to set the bitrate for multiple encoders. |                                                       \n|              |  \u2014set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.   |  === Return Value ===  - 1  if call failed  === Description ===  Set bitrate of video in kbits per second (kbits/s).  === Availability ===  Under Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.", 
            "title": "SetVideoBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getvideobitrate", 
            "text": "=== Declaration ===  GetVideoBitrate(int source)  === Parameters ===  | index:int   | index of output to get the bitrate for multiple encoders. |                                                        \n|               |  \u2014get different outputs is only available on Microsoft Windows. On Mac OS X there is only one source available.   |  === Return Value ===  Video bitrate as integer value.  === Description ===  Get the current video bitrate.  === Availability ===  Under Mac OS X there is only one output available. Under Microsoft Windows several outputs are available over the index parameter.", 
            "title": "GetVideoBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#audio_properties", 
            "text": "", 
            "title": "Audio Properties"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiobitrate", 
            "text": "=== Declaration ===  SetAudioBitrate(bitrate:int, index:int):int  === Parameters ===  | bitrate:int | Audio bitrate as integer value.  |\n| index:int   | index of output to set the bitrate for multiple encoders. |                                                        \n|               |  \u2014set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.   |  === Return Value ===  - 1  if call failed  === Description ===  Set bitrate of audio in kbits per second (kbits/s).  === Availability ===  Under Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.", 
            "title": "SetAudioBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getaudiobitrate", 
            "text": "=== Declaration ===  GetAudioBitrate(int source)  === Parameters ===  | index:int   | index of output to get the bitrate for multiple encoders. |                                                        \n|               |  \u2014Get different outputs is only available on Microsoft Windows. On Mac OS X there is only one source available.   |  === Return Value ===  Audio bitrate as integer value.  === Description ===  Get the current audio bitrate.", 
            "title": "GetAudioBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiosamplerate", 
            "text": "", 
            "title": "SetAudioSamplerate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_18", 
            "text": "SetAudioSamplerate(samplerate:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_11", 
            "text": "| samplerate:int | Samplerate of audio as integer value |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_17", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_18", 
            "text": "Set the samplerate of the audio in Hertz (Hz).", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_18", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getaudiolevel", 
            "text": "", 
            "title": "GetAudioLevel"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_19", 
            "text": "GetAudioLevel(channel:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_12", 
            "text": "| channel:int | channel id as integer. |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_18", 
            "text": "Audiolevel as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_19", 
            "text": "Get the audio level of a channel.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_19", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiovolume", 
            "text": "", 
            "title": "SetAudioVolume"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_20", 
            "text": "SetAudioVolume(volume:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_13", 
            "text": "| volume:int | volume as integer value |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_19", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_20", 
            "text": "Set audio volume.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_20", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiopreviewvolume", 
            "text": "", 
            "title": "SetAudioPreviewVolume"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_21", 
            "text": "SetAudioPreviewVolume(volume:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_14", 
            "text": "| volume:int | volume as integer value |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_20", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_21", 
            "text": "Set audio volume of preview.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_21", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#color_management", 
            "text": "", 
            "title": "Color Management"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setcolorspace", 
            "text": "", 
            "title": "SetColorSpace"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_22", 
            "text": "SetColorSpace(index:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_15", 
            "text": "| index:int     | index of the input source. |\n| mixSource:int | set  0  to to set only the first mixed source.  1  to set a second mixed source |\n|       |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_21", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_22", 
            "text": "Set the color space of an input source. Only the firtst source is supported under Mac OS X", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_22", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofcolorspaces", 
            "text": "", 
            "title": "GetNumberOfColorspaces"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_23", 
            "text": "GetNumberOfColorspaces(width:int, height:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_16", 
            "text": "| width:int     | width of the video source  |\n| height:int    | height of the video source  |\n| mixSource:int | set  0  to to get the first mixed source.  1  to get the second mixed source |\n|  |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_22", 
            "text": "Count of color spaces as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_23", 
            "text": "Get the count of color spaces. Get the color space for the specified with and height.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_23", 
            "text": "Under Windows and Mac OSX. Under Mac OSX mix source is not supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getcolorspace", 
            "text": "", 
            "title": "GetColorspace"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_24", 
            "text": "GetColorspace(index:int, mixSource:int):String", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_17", 
            "text": "| index:int     | Index of the color spaces. The index of the color spaces, from  0 - GetNumberOfColorspaces -1  |\n| mixSource:int | set  0  to to get the first mixed source.  1  to get the second mixed source |            \n|   |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_23", 
            "text": "color space name as String", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_24", 
            "text": "Get color space name as string. First call  GetNumberOfColorspaces.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_24", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#resolution_frame_rate", 
            "text": "", 
            "title": "Resolution &amp; Frame rate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofresolutions", 
            "text": "", 
            "title": "GetNumberOfResolutions"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_25", 
            "text": "GetNumberOfResolutions(mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_18", 
            "text": "| mixSource:int | set  0  to to get the first mixed source.  1  to get the second mixed source |\n|                 |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_24", 
            "text": "Count of resolutions as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_25", 
            "text": "Get count of resolutions.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_25", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getresolution", 
            "text": "", 
            "title": "GetResolution"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_26", 
            "text": "GetResolution(index:int, mixSource:int):Object", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_19", 
            "text": "| index:int     | Index of the resolutions. The index of the resolutions, from  0 - GetNumberOfResolutions -1  |\n| mixSource:int | set  0  to to get the first mixed source.  1  to get the second mixed source  |            \n|                    |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_25", 
            "text": "Get resolution of video source. First call  GetNumberOfResolutions.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_26", 
            "text": "Get count of resolutions.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_26", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofframerates", 
            "text": "", 
            "title": "GetNumberOfFramerates"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_27", 
            "text": "GetNumberOfFramerates(width:int, height:int, colorspace:String, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_20", 
            "text": "| width:int         | width of the video source  |\n| height:int        | height of the video source.                                                      |\n| colorspace:String | name of the color space get from GetColorspace                                   |\n| mixSource:int     | set  0  to to get the first mixed source.  1  to get the second mixed source |\n|        |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_26", 
            "text": "Count of available frame rates as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_27", 
            "text": "Get count of available frame rates.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_27", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getframerate", 
            "text": "", 
            "title": "GetFramerate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_28", 
            "text": "GetFramerate(index:int, mixSource:int):Number", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_21", 
            "text": "| index:int     | Index of the frame rate. The index of the frame rate, from  0 - GetNumberOfFramerates -1  |\n| mixSource:int | set  0  to to get the first mixed source.  1  to get the second mixed source  |         \n|     |  \u2014second mixed source is only available on Microsoft Windows  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_27", 
            "text": "Frame rate (FPS) as number value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_28", 
            "text": "Get the frame rate of a video source. Call  GetNumberOfFramerates  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_28", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setdeinterlacing", 
            "text": "", 
            "title": "SetDeinterlacing"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_29", 
            "text": "SetDeinterlacing(mode:int, method:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_22", 
            "text": "| mode:int   | possible values:  0 =off,  1 =auto,  2 =on   \\  no auto mode for mac |\n| method:int | possible values:  0 =duplicate field/bob,  1 =blend,  2 =vertical filter,  3 =edge, 4=median,  5 =median2 |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_28", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_29", 
            "text": "Set deinterlacing mode and method.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_29", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#outputs", 
            "text": "", 
            "title": "Outputs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofoutputs", 
            "text": "", 
            "title": "GetNumberOfOutputs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_30", 
            "text": "GetNumberOfOutputs():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_29", 
            "text": "Count of outputs as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_30", 
            "text": "Get count of outputs.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_30", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#addoutput", 
            "text": "", 
            "title": "AddOutput"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_31", 
            "text": "AddOutput(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_23", 
            "text": "| url:String | Url of outputs can be a local mp4 recording or a rtmp source. |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_30", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_31", 
            "text": "Add new output source with url.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_31", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setoutputurl", 
            "text": "", 
            "title": "SetOutputUrl"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_32", 
            "text": "SetOutputUrl(url:String, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_24", 
            "text": "| url:String | Url of outputs can be a local mp4 recording or a rtmp server. |\n| index:int  | Index of the output.                                          |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_31", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_32", 
            "text": "Set output with url. A local mp4 recording or a rtmp server.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_32", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getoutputurl", 
            "text": "", 
            "title": "GetOutputUrl"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofoutputurls", 
            "text": "", 
            "title": "GetNumberOfOutputUrls"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#acceptdatainsamplebuffer", 
            "text": "", 
            "title": "AcceptDataInSampleBuffer"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setfilesourcefilename", 
            "text": "", 
            "title": "SetFilesourceFilename"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_33", 
            "text": "SetFilesourceFilename(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_25", 
            "text": "| url:String | Url to the local file |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_32", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_33", 
            "text": "Set the filename of a local source.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_33", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#clearoutputs", 
            "text": "", 
            "title": "ClearOutputs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_34", 
            "text": "ClearOutputs():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_33", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_34", 
            "text": "Reset all outputs except the first one.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_34", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#video_special", 
            "text": "", 
            "title": "Video Special"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoeffect", 
            "text": "", 
            "title": "SetVideoEffect"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_35", 
            "text": "SetVideoEffect(mode:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_26", 
            "text": "| mode:int | Mode of video effect. See possible overlay effects on page 33 |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_34", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_35", 
            "text": "Add a video effect. For overlay.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_35", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setoverlay", 
            "text": "", 
            "title": "SetOverlay"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_36", 
            "text": "SetOverlay(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_27", 
            "text": "| url:String | Url of the overlay source. Can be a locale path or server url to a png or txt file. Also can be a txt string. |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_35", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_36", 
            "text": "Add a overlay to the video.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_36", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#showpropertypage", 
            "text": "", 
            "title": "ShowPropertyPage"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_37", 
            "text": "ShowPropertyPage(value:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_28", 
            "text": "| value:int |  1  or  0  are possible values |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_36", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_37", 
            "text": "Show property page. Only used for Blackmagic devices.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_37", 
            "text": "Only supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#logging", 
            "text": "", 
            "title": "Logging"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setlog", 
            "text": "", 
            "title": "SetLog"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_38", 
            "text": "SetLog(logFile:String, logLevel:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_29", 
            "text": "logFile:String  local path for logfile as string.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_37", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_38", 
            "text": "Set log file path and log level.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_38", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_39", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setxmlprofile", 
            "text": "", 
            "title": "SetXmlProfile"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#dispose", 
            "text": "", 
            "title": "dispose"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_39", 
            "text": "dispose():void", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_39", 
            "text": "Destructor.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_40", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setconfig_properties", 
            "text": "|  Property name                |  Description                                                                                                               |  Values                                                                                                                                                |  Mac Platform Support  | \n| license                                 | License string                                                                                                              |                                                                                                                                                                |                  \u2714                          |\n| XMLPath                              | Path to the XML file with configuration information                                                      |                                                                                                                                                                |                  \u2714                          |\n| RemoteControlPort              | Port number                                                                                                                 |                                                                                                                                                                |                  \u2714                          |\n| LiveSource                           |                                                                                                                                     |                                                                                                                                                               |                  \u2714                          |\n| RemoteIP                             |                                                                                                                                     |                                                                                                                                                               |                  \u2714                          |\n| AVOffsetMs              |                                                           |                                                                                                                                                                                                                                                     |                  \u2714                          |\n| ReconnectPeriod/ReconnectInterval              |                                                           |                                                                                                                                                                                                               |                  \u2714                          |\n| ReconnectAttempts              | Auto Reconnect No. of Attempts  | 5                                                                                                                                                                                                                                           |                  \u2714                          | \n| UseInternalReconnect              | Use RTMP Internal Reconnect of the RTMP Filter (do not stop encoder on network errors)  | 0 / 1                                                                                                                                          |                  \u2714                          |\n| UseUnlimitedReconnect              | Don t stop reconnecting after a specific number of failed attempts (encoder is not stopped)  | 0 / 1                                                                                                                                   |                  \u2714                          |\n| Auth              |  Authentication for RTMP and RTSP Push streaming                                                         | \u201cuser:password\u201d                                                                                                                                                      |                  \u2714                          | \n| RtmpUrlDelimiter              | Set delimiter for RTMP-url and streamname.                                                          | Example: \u201d+\u201c will split   so that \u201cmyStream\u201d is the stream name.                   |                  \u2714                          | \n| DeinterlacingMode              | Deinterlacing Mode                                                          | 0=off, 1=auto (default), 2=on Note: for some capture devices you need to set this to \u201eon\u201c (2). (Resolutions 480i, 576i, 1080i)             |                  \u2714                          |\n| DeinterlacingMethod              | Deinterlacing Method                                                           | 0=duplicate field/bob, 1=blend, 2=vertical filter, 3=edge, 4=median, 5=median2                                                                          |                  \u2714                          |\n| RemoteSendAudioLevelInterval              |                                                           |                                                                                                                                                                                                                        |                  \u2714                          |\n| CaptureRegion              | Capture Region of the input source, example for a input resolution of 640\u00d7480: SetConfig(\u201cCaptureRegion\u201d, \u201c10,630,10,470\u201d) - discards 10 pixels on each side | left,right,top,bottom                    |                  \u2714                          |\n| RTMPPublishMode              | RTMP Publish/Live/Record on Server (VOD)                                                          | 1=record, 2=append, 0=live (default)                                                                                                             |                  \u2714                          | \n| VideoAudioInput              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          | \n| PreviewNoInvert              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          |\n| ScreenCapMode              | Screen Capture Desktop Mode                                                          | 0=Screen, 1=FollowMouse, 2=Region relative, 3=Region absolute, 4=Window, 5=Window overlapping                               |                  \u2714                          | \n| ScreenCapWindowIndex              |                                                           |                                                                                                                                                                                                                                   |                  \u2714                          | \n| ApplyDynamicSettings              |                                                           |                                                                                                                                                                                                                                       |                  \u2714                          | \n| Mp4RecordOnTheFlyChangeName |                                                                                                     |                                                                                                                                                                                        |        \u2714          | \n| Mp4RecordOnTheFlyControl    | If Mp4RecordOnTheFly is enabled, controls start/stop recording        | 0=stop, 1=start                                                                                                                                                               |        \u2714          | \n| AudioPreview                | Enables audio preview during preview or broadcast                                       | 0=no preview, 1=visual preview (default, requires filter AudioVolume), 2=visual and audible preview, 3=audible preview  |       \u2714          | \n| Mp4RecordOnTheFly           | Enables start/stop recording to local file while the broadcast is running  | 0=off (default), 1=on                                                                                                                                                        |      \u2714           | \n| H264Quality                 | H.264 Encoder Quality/Speed Ratio                                                                 | 0=worst/fastest 1=default 6=highest/slowest                                                                                                                 |      \u2714           | \n| H264IFrameDistance              | H.264 I Frame / GOP Length in Frames (100 Frames = 4 seconds for 25 fps)   | 100=default, 1 = I-Frame-Only                                                                                                                              |                  \u2714                          |\n| H264PFrameDistance             | H.264 P/B Frame Distance                                                                   | 3 1 = IP-Only (no B-Frames)                                                                                                                                             |                  \u2714                          | \n| H264Profile              | H.264 Encoding Profile                                                          | Baseline, Main, Extended, High Most compatible but lowest quality is Baseline, (no B-Frames, no CABAC VLC)                                           |                  \u2714                          | \n| H264Level              | H.264 Level                                                           | 10=1.0, 11=1.1, 12=1.2, 13=1.3, 20=2.0, 21=2.1, 22=2.2, 30=3.0, 31=3.1, 32=3.2, 40=4.0, 41=4.1, 42=4.2, 50=5.0, 51=5.1                                         |                  \u2714                          |\n| H264VlcMode              | H.264 VLC Mode (CAVLC/CABAC)                                                          | =CAVLC, 2=CABAC (not allowed in H.264 Baseline Profile)                                                                                                     |                  \u2714                          |\n| OutputFrameRate             | Video Output (Encoded) Frame Rate                                                           | 5,10,15,20,25,30, OR 23980 OR 29970                                                                                                                          |       \u2714          | \n| RTMPWriteTimecode           | Send timecodes in RTMP streams, If enabled RTMP timecodes are sent in addition to the always sent RTMP packet timestamps | 0=off (default), 1=on                                                                 |      \u2714           |\n| UseSystemTimeAsTimecode              | Send RTMP/MP4 timecodes as UTC system date time or stream time                                                          | 0=stream time (default), 1=UTC system date time                                       |                  \u2714                          | \n| TimecodeInterval            | RTMP/MP4 timecode interval in milliseconds                                                | Should be higher or equal to 1000 (1s)                                                                                                                          |        \u2714         |\n| TcpConnectTimeout              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          | \n| RTSPSinkMode              | Determines if the RTSPSink is running as a server (passive/pull) or as a streamer to a RTSP push capable server (active/push) | 1=server/pull (default), 2=streamer/push                                            |                  \u2714                          | \n| RTSPSDPFileFolder              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          | \n| RTSPStreamDescription              |                                                           |                                                                                                                                                                                                                                             |                  \u2714                          |\n| AudioVolumePerSoftware              | Control volume with the Audio Volume Filter                                                          | 0=off (default), 1=on                                                                                                                                                                                                                                             |                  \u2714                          | \n| AVFShowBlackmagicDevices    | use AVFoundation for BlackMagic devices                                                                                                                                 | 0=off (default), 1=on                                                                 |       \u2714          |\n| OverlayRect                 | Sets the dimensions for a given overlay-image.  | \u201cindex,left,top,right,bottom\u201d. index: the overlay-index, beginning with 0. left, top, right and bottom define a rectangle in screen-coordinates.           |        \u2714         |\n| OverlayAlpha                | Sets the alpha-value for overlays.   | Range: 0-1. 0.0 (not visable), 1 (fully visable).                                                                                                                                                                                 |       \u2714          |\n| OverlayTextColor            | Text Overlay Color | Must be a hexadecimal color-value in BGR-format, e.g.: \u201c0000FF\u201d (255 (0x0000FF) - red)                                                                                                                                     |       \u2714          | \n| OverlayBackgroundColor      |                         | Must be a hexadecimal color-value in BGR-format, e.g.: \u201c000000\u201d (0 (0x000000) - black).                                                                                                                                   |       \u2714          | \n| OverlaySkipColor            | Setting skipcolor to a specific value will result in this color to be rendered transparent in the overlays.              | Example: If OverlayBackgroundColor was set to blue (\u201cFF0000\u201d) setting OverlaySkipColor to blue as well will result in a transparent background. Parameter must be a hexadecimal color-value in BGR-format, e.g.: \u201cFF0000\u201d (blue). Disable: Setting OverlaySkipColor to \u201cFF000000\u201d (ABGR) will disable the usage of skipcolor.                                                                                                                                                 |       \u2714          | \n| AudioDelay                  | Streaming Audio Delay / Offset (ms) |                                                                                                                                                                                                                                                      |        \u2714         |\n| ShowPropertyPageForDevice   | Calls the propertypage for a given device.                                                                               | 0 for device with index: 0                                                                                                         |         \u2714        |\n| UseQuicktimeH264Encoder              |                                                           |                                                                                                                                                                                                                               |                  \u2714                          | \n| RotateDegrees              | set the degrees by which video should be rotated, only works if UseRotation is set to on, set before StartPreview or StartBroadcast | 0/90/180/270                                                                           |                  \u2714                          |", 
            "title": "SetConfig Properties"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#mixmode", 
            "text": "NO_MIXING = 0 (if video mixing is not used)  LEFT_RIGHT_FULL = 1  LEFT_RIGHT_HALF = 2  TOP_BOTTOM = 3  INTERLACED_LINES = 4  INTERLACED_COLUMN = 5  ANAGLYPH = 6  PIC_IN_PIC_LEFT_TOP = 7  PIC_IN_PIC_RIGHT_TOP = 8  PIC_IN_PIC_LEFT_BOTTOM = 9  PIC_IN_PIC_RIGHT_BOTTOM = 10  VIDEO1_ONLY = 11  VIDEO2_ONLY = 12  REGION = 13  MAX = 14", 
            "title": "Mixmode"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#overlay_effects", 
            "text": "Overlay off = 0  Left Top = 1  Right Top = 2  Left Bottom = 3  Right bottom = 4  Free Postion = 5", 
            "title": "Overlay Effects"
        }, 
        {
            "location": "/nanostream/android/getting-started/", 
            "text": "nanoStream SDK for Android - Developer Manual\n\n\nPurpose\n\n\nThis documentation is about the nanoStream Live Video Streaming SDK for Android and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.\n\n\nRequirements\n\n\n\n\nAndroid 4.1+ (API Level 16)\n\n\n\n\nRequired application permissions:\n\n\n\n\nandroid.permission.INTERNET\n\n\nandroid.permission.RECORD_AUDIO\n\n\nandroid.permission.RECORD_VIDEO\n\n\n\n\nRequired application permission for local recording:\n\n\n\n\nandroid.permission.WRITE_EXTERNAL_STORAGE\n\n\n\n\nGetting Started\n\n\nCopy the SDK libraries into your Android Studio project\n\n\nAdd the \nnet.nanocosmos.nanoStream.jar\n java component to your Android Studio project by copying \n[SDK]/libs/net.nanocosmos.nanoStream.jar\n to the folder \n[projectpath]/app/libs/net.nanocosmos.nanoStream.jar\n Add the \nnanoStream.so\n native components to the Android Studio project by copying the 5 folders \n[SDK]/libs/[platform]/libRTMPStream.so\n to [projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so`\n\n\nPlatforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips\n\n\nAdd the nanoStream to the gradle file\n\n\nOpen the build.gradle file (Module:app) and add\n\n\ncompile files('libs/net.nanocosmos.nanoStream.jar')\n\n\n\n\nto the dependencies section.\n\n\nCheck library version\n\n\nString nanoStreamVersion = nanoStream.getVersion().fullVersion;\n\n\n\n\nInitialize the library\n\n\nImplement the interface \nnanoStreamEventListener\n in your class:\n\n\npublic class StreamActivity extends Activity implements NanostreamEventListener {\n  // implement your class\n\n  private class NotificationRunable implements Runnable {\n     private NanostreamEvent m_event;\n\n     public NotificationRunable(NanostreamEvent event) {\n      m_event = event;\n     }\n\n     @Override\n     public void run() {\n       Toast.makeText(getApplicationContext(), m_event.GetDescription(), Toast.LENGTH_SHORT).show();\n     }\n   }\n\n  @Override\n  public void onNanostreamEvent(NanostreamEvent event) {\n    if (event.GetType() != NanostreamEvent.TYPE_RTMP_QUALITY) {\n      this.runOnUiThread(new NotificationRunable(event));\n    }\n  }\n}\n\n\n\n\nConfigure the nanoStreamSettings object for the library:\n\n\n  private String license = \n--- add your nanoStream license here ---\n;\n  private String serverUrl = \nrtmp://example.org/live\n;\n  private String streamName = \nmyStream\n;\n  private nanoStream streamLib = null;\n\n  void initStreamLib() {\n    if(null == streamLib) {\n      nanoStreamSettings nss = new nanoStreamSettings();\n      nss.setLicense(license);\n      nss.setLogSettings(logSettings);\n      nss.setStreamUrl(serverUrl);\n      nss.setStreamName(streamName);\n      nss.setEventListener(this);\n\n      try {\n        streamLib = new nanoStream(nss);\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      }\n\n      if(null != streamLib) {\n        try {\n          streamLib.init();\n        } catch (NanostreamException e) {\n          Toast.makeText(getApplicationContext(), e.toString(), Toast.LENGTH_LONG).show();\n        } catch (IllegalArgumentException e) {\n          e.printStackTrace();\n        }\n      }\n    }\n  }\n\n\n\n\nStart/Stop the Stream:\n\n\npublic void toggleStreaming(View clicked) {\n  if (null == streamLib) {\n    Toast.makeText(getApplicationContext(), \nnanoStream failed to initialize\n, Toast.LENGTH_LONG).show();\n    return;\n  }\n\n  if (!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n    Toast.makeText(getApplicationContext(), \nStarting...\n, Toast.LENGTH_SHORT).show();\n\n    if (streamLib.hasState(nanoStream.EncoderState.STOPPED) || streamLib.hasState(nanoStream.EncoderState.CREATED)) {\n      try {\n        Logging.log(Logging.LogLevel.DEBUG, TAG, \ntoggleStreaming init nanoStream\n);\n        streamLib.init();\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n        return;\n      }\n    }\n\n    try {\n      streamLib.start();\n    } catch (NanostreamException en) {\n      Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      return;\n    }\n  } else {\n    Toast.makeText(getApplicationContext(), \nStopping...\n, Toast.LENGTH_SHORT).show();\n    streamLib.stop();\n  }\n}\n\n\n\n\nFurther questions? Would you like a feature not available yet?\n\n\nWe can make it work for you based on our consulting and development / implementation services. \nContact us\n\n\nCrash Logs\n\n\nIf you encounter a crash, please send us the crash log as explained in the following steps:\n\n\n\n\nPlug in the device and open Android Studio\n\n\nIn Android Studios Android Monitor\n\n\nClear the logcat output\n\n\nSet the Log Level to \nVerbose\n\n\nSet the filter to \nNo Filters\n\n\n\n\n\n\nRun the critical section\n\n\nMark the entire logcat output\n\n\nRight click in the logcat View and \nCopy as Plain Text\n\n\nOpen an editor of your choice\n\n\nPaste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Getting Started"
        }, 
        {
            "location": "/nanostream/android/getting-started/#nanostream_sdk_for_android_-_developer_manual", 
            "text": "", 
            "title": "nanoStream SDK for Android - Developer Manual"
        }, 
        {
            "location": "/nanostream/android/getting-started/#purpose", 
            "text": "This documentation is about the nanoStream Live Video Streaming SDK for Android and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.", 
            "title": "Purpose"
        }, 
        {
            "location": "/nanostream/android/getting-started/#requirements", 
            "text": "Android 4.1+ (API Level 16)", 
            "title": "Requirements"
        }, 
        {
            "location": "/nanostream/android/getting-started/#required_application_permissions", 
            "text": "android.permission.INTERNET  android.permission.RECORD_AUDIO  android.permission.RECORD_VIDEO", 
            "title": "Required application permissions:"
        }, 
        {
            "location": "/nanostream/android/getting-started/#required_application_permission_for_local_recording", 
            "text": "android.permission.WRITE_EXTERNAL_STORAGE", 
            "title": "Required application permission for local recording:"
        }, 
        {
            "location": "/nanostream/android/getting-started/#getting_started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/nanostream/android/getting-started/#copy_the_sdk_libraries_into_your_android_studio_project", 
            "text": "Add the  net.nanocosmos.nanoStream.jar  java component to your Android Studio project by copying  [SDK]/libs/net.nanocosmos.nanoStream.jar  to the folder  [projectpath]/app/libs/net.nanocosmos.nanoStream.jar  Add the  nanoStream.so  native components to the Android Studio project by copying the 5 folders  [SDK]/libs/[platform]/libRTMPStream.so  to [projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so`  Platforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips", 
            "title": "Copy the SDK libraries into your Android Studio project"
        }, 
        {
            "location": "/nanostream/android/getting-started/#add_the_nanostream_to_the_gradle_file", 
            "text": "Open the build.gradle file (Module:app) and add  compile files('libs/net.nanocosmos.nanoStream.jar')  to the dependencies section.", 
            "title": "Add the nanoStream to the gradle file"
        }, 
        {
            "location": "/nanostream/android/getting-started/#check_library_version", 
            "text": "String nanoStreamVersion = nanoStream.getVersion().fullVersion;", 
            "title": "Check library version"
        }, 
        {
            "location": "/nanostream/android/getting-started/#initialize_the_library", 
            "text": "Implement the interface  nanoStreamEventListener  in your class:  public class StreamActivity extends Activity implements NanostreamEventListener {\n  // implement your class\n\n  private class NotificationRunable implements Runnable {\n     private NanostreamEvent m_event;\n\n     public NotificationRunable(NanostreamEvent event) {\n      m_event = event;\n     }\n\n     @Override\n     public void run() {\n       Toast.makeText(getApplicationContext(), m_event.GetDescription(), Toast.LENGTH_SHORT).show();\n     }\n   }\n\n  @Override\n  public void onNanostreamEvent(NanostreamEvent event) {\n    if (event.GetType() != NanostreamEvent.TYPE_RTMP_QUALITY) {\n      this.runOnUiThread(new NotificationRunable(event));\n    }\n  }\n}  Configure the nanoStreamSettings object for the library:    private String license =  --- add your nanoStream license here --- ;\n  private String serverUrl =  rtmp://example.org/live ;\n  private String streamName =  myStream ;\n  private nanoStream streamLib = null;\n\n  void initStreamLib() {\n    if(null == streamLib) {\n      nanoStreamSettings nss = new nanoStreamSettings();\n      nss.setLicense(license);\n      nss.setLogSettings(logSettings);\n      nss.setStreamUrl(serverUrl);\n      nss.setStreamName(streamName);\n      nss.setEventListener(this);\n\n      try {\n        streamLib = new nanoStream(nss);\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      }\n\n      if(null != streamLib) {\n        try {\n          streamLib.init();\n        } catch (NanostreamException e) {\n          Toast.makeText(getApplicationContext(), e.toString(), Toast.LENGTH_LONG).show();\n        } catch (IllegalArgumentException e) {\n          e.printStackTrace();\n        }\n      }\n    }\n  }  Start/Stop the Stream:  public void toggleStreaming(View clicked) {\n  if (null == streamLib) {\n    Toast.makeText(getApplicationContext(),  nanoStream failed to initialize , Toast.LENGTH_LONG).show();\n    return;\n  }\n\n  if (!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n    Toast.makeText(getApplicationContext(),  Starting... , Toast.LENGTH_SHORT).show();\n\n    if (streamLib.hasState(nanoStream.EncoderState.STOPPED) || streamLib.hasState(nanoStream.EncoderState.CREATED)) {\n      try {\n        Logging.log(Logging.LogLevel.DEBUG, TAG,  toggleStreaming init nanoStream );\n        streamLib.init();\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n        return;\n      }\n    }\n\n    try {\n      streamLib.start();\n    } catch (NanostreamException en) {\n      Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      return;\n    }\n  } else {\n    Toast.makeText(getApplicationContext(),  Stopping... , Toast.LENGTH_SHORT).show();\n    streamLib.stop();\n  }\n}", 
            "title": "Initialize the library"
        }, 
        {
            "location": "/nanostream/android/getting-started/#further_questions_would_you_like_a_feature_not_available_yet", 
            "text": "We can make it work for you based on our consulting and development / implementation services.  Contact us", 
            "title": "Further questions? Would you like a feature not available yet?"
        }, 
        {
            "location": "/nanostream/android/getting-started/#crash_logs", 
            "text": "If you encounter a crash, please send us the crash log as explained in the following steps:   Plug in the device and open Android Studio  In Android Studios Android Monitor  Clear the logcat output  Set the Log Level to  Verbose  Set the filter to  No Filters    Run the critical section  Mark the entire logcat output  Right click in the logcat View and  Copy as Plain Text  Open an editor of your choice  Paste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Crash Logs"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/", 
            "text": "nanoStream SDK for Android Advanced Settings/Usage\n\n\nResolution, Aspect Ratio and Orientation\n\n\nResolution\n\n\nResolution means the native resolution of the camera (input). In the most situations this will be the same for the output. To set the resolution there is a function in the \nVideoSettings\n object called \nsetResolution(Resolution res)\n. If you set a resolution that the device doesn\nt support, nanoStream will automatically switch to the nearest resolution available on the device. A list of supported resolutions for the current video source can be obtained from \ngetCapabilities().listAvailableVideoResolutions()\n on the \nnanoStream\n object.\n\n\nAspect Ratio\n\n\nAspect ratio means the aspect ratio of the outgoing stream. The aspect ratio determines if the input video needs to be cropped. The aspect ratio can be set through the \nsetAspectRatio(AspectRatio aspectRatio)\n function on the \nVideoSettings\n object.\n\n\nSupported Aspect Ratios\n\n\n\n\n\n\n\n\nAspect Ratio\n\n\nAspectRatio value\n\n\n\n\n\n\n\n\n\n\nKeep Input\n\n\nAspectRatio.RATIO_KEEP_INPUT\n\n\n\n\n\n\n1:1\n\n\nAspectRatio.RATIO_1_1\n\n\n\n\n\n\n4:3\n\n\nAspectRatio.RATIO_4_3\n\n\n\n\n\n\n16:9\n\n\nAspectRatio.RATIO_16_9\n\n\n\n\n\n\n3:4\n\n\nAspectRatio.RATIO_3_4\n\n\n\n\n\n\n9:16\n\n\nAspectRatio.RATIO_9_16\n\n\n\n\n\n\n\n\nOrientation\n\n\nThe default stream orientation is landscape. If you switch to portrait the resolution will swap width and height, e.g. from 640x480 to 480x640. You can set the stream orientation on the \nnanoStream\n object with the \nsetStreamRotation\n function. The stream orientation needs to be set before starting the stream, it is not possible to switch the orientation during the stream.\n\n\nSupported Orientations\n\n\n\n\n\n\n\n\nOrientation\n\n\nRotation Value\n\n\n\n\n\n\n\n\n\n\nLandscape\n\n\nRotation.ROTATION_0\n\n\n\n\n\n\nPortrait\n\n\nRotation.ROTATION_90\n\n\n\n\n\n\nLandscape Upside Down\n\n\nRotation.ROTATION_180\n\n\n\n\n\n\nPortrait Upside Down\n\n\nRotation.ROTATION_270\n\n\n\n\n\n\n\n\nExample Combinations of Aspect Ratios and Orientations\n\n\nThe input resolution is set to 640x480 here. The red rectangle marks up the active area that is included in the output stream.\n\n\n\n\n\n\n\n\nOrientation\n\n\nAspect Ratio\n\n\nStream Area\n\n\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\nKeep Input\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n4:3\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n3:4\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n16:9\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n9:16\n\n\n\n\n\n\n\n\nLandscape\n\n\nKeep Input\n\n\n\n\n\n\n\n\nLandscape\n\n\n4:3\n\n\n\n\n\n\n\n\nLandscape\n\n\n3:4\n\n\n\n\n\n\n\n\nLandscape\n\n\n16:9\n\n\n\n\n\n\n\n\nLandscape\n\n\n9:16\n\n\n\n\n\n\n\n\n\n\n1\n: In this sample APP we crop the preview so it doesn\nt look ugly, so the stream is actually larger then the preview.\n\n\nExample\n\n\nIf you want to stream with a resolution of 640x360 but your device doesn\nt supports this resolution, you need to crop the resolution from 640x480 (this resolution is supported by the most devices) to 640x360. This can be done through the aspect ratio, so you need to set the aspect ratio to 16:9 to stream with a resolution of 640x360.\n\n\nImplementation Example\n\n\npublic class MainActifity {\n    ...\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n      super.onCreate(savedInstanceState);\n      nanoStreamSettings nss = new nanoStreamSettings();\n      VideoSettings vs = new VideoSettings();\n      ...\n      vs.setResolution(new Resolution(640, 480)); // default value\n      vs.setAspectRatio(AspectRatio.RATIO_16_9); // default value is AspectRatio.KEEP_INPUT\n      ...\n      streamLib = new nanoStream(nss);\n      streaLib.init();\n\n      streamLib.setStreamRotation(Rotation.ROTATION_0); // default value\n      ...\n    }\n    ...\n}\n\n\n\n\nRotationHelper\n\n\nDescription\n\n\nWith the nanoStream SDK 4.3.1 release we added a \nRotationHelper\n Class, this Class improves the Rotation handling. The RotationHelper class has two static Methods, \ngetDeviceDefaultOrientation(Context context)\n and \ngetRotation(int orientation, boolean isDefaultOrientationLandscape)\n.\n\n\ngetDeviceDefaultOrientation\n\n\nThe return values are one of the following:\n\n\n\n\nConfiguration.ORIENTATION_LANDSCAPE\n\n\nConfiguration.ORIENTATION_PORTRAIT\n\n\n\n\ngetRotation\n\n\nParameter\n\n\nThe \norientation\n parameter of the \ngetRoation\n Method is one of the following:\n\n\n\n\nActivityInfo.SCREEN_ORIENTATION_PORTRAIT\n\n\nActivityInfo.SCREEN_ORIENTATION_LANDSCAPE\n\n\nActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT\n\n\nActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE\n\n\n\n\nThe \nisDefaultOrientationLandscape\n parameter is true or false.\n\n\nReturn Values\n\n\nThe return values given from \nRotationHelper.getRoation\n can be used as a Parameter for \nsetStreamRotation\n and \nsetPreviewRotation\n. is the \norientation\n parameter non of the above described the \ngetRotation\n Method returns \nnull\n.\n\n\nImplementation Example\n\n\nimport net.nanocosmos.nanoStream.streamer.Rotation;\nimport net.nanocosmos.nanoStream.streamer.RotationHelper;\n\npublic class MainActivity extends Activity {\n  // ...\n  private boolean isDefaultOrientationLandscape = false;\n  private CustomOrientationEventListener orientation = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    // ...\n    streamLib = new nanoStream(/*settings*/);\n\n    isDefaultOrientationLandscape = (RotationHelper.getDeviceDefaultOrientation(this) == android.content.res.Configuration.ORIENTATION_LANDSCAPE);\n    orientation = new CustomOrientationEventListener(this, SensorManager.SENSOR_DELAY_UI);\n    orientation.enable();\n  }\n\n  private class CustomOrientationEventListener extends OrientationEventListener {\n    private int lastScreenOrientation = 0;\n    public CustomOrientationEventListener(Context context, int rate) {\n      super(context, rate);\n    }\n\n    @Override\n    public void onOrientationChanged(int orientation) {\n      if (null != streamLib) {\n        if(!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n          if (isDefaultOrientationLandscape) {\n              orientation -= 90;\n\n              if (orientation \n 0) {\n                  orientation += 360;\n              }\n          }\n          int screenOrientation = -1;\n\n          if (orientation \n 70 \n orientation \n 110) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE;\n          } else if (orientation \n 160 \n orientation \n 200) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT;\n          } else if (orientation \n 250 \n orientation \n 290) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE;\n          } else if ((orientation \n 340 \n orientation \n= 360) || (orientation \n= 0 \n orientation \n 20)) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_PORTRAIT;\n          }\n\n          if (screenOrientation != lastScreenOrientation) {\n            Rotation rotation = RotationHelper.getRotation(screenOrientation, isDefaultOrientationLandscape);\n            if (null != rotation) {\n              try {\n                streamLib.setPreviewRotation(rotation);\n                streamLib.setStreamRotation(rotation);\n                streamLib.setAspectRatio(videoAspectRatio);\n              } catch (IllegalStateException e) {\n                Logging.log(Logging.LogLevel.ERROR, TAG, \nCamera rotate failed\n, e);\n              }\n            }\n            lastScreenOrientation = screenOrientation;\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\n\nStream Type\n\n\nThe SDK supports differnet streaming modes:\n\n\n\n\nVideo and Audio\n\n\nVideo only\n\n\nAudio only\n\n\n\n\nYou can en/disable Video/Audio in the \nnanoStreamSettings\n.\n\n\nImplementation Example\n\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setHaveVideo(true); // false\nnss.setHaveAudio(true); // false\n\n\n\n\nLocal Recording\n\n\nDescription\n\n\nThe nanoStream Android SDK supports local file recording on the device in MP4 format. This document describes how to enable and configure nanoStream for local recording.\n\n\nSteps to configure MP4 recording\n\n\nMP4 recording can be configured with two function calls on a nanoStreamSettings object.\n\n\n\n\nEnabling MP4 recording: setRecordMp4(boolean)\n\n\nSetting up the file path: setMp4Path(String)\n\n\n\n\nsetRecordMp4(boolean)\n\n\nThe setRecordMp4 function takes a boolean as parameter to enable/disable the recording function.\n\n\nsetMp4Path(String)\n\n\nThe setMp4Path function takes a String as parameter. This string needs to be a valid file path (e.g. /sdcard/test.mp4).\nIt is recommended to use the getExternalStorageDirectory or getExternalStoragePublicDirectory functions from the\n\nAndroid Enviroment\n API, and add a file name to the returned path. Please find the code snippet below as an example.\n\n\nAndroid Permission\n\n\nTo be able to write to an external file path your Android app needs the following permissions to be added to the app manifest (AndroidMainfest.xml).\n\n\nuses-permission android:name=\nandroid.permission.WRITE_EXTERNAL_STORAGE\n /\n\n\nuses-permission android:name=\nandroid.permission.STORAGE\n /\n\n\n\n\n\nAndroid 6.0\n\n\nDue to the new permission handling in Android 6 (M) writing to external directories (DCIM) requires a permission by user. Writing to the applications own data directory (/Android/data/com.companyname.appname/) is not restricted.\n\n\nImplementation Example\n\n\nFile externalFilePath = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM);\nFile filePath = new File(externalFilePath, \nmyMp4File.mp4\n);\nString mp4FilePath = filePath.getAbsolutePath();\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setRecordMp4(true);\nnss.setMp4Path(mp4FilePath);\n\n\n\n\nAdaptive Bitrate Streaming\n\n\nBy using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth. There are four modes available:\n\n\n\n\nDISABLED: The Adaptive Bitrate Control is disabled.\n\n\nQUALITY_DEGRADE: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.\n\n\nFRAME_DROP: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.\n\n\nQUALITY_DEGRADE_AND_FRAME_DROP: The video quality and the framerate (FPS) decreased if the not enough bandwidth is available.\n\n\n\n\nMake sure to set the ABC settings before a stream is started.\n\n\nImplementation Example\n\n\nprivate AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode abcMode = AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode.QUALITY_DEGRADE_AND_FRAME_DROP;\nprivate int videoBitrate = 500000;\n\nprivate void initStreamLib() {\n  AdaptiveBitrateControlSettings abcSettings = new AdaptiveBitrateControlSettings(abcMode);\n  abcSettings.SetMaximumBitrate((int)(videoBitrate * 1.5));\n\n  nanoStreamSettings nss = new nanoStreamSettings();\n  nss.setAbcSettings(abcSettings);\n}\n\n\n\n\nMeasuring the available bandwidth\n\n\nFor measuring the available bandwidth you can use the method \nrunBandwidthCheck\n. After the check finished, the result can be used to set the bitrate for the nanoStream object.\nThe check measures the bandwidth by running a test stream to the server.\n\n\nThe BandwidthCheck Class has three public functions:\n\n\n\n\nrunBandwidthCheck(BandwidthCheckSettings settings, BandwidthCheckResultCallback callback()\n\n\nforceStop()\n\n\nabort()\n\n\n\n\nThere is a BandwidthCheckSettings Class, the constructor creates a standard object of BandwidthCheckSettings, with the following settings:\n\n\n\n\n\n\n\n\nproperty\n\n\ndefault values\n\n\nmeaning\n\n\n\n\n\n\n\n\n\n\nprerollSeconds\n\n\n1 (in sec.)\n\n\nthis is the pre roll time to connect to the server\n\n\n\n\n\n\nrunTime\n\n\n5 (in sec.)\n\n\nthe run time of the bandwidth check\n\n\n\n\n\n\nmaxBitrate\n\n\n3000000 (bit/s = 3 MBit/s)\n\n\nthe maximum bit rate for the bandwidth check\n\n\n\n\n\n\nrtmpUrl\n\n\nempty\n\n\nthe rtmp url for the bandwidth check\n\n\n\n\n\n\nstreamId\n\n\nempty\n\n\nthe stream id for the bandwidth check\n\n\n\n\n\n\n\n\nWith this settings you can call the runBandwidthCheck methode, the second parameter is the callback for the results. This callback class has a finished method that will be called after bandwidth check is done.\nThe finished method has one parameter from type BandwidthCheckResult, this object has 6 getter methods:\n\n\n\n\ngetAverageBitrate() // the average measured bandwidth\n\n\ngetMedianBitrate() // the median measured bandwidth\n\n\ngetMaxBitrate() // the maximum measured bandwidth\n\n\ngetMinBitrate() // the minimum measured bandwidth\n\n\ngetRunTimeMS() // the run time in ms\n\n\ngetErrorCode() // the error code if all is ok this is nanoResults.N_OK (all error codes can be found in the nanoStream API Reference documentation for nanoResults)\n\n\n\n\nThe forceStop call stops the bandwidth check and will return the results that where measured until then. The abort call stops the bandwidth check but don\nt return any results.\n\n\nThe bandwidth check, sends a special type of metadata that will not be recorded on the Streaming Server.\n\n\nImplementation Example\n\n\nprivate BandwidthCheck bwCheck = null;\n\nprivate class CustomBandwidthCheckResultCallback implements BandwidthCheckResultCallback {\n  @Override\n  public void finished(final BandwidthCheckResult bandwidthCheckResult) {\n    Log.d(TAG, \nBandwidthCheck results: \n +\n      \n\\n\\tAverage Bitrate (kBit/s): \n + bandwidthCheckResult.getAverageBitrate() / 1000 +\n      \n\\n\\tMedian Bitrate  (kBit/s): \n + bandwidthCheckResult.getMedianBitrate() / 1000 +\n      \n\\n\\tMax Bitrate     (kBit/s): \n + bandwidthCheckResult.getMaxBitrate() / 1000 +\n      \n\\n\\tMin Bitrate     (kBit/s): \n + bandwidthCheckResult.getMinBitrate() / 1000 +\n      \n\\n\\tRun Time        (ms)    : \n + bandwidthCheckResult.getRunTimeMS());\n  }\n}\n\nprivate void initBandwidthCheck() {\n  if(null == bwCheck) {\n    BandwidthCheckSettings settings = new BandwidthCheckSettings();\n    settings.setRtmpUrl(serverUrl);\n    settings.setStreamId(streamName);\n    bwCheck = new BandwidthCheck();\n    bwCheck.runBandwidthCheck(settings, new CustomBandwidthCheckResultCallback());\n  }\n}\n\n\n\n\nRTMP Quality Statistics\n\n\nDescription\n\n\nThe RTMP Module provides the current RTMP Quality over the \nNanostreamEventListener\n. These includes the \noutput bit rate\n, \nbuffer fullness\n, \nbit rate\n and \nframe rate\n.\n\n\nImplementation Example\n\n\npublic class MainActivity extends Activity implements NanostreamEventListener {\n  private LinearLayout qualityView = null;\n    private TextView outputBitrate = null;\n    private TextView bufferFullness = null;\n    private TextView bitrate = null;\n    private TextView framerate = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    qualityView = (LinearLayout) findViewById(R.id.qualityView);\n        outputBitrate = (TextView) findViewById(R.id.outputBitrateText);\n        bufferFullness = (TextView) findViewById(R.id.bufferfillnessText);\n        bitrate = (TextView) findViewById(R.id.bitrateText);\n        framerate = (TextView) findViewById(R.id.framerateText);\n\n    // Init nanoStream    \n  }\n\n  @Override\n    public void onNanostreamEvent(NanostreamEvent event)\n    {\n        if (event.GetType() == NanostreamEvent.TYPE_RTMP_QUALITY)\n        {\n            this.runOnUiThread(new ViewQualityRunnable(event));\n        }\n    }\n\n  private class ViewQualityRunnable implements Runnable\n    {\n        private NanostreamEvent m_event;\n        private DecimalFormat format;\n\n        public ViewQualityRunnable(NanostreamEvent m_event)\n        {\n            super();\n            this.m_event = m_event;\n            format = new DecimalFormat(\n#0.00\n);\n        }\n\n        @Override\n        public void run()\n        {\n            if (qualityView.getAlpha() == 0 \n m_event.GetParam1() != 0 \n m_event.GetParam2() != 0 \n m_event.GetParam3() != 0 \n m_event.GetParam4() != 0)\n            {\n                qualityView.setAlpha(0.5f);\n            }\n            int qualityColor = Color.YELLOW;\n            if (m_event.GetParam2() \n= 1000)\n            {\n                qualityColor = Color.rgb(255, 0, 0);\n            } else if (m_event.GetParam2() \n= 750)\n            {\n                qualityColor = Color.YELLOW;\n            } else if (m_event.GetParam2() \n= 750)\n            {\n                qualityColor = Color.GREEN;\n            }\n\n            outputBitrate.setText(Long.toString(m_event.GetParam1() / 1000) + \nkbit/s\n);\n            outputBitrate.setTextColor(qualityColor);\n            bufferFullness.setText(format.format(((double) m_event.GetParam2() / 100.0)) + \n%\n);\n            bufferFullness.setTextColor(qualityColor);\n            bitrate.setText(Long.toString(m_event.GetParam3() / 1000) + \nkbit/s\n);\n            framerate.setText(m_event.GetParam4() + \nfps\n);\n\n        }\n    }\n}\n\n\n\n\nCamera Zoom\n\n\nDescription\n\n\nThe nanoStream Android SDK supports camera zoom, if the internal camera supports it. Therefor there are a few functions, the most important are:\n\n\n\n\n\n\n\n\nFunction\n\n\nReturn Type\n\n\nreturns\n\n\n\n\n\n\n\n\n\n\nhasZoom()\n\n\nbooelan\n\n\ntrue if zoom is supported by the video source / device\n\n\n\n\n\n\ngetZoomRatios()\n\n\nList\nInteger\n\n\nlist with of ale zoom ratios\n\n\n\n\n\n\ngetZoom()\n\n\nint\n\n\nthe index of the \nList\nInteger\n that returned from \ngetZommRatios()\n\n\n\n\n\n\nsetZoom(int)\n\n\nint\n\n\nthe new index of the \nList\nInteger\n that returned from \ngetZommRatios()\n\n\n\n\n\n\n\n\nIt is recommended to use \npinch to zoom\n, therefor you need to implement a \nScaleGestureDetector.SimpleOnScaleGestureListener\n, and a \npinch2zoom\n function, that takes the \nscalefactor\n from the \nSimpleOnScaleGestureListener\n as a int parameter, take a look at the \nImplementation Example\n.\n\n\ngetZoomRatios()\n\n\ngetZoomRatios()\n returns a List of Integer values, this values are the zoom ratios in 1/100 increments (e.g. a zoom of 3.2x is returned as 320).\n\n\nsetZoom(int)\n\n\nThe int parameter from \nsetZoom(int zoom)\n is the index of zoom ratios that returns \ngetZoomRatios()\n.\n\n\nZoom Behavior on Camera Switch\n\n\nDuring a camera switch (e.g. from back to front) the zoom remains unaffected.\n\n\nImplementation Example\n\n\npublic class MainActivity extends Activity {\n  private ScaleGestureDetector scaleGestureDetector;\n  private List\nInteger\n mZoomRatios = null;\n\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n\n    nanoStreamSettings nss = new nanoStreamSettings();\n    // configure nanoStreamSettings\n\n    streamLib = new nanoStream(nss);\n\n    if(streamLib.hasZoom()) {\n      mZoomRatios = streamLib.getZoomRatio();\n    }\n\n    if(null == scaleGestureDetector) {\n      scaleGestureDetector = new ScaleGestureDetector(this, new ScaleGestureListener());\n    }\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (scaleGestureDetector != null)\n    {\n      scaleGestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n\n  private class ScaleGestureListener extends ScaleGestureDetector.SimpleOnScaleGestureListener {\n    @Override\n    public boolean onScale(ScaleGestureDetector detector) {\n      if(null != streamLib) {\n        if (streamLib.hasZoom()) {\n          pinch2Zoom(detector.getScaleFactor());\n        }\n      }\n      return true;\n    }\n  }\n\n  public void pinch2Zoom(float scaleFactor) {\n    if (streamLib.hasZoom() \n null != mZoomRatios) {\n      int zoomFactor = streamLib.getZoom();\n      float zoomRatio = mZoomRatios.get(zoomFactor) / 100f;\n      zoomRatio *= scaleFactor;\n      if (zoomRatio \n 1.0f) {\n        if (scaleFactor \n 1.0f) {\n          for (int i = zoomFactor; i \n mZoomRatios.size(); i++) {\n            Double zoom = mZoomRatios.get(i) / 100.0;\n            if (zoom \n= zoomRatio) {\n              streamLib.setZoom(i);\n              break;\n            }\n          }\n        } else {\n          for (int i = zoomFactor; i \n 0; i--) {\n            Double zoom = mZoomRatios.get(i) / 100.0;\n            if (zoom \n= zoomRatio) {\n              streamLib.setZoom(i);\n              break;\n            }\n          }\n        }\n      }\n    }\n  }   \n}\n\n\n\n\nCamera Focus\n\n\nDescription\n\n\nThe nanoStream Android SDK supports camera focus and focus lock, if the internal cameras supports them. There are two non-blocking functions\n\n\nsetFocusArea(int focusWidth, int focusHeight, float areaMultiple, int x,\n    int y, int previewWidth, int previewHeight, int weigh)\nsetFocusLockArea(int focusWidth, int focusHeight, float areaMultiple, int x,\n    int y, int previewWidth, int previewHeight, int weigh)\n\n\n\n\nthrough the\n\n\naddFocusCalback(FocusCallback callback)\nremoveFocusCalback(FocusCallback callback)\n\n\n\n\nyou can attach or remove a FocusCallback listener. To check if your device supports focus call the function\n\n\nisFocusSupported()\n\n\n\n\nwhich will return true or false.\n\n\nParameter List\n\n\n\n\n\n\n\n\nParameter name\n\n\nmeaning\n\n\n\n\n\n\n\n\n\n\nfocusWidth\n\n\nthe focus Area width\n\n\n\n\n\n\nfocusHeight\n\n\nthe focus Area height\n\n\n\n\n\n\nareaMultiple\n\n\na Multiple for the focus area (default: 1f)\n\n\n\n\n\n\nx\n\n\nthe x position on the Screen\n\n\n\n\n\n\ny\n\n\nthe y position on the Screen\n\n\n\n\n\n\npreviewWidth\n\n\nthe width of the preview\n\n\n\n\n\n\npreviewHeight\n\n\nthe height of the preview\n\n\n\n\n\n\nweight\n\n\nthe weight of the area must be range from 1 to 1000\n\n\n\n\n\n\n\n\nFocusCallback interface\n\n\nThe FocusCallback interface has three abstract functions\n\n\nonSuccess()\nonSuccess(Rect rect, Boolean focusLock)\nonFailure()\n\n\n\n\nImplementation Example\n\n\npublic class MainActifity extens Actifity implements FocusCallback {\n  private GestureDetector gestureDetector;\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    streamLib = new nanoStream(new nanoStreamSettings());\n    if(streamLib.isFocusSupported()) {\n      gestureDetector = new GestureDetector(this, new GestureListener());\n    }\n    ...\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (gestureDetector != null)\n    {\n        gestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n  ....\n  private class GestureListener implements OnGestureListener {\n    @Override\n    public boolean onSingleTapUp(MotionEvent e)\n    {\n      if (streamLib != null)\n        {\n          streamLib.setFocusArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n        }\n        return true;\n    }\n\n    @Override\n    public void onLongPress(MotionEvent e)\n    {\n      if (streamLib != null)\n      {\n        streamLib.setFocusLockArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n      }\n    }\n  }\n\n  @Override\n  public void onSuccess(Rect rect, Boolean aBoolean) {\n    Log.i(TAG, \nfocus success\n);\n  }\n\n  @Override\n  public void onFailure() {\n    Log.i(TAG, \nfocus failed\n);\n  }\n}\n\n\n\n\nSnapshot from the current stream\n\n\nTo get a snapshot (image) of the current preview/stream, the method \ntakeSnapshot\n can be used. This is a non blocking function, for the result you need to implement the SnapshotCallback interface. The snapshot returns as a base64 encoded JPEG\n\n\nImplementation Example\n\n\nprivate class CustomSnapshotCallback implements SnapshotCallback {\n  @Override\n  void onSuccess(String arg0){\n    // do something with the base64 encoded JPEG.\n  }\n\n  @Override\n void onFailure(){\n   Log.d(TAG, \ntakeSnapshot() failed!\n)\n }\n}\nprivate void shapshot() {\n  streamLib.takeSnapshot(new CustomSnapshotCallback());\n}\n\n\n\n\nServer Authentication\n\n\nIn case authentication is required, the credentials can be set on the \nnanoStreamSettings\n object.\n\n\nImplementation Example\n\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setAuthUser(\nuser\n);\nnss.setAuthPassword(\npassword\n);\n\n\n\n\nDeviceProperties\n\n\nBefore Android 4.3 there was no obligation for Android hardware manufacturers to pass the video related parts of the CTS (Compatibility Test Suite). Therefore some Android 4.1 and 4.2 Devices show non standard behaviour in regard to color format definitions and representation of video frames in memory. This could lead to issues in the video stream like switched red and blue colors, dislocated color components or a green bar at the bottom of the video frame. nanoStream Android now provides the functionality to detect and compensate common issues related to this.\n\n\nDescription\n\n\nnanoStream.getDeviceProperties()\n is a static function that is running a test on the device hardware to detect non standard behaviour and returning a DeviceProperties object containing the result.\nDeviceProperties.getFlags()\n returns the test result as an integer value that can be stored in the application preferences, to avoid running the device test on every app start. DeviceProperties can be applied to a new nanoStream instance by calling \nnanoStream.setDeviceProperties(DeviceProperties)\n. We recommend to call \ngetDeviceProperties()\n in a background thread during the first app start on a pre 4.3 device, because the call is blocking and might last up to 5 seconds on older/weaker devices. We also recommend to store the OS version in the preferences, to be able to detect OS updates and to eventually rerun the device test or stop setting the DeviceProperties if the new OS is 4.3 or higher.\n\n\nImplementation Example\n\n\npublic class App extends Application {\n  private static DeviceProperties deviceProp = null;\n\n  public void onCreate(){\n    super.onCreate();\n\n    Thread chkThread = new Thread(new Runnable(){\n      @Override\n      public void run() {\n        try {\n          SharedPreferences prefs = PreferenceManager.getDefaultSharedPreferences(getApplicationContext());\n          int curApiVer = android.os.Build.VERSION.SDK_INT;\n          int curAppVer = getPackageManager().getPackageInfo(getPackageName(), 0).versionCode;\n          int curEncVer = DeviceProperties.VERSION;\n\n          int oldApiVer = prefs.getInt(\nPref_Android_API\n, 0);\n          int oldAppVer = prefs.getInt(\nPref_App_Version\n, 0);\n          int oldChkVer = prefs.getInt(\nPref_Check_Version\n, 0);\n          int oldChkResult = prefs.getInt(\nPref_Check_Result\n, -1);\n\n          if (((oldApiVer * oldAppVer * oldApiVer) == 0)\n          || (oldApiVer \n curApiVer)\n          || (oldAppVer \n curAppVer)\n          || (oldChkVer \n curEncVer)\n          || oldChkResult \n 0) {\n            Editor edit = prefs.edit();\n            edit.putInt(\nPref_Android_API\n, curApiVer);\n            edit.putInt(\nPref_App_Version\n, curAppVer);\n\n            /* Run  device check */\n            try {\n              deviceProp = nanoStream.getDeviceProperties();\n              edit.putInt(\nPref_Check_Result\n, deviceProp.getFlags());\n              edit.putInt(\nPref_Check_Version\n, deviceProp.getVersion());\n              edit.commit();\n            } catch (RuntimeException e) {\n              Log.d(\nDevice Check failed\n, e.toString());\n              edit.putInt(\nPref_Check_Result\n, -1);\n              edit.putInt(\nPref_Check_Version\n, 0);\n              edit.commit();\n            }\n          } else {\n            deviceProp = new DeviceProperties(oldChkResult);\n          }\n            Log.d(\nDevice Properties: \n, deviceProp.toString());\n        } catch (Exception e) {\n          Log.d(this.getClass().getName(), \nDevice Check Runnable\n);\n          e.printStackTrace();\n        }\n      }\n    });\n    if (android.os.Build.VERSION.SDK_INT \n 18) {\n      chkThread.start();\n    }\n        ...\n  }\n\n  public static DeviceProperties getDeviceProperties()\n  {\n    return deviceProp;\n  }\n}\n\n\n\n\npublic class MainActivity extends Activity implements NanostreamEventListener {\n  ...\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    try {\n      nanoStreamSettings nss = new nanoStreamSettings();\n      streamLib = new nanoStream(nss);\n\n      DeviceProperties deviceProperties = App.getDeviceProperties();\n      if(null != streamLib \n null != deviceProperties) {\n        streamLib.setDeviceProperties(deviceProperties);\n      }\n    } catch(NanostreamException en) {\n      Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n    }\n  }\n  ...\n}", 
            "title": "Advanced Settings/Usage"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#nanostream_sdk_for_android_advanced_settingsusage", 
            "text": "", 
            "title": "nanoStream SDK for Android Advanced Settings/Usage"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#resolution_aspect_ratio_and_orientation", 
            "text": "", 
            "title": "Resolution, Aspect Ratio and Orientation"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#resolution", 
            "text": "Resolution means the native resolution of the camera (input). In the most situations this will be the same for the output. To set the resolution there is a function in the  VideoSettings  object called  setResolution(Resolution res) . If you set a resolution that the device doesn t support, nanoStream will automatically switch to the nearest resolution available on the device. A list of supported resolutions for the current video source can be obtained from  getCapabilities().listAvailableVideoResolutions()  on the  nanoStream  object.", 
            "title": "Resolution"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#aspect_ratio", 
            "text": "Aspect ratio means the aspect ratio of the outgoing stream. The aspect ratio determines if the input video needs to be cropped. The aspect ratio can be set through the  setAspectRatio(AspectRatio aspectRatio)  function on the  VideoSettings  object.", 
            "title": "Aspect Ratio"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#supported_aspect_ratios", 
            "text": "Aspect Ratio  AspectRatio value      Keep Input  AspectRatio.RATIO_KEEP_INPUT    1:1  AspectRatio.RATIO_1_1    4:3  AspectRatio.RATIO_4_3    16:9  AspectRatio.RATIO_16_9    3:4  AspectRatio.RATIO_3_4    9:16  AspectRatio.RATIO_9_16", 
            "title": "Supported Aspect Ratios"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#orientation", 
            "text": "The default stream orientation is landscape. If you switch to portrait the resolution will swap width and height, e.g. from 640x480 to 480x640. You can set the stream orientation on the  nanoStream  object with the  setStreamRotation  function. The stream orientation needs to be set before starting the stream, it is not possible to switch the orientation during the stream.", 
            "title": "Orientation"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#supported_orientations", 
            "text": "Orientation  Rotation Value      Landscape  Rotation.ROTATION_0    Portrait  Rotation.ROTATION_90    Landscape Upside Down  Rotation.ROTATION_180    Portrait Upside Down  Rotation.ROTATION_270", 
            "title": "Supported Orientations"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#example_combinations_of_aspect_ratios_and_orientations", 
            "text": "The input resolution is set to 640x480 here. The red rectangle marks up the active area that is included in the output stream.     Orientation  Aspect Ratio  Stream Area      Portrait 1  Keep Input     Portrait 1  4:3     Portrait 1  3:4     Portrait 1  16:9     Portrait 1  9:16     Landscape  Keep Input     Landscape  4:3     Landscape  3:4     Landscape  16:9     Landscape  9:16      1 : In this sample APP we crop the preview so it doesn t look ugly, so the stream is actually larger then the preview.", 
            "title": "Example Combinations of Aspect Ratios and Orientations"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#example", 
            "text": "If you want to stream with a resolution of 640x360 but your device doesn t supports this resolution, you need to crop the resolution from 640x480 (this resolution is supported by the most devices) to 640x360. This can be done through the aspect ratio, so you need to set the aspect ratio to 16:9 to stream with a resolution of 640x360.", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example", 
            "text": "public class MainActifity {\n    ...\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n      super.onCreate(savedInstanceState);\n      nanoStreamSettings nss = new nanoStreamSettings();\n      VideoSettings vs = new VideoSettings();\n      ...\n      vs.setResolution(new Resolution(640, 480)); // default value\n      vs.setAspectRatio(AspectRatio.RATIO_16_9); // default value is AspectRatio.KEEP_INPUT\n      ...\n      streamLib = new nanoStream(nss);\n      streaLib.init();\n\n      streamLib.setStreamRotation(Rotation.ROTATION_0); // default value\n      ...\n    }\n    ...\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#rotationhelper", 
            "text": "", 
            "title": "RotationHelper"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#description", 
            "text": "With the nanoStream SDK 4.3.1 release we added a  RotationHelper  Class, this Class improves the Rotation handling. The RotationHelper class has two static Methods,  getDeviceDefaultOrientation(Context context)  and  getRotation(int orientation, boolean isDefaultOrientationLandscape) .", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#getdevicedefaultorientation", 
            "text": "The return values are one of the following:   Configuration.ORIENTATION_LANDSCAPE  Configuration.ORIENTATION_PORTRAIT", 
            "title": "getDeviceDefaultOrientation"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#getrotation", 
            "text": "", 
            "title": "getRotation"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#parameter", 
            "text": "The  orientation  parameter of the  getRoation  Method is one of the following:   ActivityInfo.SCREEN_ORIENTATION_PORTRAIT  ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE  ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT  ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE   The  isDefaultOrientationLandscape  parameter is true or false.", 
            "title": "Parameter"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#return_values", 
            "text": "The return values given from  RotationHelper.getRoation  can be used as a Parameter for  setStreamRotation  and  setPreviewRotation . is the  orientation  parameter non of the above described the  getRotation  Method returns  null .", 
            "title": "Return Values"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_1", 
            "text": "import net.nanocosmos.nanoStream.streamer.Rotation;\nimport net.nanocosmos.nanoStream.streamer.RotationHelper;\n\npublic class MainActivity extends Activity {\n  // ...\n  private boolean isDefaultOrientationLandscape = false;\n  private CustomOrientationEventListener orientation = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    // ...\n    streamLib = new nanoStream(/*settings*/);\n\n    isDefaultOrientationLandscape = (RotationHelper.getDeviceDefaultOrientation(this) == android.content.res.Configuration.ORIENTATION_LANDSCAPE);\n    orientation = new CustomOrientationEventListener(this, SensorManager.SENSOR_DELAY_UI);\n    orientation.enable();\n  }\n\n  private class CustomOrientationEventListener extends OrientationEventListener {\n    private int lastScreenOrientation = 0;\n    public CustomOrientationEventListener(Context context, int rate) {\n      super(context, rate);\n    }\n\n    @Override\n    public void onOrientationChanged(int orientation) {\n      if (null != streamLib) {\n        if(!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n          if (isDefaultOrientationLandscape) {\n              orientation -= 90;\n\n              if (orientation   0) {\n                  orientation += 360;\n              }\n          }\n          int screenOrientation = -1;\n\n          if (orientation   70   orientation   110) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE;\n          } else if (orientation   160   orientation   200) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT;\n          } else if (orientation   250   orientation   290) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE;\n          } else if ((orientation   340   orientation  = 360) || (orientation  = 0   orientation   20)) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_PORTRAIT;\n          }\n\n          if (screenOrientation != lastScreenOrientation) {\n            Rotation rotation = RotationHelper.getRotation(screenOrientation, isDefaultOrientationLandscape);\n            if (null != rotation) {\n              try {\n                streamLib.setPreviewRotation(rotation);\n                streamLib.setStreamRotation(rotation);\n                streamLib.setAspectRatio(videoAspectRatio);\n              } catch (IllegalStateException e) {\n                Logging.log(Logging.LogLevel.ERROR, TAG,  Camera rotate failed , e);\n              }\n            }\n            lastScreenOrientation = screenOrientation;\n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#stream_type", 
            "text": "The SDK supports differnet streaming modes:   Video and Audio  Video only  Audio only   You can en/disable Video/Audio in the  nanoStreamSettings .", 
            "title": "Stream Type"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_2", 
            "text": "nanoStreamSettings nss = new nanoStreamSettings();\nnss.setHaveVideo(true); // false\nnss.setHaveAudio(true); // false", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#local_recording", 
            "text": "", 
            "title": "Local Recording"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#description_1", 
            "text": "The nanoStream Android SDK supports local file recording on the device in MP4 format. This document describes how to enable and configure nanoStream for local recording.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#steps_to_configure_mp4_recording", 
            "text": "MP4 recording can be configured with two function calls on a nanoStreamSettings object.   Enabling MP4 recording: setRecordMp4(boolean)  Setting up the file path: setMp4Path(String)", 
            "title": "Steps to configure MP4 recording"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#setrecordmp4boolean", 
            "text": "The setRecordMp4 function takes a boolean as parameter to enable/disable the recording function.", 
            "title": "setRecordMp4(boolean)"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#setmp4pathstring", 
            "text": "The setMp4Path function takes a String as parameter. This string needs to be a valid file path (e.g. /sdcard/test.mp4).\nIt is recommended to use the getExternalStorageDirectory or getExternalStoragePublicDirectory functions from the Android Enviroment  API, and add a file name to the returned path. Please find the code snippet below as an example.", 
            "title": "setMp4Path(String)"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#android_permission", 
            "text": "To be able to write to an external file path your Android app needs the following permissions to be added to the app manifest (AndroidMainfest.xml).  uses-permission android:name= android.permission.WRITE_EXTERNAL_STORAGE  /  uses-permission android:name= android.permission.STORAGE  /", 
            "title": "Android Permission"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#android_60", 
            "text": "Due to the new permission handling in Android 6 (M) writing to external directories (DCIM) requires a permission by user. Writing to the applications own data directory (/Android/data/com.companyname.appname/) is not restricted.", 
            "title": "Android 6.0"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_3", 
            "text": "File externalFilePath = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM);\nFile filePath = new File(externalFilePath,  myMp4File.mp4 );\nString mp4FilePath = filePath.getAbsolutePath();\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setRecordMp4(true);\nnss.setMp4Path(mp4FilePath);", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#adaptive_bitrate_streaming", 
            "text": "By using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth. There are four modes available:   DISABLED: The Adaptive Bitrate Control is disabled.  QUALITY_DEGRADE: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.  FRAME_DROP: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.  QUALITY_DEGRADE_AND_FRAME_DROP: The video quality and the framerate (FPS) decreased if the not enough bandwidth is available.   Make sure to set the ABC settings before a stream is started.", 
            "title": "Adaptive Bitrate Streaming"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_4", 
            "text": "private AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode abcMode = AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode.QUALITY_DEGRADE_AND_FRAME_DROP;\nprivate int videoBitrate = 500000;\n\nprivate void initStreamLib() {\n  AdaptiveBitrateControlSettings abcSettings = new AdaptiveBitrateControlSettings(abcMode);\n  abcSettings.SetMaximumBitrate((int)(videoBitrate * 1.5));\n\n  nanoStreamSettings nss = new nanoStreamSettings();\n  nss.setAbcSettings(abcSettings);\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#measuring_the_available_bandwidth", 
            "text": "For measuring the available bandwidth you can use the method  runBandwidthCheck . After the check finished, the result can be used to set the bitrate for the nanoStream object.\nThe check measures the bandwidth by running a test stream to the server.  The BandwidthCheck Class has three public functions:   runBandwidthCheck(BandwidthCheckSettings settings, BandwidthCheckResultCallback callback()  forceStop()  abort()   There is a BandwidthCheckSettings Class, the constructor creates a standard object of BandwidthCheckSettings, with the following settings:     property  default values  meaning      prerollSeconds  1 (in sec.)  this is the pre roll time to connect to the server    runTime  5 (in sec.)  the run time of the bandwidth check    maxBitrate  3000000 (bit/s = 3 MBit/s)  the maximum bit rate for the bandwidth check    rtmpUrl  empty  the rtmp url for the bandwidth check    streamId  empty  the stream id for the bandwidth check     With this settings you can call the runBandwidthCheck methode, the second parameter is the callback for the results. This callback class has a finished method that will be called after bandwidth check is done.\nThe finished method has one parameter from type BandwidthCheckResult, this object has 6 getter methods:   getAverageBitrate() // the average measured bandwidth  getMedianBitrate() // the median measured bandwidth  getMaxBitrate() // the maximum measured bandwidth  getMinBitrate() // the minimum measured bandwidth  getRunTimeMS() // the run time in ms  getErrorCode() // the error code if all is ok this is nanoResults.N_OK (all error codes can be found in the nanoStream API Reference documentation for nanoResults)   The forceStop call stops the bandwidth check and will return the results that where measured until then. The abort call stops the bandwidth check but don t return any results.  The bandwidth check, sends a special type of metadata that will not be recorded on the Streaming Server.", 
            "title": "Measuring the available bandwidth"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_5", 
            "text": "private BandwidthCheck bwCheck = null;\n\nprivate class CustomBandwidthCheckResultCallback implements BandwidthCheckResultCallback {\n  @Override\n  public void finished(final BandwidthCheckResult bandwidthCheckResult) {\n    Log.d(TAG,  BandwidthCheck results:   +\n       \\n\\tAverage Bitrate (kBit/s):   + bandwidthCheckResult.getAverageBitrate() / 1000 +\n       \\n\\tMedian Bitrate  (kBit/s):   + bandwidthCheckResult.getMedianBitrate() / 1000 +\n       \\n\\tMax Bitrate     (kBit/s):   + bandwidthCheckResult.getMaxBitrate() / 1000 +\n       \\n\\tMin Bitrate     (kBit/s):   + bandwidthCheckResult.getMinBitrate() / 1000 +\n       \\n\\tRun Time        (ms)    :   + bandwidthCheckResult.getRunTimeMS());\n  }\n}\n\nprivate void initBandwidthCheck() {\n  if(null == bwCheck) {\n    BandwidthCheckSettings settings = new BandwidthCheckSettings();\n    settings.setRtmpUrl(serverUrl);\n    settings.setStreamId(streamName);\n    bwCheck = new BandwidthCheck();\n    bwCheck.runBandwidthCheck(settings, new CustomBandwidthCheckResultCallback());\n  }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#rtmp_quality_statistics", 
            "text": "", 
            "title": "RTMP Quality Statistics"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#description_2", 
            "text": "The RTMP Module provides the current RTMP Quality over the  NanostreamEventListener . These includes the  output bit rate ,  buffer fullness ,  bit rate  and  frame rate .", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_6", 
            "text": "public class MainActivity extends Activity implements NanostreamEventListener {\n  private LinearLayout qualityView = null;\n    private TextView outputBitrate = null;\n    private TextView bufferFullness = null;\n    private TextView bitrate = null;\n    private TextView framerate = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    qualityView = (LinearLayout) findViewById(R.id.qualityView);\n        outputBitrate = (TextView) findViewById(R.id.outputBitrateText);\n        bufferFullness = (TextView) findViewById(R.id.bufferfillnessText);\n        bitrate = (TextView) findViewById(R.id.bitrateText);\n        framerate = (TextView) findViewById(R.id.framerateText);\n\n    // Init nanoStream    \n  }\n\n  @Override\n    public void onNanostreamEvent(NanostreamEvent event)\n    {\n        if (event.GetType() == NanostreamEvent.TYPE_RTMP_QUALITY)\n        {\n            this.runOnUiThread(new ViewQualityRunnable(event));\n        }\n    }\n\n  private class ViewQualityRunnable implements Runnable\n    {\n        private NanostreamEvent m_event;\n        private DecimalFormat format;\n\n        public ViewQualityRunnable(NanostreamEvent m_event)\n        {\n            super();\n            this.m_event = m_event;\n            format = new DecimalFormat( #0.00 );\n        }\n\n        @Override\n        public void run()\n        {\n            if (qualityView.getAlpha() == 0   m_event.GetParam1() != 0   m_event.GetParam2() != 0   m_event.GetParam3() != 0   m_event.GetParam4() != 0)\n            {\n                qualityView.setAlpha(0.5f);\n            }\n            int qualityColor = Color.YELLOW;\n            if (m_event.GetParam2()  = 1000)\n            {\n                qualityColor = Color.rgb(255, 0, 0);\n            } else if (m_event.GetParam2()  = 750)\n            {\n                qualityColor = Color.YELLOW;\n            } else if (m_event.GetParam2()  = 750)\n            {\n                qualityColor = Color.GREEN;\n            }\n\n            outputBitrate.setText(Long.toString(m_event.GetParam1() / 1000) +  kbit/s );\n            outputBitrate.setTextColor(qualityColor);\n            bufferFullness.setText(format.format(((double) m_event.GetParam2() / 100.0)) +  % );\n            bufferFullness.setTextColor(qualityColor);\n            bitrate.setText(Long.toString(m_event.GetParam3() / 1000) +  kbit/s );\n            framerate.setText(m_event.GetParam4() +  fps );\n\n        }\n    }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#camera_zoom", 
            "text": "", 
            "title": "Camera Zoom"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#description_3", 
            "text": "The nanoStream Android SDK supports camera zoom, if the internal camera supports it. Therefor there are a few functions, the most important are:     Function  Return Type  returns      hasZoom()  booelan  true if zoom is supported by the video source / device    getZoomRatios()  List Integer  list with of ale zoom ratios    getZoom()  int  the index of the  List Integer  that returned from  getZommRatios()    setZoom(int)  int  the new index of the  List Integer  that returned from  getZommRatios()     It is recommended to use  pinch to zoom , therefor you need to implement a  ScaleGestureDetector.SimpleOnScaleGestureListener , and a  pinch2zoom  function, that takes the  scalefactor  from the  SimpleOnScaleGestureListener  as a int parameter, take a look at the  Implementation Example .", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#getzoomratios", 
            "text": "getZoomRatios()  returns a List of Integer values, this values are the zoom ratios in 1/100 increments (e.g. a zoom of 3.2x is returned as 320).", 
            "title": "getZoomRatios()"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#setzoomint", 
            "text": "The int parameter from  setZoom(int zoom)  is the index of zoom ratios that returns  getZoomRatios() .", 
            "title": "setZoom(int)"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#zoom_behavior_on_camera_switch", 
            "text": "During a camera switch (e.g. from back to front) the zoom remains unaffected.", 
            "title": "Zoom Behavior on Camera Switch"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_7", 
            "text": "public class MainActivity extends Activity {\n  private ScaleGestureDetector scaleGestureDetector;\n  private List Integer  mZoomRatios = null;\n\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n\n    nanoStreamSettings nss = new nanoStreamSettings();\n    // configure nanoStreamSettings\n\n    streamLib = new nanoStream(nss);\n\n    if(streamLib.hasZoom()) {\n      mZoomRatios = streamLib.getZoomRatio();\n    }\n\n    if(null == scaleGestureDetector) {\n      scaleGestureDetector = new ScaleGestureDetector(this, new ScaleGestureListener());\n    }\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (scaleGestureDetector != null)\n    {\n      scaleGestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n\n  private class ScaleGestureListener extends ScaleGestureDetector.SimpleOnScaleGestureListener {\n    @Override\n    public boolean onScale(ScaleGestureDetector detector) {\n      if(null != streamLib) {\n        if (streamLib.hasZoom()) {\n          pinch2Zoom(detector.getScaleFactor());\n        }\n      }\n      return true;\n    }\n  }\n\n  public void pinch2Zoom(float scaleFactor) {\n    if (streamLib.hasZoom()   null != mZoomRatios) {\n      int zoomFactor = streamLib.getZoom();\n      float zoomRatio = mZoomRatios.get(zoomFactor) / 100f;\n      zoomRatio *= scaleFactor;\n      if (zoomRatio   1.0f) {\n        if (scaleFactor   1.0f) {\n          for (int i = zoomFactor; i   mZoomRatios.size(); i++) {\n            Double zoom = mZoomRatios.get(i) / 100.0;\n            if (zoom  = zoomRatio) {\n              streamLib.setZoom(i);\n              break;\n            }\n          }\n        } else {\n          for (int i = zoomFactor; i   0; i--) {\n            Double zoom = mZoomRatios.get(i) / 100.0;\n            if (zoom  = zoomRatio) {\n              streamLib.setZoom(i);\n              break;\n            }\n          }\n        }\n      }\n    }\n  }   \n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#camera_focus", 
            "text": "", 
            "title": "Camera Focus"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#description_4", 
            "text": "The nanoStream Android SDK supports camera focus and focus lock, if the internal cameras supports them. There are two non-blocking functions  setFocusArea(int focusWidth, int focusHeight, float areaMultiple, int x,\n    int y, int previewWidth, int previewHeight, int weigh)\nsetFocusLockArea(int focusWidth, int focusHeight, float areaMultiple, int x,\n    int y, int previewWidth, int previewHeight, int weigh)  through the  addFocusCalback(FocusCallback callback)\nremoveFocusCalback(FocusCallback callback)  you can attach or remove a FocusCallback listener. To check if your device supports focus call the function  isFocusSupported()  which will return true or false.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#parameter_list", 
            "text": "Parameter name  meaning      focusWidth  the focus Area width    focusHeight  the focus Area height    areaMultiple  a Multiple for the focus area (default: 1f)    x  the x position on the Screen    y  the y position on the Screen    previewWidth  the width of the preview    previewHeight  the height of the preview    weight  the weight of the area must be range from 1 to 1000", 
            "title": "Parameter List"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#focuscallback_interface", 
            "text": "The FocusCallback interface has three abstract functions  onSuccess()\nonSuccess(Rect rect, Boolean focusLock)\nonFailure()", 
            "title": "FocusCallback interface"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_8", 
            "text": "public class MainActifity extens Actifity implements FocusCallback {\n  private GestureDetector gestureDetector;\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    streamLib = new nanoStream(new nanoStreamSettings());\n    if(streamLib.isFocusSupported()) {\n      gestureDetector = new GestureDetector(this, new GestureListener());\n    }\n    ...\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (gestureDetector != null)\n    {\n        gestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n  ....\n  private class GestureListener implements OnGestureListener {\n    @Override\n    public boolean onSingleTapUp(MotionEvent e)\n    {\n      if (streamLib != null)\n        {\n          streamLib.setFocusArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n        }\n        return true;\n    }\n\n    @Override\n    public void onLongPress(MotionEvent e)\n    {\n      if (streamLib != null)\n      {\n        streamLib.setFocusLockArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n      }\n    }\n  }\n\n  @Override\n  public void onSuccess(Rect rect, Boolean aBoolean) {\n    Log.i(TAG,  focus success );\n  }\n\n  @Override\n  public void onFailure() {\n    Log.i(TAG,  focus failed );\n  }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#snapshot_from_the_current_stream", 
            "text": "To get a snapshot (image) of the current preview/stream, the method  takeSnapshot  can be used. This is a non blocking function, for the result you need to implement the SnapshotCallback interface. The snapshot returns as a base64 encoded JPEG", 
            "title": "Snapshot from the current stream"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_9", 
            "text": "private class CustomSnapshotCallback implements SnapshotCallback {\n  @Override\n  void onSuccess(String arg0){\n    // do something with the base64 encoded JPEG.\n  }\n\n  @Override\n void onFailure(){\n   Log.d(TAG,  takeSnapshot() failed! )\n }\n}\nprivate void shapshot() {\n  streamLib.takeSnapshot(new CustomSnapshotCallback());\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#server_authentication", 
            "text": "In case authentication is required, the credentials can be set on the  nanoStreamSettings  object.", 
            "title": "Server Authentication"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_10", 
            "text": "nanoStreamSettings nss = new nanoStreamSettings();\nnss.setAuthUser( user );\nnss.setAuthPassword( password );", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#deviceproperties", 
            "text": "Before Android 4.3 there was no obligation for Android hardware manufacturers to pass the video related parts of the CTS (Compatibility Test Suite). Therefore some Android 4.1 and 4.2 Devices show non standard behaviour in regard to color format definitions and representation of video frames in memory. This could lead to issues in the video stream like switched red and blue colors, dislocated color components or a green bar at the bottom of the video frame. nanoStream Android now provides the functionality to detect and compensate common issues related to this.", 
            "title": "DeviceProperties"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#description_5", 
            "text": "nanoStream.getDeviceProperties()  is a static function that is running a test on the device hardware to detect non standard behaviour and returning a DeviceProperties object containing the result. DeviceProperties.getFlags()  returns the test result as an integer value that can be stored in the application preferences, to avoid running the device test on every app start. DeviceProperties can be applied to a new nanoStream instance by calling  nanoStream.setDeviceProperties(DeviceProperties) . We recommend to call  getDeviceProperties()  in a background thread during the first app start on a pre 4.3 device, because the call is blocking and might last up to 5 seconds on older/weaker devices. We also recommend to store the OS version in the preferences, to be able to detect OS updates and to eventually rerun the device test or stop setting the DeviceProperties if the new OS is 4.3 or higher.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android-advanced-settings/#implementation_example_11", 
            "text": "public class App extends Application {\n  private static DeviceProperties deviceProp = null;\n\n  public void onCreate(){\n    super.onCreate();\n\n    Thread chkThread = new Thread(new Runnable(){\n      @Override\n      public void run() {\n        try {\n          SharedPreferences prefs = PreferenceManager.getDefaultSharedPreferences(getApplicationContext());\n          int curApiVer = android.os.Build.VERSION.SDK_INT;\n          int curAppVer = getPackageManager().getPackageInfo(getPackageName(), 0).versionCode;\n          int curEncVer = DeviceProperties.VERSION;\n\n          int oldApiVer = prefs.getInt( Pref_Android_API , 0);\n          int oldAppVer = prefs.getInt( Pref_App_Version , 0);\n          int oldChkVer = prefs.getInt( Pref_Check_Version , 0);\n          int oldChkResult = prefs.getInt( Pref_Check_Result , -1);\n\n          if (((oldApiVer * oldAppVer * oldApiVer) == 0)\n          || (oldApiVer   curApiVer)\n          || (oldAppVer   curAppVer)\n          || (oldChkVer   curEncVer)\n          || oldChkResult   0) {\n            Editor edit = prefs.edit();\n            edit.putInt( Pref_Android_API , curApiVer);\n            edit.putInt( Pref_App_Version , curAppVer);\n\n            /* Run  device check */\n            try {\n              deviceProp = nanoStream.getDeviceProperties();\n              edit.putInt( Pref_Check_Result , deviceProp.getFlags());\n              edit.putInt( Pref_Check_Version , deviceProp.getVersion());\n              edit.commit();\n            } catch (RuntimeException e) {\n              Log.d( Device Check failed , e.toString());\n              edit.putInt( Pref_Check_Result , -1);\n              edit.putInt( Pref_Check_Version , 0);\n              edit.commit();\n            }\n          } else {\n            deviceProp = new DeviceProperties(oldChkResult);\n          }\n            Log.d( Device Properties:  , deviceProp.toString());\n        } catch (Exception e) {\n          Log.d(this.getClass().getName(),  Device Check Runnable );\n          e.printStackTrace();\n        }\n      }\n    });\n    if (android.os.Build.VERSION.SDK_INT   18) {\n      chkThread.start();\n    }\n        ...\n  }\n\n  public static DeviceProperties getDeviceProperties()\n  {\n    return deviceProp;\n  }\n}  public class MainActivity extends Activity implements NanostreamEventListener {\n  ...\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    try {\n      nanoStreamSettings nss = new nanoStreamSettings();\n      streamLib = new nanoStream(nss);\n\n      DeviceProperties deviceProperties = App.getDeviceProperties();\n      if(null != streamLib   null != deviceProperties) {\n        streamLib.setDeviceProperties(deviceProperties);\n      }\n    } catch(NanostreamException en) {\n      Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n    }\n  }\n  ...\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/", 
            "text": "nanoStream SDK for Android RTMP Playback\n\n\nDescription\n\n\nRTMP Playback Component enables application developers to add playback of RTMP live and on demand streams to their apps.\n\n\nSupported codecs are H.264 Video, AAC and MP3 Audio.\n\n\nVideo streams are decoded and rendered on a Surface that is hold by the application, usually connected to a \nSurfaceView\n.\n\n\nAudio streams are decoded and rendered to system audio using the Android AudioSession/AudioTrack API.\n\n\nThe interface and usage are similar to the Android MediaPlayer. The Android MediaPlayerControl interface is implemented to enable control through an \nandroid.widget.MediaController\n instance.\n\n\nRequirements\n\n\nRelated nanoStream SDK Version: 4.1\n\n\nMinimum supported Android OS/API: 4.1/API 16\n\n\nRequired application permissions:\n\n\n\n\nandroid.permission.INTERNET\n\n\nandroid.permission.RECORD_AUDIO\n\n\nandroid.permission.RECORD_VIDEO\n\n\nandroid.permission.MODIFY_AUDIO_SETTINGS\n\n\n\n\nLicense\n\n\nThe playback component requires a special feature flag to be enabled in your nanoStream license key. It not necessarily included in nanoStream Android SDK licenses.\n\n\nInterface\n\n\nPackage name\n\n\nnet.nanocosmos.nanoStream.streamer\n\n\nDeclaration\n\n\npublic abstract class NanostreamPlayer implements MediaPlayercontrol, Surfaceholder.Callback\n\n\nFunction Life Cycle\n\n\n\n\n\n\n\n\nInstance Handling\n\n\nInitialization\n\n\nCapabilities\n\n\nQueries\n\n\nPlayback Control\n\n\nSupported by RTMP Player\n\n\n\n\n\n\n\n\n\n\ncreateNanostreamPlayer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsetSettings\n\n\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\nsetPlayerEventListener\n\n\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanPrepare\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanPrepareAsync\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanPause\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanSeekBackward\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanSeekForward\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\ngetState\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\nisPlaying\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\ngetCurrentPosition\n\n\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\ngetDuration\n\n\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprepare\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprepareAsync\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstart\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npause\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nseekTo\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstop\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstart\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstop\n\n\nyes\n\n\n\n\n\n\n\n\nclose\n\n\n\n\n\n\n\n\nno\n\n\n\n\n\n\n\n\nrelease\n\n\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\nCreating an Instance\n\n\nNanostreamPlayer\n instances can be created through the static factory function \ncreateNanostreamPlayer\n at the top level \nnanoStream class\n. NanostreamPlayer is designed to support multiple player instances. The number of parallel instances can be limited by system resources such as codec,surfaces,memory, network connections and bandwidth.\n\n\nConfiguration and Settings\n\n\nInitial player settings are wrapped by the \nNanostreamPlayer.PlayerSettings\n class. The settings can be applied by calling \nNanostreamPlayer.setSettings\n.\n\n\nPlayerSettings:\n\n\n\n\n\n\n\n\nSetting\n\n\nFunctions\n\n\nDescription\n\n\nType\n\n\nDefault Values\n\n\n\n\n\n\n\n\n\n\nLicense\n\n\ngetLicense/setLicense\n\n\nnanoStream license key\n\n\nString\n\n\nempty\n\n\n\n\n\n\nUrl\n\n\ngetUrl/setUrl\n\n\nRTMP url\n\n\nString\n\n\nempty\n\n\n\n\n\n\nStream Name\n\n\ngetStreamname/setStreamname\n\n\nRTMP stream name\n\n\nString\n\n\nempty\n\n\n\n\n\n\nUser Name\n\n\ngetUsername/setUsername\n\n\nUser name if RTMP authentication is required\n\n\nString\n\n\nempty\n\n\n\n\n\n\nPassword\n\n\ngetPassword/setPassword Password if RTMP authentication is required\n\n\nString\n\n\nempty\n\n\n\n\n\n\n\n\nBuffer Time\n\n\ngetBufferTimeMs/setBufferTimeMs\n\n\nLength of the stream buffer in milliseconds\n\n\nInteger\n\n\n2000ms/2s\n\n\n\n\n\n\nFrame Dropping Mode\n\n\ngetFrameDroppingMode/setFrameDroppingMode\n\n\nConfiguration of the dropping mode regarding different droppable frame types\n\n\nFrameDroppingMode\n\n\nDROP_NO_FRAMES\n\n\n\n\n\n\nStream Playback\n\n\ngetVideoPlayback/getAudioPlayback/setStreamPlayback\n\n\nEnable stream types to be decoded and played\n\n\nboolean\n\n\nvideo:true, audio:true\n\n\n\n\n\n\nTrackTimout\n\n\ngetTrackTimeout/setTrackTimeout\n\n\nTimeout to waiting for Track info\n\n\nlong\n\n\n10000\n\n\n\n\n\n\nEndlessMode\n\n\ngetEndlessMode/setEndlessMode\n\n\nReopen the stream until stop call\n\n\nboolean\n\n\nfalse\n\n\n\n\n\n\n\n\nPlayer State\n\n\nThe player stat can be queried through the \ngetState()\n function\n\n\n/**\n*\n* The different states of the player instance.\n*\n*/\npublic enum PlayerState\n{\n    IDLE, INITIALIZED, PREPARED, STARTED, PAUSED, SEEKING, BUFFERING, RECONNECTING, PLAYBACKCOMPLETED, STOPPING, STOPPED;\n}\n\n\n\n\n\n\n\n\n\n\nState\n\n\nDescription\n\n\nSupported by RTMP Player\n\n\n\n\n\n\n\n\n\n\nPlayerState.IDLE\n\n\nInitial state. Player has not yet been initialized or has been closed.\n\n\nyes\n\n\n\n\n\n\nPlayerState.INITIALIZED\n\n\nPlayer has been initialized with license and settings.\n\n\nyes\n\n\n\n\n\n\nPlayerState.PREPARED\n\n\nPlayer has been prepared and is ready to start.\n\n\nno\n\n\n\n\n\n\nPlayerState.STARTED\n\n\nPlayback has been started.\n\n\nyes\n\n\n\n\n\n\nPlayerState.PAUSED\n\n\nPlayback has been paused.\n\n\nyes\n\n\n\n\n\n\nPlayerState.SEEKING\n\n\nPlayer is Seeking\n\n\nyes\n\n\n\n\n\n\nPlayerState.BUFFERING\n\n\nPlayer is buffering stream data.\n\n\nyes\n\n\n\n\n\n\nPlayerState.RECONNECTING\n\n\nPlayer is performing a reconnect\n\n\nno\n\n\n\n\n\n\nPlayerState.PLAYBACKCOMPLETED\n\n\nPlayback has ended due to end of stream.\n\n\nyes\n\n\n\n\n\n\nPlayerState.STOPPING\n\n\nPlayer is stopping\n\n\nyes\n\n\n\n\n\n\nPlayerState.STOPPED\n\n\nPlayer is stopped\n\n\nyes\n\n\n\n\n\n\n\n\nEvent Notification\n\n\nEvent notifications can be received through the \nNanostreamPlayer.PlayerEventListener\n interface. Derive your listener from this interface and add it to the player by calling \nsetPlayerEventListener()\n.\n\n\nStatus Events\n\n\nEvent Type : \nTYPE_RTMP_STATUS\n\n\n\n\n\n\n\n\nEvent Code\n\n\nDescription\n\n\nCorresponding State\n\n\n\n\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_STARTED\n\n\nPlayback has been started.\n\n\nPlayerState.STARTED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_STOPPING\n\n\nPlayback will stop.\n\n\nPlayerState.STOPPING\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_STOPPED\n\n\nPlayback has been stopped.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_ERROR_CONNECT\n\n\nThe connect to the stream url failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_BUFFERING\n\n\nPlayer is buffering stream data\n\n\nPlayerState.BUFFERING\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_PLAYBACKCOMPLETED\n\n\nPlayback has ended due to end of stream.\n\n\nPlayerState.PLAYBACKCOMPLETED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_NOT_FOUND\n\n\nThe specified stream could not be found.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_SEEKING\n\n\nThe Stream is seeking.\n\n\nPlayerState.SEEKING\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_PAUSED\n\n\nThe Stream is paused\n\n\nPlayerState.PAUSED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_VIDEO_FORMAT_AVAILABLE\n\n\nThe Stream has a MediaFormat for the Video Track\n\n\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_AUDIO_FORMAT_AVAILABLE\n\n\nThe Stream has a MediaFormat for the Audio Track\n\n\n\n\n\n\n\n\n\n\nResults and Error Events\n\n\nEvent Type : \nTYPENANORESULTS\n Event Codes : Values of type nanoResults\n\n\n\n\n\n\n\n\nEvent Code\n\n\nDescription\n\n\nCorresponding State\n\n\n\n\n\n\n\n\n\n\nnanoResults.N_NOT_INITIALIZED\n\n\nThe RTMP library has not been initialized properly.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_ALLOCATEDATA_FAILED_RTMP_SRC\n\n\nMemory allocation failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_LICENSE_INVALID\n\n\nLicense check failed - License invalid.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_LICENSE_INVALID_RTMP_SRC\n\n\nLicense check failed - RTMP playback is not included.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_LICENSE_EXPIRED\n\n\nLicense check failed - The license period has ended.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_TCP_CONNECT_FAILED\n\n\nTCP connect failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_HANDSHAKE_FAILED\n\n\nRTMP handshake failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_CONNECT_FAILED\n\n\nRTMP connect failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_AUTH_FAILED\n\n\nRTMP authentication is required and failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_APP_INVALID\n\n\nThe application part of the url is invalid and has been rejected.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_STATUS_PLAY_STREAM_NOT_FOUND\n\n\nThe stream name could not be found.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_STATUS_PLAY_STREAM_SEEK\n\n\nThe player is seeking.\n\n\nPlayerState.SEEKING\n\n\n\n\n\n\nnanoResults.N_RTMP_SEEK_NOT_AVAILABLE\n\n\nThe stream can not seek.\n\n\n\n\n\n\n\n\nnanoResults.N_RTMP_SEEK_FAILED\n\n\nThe stream can not seek.\n\n\n\n\n\n\n\n\n\n\nAudio / Video Format\n\n\nAfter the \nNanostreamEvent.CODE_STREAM_AUDIO/VIDEO_FORMAT_AVAILABLE\n event, you can get the MediaFormat Object with the \ngetAudio/VideoFormat()\n1\n function call.\n\n\nWe added two custom Fields for the Video MediaFormat:\n\n\n\n\nNanostreamPlayer.KEY_ASPECT_RATIO_WIDTH\n\n\nNanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT\n\n\n\n\nWith these custom fields you can get the aspect ratio width and height.\n\n\nMediaFormat videoFormat = mPlayer.getVideoFormat();\n\nint aspectRatioWidth = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_WIDTH);\nint aspectRatioHeight = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT);\n\n\n\n\nImplementation Example\n\n\npublic class PlayerActivity extends Activity implements PlayerEventListener, SurfaceHolder.Callback {\n    ...\n    private NanostreamPlayer mPlayer = null;\n    private String license = \nYOUR LICENSE CODE\n;\n\n    private String strStreamUrl = \nrtmp://192.168.1.100/vod\n;\n    private String strStreamname = \nmp4:file.mp4\n;\n\n    private LinearLayout root;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        root = new LinearLayout(this);\n        root.setOrientation(LinearLayout.VERTICAL);\n        root.setLayoutParams(containerParams);\n        root.setBackgroundColor(Color.BLACK);\n\n        ...\n\n        mPlayer = nanoStream.createNanostreamPlayer();\n\n        PlayerSettings settings = mPlayer.new PlayerSettings();\n\n        settings.setLicense(license);\n        settings.setUrl(strStreamUrl);\n        settings.setStreamname(strStreamname);\n        settings.setAuthUsername(\n);\n        settings.setAuthPassword(\n);\n        settings.setBufferTimeMs(2000);\n\n        mPlayer.setSettings(settings);\n        mPlayer.setPlayerEventListener(this);\n\n        ...\n        // we need a surface Callback for the application\n        LinearLayout.LayoutParams surfaceParams = new LinearLayout.LayoutParams(ViewGroup.LayoutParams.FILL_PARENT, ViewGroup.LayoutParams.FILL_PARENT, 0.5F);\n        surfaceParams.gravity = Gravity.CENTER;\n        surfaceParams.weight = 0.5f;\n\n        SurfaceView surfaceView = new SurfaceView(this);\n        surfaceView.setLayoutParams(surfaceParams);\n        surfaceView.getHolder.addCallback(this);\n\n        root.addView(surfaceView);\n        setContentView(root);\n    }\n\n    ...\n\n    @Override\n    public void onPlayerEvent(NanostreamEvent event, NanostreamPlayer instance) {\n        final String msg = event.GetDescription();\n        Log.d(this.getClass().getName(), event.GetDescription());\n    }\n\n    @Override\n    public void surfaceCreated(SurfaceHolder holder) {\n        mPlayer.surfaceCreated(holder);\n\n        try {\n            if (!mPlayer.getState().equals(PlayerState.STARTED)) {\n                mPlayer.start();\n            }\n        } catch (IllegalStateException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {\n        mPlayer.surfaceChanged(holder, format, width, height);\n    }\n\n    @Override\n    public void surfaceDestroyed(SurfaceHolder holder) {\n        mPlayer.surfaceDestroyed(holder);\n    }\n}\n\n\n\n\n1\n: since nanoStream Android SDK 3.2", 
            "title": "RTMP Playback"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#nanostream_sdk_for_android_rtmp_playback", 
            "text": "", 
            "title": "nanoStream SDK for Android RTMP Playback"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#requirements", 
            "text": "Related nanoStream SDK Version: 4.1  Minimum supported Android OS/API: 4.1/API 16  Required application permissions:   android.permission.INTERNET  android.permission.RECORD_AUDIO  android.permission.RECORD_VIDEO  android.permission.MODIFY_AUDIO_SETTINGS", 
            "title": "Requirements"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#license", 
            "text": "The playback component requires a special feature flag to be enabled in your nanoStream license key. It not necessarily included in nanoStream Android SDK licenses.", 
            "title": "License"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#package_name", 
            "text": "net.nanocosmos.nanoStream.streamer", 
            "title": "Package name"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#declaration", 
            "text": "public abstract class NanostreamPlayer implements MediaPlayercontrol, Surfaceholder.Callback", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#function_life_cycle", 
            "text": "Instance Handling  Initialization  Capabilities  Queries  Playback Control  Supported by RTMP Player      createNanostreamPlayer          setSettings     yes     setPlayerEventListener     yes      canPrepare    yes      canPrepareAsync    yes      canPause    yes      canSeekBackward    yes      canSeekForward    yes       getState   yes       isPlaying   yes       getCurrentPosition   no       getDuration   no        prepare  no        prepareAsync  no        start  yes        pause  yes        seekTo  yes        stop  yes        start  yes        stop  yes     close     no     release     yes", 
            "title": "Function Life Cycle"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#creating_an_instance", 
            "text": "NanostreamPlayer  instances can be created through the static factory function  createNanostreamPlayer  at the top level  nanoStream class . NanostreamPlayer is designed to support multiple player instances. The number of parallel instances can be limited by system resources such as codec,surfaces,memory, network connections and bandwidth.", 
            "title": "Creating an Instance"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#configuration_and_settings", 
            "text": "Initial player settings are wrapped by the  NanostreamPlayer.PlayerSettings  class. The settings can be applied by calling  NanostreamPlayer.setSettings .", 
            "title": "Configuration and Settings"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#playersettings", 
            "text": "Setting  Functions  Description  Type  Default Values      License  getLicense/setLicense  nanoStream license key  String  empty    Url  getUrl/setUrl  RTMP url  String  empty    Stream Name  getStreamname/setStreamname  RTMP stream name  String  empty    User Name  getUsername/setUsername  User name if RTMP authentication is required  String  empty    Password  getPassword/setPassword Password if RTMP authentication is required  String  empty     Buffer Time  getBufferTimeMs/setBufferTimeMs  Length of the stream buffer in milliseconds  Integer  2000ms/2s    Frame Dropping Mode  getFrameDroppingMode/setFrameDroppingMode  Configuration of the dropping mode regarding different droppable frame types  FrameDroppingMode  DROP_NO_FRAMES    Stream Playback  getVideoPlayback/getAudioPlayback/setStreamPlayback  Enable stream types to be decoded and played  boolean  video:true, audio:true    TrackTimout  getTrackTimeout/setTrackTimeout  Timeout to waiting for Track info  long  10000    EndlessMode  getEndlessMode/setEndlessMode  Reopen the stream until stop call  boolean  false", 
            "title": "PlayerSettings:"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#player_state", 
            "text": "The player stat can be queried through the  getState()  function  /**\n*\n* The different states of the player instance.\n*\n*/\npublic enum PlayerState\n{\n    IDLE, INITIALIZED, PREPARED, STARTED, PAUSED, SEEKING, BUFFERING, RECONNECTING, PLAYBACKCOMPLETED, STOPPING, STOPPED;\n}     State  Description  Supported by RTMP Player      PlayerState.IDLE  Initial state. Player has not yet been initialized or has been closed.  yes    PlayerState.INITIALIZED  Player has been initialized with license and settings.  yes    PlayerState.PREPARED  Player has been prepared and is ready to start.  no    PlayerState.STARTED  Playback has been started.  yes    PlayerState.PAUSED  Playback has been paused.  yes    PlayerState.SEEKING  Player is Seeking  yes    PlayerState.BUFFERING  Player is buffering stream data.  yes    PlayerState.RECONNECTING  Player is performing a reconnect  no    PlayerState.PLAYBACKCOMPLETED  Playback has ended due to end of stream.  yes    PlayerState.STOPPING  Player is stopping  yes    PlayerState.STOPPED  Player is stopped  yes", 
            "title": "Player State"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#event_notification", 
            "text": "Event notifications can be received through the  NanostreamPlayer.PlayerEventListener  interface. Derive your listener from this interface and add it to the player by calling  setPlayerEventListener() .", 
            "title": "Event Notification"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#status_events", 
            "text": "Event Type :  TYPE_RTMP_STATUS     Event Code  Description  Corresponding State      NanostreamEvent.CODE_STREAM_STARTED  Playback has been started.  PlayerState.STARTED    NanostreamEvent.CODE_STREAM_STOPPING  Playback will stop.  PlayerState.STOPPING    NanostreamEvent.CODE_STREAM_STOPPED  Playback has been stopped.  PlayerState.STOPPED    NanostreamEvent.CODE_STREAM_ERROR_CONNECT  The connect to the stream url failed.  PlayerState.STOPPED    NanostreamEvent.CODE_STREAM_BUFFERING  Player is buffering stream data  PlayerState.BUFFERING    NanostreamEvent.CODE_STREAM_PLAYBACKCOMPLETED  Playback has ended due to end of stream.  PlayerState.PLAYBACKCOMPLETED    NanostreamEvent.CODE_STREAM_NOT_FOUND  The specified stream could not be found.  PlayerState.STOPPED    NanostreamEvent.CODE_STREAM_SEEKING  The Stream is seeking.  PlayerState.SEEKING    NanostreamEvent.CODE_STREAM_PAUSED  The Stream is paused  PlayerState.PAUSED    NanostreamEvent.CODE_STREAM_VIDEO_FORMAT_AVAILABLE  The Stream has a MediaFormat for the Video Track     NanostreamEvent.CODE_STREAM_AUDIO_FORMAT_AVAILABLE  The Stream has a MediaFormat for the Audio Track", 
            "title": "Status Events"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#results_and_error_events", 
            "text": "Event Type :  TYPENANORESULTS  Event Codes : Values of type nanoResults     Event Code  Description  Corresponding State      nanoResults.N_NOT_INITIALIZED  The RTMP library has not been initialized properly.  PlayerState.STOPPED    nanoResults.N_ALLOCATEDATA_FAILED_RTMP_SRC  Memory allocation failed.  PlayerState.STOPPED    nanoResults.N_LICENSE_INVALID  License check failed - License invalid.  PlayerState.STOPPED    nanoResults.N_LICENSE_INVALID_RTMP_SRC  License check failed - RTMP playback is not included.  PlayerState.STOPPED    nanoResults.N_LICENSE_EXPIRED  License check failed - The license period has ended.  PlayerState.STOPPED    nanoResults.N_TCP_CONNECT_FAILED  TCP connect failed.  PlayerState.STOPPED    nanoResults.N_RTMP_HANDSHAKE_FAILED  RTMP handshake failed.  PlayerState.STOPPED    nanoResults.N_RTMP_CONNECT_FAILED  RTMP connect failed.  PlayerState.STOPPED    nanoResults.N_RTMP_AUTH_FAILED  RTMP authentication is required and failed.  PlayerState.STOPPED    nanoResults.N_RTMP_APP_INVALID  The application part of the url is invalid and has been rejected.  PlayerState.STOPPED    nanoResults.N_RTMP_STATUS_PLAY_STREAM_NOT_FOUND  The stream name could not be found.  PlayerState.STOPPED    nanoResults.N_RTMP_STATUS_PLAY_STREAM_SEEK  The player is seeking.  PlayerState.SEEKING    nanoResults.N_RTMP_SEEK_NOT_AVAILABLE  The stream can not seek.     nanoResults.N_RTMP_SEEK_FAILED  The stream can not seek.", 
            "title": "Results and Error Events"
        }, 
        {
            "location": "/nanostream/android/rtmp-playback/#audio_video_format", 
            "text": "After the  NanostreamEvent.CODE_STREAM_AUDIO/VIDEO_FORMAT_AVAILABLE  event, you can get the MediaFormat Object with the  getAudio/VideoFormat() 1  function call.  We added two custom Fields for the Video MediaFormat:   NanostreamPlayer.KEY_ASPECT_RATIO_WIDTH  NanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT   With these custom fields you can get the aspect ratio width and height.  MediaFormat videoFormat = mPlayer.getVideoFormat();\n\nint aspectRatioWidth = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_WIDTH);\nint aspectRatioHeight = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT);", 
            "title": "Audio / Video Format"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/", 
            "text": "bintu.live client SDK for Android\n\n\n\u00a9 2016 nanocosmos gmbh \nhttp://www.nanocosmos.de\n\n\nVersion 0.1.1\n\n\nThe bintu.live client SDK is used to generate and access live stream URLs from the bintu.live service to be used in combination with the nanoStream SDKs for live video encoding and broadcast.\n\n\nLegal Notice\n\n\nThis material is subject to the terms and conditions defined in separate license conditions (\nLICENSE.txt\n) All information contained herein is, and remains the property of nanocosmos GmbH and its suppliers if any. The intellectual and technical concepts contained herein are proprietary to nanocosmos GmbH, and are protected by trade secret or copyright law. Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from nanocosmos.\n\n\nProject setup\n\n\nAndroid Studio\n\n\nTo use the bintu.live SDK in your Android Studio project you need to include the bintu android archive as a module. In order to do this copy the android archive (bintu-sdk.aar) to your drive and open the \nCreate Module\n menu in Android Studio (via File -\n New -\n Create Module). On the \nCreate New Module\n menu select \nImport .JAR/.AAR Package\n, as shown below, and click on \nNext\n.\n\n\n\nAfterwards select the location of the bintu.live sdk archive file and enter a name for this module (e.g. \nBintuSDK\n).\nAfter finishing the bintu.live sdk is included in your project and ready to use.\n\n\nEclipse ADT\n\n\nbintu.live platform connection\n\n\nOur bintu.live connection component (bintu-sdk.aar) consists of an entry point API client class BintuSDK (net.nanocosmos.bintu.bintusdk.BintuSDK) which you use to make calls to our streaming platform. There are other classes, like StreamInfo (net.nanocosmos.bintu.bintusdk.stream.StreamInfo) and RtmpIngest  (net.nanocosmos.bintu.bintusdk.stream.RtmpIngest), which mainly hold the configuration you receive from the BintuSDK.\n\n\nIn general, if you want to interface with our streaming platform, you construct an instance of the BintuSDK with its main constructor:\n\n\nBintuSDK bintuSDK = new BintuSDK(apiKey);\n\n\n\n\nOnce you have an instance, you can create new streams with it, receive information about a previously created stream or list all streams that are present on your account.\n\n\nLets step through these in detail:\n\n\nWith the createStream call you create a new stream. You would use this in your broadcaster app. As argument you pass an instace of an implementation of the StreamInfoResponseHandler interface to the createStream call. This interface represents callback classes to handle the result of the create stream call. It contains two method declarations. One to handle the success result, called \nhandle\n, and one to handle errors, called \nonError\n. One of these will be executed as result of the createStream call. When the \nhandle\n-method is executed it is passed the result data of the createStream call as a StreamInfo object.\n\n\nbintu.createStream(new StreamInfoResponseHandler() {\n                @Override\n                public void handle(StreamInfo streamInfo) {\n                    //TODO Handle the Result\n                }\n\n                @Override\n                public void onError(Throwable error) {\n                    //TODO Handle the Error\n                }\n\n            });\n\n\n\n\nWith the getStream call you can receive information about a previously created stream, by passing its id to the call. In most cases, you would take the stream ID you get while creating a stream and store it on your own server somewhere. If anyone wants to view a stream, you send that ID to the player app. Then you can receive that stream\ns playout information. For example, if you want to play the stream via RTMP:\n\n\nbintuSDK.getStream(streamID, new StreamInfoResponseHandler() {\n            @Override\n            public void handle(StreamInfo streamInfo) {\n                RtmpPlayout rtmpPlayout = streamInfo.getRtmpPlayouts().get(0);\n                String rtmpURL = rtmpPlayout.getUrl();\n                String streamName = rtmpPlayout.getStreamName();\n                //TODO Play the stream\n            }\n\n            @Override\n            public void onError(Throwable error) {\n                //TODO Handle the Error\n            }\n        });\n\n\n\n\nYou can also list all streams on your account with the getStreams call. For example, you can bypass your server, get all streams on the player and let the user select the one they want to see. Or you just play the first one that is live, like shown below:\n\n\nbintuSDK.getStreams(new StreamInfoListResponseHandler() {\n               @Override\n               public void handle(List\nStreamInfo\n result) {\n                 for(StreamInfo info : result){\n                       if (info.getState() == State.LIVE){\n                           //TODO Play this stream\n                           break;\n                       }\n                   }\n               }\n\n               @Override\n               public void onError(Throwable e) {\n                   //TODO Handle the Error\n               }\n           });\n\n\n\n\nBut this example can be made simpler. There is also the getStreams call (added in version 0.?.? of the bintu-sdk.aar) which allows you filter the streams by state directly on the server, resulting in quicker load times. The above example can be implemented like this:\n\n\nbintuSDK.getStreams(State.LIVE, new StreamInfoListResponseHandler() {\n                @Override\n                public void handle(List\nStreamInfo\n result) {\n                    try {\n                        StreamInfo info = result.get(0);\n                        //TODO Play stream\n                    }catch (Exception ex){\n                        //TODO Handle the Error    \n                    }\n                }\n\n                @Override\n                public void onError(Throwable e) {\n                    //TODO Handle the Error\n                }\n            });\n\n\n\n\nThat was a basic overview of our bintu.live component.", 
            "title": "Android SDK"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#bintulive_client_sdk_for_android", 
            "text": "\u00a9 2016 nanocosmos gmbh  http://www.nanocosmos.de  Version 0.1.1  The bintu.live client SDK is used to generate and access live stream URLs from the bintu.live service to be used in combination with the nanoStream SDKs for live video encoding and broadcast.", 
            "title": "bintu.live client SDK for Android"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#legal_notice", 
            "text": "This material is subject to the terms and conditions defined in separate license conditions ( LICENSE.txt ) All information contained herein is, and remains the property of nanocosmos GmbH and its suppliers if any. The intellectual and technical concepts contained herein are proprietary to nanocosmos GmbH, and are protected by trade secret or copyright law. Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from nanocosmos.", 
            "title": "Legal Notice"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#project_setup", 
            "text": "", 
            "title": "Project setup"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#android_studio", 
            "text": "To use the bintu.live SDK in your Android Studio project you need to include the bintu android archive as a module. In order to do this copy the android archive (bintu-sdk.aar) to your drive and open the  Create Module  menu in Android Studio (via File -  New -  Create Module). On the  Create New Module  menu select  Import .JAR/.AAR Package , as shown below, and click on  Next .  Afterwards select the location of the bintu.live sdk archive file and enter a name for this module (e.g.  BintuSDK ).\nAfter finishing the bintu.live sdk is included in your project and ready to use.", 
            "title": "Android Studio"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#eclipse_adt", 
            "text": "", 
            "title": "Eclipse ADT"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#bintulive_platform_connection", 
            "text": "Our bintu.live connection component (bintu-sdk.aar) consists of an entry point API client class BintuSDK (net.nanocosmos.bintu.bintusdk.BintuSDK) which you use to make calls to our streaming platform. There are other classes, like StreamInfo (net.nanocosmos.bintu.bintusdk.stream.StreamInfo) and RtmpIngest  (net.nanocosmos.bintu.bintusdk.stream.RtmpIngest), which mainly hold the configuration you receive from the BintuSDK.  In general, if you want to interface with our streaming platform, you construct an instance of the BintuSDK with its main constructor:  BintuSDK bintuSDK = new BintuSDK(apiKey);  Once you have an instance, you can create new streams with it, receive information about a previously created stream or list all streams that are present on your account.  Lets step through these in detail:  With the createStream call you create a new stream. You would use this in your broadcaster app. As argument you pass an instace of an implementation of the StreamInfoResponseHandler interface to the createStream call. This interface represents callback classes to handle the result of the create stream call. It contains two method declarations. One to handle the success result, called  handle , and one to handle errors, called  onError . One of these will be executed as result of the createStream call. When the  handle -method is executed it is passed the result data of the createStream call as a StreamInfo object.  bintu.createStream(new StreamInfoResponseHandler() {\n                @Override\n                public void handle(StreamInfo streamInfo) {\n                    //TODO Handle the Result\n                }\n\n                @Override\n                public void onError(Throwable error) {\n                    //TODO Handle the Error\n                }\n\n            });  With the getStream call you can receive information about a previously created stream, by passing its id to the call. In most cases, you would take the stream ID you get while creating a stream and store it on your own server somewhere. If anyone wants to view a stream, you send that ID to the player app. Then you can receive that stream s playout information. For example, if you want to play the stream via RTMP:  bintuSDK.getStream(streamID, new StreamInfoResponseHandler() {\n            @Override\n            public void handle(StreamInfo streamInfo) {\n                RtmpPlayout rtmpPlayout = streamInfo.getRtmpPlayouts().get(0);\n                String rtmpURL = rtmpPlayout.getUrl();\n                String streamName = rtmpPlayout.getStreamName();\n                //TODO Play the stream\n            }\n\n            @Override\n            public void onError(Throwable error) {\n                //TODO Handle the Error\n            }\n        });  You can also list all streams on your account with the getStreams call. For example, you can bypass your server, get all streams on the player and let the user select the one they want to see. Or you just play the first one that is live, like shown below:  bintuSDK.getStreams(new StreamInfoListResponseHandler() {\n               @Override\n               public void handle(List StreamInfo  result) {\n                 for(StreamInfo info : result){\n                       if (info.getState() == State.LIVE){\n                           //TODO Play this stream\n                           break;\n                       }\n                   }\n               }\n\n               @Override\n               public void onError(Throwable e) {\n                   //TODO Handle the Error\n               }\n           });  But this example can be made simpler. There is also the getStreams call (added in version 0.?.? of the bintu-sdk.aar) which allows you filter the streams by state directly on the server, resulting in quicker load times. The above example can be implemented like this:  bintuSDK.getStreams(State.LIVE, new StreamInfoListResponseHandler() {\n                @Override\n                public void handle(List StreamInfo  result) {\n                    try {\n                        StreamInfo info = result.get(0);\n                        //TODO Play stream\n                    }catch (Exception ex){\n                        //TODO Handle the Error    \n                    }\n                }\n\n                @Override\n                public void onError(Throwable e) {\n                    //TODO Handle the Error\n                }\n            });  That was a basic overview of our bintu.live component.", 
            "title": "bintu.live platform connection"
        }, 
        {
            "location": "/bintu/", 
            "text": "Test this", 
            "title": "Getting"
        }, 
        {
            "location": "/bintu/#test_this", 
            "text": "", 
            "title": "Test this"
        }
    ]
}