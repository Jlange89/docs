{
    "docs": [
        {
            "location": "/", 
            "text": "nanocosmos Developer Documentation\n\n\nWelcome to the nanocosmos Developer Documentation. Here you can find every documentation available for our products nanoStream and bintu. nanoStream is our streaming sdk, which can be used to stream live av-streams using for example rtmp. Bintu, our streaming service, allows you to use our streaming environment in your application. Therefore you need to use the bintu sdk which is described in this documentation\n\n\nnanoStream Documentation\n\n\nBintu Documentation", 
            "title": "Home"
        }, 
        {
            "location": "/#nanocosmos_developer_documentation", 
            "text": "Welcome to the nanocosmos Developer Documentation. Here you can find every documentation available for our products nanoStream and bintu. nanoStream is our streaming sdk, which can be used to stream live av-streams using for example rtmp. Bintu, our streaming service, allows you to use our streaming environment in your application. Therefore you need to use the bintu sdk which is described in this documentation", 
            "title": "nanocosmos Developer Documentation"
        }, 
        {
            "location": "/#nanostream_documentation", 
            "text": "", 
            "title": "nanoStream Documentation"
        }, 
        {
            "location": "/#bintu_documentation", 
            "text": "", 
            "title": "Bintu Documentation"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/", 
            "text": "nanoStream Live Video Encoder\n\n\nWebcaster / Browser based Live Encoder\nVersion 4.0\nCompatible to NPAPI, ActiveX and Chrome Extension\n(c) 2015 nanocosmos gmbh\n\n\nWork in Progress\n\n\nNANO.NanoStream\n\n\n\n\n\n\nDescription\n\n\n\n\nUse the \nNANO.NanoStream\n API to communicate with the plugin. It provide async functions and events to handle devices, configs, preview and broadcast. Use the functions with callbacks to retrieve necessary informations and data for the encoder lifecycle and the usage with frontend javascript code.\n\n\n\n\n\n\n\n\nBrowser\n\n\n\n\nChrome, Firefox, Internet Explorer, Safari\n\n\n\n\n\n\n\n\nOS\n\n\n\n\nWindows Support for NPAPI / Chrome\n\n\nMacOS Support only for NPAPI (Chrome not supported yet)\n\n\n\n\n\n\n\n\nAvailability\n\n\n\n\nSince nanoStream 4.0\n\n\n\n\n\n\n\n\nNanoStream Summary\n\n\n\n\n\n\nAPI Methods (async with callbacks)\n\n\n\n\nGetAudioDeviceConfig\n\n\nGetAudioDevices\n\n\nGetAudioLevels\n\n\nGetConfig\n\n\nGetInputs\n\n\nGetOutputs\n\n\nGetVideoDeviceConfig\n\n\nGetVideoDevices\n\n\nGetWindows\n\n\nSaveXmlProfile\n\n\nSetAudioVolume\n\n\nSetConfigs\n\n\nSetInputs\n\n\nSetOutputs\n\n\nSetPictureInPictureSize\n\n\nSetVideoMixingMode\n\n\nSetXmlProfile\n\n\nStartBroadcast\n\n\nStartPreview\n\n\nStopBroadcast\n\n\nStopPreview\n\n\nInit\n\n\n\n\n\n\n\n\nHelper Methods (sync)\n\n\n\n\nDetectBrowser\n\n\nInstallExtensionInline\n\n\nInstallExtensionWebstore\n\n\nFireEvent\n\n\n\n\n\n\n\n\nEvents\n\n\n\n\nonError\n\n\nonNotifyEvent\n\n\nonStopEvent\n\n\nonSupported\n\n\nonUnsupported\n\n\n\n\n\n\n\n\nAPI Methods (async with callbacks)\n\n\nGetAudioDeviceConfig\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetAudioDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn object with all possible config parameters of the the audio device by index will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetAudioDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n index\n\n\nThe index of the audio device\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: string, // the device name\n                            \nindex\n: integer, // the device index\n                            \noptions\n: [ // array with options\n                                {\n                                    \nsamplerates\n: [ // array available samplerates\n                                        integer,\n                                        integer,\n                                        ...\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: \nMikrofon (HD Pro Webcam C920)\n,\n                            \nindex\n: 2,\n                            \noptions\n: [\n                                {\n                                    \nsamplerates\n: [\n                                        22050,\n                                        24000,\n                                        44100,\n                                        48000\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n:\nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetAudioDeviceConfig\n,\n                \nparams\n: [\n                    index\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var index = 0;\n    var message = NANO.NanoStream.GetAudioDeviceConfig(\n        index,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i \n options.length; i += 1) {\n                console.log(\nFound options \n + i + \n for audio device '\n + device.id + \n' with index = \n + device.index);\n                var samplerates = options[i].samplerates;\n                for (var j = 0; j \n samplerates.length; j += 1) {\n                    console.log(\nAvailable samplerate: \n + samplerates[j]);                \n                }\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetAudioDevices\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetAudioDevices(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn array object with all available audio devices will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetAudioDevices(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetAudioDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \naudio\n: [ // array with device objects\n                                {\n                                    \nid\n: string, // the device name\n                                    \nindex\n: integer // the device index\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetAudioDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \naudio\n: [\n                                {\n                                    \nid\n: \nMikrofon (HD Pro Webcam C920)\n,\n                                    \nindex\n: 0\n                                },\n                                {\n                                    \nid\n: \nnanocosmos Live Audio Capture\n,\n                                    \nindex\n: 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetAudioDevices\n,\n                \ndata\n: {\n                    \nvalue\n: string // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetAudioDevices\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.GetAudioDevices(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var devices = message.data.value.devices.audio;\n            for (var i = 0; i \n devices.length; i += 1) {\n                console.log(\nFound audio device '\n + devices[i].id + \n' with index = \n + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetAudioLevels\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetAudioLevels(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn array object with the current audio levels (stereo) will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetAudioLevels(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetAudioLevels\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nlevels\n: [\n                            integer,\n                            integer\n                        ]\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetAudioLevels\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nlevels\n: [\n                            14326,\n                            13954\n                        ]\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetAudioLevels\n,\n                \ndata\n: {\n                    \nvalue\n: string // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetAudioLevels\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    NANO.NanoStream.GetAudioLevels(function success(message) {\n        var levels = message.data.value.levels;\n        var reference = 32768.0;\n        var left = Math.round(levels[0] / reference * 100) / 100;\n        var right = Math.round(levels[1] / reference * 100) / 100;\n        console.log(\nAudio level left: \n + left);\n        console.log(\nAudio level right: \n + right);\n    }, null);\n\n\n\n\nup\n\n\n\n\nGetConfig\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetConfig(\nstring\n key, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method gets the value from a defined key of the advanced configuration.\n\n\nNOTE: see possible advanced configuration \nhere \n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetConfig(\nstring\n key, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nstring\n key\n\n\nThe key of the key value pair\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nkey\n: string, // the key of the key value pair\n                        \nvalue\n: string // the value of the key value pair\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nkey\n: \nVideoMixerMode\n,\n                        \nvalue\n: \n0\n\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetConfig\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetConfig\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var key = \nVideoMixerMode\n;\n    var message = NANO.NanoStream.GetConfig(\n        key,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nConfig pair: \n + message.data.value.key + \n,\n + message.data.value.value);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetInputs\n\n\nGetOutputs\n\n\nGetVideoDeviceConfig\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetVideoDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn object with all possible config parameters of the the video device by index will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetVideoDeviceConfig(\ninteger\n index, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n index\n\n\nThe index of the video device\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: string, // the device name\n                            \nindex\n: integer, // the device index\n                            \noptions\n: [ // array with options\n                                { // the option object with an available resolution\n                                    \ncolorspaces\n: [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                            \nframerates\n: [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                            \nid\n: string, // the name of the colorspace\n                                            \nindex\n: integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                    \nresolution\n: { // the resolution object\n                                        \nheight\n: integer, // the height\n                                        \nwidth\n: integer // the width\n                                    }\n                                },\n                                { // the option object with an available resolution\n                                    \ncolorspaces\n: [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                            \nframerates\n: [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                            \nid\n: string, // the name of the colorspace\n                                            \nindex\n: integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                    \nresolution\n: { // the resolution object\n                                        \nheight\n: integer, // the height\n                                        \nwidth\n: integer // the width\n                                    }\n                                },\n                                ... // more objects\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevice\n: {\n                            \nid\n: \nLogitech HD Pro Webcam C920\n,\n                            \nindex\n: 1,\n                            \noptions\n: [\n                                {\n                                    \ncolorspaces\n: [\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nMJPG\n,\n                                            \nindex\n: 0\n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nRGB24\n,\n                                            \nindex\n: 1\n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nI420\n,\n                                            \nindex\n: 2\n                                        }\n                                    ],\n                                    \nresolution\n: {\n                                        \nheight\n: 360,\n                                        \nwidth\n: 640\n                                    }\n                                },\n                                {\n                                    \ncolorspaces\n: [\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nMJPG\n,\n                                            \nindex\n: 0\n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nRGB24\n,\n                                            \nindex\n: 1\n                                        },\n                                        {\n                                            \nframerates\n: [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                            \nid\n: \nI420\n,\n                                            \nindex\n: 2\n                                        }\n                                    ],\n                                    \nresolution\n: {\n                                        \nheight\n: 720,\n                                        \nwidth\n: 1280\n                                    }\n                                }\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: \nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetVideoDeviceConfig\n,\n                \nparams\n: [\n                    index\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var index = 0;\n    var message = NANO.NanoStream.GetVideoDeviceConfig(\n        index,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i \n options.length; i += 1) {\n                console.log(\nFound options \n + i + \n for audio device '\n + device.id + \n' with index = \n + device.index);\n                var width = options[i].resolution.width;\n                var height = options[i].resolution.height;\n                console.log(\nAvailable resolution: \n + width + \nx\n + height);\n                var colorspaces = options[i].colorspaces;\n                for (var j = 0; j \n colorspaces.length; j += 1) {\n                    var name = colorspaces[j].id;\n                    var index = colorspaces[j].index;\n                    console.log(\nAvailable colorspace for resolution \n + width + \nx\n + height + \n: name = \n + name + \n, index = \n + index);\n                    for (var k = 0; k \n colorspaces[j].framerates.length; k += 1) {\n                        console.log(\nAvailable framerate for \n + width + \nx\n + height + \n, \n + name + \n: \n + colorspaces[j].framerates[k]);\n                    }\n                }\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetVideoDevices\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.GetVideoDevices(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nAn array object with all available video devices will be passed in the success callback.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.GetVideoDevices(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nGetVideoDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \nvideo\n: [ // array with device objects\n                                {\n                                    \nid\n: string, // the device name\n                                    \nindex\n: integer // the device index\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                {\n                                    \nid\n: string,\n                                    \nindex\n: integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nGetVideoDevices\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ndevices\n: {\n                            \nvideo\n: [\n                                {\n                                    \nid\n: \nMikrofon (HD Pro Webcam C920)\n,\n                                    \nindex\n: 0\n                                },\n                                {\n                                    \nid\n: \nnanocosmos Live Video Capture\n,\n                                    \nindex\n: 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nGetVideoDevices\n,\n                \ndata\n: {\n                    \nvalue\n: string // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nGetVideoDevices\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.GetVideoDevices(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            var devices = message.data.value.devices.video;\n            for (var i = 0; i \n devices.length; i += 1) {\n                console.log(\nFound video device '\n + devices[i].id + \n' with index = \n + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nGetWindows\n\n\nSaveXmlProfile\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method saves an \nXML\n profile to a defined path.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SaveXmlProfile(\nstring\n path, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nstring\n path\n\n\nThe path to save the profile to\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSaveXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSaveXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSaveXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSaveXmlProfile\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var path = \nC:\\profile.xml\n;\n    var message = NANO.NanoStream.SaveXmlProfile(\n        path,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nProfile saved\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetAudioVolume\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method sets the audio volume in a range between 0 and 100.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetAudioVolume(\ninteger\n volume, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n volume\n\n\nThe volume to set in a range between 0 and 100\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetAudioVolume\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetAudioVolume\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetAudioVolume\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetAudioVolume\n,\n                \nparams\n: [\n                    integer\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var volume = 50;\n    var message = NANO.NanoStream.SetAudioVolume(\n        volume,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nVolume set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetConfigs\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetConfigs(\nobject\n \nnanoConfigObject\n, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\n\n\nThis method sets multiple key value pairs for advanced configuration.\n\n\n\n\n\n\nNOTE: see possible advanced configurations \nhere\n\n\n\n\n\n\nNOTE: it\ns necesary to use the \nNANO.Config\n class to generate the needed object \nnanoConfigObject\n\n\n\n\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetConfigs(\nobject\n \nnanoConfigObject\n, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nobject\n \nnanoConfigObject\n\n\nThe object with one or multiple key value pairs\n\n\nNOTE: see the description to the usage of this object \nhere\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetConfigs\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetConfigs\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n            \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetConfigs\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetConfigs\n,\n                \nparams\n: [ object ]                \n            }\n\n\n\n\nExamples\n\n\n\n\nlow latency configuration\n\n\n\n\n    var config = new NANO.Config();\n    config.AddConfig(\nH264Profile\n, \nBaseline\n); // Baseline Profile supported by most devices and players\n    config.AddConfig(\nH264IFrameDistance\n, \n50\n); // Moderate GOP length\n    config.AddConfig(\nH264PFrameDistance\n, \n1\n); // No B-frames\n    //(optional)\n    //config.AddConfig(\nH264VlcMode\n, \n1\n); // CAVLC entropy coding mode\n    //config.AddConfig(\nRateControl\n, \n1\n); // Strict constant bitrate\n    var nanoConfigObject = config.GetConfig(); // returns the well json parsed object we need to pass\n    var message = NANO.NanoStream.SetConfigs(\n        nanoConfigObject,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nConfiguration set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetInputs\n\n\nSetOutputs\n\n\nSetPictureInPictureSize\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method sets the picture in picture size in a range between 0 and 3.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetPictureInPictureSize(\ninteger\n size, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n size\n\n\nThe picture in picture size to set in a range between 0 and 3\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetPictureInPictureSize\n,\n                \nparams\n: [\n                    integer\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var size = 2;\n    var message = NANO.NanoStream.SetPictureInPictureSize(\n        size,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nPicture in picture size set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetVideoMixingMode\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method sets the video mix mode.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetVideoMixingMode(\ninteger\n mode, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\ninteger\n mode\n\n\nThe video mix mode to set\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetVideoMixingMode\n,\n                \nparams\n: [\n                    integer\n                ]                \n            }\n\n\n\n\nExample\n\n\n    var mode = 0;\n    var message = NANO.NanoStream.SetVideoMixingMode(\n        mode,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nVideo mix mode set\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nSetXmlProfile\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method loads an \nXML\n profile from a defined path.\n\n\nThe error callback parameters is optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.SetXmlProfile(\nstring\n path, \nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nstring\n path\n\n\nThe path to load the profile from\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nSetXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nSetXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nSetXmlProfile\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nSetXmlProfile\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var path = \nC:\\profile.xml\n;\n    var message = NANO.NanoStream.SetXmlProfile(\n        path,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nProfile loaded\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStartBroadcast\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StartBroadcast(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the broadcast and/or recording.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StartBroadcast(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartBroadcast(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartBroadcast(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStartBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: float\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStartBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: 30\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStartBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStartBroadcast\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StartBroadcast(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nBroadcast started with framerate \n + message.data.value.framerate);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStartPreview\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StartPreview(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the preview.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StartPreview(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartPreview(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StartPreview(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStartPreview\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: float\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStartPreview\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \nframerate\n: 30\n                    }                    \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStartPreview\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStartPreview\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StartPreview(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nPreview started with framerate \n + message.data.value.framerate);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStopBroadcast\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StopBroadcast(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the preview.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StopBroadcast(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopBroadcast(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopBroadcast(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStopBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: string           \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStopBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n            \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStopBroadcast\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStopBroadcast\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StopBroadcast(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nBroadcast stopped\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nStopPreview\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.StopPreview(\nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method will start the preview.\n\n\nThe callback parameters are optional. If no callback should be used, pass \nnull\n\n\ne.g. \nobject\n NANO.NanoStream.StopPreview(\nfunction\n successCallback, \nnull\n)\n\n\nonly with success callback\n\n\nthe \nNANO.NanoStream.onError\n event will be used if defined\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopPreview(\nnull\n, \nfunction\n errorCallback)\n\n\nonly with error callback\n\n\n\n\n\n\ne.g. \nobject\n NANO.NanoStream.StopPreview(\nnull\n, \nnull\n)\n\n\nno callback\n\n\n\n\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nStopPreview\n,\n                \ndata\n: {\n                    \nvalue\n: string            \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nStopPreview\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n\n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nStopPreview\n,\n                \ndata\n: {\n                    \nvalue\n: string  // the error message\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nStopPreview\n,\n                \nparams\n: []                \n            }\n\n\n\n\nExample\n\n\n    var message = NANO.NanoStream.StopPreview(\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nPreview stopped\n);\n        },\n        function error(message) {\n            alert(\nCallback Error: \n + JSON.stringify(message));\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nInit\n\n\nup to summary\n\n\nobject\n NANO.NanoStream.Init(\nstring\n elementId, \nstring\n license, \nfunction\n successCallback, \nfunction\n errorCallback)\n\n\nDescription\n\n\n\n\nThis method embeds the plugin into an container element (div) and initilize the plugin.\n\n\nCall this method after \nNANO.NanoStream.DetectBrowser()\n and before any other API call.\n\n\n\n\nParameters\n\n\n\n\nstring\n elementId\n\n\nThe id of the div element where to embed the plugin into\n\n\n\n\n\n\nstring\n license\n\n\nThe license string\n\n\n\n\n\n\nfunction\n successCallback(message)\n\n\nThe success callback method if defined\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n        general:\n            {\n                \ncommand\n: \nInit\n,\n                \ndata\n: {\n                    \nvalue\n: string             \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string // defines the sender\n            }\n        example:\n            {\n                \ncommand\n: \nInit\n,\n                \ndata\n: {\n                    \nvalue\n: \nnoreturnvalue\n          \n                },\n                \nresult\n: \nOK\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n:\nnanonative\n\n            }\n\n\n\n\n\n\nfunction\n errorCallback(message)\n\n\nobject\n message\n\n\nThe parsed message that will be send back to the client\n\n\n\n\n\n\n\n\n\n\n\n\n            {\n                \ncommand\n: \nInit\n,\n                \ndata\n: {\n                    \nvalue\n: {\n                        \ncode\n: integer, // the error code\n                        \nerror\n: string // the error message\n                    }\n                },\n                \nresult\n: \nFAILED\n,\n                \nstatus\n: \nCOMPLETE\n,\n                \ntype\n: string\n            }\n\n\n\n\nReturns\n\n\n\n\nThe parsed message that will be send to the plugin\n\n\nobject\n\n\n\n\n\n\n\n\n            {\n                \ntype\n: \nnanoclient\n,\n                \ncommand\n: \nInit\n,\n                \nparams\n: [\n                    string,\n                    string\n                ]\n            }\n\n\n\n\nExample (with all possible errors)\n\n\n    var elementId = \nvideo-container\n; // an existing div element with this id\n    var license = \nnlic::...\n; // an valid nanostream license string\n    var message = NANO.NanoStream.Init(\n        elementId,\n        license,\n        function success(message) {\n            console.log(\nCallback: \n + JSON.stringify(message));\n            console.log(\nNanoStream plugin successfully embedded and ready!\n);\n        },\n        function error(message) {\n            if (message.type === \nnanoextensioncheck\n) { // only chrome\n                if (message.data.value.code === 0) { // extension not installed or unavailable\n                    // DO STUFF\n                    var result = confirm(\nYou using chrome browser, but don't have installed your extension!\\r\\nDo you want to install it now?\n);\n                    if (result) {\n                        NANO.NanoStream.InstallExtensionInline();\n                    }\n                } else if (message.data.value.code === 1) { // extension installation finished (not really an error, but passed within the handler)\n                    // DO STUFF\n                    console.log(\nExtension now installed\n);\n                }\n            } else if (message.type === \nnanoversioncheck\n) { // only chrome\n                if (message.data.value.code === 0) { // native version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 1) { // extension version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 2) { // lib version outdated\n                    alert(message.data.value.error);\n                }\n            } else {\n                if (message.data.value.code === 100) { // error initialization\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 101) { // error setting license\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 102) { // error connecting to the native plugin (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 103) { // error connecting to the extension (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 104) { // error passing parameters / wrong parameters\n                    alert(message.data.value.error);\n                } else { // error embedding plugin\n                    if (message.data.value.code === 0) { // plugin found but no version\n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -1) { // general no plugins available (unsupported browser)\n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -2) { // plugin not found / not installed / not activated\n                        alert(message.data.value.error);\n                    } else {\n                        alert(\nUnknown Error Init: code = \n + message.data.value.code + \n, error = '\n + message.data.value.error + \n'\n);\n                    }\n                }\n            }\n        }\n    );\n    console.log(\nCall: \n + JSON.stringify(message));\n\n\n\n\nup\n\n\n\n\nHelper Methods (sync)\n\n\nDetectBrowser\n\n\nFireEvent\n\n\nInstallExtensionInline\n\n\nInstallExtensionWebstore\n\n\nEvents\n\n\nonError\n\n\nonNotifyEvent\n\n\nonStopEvent\n\n\nonSupported\n\n\nonUnsupported\n\n\nNANO Config", 
            "title": "API Manual"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nanostream_live_video_encoder", 
            "text": "Webcaster / Browser based Live Encoder\nVersion 4.0\nCompatible to NPAPI, ActiveX and Chrome Extension\n(c) 2015 nanocosmos gmbh  Work in Progress", 
            "title": "nanoStream Live Video Encoder"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nanonanostream", 
            "text": "Description   Use the  NANO.NanoStream  API to communicate with the plugin. It provide async functions and events to handle devices, configs, preview and broadcast. Use the functions with callbacks to retrieve necessary informations and data for the encoder lifecycle and the usage with frontend javascript code.     Browser   Chrome, Firefox, Internet Explorer, Safari     OS   Windows Support for NPAPI / Chrome  MacOS Support only for NPAPI (Chrome not supported yet)     Availability   Since nanoStream 4.0", 
            "title": "NANO.NanoStream"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nanostream_summary", 
            "text": "API Methods (async with callbacks)   GetAudioDeviceConfig  GetAudioDevices  GetAudioLevels  GetConfig  GetInputs  GetOutputs  GetVideoDeviceConfig  GetVideoDevices  GetWindows  SaveXmlProfile  SetAudioVolume  SetConfigs  SetInputs  SetOutputs  SetPictureInPictureSize  SetVideoMixingMode  SetXmlProfile  StartBroadcast  StartPreview  StopBroadcast  StopPreview  Init     Helper Methods (sync)   DetectBrowser  InstallExtensionInline  InstallExtensionWebstore  FireEvent     Events   onError  onNotifyEvent  onStopEvent  onSupported  onUnsupported", 
            "title": "NanoStream Summary"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#api_methods_async_with_callbacks", 
            "text": "", 
            "title": "API Methods (async with callbacks)"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getaudiodeviceconfig", 
            "text": "up to summary  object  NANO.NanoStream.GetAudioDeviceConfig( integer  index,  function  successCallback,  function  errorCallback)", 
            "title": "GetAudioDeviceConfig"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description", 
            "text": "An object with all possible config parameters of the the audio device by index will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetAudioDeviceConfig( integer  index,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters", 
            "text": "integer  index  The index of the audio device    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetAudioDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id : string, // the device name\n                             index : integer, // the device index\n                             options : [ // array with options\n                                {\n                                     samplerates : [ // array available samplerates\n                                        integer,\n                                        integer,\n                                        ...\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetAudioDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id :  Mikrofon (HD Pro Webcam C920) ,\n                             index : 2,\n                             options : [\n                                {\n                                     samplerates : [\n                                        22050,\n                                        24000,\n                                        44100,\n                                        48000\n                                    ]\n                                }\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status : COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetAudioDeviceConfig ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetAudioDeviceConfig ,\n                 params : [\n                    index\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example", 
            "text": "var index = 0;\n    var message = NANO.NanoStream.GetAudioDeviceConfig(\n        index,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i   options.length; i += 1) {\n                console.log( Found options   + i +   for audio device '  + device.id +  ' with index =   + device.index);\n                var samplerates = options[i].samplerates;\n                for (var j = 0; j   samplerates.length; j += 1) {\n                    console.log( Available samplerate:   + samplerates[j]);                \n                }\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getaudiodevices", 
            "text": "up to summary  object  NANO.NanoStream.GetAudioDevices( function  successCallback,  function  errorCallback)", 
            "title": "GetAudioDevices"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_1", 
            "text": "An array object with all available audio devices will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetAudioDevices( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_1", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetAudioDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             audio : [ // array with device objects\n                                {\n                                     id : string, // the device name\n                                     index : integer // the device index\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetAudioDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             audio : [\n                                {\n                                     id :  Mikrofon (HD Pro Webcam C920) ,\n                                     index : 0\n                                },\n                                {\n                                     id :  nanocosmos Live Audio Capture ,\n                                     index : 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetAudioDevices ,\n                 data : {\n                     value : string // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_1", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetAudioDevices ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_1", 
            "text": "var message = NANO.NanoStream.GetAudioDevices(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var devices = message.data.value.devices.audio;\n            for (var i = 0; i   devices.length; i += 1) {\n                console.log( Found audio device '  + devices[i].id +  ' with index =   + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getaudiolevels", 
            "text": "up to summary  object  NANO.NanoStream.GetAudioLevels( function  successCallback,  function  errorCallback)", 
            "title": "GetAudioLevels"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_2", 
            "text": "An array object with the current audio levels (stereo) will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetAudioLevels( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_2", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetAudioLevels ,\n                 data : {\n                     value : {\n                         levels : [\n                            integer,\n                            integer\n                        ]\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetAudioLevels ,\n                 data : {\n                     value : {\n                         levels : [\n                            14326,\n                            13954\n                        ]\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetAudioLevels ,\n                 data : {\n                     value : string // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_2", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetAudioLevels ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_2", 
            "text": "NANO.NanoStream.GetAudioLevels(function success(message) {\n        var levels = message.data.value.levels;\n        var reference = 32768.0;\n        var left = Math.round(levels[0] / reference * 100) / 100;\n        var right = Math.round(levels[1] / reference * 100) / 100;\n        console.log( Audio level left:   + left);\n        console.log( Audio level right:   + right);\n    }, null);  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getconfig", 
            "text": "up to summary  object  NANO.NanoStream.GetConfig( string  key,  function  successCallback,  function  errorCallback)", 
            "title": "GetConfig"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_3", 
            "text": "This method gets the value from a defined key of the advanced configuration.  NOTE: see possible advanced configuration  here   The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetConfig( string  key,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_3", 
            "text": "string  key  The key of the key value pair    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetConfig ,\n                 data : {\n                     value : {\n                         key : string, // the key of the key value pair\n                         value : string // the value of the key value pair\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetConfig ,\n                 data : {\n                     value : {\n                         key :  VideoMixerMode ,\n                         value :  0 \n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetConfig ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_3", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetConfig ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_3", 
            "text": "var key =  VideoMixerMode ;\n    var message = NANO.NanoStream.GetConfig(\n        key,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Config pair:   + message.data.value.key +  ,  + message.data.value.value);\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getinputs", 
            "text": "", 
            "title": "GetInputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getoutputs", 
            "text": "", 
            "title": "GetOutputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getvideodeviceconfig", 
            "text": "up to summary  object  NANO.NanoStream.GetVideoDeviceConfig( integer  index,  function  successCallback,  function  errorCallback)", 
            "title": "GetVideoDeviceConfig"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_4", 
            "text": "An object with all possible config parameters of the the video device by index will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetVideoDeviceConfig( integer  index,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_4", 
            "text": "integer  index  The index of the video device    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetVideoDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id : string, // the device name\n                             index : integer, // the device index\n                             options : [ // array with options\n                                { // the option object with an available resolution\n                                     colorspaces : [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                             framerates : [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                             id : string, // the name of the colorspace\n                                             index : integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                     resolution : { // the resolution object\n                                         height : integer, // the height\n                                         width : integer // the width\n                                    }\n                                },\n                                { // the option object with an available resolution\n                                     colorspaces : [ // array of colorspace objects related to the resolution (available colorspaces)\n                                        {\n                                             framerates : [ // array of framerates related to the specified available colorspace\n                                                float, // available framerate\n                                                float,\n                                                ...\n                                            ],\n                                             id : string, // the name of the colorspace\n                                             index : integer // the index of the colorspace\n                                        },\n                                        ... // more available colorspaces\n                                    ],\n                                     resolution : { // the resolution object\n                                         height : integer, // the height\n                                         width : integer // the width\n                                    }\n                                },\n                                ... // more objects\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetVideoDeviceConfig ,\n                 data : {\n                     value : {\n                         device : {\n                             id :  Logitech HD Pro Webcam C920 ,\n                             index : 1,\n                             options : [\n                                {\n                                     colorspaces : [\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  MJPG ,\n                                             index : 0\n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  RGB24 ,\n                                             index : 1\n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  I420 ,\n                                             index : 2\n                                        }\n                                    ],\n                                     resolution : {\n                                         height : 360,\n                                         width : 640\n                                    }\n                                },\n                                {\n                                     colorspaces : [\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  MJPG ,\n                                             index : 0\n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  RGB24 ,\n                                             index : 1\n                                        },\n                                        {\n                                             framerates : [ 5, 7.5, 10, 15, 20, 24, 30 ],\n                                             id :  I420 ,\n                                             index : 2\n                                        }\n                                    ],\n                                     resolution : {\n                                         height : 720,\n                                         width : 1280\n                                    }\n                                }\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type :  nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetVideoDeviceConfig ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_4", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetVideoDeviceConfig ,\n                 params : [\n                    index\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_4", 
            "text": "var index = 0;\n    var message = NANO.NanoStream.GetVideoDeviceConfig(\n        index,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var device = message.data.value.device;\n            var options = message.data.value.device.options;\n            for (var i = 0; i   options.length; i += 1) {\n                console.log( Found options   + i +   for audio device '  + device.id +  ' with index =   + device.index);\n                var width = options[i].resolution.width;\n                var height = options[i].resolution.height;\n                console.log( Available resolution:   + width +  x  + height);\n                var colorspaces = options[i].colorspaces;\n                for (var j = 0; j   colorspaces.length; j += 1) {\n                    var name = colorspaces[j].id;\n                    var index = colorspaces[j].index;\n                    console.log( Available colorspace for resolution   + width +  x  + height +  : name =   + name +  , index =   + index);\n                    for (var k = 0; k   colorspaces[j].framerates.length; k += 1) {\n                        console.log( Available framerate for   + width +  x  + height +  ,   + name +  :   + colorspaces[j].framerates[k]);\n                    }\n                }\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getvideodevices", 
            "text": "up to summary  object  NANO.NanoStream.GetVideoDevices( function  successCallback,  function  errorCallback)", 
            "title": "GetVideoDevices"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_5", 
            "text": "An array object with all available video devices will be passed in the success callback.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.GetVideoDevices( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_5", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  GetVideoDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             video : [ // array with device objects\n                                {\n                                     id : string, // the device name\n                                     index : integer // the device index\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                {\n                                     id : string,\n                                     index : integer\n                                },\n                                ...\n                            ]\n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  GetVideoDevices ,\n                 data : {\n                     value : {\n                         devices : {\n                             video : [\n                                {\n                                     id :  Mikrofon (HD Pro Webcam C920) ,\n                                     index : 0\n                                },\n                                {\n                                     id :  nanocosmos Live Video Capture ,\n                                     index : 1\n                                }\n                            ]                            \n                        }\n                    }\n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  GetVideoDevices ,\n                 data : {\n                     value : string // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_5", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  GetVideoDevices ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_5", 
            "text": "var message = NANO.NanoStream.GetVideoDevices(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            var devices = message.data.value.devices.video;\n            for (var i = 0; i   devices.length; i += 1) {\n                console.log( Found video device '  + devices[i].id +  ' with index =   + devices[i].index);\n            }\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#getwindows", 
            "text": "", 
            "title": "GetWindows"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#savexmlprofile", 
            "text": "up to summary  object  NANO.NanoStream.SaveXmlProfile( string  path,  function  successCallback,  function  errorCallback)", 
            "title": "SaveXmlProfile"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_6", 
            "text": "This method saves an  XML  profile to a defined path.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SaveXmlProfile( string  path,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SaveXmlProfile( string  path,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SaveXmlProfile( string  path,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_6", 
            "text": "string  path  The path to save the profile to    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SaveXmlProfile ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SaveXmlProfile ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SaveXmlProfile ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_6", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SaveXmlProfile ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_6", 
            "text": "var path =  C:\\profile.xml ;\n    var message = NANO.NanoStream.SaveXmlProfile(\n        path,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Profile saved );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setaudiovolume", 
            "text": "up to summary  object  NANO.NanoStream.SetAudioVolume( integer  volume,  function  successCallback,  function  errorCallback)", 
            "title": "SetAudioVolume"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_7", 
            "text": "This method sets the audio volume in a range between 0 and 100.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetAudioVolume( integer  volume,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetAudioVolume( integer  volume,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetAudioVolume( integer  volume,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_7", 
            "text": "integer  volume  The volume to set in a range between 0 and 100    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetAudioVolume ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetAudioVolume ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetAudioVolume ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_7", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetAudioVolume ,\n                 params : [\n                    integer\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_7", 
            "text": "var volume = 50;\n    var message = NANO.NanoStream.SetAudioVolume(\n        volume,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Volume set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setconfigs", 
            "text": "up to summary  object  NANO.NanoStream.SetConfigs( object   nanoConfigObject ,  function  successCallback,  function  errorCallback)", 
            "title": "SetConfigs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_8", 
            "text": "This method sets multiple key value pairs for advanced configuration.    NOTE: see possible advanced configurations  here    NOTE: it s necesary to use the  NANO.Config  class to generate the needed object  nanoConfigObject    The error callback parameters is optional. If no callback should be used, pass  null   e.g.  object  NANO.NanoStream.SetConfigs( object   nanoConfigObject ,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_8", 
            "text": "object   nanoConfigObject  The object with one or multiple key value pairs  NOTE: see the description to the usage of this object  here    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetConfigs ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetConfigs ,\n                 data : {\n                     value :  noreturnvalue             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetConfigs ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_8", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetConfigs ,\n                 params : [ object ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#examples", 
            "text": "low latency configuration       var config = new NANO.Config();\n    config.AddConfig( H264Profile ,  Baseline ); // Baseline Profile supported by most devices and players\n    config.AddConfig( H264IFrameDistance ,  50 ); // Moderate GOP length\n    config.AddConfig( H264PFrameDistance ,  1 ); // No B-frames\n    //(optional)\n    //config.AddConfig( H264VlcMode ,  1 ); // CAVLC entropy coding mode\n    //config.AddConfig( RateControl ,  1 ); // Strict constant bitrate\n    var nanoConfigObject = config.GetConfig(); // returns the well json parsed object we need to pass\n    var message = NANO.NanoStream.SetConfigs(\n        nanoConfigObject,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Configuration set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Examples"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setinputs", 
            "text": "", 
            "title": "SetInputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setoutputs", 
            "text": "", 
            "title": "SetOutputs"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setpictureinpicturesize", 
            "text": "up to summary  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  function  successCallback,  function  errorCallback)", 
            "title": "SetPictureInPictureSize"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_9", 
            "text": "This method sets the picture in picture size in a range between 0 and 3.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetPictureInPictureSize( integer  size,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_9", 
            "text": "integer  size  The picture in picture size to set in a range between 0 and 3    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetPictureInPictureSize ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetPictureInPictureSize ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetPictureInPictureSize ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_9", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetPictureInPictureSize ,\n                 params : [\n                    integer\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_8", 
            "text": "var size = 2;\n    var message = NANO.NanoStream.SetPictureInPictureSize(\n        size,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Picture in picture size set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setvideomixingmode", 
            "text": "up to summary  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  function  successCallback,  function  errorCallback)", 
            "title": "SetVideoMixingMode"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_10", 
            "text": "This method sets the video mix mode.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetVideoMixingMode( integer  mode,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_10", 
            "text": "integer  mode  The video mix mode to set    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetVideoMixingMode ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetVideoMixingMode ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetVideoMixingMode ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_10", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetVideoMixingMode ,\n                 params : [\n                    integer\n                ]                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_9", 
            "text": "var mode = 0;\n    var message = NANO.NanoStream.SetVideoMixingMode(\n        mode,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Video mix mode set );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#setxmlprofile", 
            "text": "up to summary  object  NANO.NanoStream.SetXmlProfile( string  path,  function  successCallback,  function  errorCallback)", 
            "title": "SetXmlProfile"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_11", 
            "text": "This method loads an  XML  profile from a defined path.  The error callback parameters is optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.SetXmlProfile( string  path,  function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.SetXmlProfile( string  path,  null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.SetXmlProfile( string  path,  null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_11", 
            "text": "string  path  The path to load the profile from    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  SetXmlProfile ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  SetXmlProfile ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  SetXmlProfile ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_11", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  SetXmlProfile ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_10", 
            "text": "var path =  C:\\profile.xml ;\n    var message = NANO.NanoStream.SetXmlProfile(\n        path,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Profile loaded );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#startbroadcast", 
            "text": "up to summary  object  NANO.NanoStream.StartBroadcast( function  successCallback,  function  errorCallback)", 
            "title": "StartBroadcast"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_12", 
            "text": "This method will start the broadcast and/or recording.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StartBroadcast( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StartBroadcast( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StartBroadcast( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_12", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StartBroadcast ,\n                 data : {\n                     value : {\n                         framerate : float\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StartBroadcast ,\n                 data : {\n                     value : {\n                         framerate : 30\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StartBroadcast ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_12", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StartBroadcast ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_11", 
            "text": "var message = NANO.NanoStream.StartBroadcast(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Broadcast started with framerate   + message.data.value.framerate);\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#startpreview", 
            "text": "up to summary  object  NANO.NanoStream.StartPreview( function  successCallback,  function  errorCallback)", 
            "title": "StartPreview"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_13", 
            "text": "This method will start the preview.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StartPreview( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StartPreview( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StartPreview( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_13", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StartPreview ,\n                 data : {\n                     value : {\n                         framerate : float\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StartPreview ,\n                 data : {\n                     value : {\n                         framerate : 30\n                    }                    \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StartPreview ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_13", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StartPreview ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_12", 
            "text": "var message = NANO.NanoStream.StartPreview(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Preview started with framerate   + message.data.value.framerate);\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#stopbroadcast", 
            "text": "up to summary  object  NANO.NanoStream.StopBroadcast( function  successCallback,  function  errorCallback)", 
            "title": "StopBroadcast"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_14", 
            "text": "This method will start the preview.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StopBroadcast( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StopBroadcast( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StopBroadcast( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_14", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StopBroadcast ,\n                 data : {\n                     value : string           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StopBroadcast ,\n                 data : {\n                     value :  noreturnvalue             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StopBroadcast ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_14", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StopBroadcast ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_13", 
            "text": "var message = NANO.NanoStream.StopBroadcast(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Broadcast stopped );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#stoppreview", 
            "text": "up to summary  object  NANO.NanoStream.StopPreview( function  successCallback,  function  errorCallback)", 
            "title": "StopPreview"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_15", 
            "text": "This method will start the preview.  The callback parameters are optional. If no callback should be used, pass  null  e.g.  object  NANO.NanoStream.StopPreview( function  successCallback,  null )  only with success callback  the  NANO.NanoStream.onError  event will be used if defined    e.g.  object  NANO.NanoStream.StopPreview( null ,  function  errorCallback)  only with error callback    e.g.  object  NANO.NanoStream.StopPreview( null ,  null )  no callback", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_15", 
            "text": "function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  StopPreview ,\n                 data : {\n                     value : string            \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  StopPreview ,\n                 data : {\n                     value :  noreturnvalue \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  StopPreview ,\n                 data : {\n                     value : string  // the error message\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_15", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  StopPreview ,\n                 params : []                \n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_14", 
            "text": "var message = NANO.NanoStream.StopPreview(\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( Preview stopped );\n        },\n        function error(message) {\n            alert( Callback Error:   + JSON.stringify(message));\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#init", 
            "text": "up to summary  object  NANO.NanoStream.Init( string  elementId,  string  license,  function  successCallback,  function  errorCallback)", 
            "title": "Init"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#description_16", 
            "text": "This method embeds the plugin into an container element (div) and initilize the plugin.  Call this method after  NANO.NanoStream.DetectBrowser()  and before any other API call.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#parameters_16", 
            "text": "string  elementId  The id of the div element where to embed the plugin into    string  license  The license string    function  successCallback(message)  The success callback method if defined  object  message  The parsed message that will be send back to the client               general:\n            {\n                 command :  Init ,\n                 data : {\n                     value : string             \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : string // defines the sender\n            }\n        example:\n            {\n                 command :  Init ,\n                 data : {\n                     value :  noreturnvalue           \n                },\n                 result :  OK ,\n                 status :  COMPLETE ,\n                 type : nanonative \n            }   function  errorCallback(message)  object  message  The parsed message that will be send back to the client                   {\n                 command :  Init ,\n                 data : {\n                     value : {\n                         code : integer, // the error code\n                         error : string // the error message\n                    }\n                },\n                 result :  FAILED ,\n                 status :  COMPLETE ,\n                 type : string\n            }", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#returns_16", 
            "text": "The parsed message that will be send to the plugin  object                 {\n                 type :  nanoclient ,\n                 command :  Init ,\n                 params : [\n                    string,\n                    string\n                ]\n            }", 
            "title": "Returns"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#example_with_all_possible_errors", 
            "text": "var elementId =  video-container ; // an existing div element with this id\n    var license =  nlic::... ; // an valid nanostream license string\n    var message = NANO.NanoStream.Init(\n        elementId,\n        license,\n        function success(message) {\n            console.log( Callback:   + JSON.stringify(message));\n            console.log( NanoStream plugin successfully embedded and ready! );\n        },\n        function error(message) {\n            if (message.type ===  nanoextensioncheck ) { // only chrome\n                if (message.data.value.code === 0) { // extension not installed or unavailable\n                    // DO STUFF\n                    var result = confirm( You using chrome browser, but don't have installed your extension!\\r\\nDo you want to install it now? );\n                    if (result) {\n                        NANO.NanoStream.InstallExtensionInline();\n                    }\n                } else if (message.data.value.code === 1) { // extension installation finished (not really an error, but passed within the handler)\n                    // DO STUFF\n                    console.log( Extension now installed );\n                }\n            } else if (message.type ===  nanoversioncheck ) { // only chrome\n                if (message.data.value.code === 0) { // native version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 1) { // extension version outdated\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 2) { // lib version outdated\n                    alert(message.data.value.error);\n                }\n            } else {\n                if (message.data.value.code === 100) { // error initialization\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 101) { // error setting license\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 102) { // error connecting to the native plugin (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 103) { // error connecting to the extension (only chrome)\n                    alert(message.data.value.error);\n                } else if (message.data.value.code === 104) { // error passing parameters / wrong parameters\n                    alert(message.data.value.error);\n                } else { // error embedding plugin\n                    if (message.data.value.code === 0) { // plugin found but no version\n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -1) { // general no plugins available (unsupported browser)\n                        alert(message.data.value.error);\n                    } else if (message.data.value.code === -2) { // plugin not found / not installed / not activated\n                        alert(message.data.value.error);\n                    } else {\n                        alert( Unknown Error Init: code =   + message.data.value.code +  , error = '  + message.data.value.error +  ' );\n                    }\n                }\n            }\n        }\n    );\n    console.log( Call:   + JSON.stringify(message));  up", 
            "title": "Example (with all possible errors)"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#helper_methods_sync", 
            "text": "", 
            "title": "Helper Methods (sync)"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#detectbrowser", 
            "text": "", 
            "title": "DetectBrowser"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#fireevent", 
            "text": "", 
            "title": "FireEvent"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#installextensioninline", 
            "text": "", 
            "title": "InstallExtensionInline"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#installextensionwebstore", 
            "text": "", 
            "title": "InstallExtensionWebstore"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#events", 
            "text": "", 
            "title": "Events"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onerror", 
            "text": "", 
            "title": "onError"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onnotifyevent", 
            "text": "", 
            "title": "onNotifyEvent"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onstopevent", 
            "text": "", 
            "title": "onStopEvent"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onsupported", 
            "text": "", 
            "title": "onSupported"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#onunsupported", 
            "text": "", 
            "title": "onUnsupported"
        }, 
        {
            "location": "/nanostream/web/nanostream-4.x-web-api/#nano_config", 
            "text": "", 
            "title": "NANO Config"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/", 
            "text": "Live Video Encoder - Plugin API\n\n\nNOTE: This is the Plugin API for NPAPI and ActiveX.\nFor using Chrome Browsers, see our \nnanoStream Web API 4.x\n\n\n\n\nBrowser based usage with HTML and Javascript\n\n\nThe Live Video Encoder core components are available as plugins for several browsers:\\\nInternet Explorer (IE), based on ActiveX, and NP-Plugin based browsers (Firefox, Safari, Chrome).\\\nThe same API is valid for integration into other languages, C++, .NET, Delphi, etc.\\\nSee the sample web page for functionality or contact us for further help.\\\n\n\nHow to embed the encoder plugin into HTML\n\n\nActive-X Control\n\n\nThe Active-X Control is compatible with Microsoft Internet Explorer only. It is loaded by specifying the classid for the plugin. The plugin then may be accessed by Javascript via the ID specified, here \nnanovid1\n.\n\n\nSimple Version without auto-install:\n\n\nobject ID=\nnanovid1\n classid=\nclsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B\n\n\n/object\n\n\n\n\n\nAdvanced Version with auto-install from CAB file:\n\n\nobject ID=\nnanovid1\n\n  classid=\nclsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B\n\n  width=\n480\n height=\n360\n\n  codebase=\n../packages/nanostream-1.5.0.6.cab#version=1,5,0,6\n\n\n/object\n\n\n\n\n\nNote: replace the codebase path and version with the cab file you received for installation.\n\n\nNPAPI Plugin\n\n\nThe NPAPI plugin is compatible with Mozilla Firefox, Apple Safari and Google Chrome.\n\n\n    \nembed id=\nnanovid1\n type=\napplication/x-nanocosmos-LiveVideoEncoder\n width=480 height=360\n\n    \nnoembed\n\n      Can't embed plugin.\n    \n/noembed\n\n    \n/embed\n\n\n\n\n\nIt may be used with an \n tag as well.\n\n\nBrowser independent plugin loading\n\n\nThe object tags may be nested to support all browser types:\n\n\nobject ID=\nnanovid1\n\n  classid=\nclsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B\n width=\n480\n height=\n360\n\n    \ncomment\n\n        \nembed id=\nnanovid1\n type=\napplication/x-nanocosmos-LiveVideoEncoder\n width=480 height=360\n\n            \nnoembed\nCan't embed plugin.\n/noembed\n\n        \n/embed\n\n    \n/comment\n\n\n/object\n\n\n\n\n\nLicense and other custom settings\n\n\nThe License key is a string which needs to be placed into the nanoLicense.js file.\\\nThe nanoLicense.js also contains the mime type and path to the Mozilla based plugin (XPI). The default path is \n../packages/nanostream.xpi\n:\n\n\nContents of nanoLicense.js\n\n\n// nanoStream License Code and custom settings\n// replace the \nnlic\n string with your custom license\ng_nanoLicense = \nnlic:1.0:nanoLiveEncDemo:\u2026\u2026\u2026 \n;\n\n//url to xpi installer package\nvar nano_xpi_source = \n../packages/nanostream.xpi\n;\n\n\n\n\nDynamic DOM Loading of the Plugin\n\n\nThe plugin may be loaded into the HTML Document (DOM) by dynamically creating it with Javascript:\n\n\nfunction createNanoVideoObject()\n{\n    var nanovid = document.createElement(\nobject\n);\n    if(isIE)\n        nanovid.setAttribute(\nclassid\n,\nclsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B\n);\n    else\n          nanovid.setAttribute(\ntype\n,\napplication/x-nanocosmos-LiveVideoEncoder\n);\n    return nanovid;\n}\n\n\n\n\nAccessing the plugin\n\n\nnanoStream is then available as a DOM object with the id \nnanovid1\n. The member functions and variables can be accessed as other Javascript objects, e.g. nanovid1.StartPreview().\n\n\nPlugin Interface\n\n\nThe nanoStream Plugin may be controlled from almost any language which is able to load the plugin.\\\nThe plugin exposes methods and properties to set options, start preview and encoding.\n\n\nList of Properties/Functions with example settings:\n\n\ndestination URL (Flash or Wowza Media Server, or local file)\nnanovid1.DestinationURL = \nrtmp://localhost/live+myStream\n;\nnanovid1.DestinationURL = \nc:\\temp\\h264.mp4\n;\nnanovid1.VideoSource = 0;       // Video Capture Device ID\nnanovid1.AudioSource = 0;       // Audio Capture Device ID\nnanovid1.VideoBitrate = 400000;         // Video Bitrate (bits/s)\nnanovid1.AudioBitrate = 32000;          // Audio Bitrate (bits/s)\nnanovid1.VideoWidth = 352;      // Video Pixel Width\nnanovid1.VideoHeight = 288;     // Video Pixel Height\nnanovid1.VideoFrameRate = 15;           // Video FPS\n\n//start the preview from the current camera\nnanovid1.StartPreview();\n\n//Start Encoding/Broadcast\nnanovid1.StartBroadcast();\n\n\n\n\nJavascript Helper Functions\n\n\nFor simple usage, a set of Javascript functions is provided (nanoEncoder.js).\n\n\n// setup a live stream to a Flash Media/Wowza server\nSetEncodingUrl(\nrtmp://myServer.com/live/myStream\n);\nSetVideoBitrate(400000);    // sets the bitrate to 400 kbps\nOnStartPreview();       // calls nanovid1.StartPreview()\nOnStartBroadcast();     // calls nanovid1.StartBroadcast()\n\n\n\n\nAdditional Configuration can be set with \nnanoSetConfig();\n\n\nExample:\n\n\nnanoSetConfig(\nH264Profile\n,\nBaseline\n);\n\n\n\n\nJavascript API (nanoEncoder.js)\n\n\n// SetEncodingUrl()\n// call this to set custom encoding URL here\nfunction SetEncodingUrl(url)\n\n// get current internal encoding url\nfunction GetEncodingUrl()\n\n// SetVideoBitrate()\n// sets encoder bitrate (bits/s)\nfunction SetVideoBitrate(bitrate)\n\nfunction GetVideoBitrate()\n\n// SetVideoResolution()\n// sets video capture resolution (x/y)\n// warning: resolutions are hardware/driver dependent!\nfunction SetVideoResolution(x,y)\n\n// SetVideoFrameRate()\n// sets video capture frames/sec (e.g. 15, 25)\nfunction SetVideoFrameRate(fps)\n\n// Start/Stop Video Capture Preview\nfunction OnStartPreview(doCheckFormat)\nfunction OnStopPreview()\n\n// OnStartBroadcast()\n// starts encoding / network broadcast\nfunction OnStartBroadcast()\nfunction OnStopBroadcast()\n\n// SetAudioSource()\n// sets audio source device id (0...)\nfunction SetAudioSource(audioSource) {\n\n// SetVideoSource()\n// sets video  source device id (0...)\nfunction SetVideoSource(source) {\n\n// event_OnStop\n// called by plugin on stop events\nfunction event_OnStop(e)\n\n// set basic encoding options to init plugin\nfunction nanoSetOptions()\n\n// Set license string to unlock the API\nfunction nanoSetLicense(license) // call this before Init\n\n\n\n\nNew functions for Version 1.5\n\n\nSpecial configuration data can be sent with the SetConfig method:\\\nnanovid1.SetConfig(property,value);\n\n\nFor some functions wrapper functions are available.\n\n\n// H264 Encoding Profile (\nBaseline\n or \nMain\n)\nfunction nanoSetH264Profile(p) {\n    nanoSetConfig(\nH264Profile\n,p);\n}\n\n// H.264 I-Frame Distance\nnanoSetH264IFrameDistance(50);          // Default=50\n\n// special h264 settings\nnanoSetH264Profile(0);          // 0 or \nBaseline\n, 1 or \nMain\n\nnanoSetH264VlcMode(1);              // VLC mode: 0=auto, 1=cavlc, 2=cabac\n\n// Constant/Variable Bit Rate\nnanoSetConfig(\nRateControl\n,0);     // 0=auto, 1=cbr, 2=vbr\n\n// set server authentication (wowza/flash media server)\nfunction nanoSetServerAuth(user,pass) {\n    nanoSetConfig(\nAuth\n,user+pass);\n}\n\n\n// SetVideoResolution()\n// sets video capture resolution (x/y)\n// warning: resolutions are hardware/driver dependent!\nfunction SetVideoResolution(x,y) {\n    nlog(\nSetVideoResolution \n+x+\nx\n+y);\n    nanovid1.VideoWidth = x;\n    nanovid1.VideoHeight = y;\n}\n\n// SetVideoResize()\n// sets video resize resolution (x/y) (output of encoder)\nfunction SetVideoResize(x,y,enableResize) {\n    if(enableResize) {\n        nlog(\nSetVideoResize \n+x+\nx\n+y);\n        nanovid1.VideoResizeWidth = resizeWidth;\n        nanovid1.VideoResizeHeight = resizeHeight;\n        nanovid1.EnableResize = 1;\n    }\n}\n\n// set deinterlacing mode\nnanoSetConfig(\nDeinterlacingMode\n, m);      // 0=off, 1=auto, 2=always\nnanoSetConfig(\nDeinterlacingMethod\n, m);    // 0=bob/weave, 1=blend, 2=filter, 3=edge\n\n\n\n\nNew Javascript functions for Version 2.0\n\n\nBeginning with nanoStream API 2.0, the Javascript code has been restructured with a surrounding object \nnanoStream.api\n.\n\n\nSimple example:\\\nIn nanoEncoder.js:\n\n\n// set one global liveObj\nvar liveObj = nanoStream.api;\n\n\n\n\nHTML usage:\\\nButton with \nStartBroadcast\n event handler:\n\n`html\n\ninput type=\"button\" value=\"Start BroadCasting\" onclick='liveObj.StartBroadcast()'\n\n\nSee nanoStream.html for an example implementation.\n\n\nFor 2.0, there are a number of additional API functions available which are documented in the separate documentation //LiveVideoEncoder-Plugin-API.", 
            "title": "Javascript Integration"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#live_video_encoder_-_plugin_api", 
            "text": "NOTE: This is the Plugin API for NPAPI and ActiveX.\nFor using Chrome Browsers, see our  nanoStream Web API 4.x", 
            "title": "Live Video Encoder - Plugin API"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#browser_based_usage_with_html_and_javascript", 
            "text": "The Live Video Encoder core components are available as plugins for several browsers:\\\nInternet Explorer (IE), based on ActiveX, and NP-Plugin based browsers (Firefox, Safari, Chrome).\\\nThe same API is valid for integration into other languages, C++, .NET, Delphi, etc.\\\nSee the sample web page for functionality or contact us for further help.\\", 
            "title": "Browser based usage with HTML and Javascript"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#how_to_embed_the_encoder_plugin_into_html", 
            "text": "", 
            "title": "How to embed the encoder plugin into HTML"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#active-x_control", 
            "text": "The Active-X Control is compatible with Microsoft Internet Explorer only. It is loaded by specifying the classid for the plugin. The plugin then may be accessed by Javascript via the ID specified, here  nanovid1 .  Simple Version without auto-install:  object ID= nanovid1  classid= clsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B  /object   Advanced Version with auto-install from CAB file:  object ID= nanovid1 \n  classid= clsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B \n  width= 480  height= 360 \n  codebase= ../packages/nanostream-1.5.0.6.cab#version=1,5,0,6  /object   Note: replace the codebase path and version with the cab file you received for installation.", 
            "title": "Active-X Control"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#npapi_plugin", 
            "text": "The NPAPI plugin is compatible with Mozilla Firefox, Apple Safari and Google Chrome.       embed id= nanovid1  type= application/x-nanocosmos-LiveVideoEncoder  width=480 height=360 \n     noembed \n      Can't embed plugin.\n     /noembed \n     /embed   It may be used with an   tag as well.", 
            "title": "NPAPI Plugin"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#browser_independent_plugin_loading", 
            "text": "The object tags may be nested to support all browser types:  object ID= nanovid1 \n  classid= clsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B  width= 480  height= 360 \n     comment \n         embed id= nanovid1  type= application/x-nanocosmos-LiveVideoEncoder  width=480 height=360 \n             noembed Can't embed plugin. /noembed \n         /embed \n     /comment  /object", 
            "title": "Browser independent plugin loading"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#license_and_other_custom_settings", 
            "text": "The License key is a string which needs to be placed into the nanoLicense.js file.\\\nThe nanoLicense.js also contains the mime type and path to the Mozilla based plugin (XPI). The default path is  ../packages/nanostream.xpi :", 
            "title": "License and other custom settings"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#contents_of_nanolicensejs", 
            "text": "// nanoStream License Code and custom settings\n// replace the  nlic  string with your custom license\ng_nanoLicense =  nlic:1.0:nanoLiveEncDemo:\u2026\u2026\u2026  ;\n\n//url to xpi installer package\nvar nano_xpi_source =  ../packages/nanostream.xpi ;", 
            "title": "Contents of nanoLicense.js"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#dynamic_dom_loading_of_the_plugin", 
            "text": "The plugin may be loaded into the HTML Document (DOM) by dynamically creating it with Javascript:  function createNanoVideoObject()\n{\n    var nanovid = document.createElement( object );\n    if(isIE)\n        nanovid.setAttribute( classid , clsid:E6F9EDB5-797B-4bc3-95E2-B7EA0886273B );\n    else\n          nanovid.setAttribute( type , application/x-nanocosmos-LiveVideoEncoder );\n    return nanovid;\n}", 
            "title": "Dynamic DOM Loading of the Plugin"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#accessing_the_plugin", 
            "text": "nanoStream is then available as a DOM object with the id  nanovid1 . The member functions and variables can be accessed as other Javascript objects, e.g. nanovid1.StartPreview().", 
            "title": "Accessing the plugin"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#plugin_interface", 
            "text": "The nanoStream Plugin may be controlled from almost any language which is able to load the plugin.\\\nThe plugin exposes methods and properties to set options, start preview and encoding.", 
            "title": "Plugin Interface"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#list_of_propertiesfunctions_with_example_settings", 
            "text": "destination URL (Flash or Wowza Media Server, or local file)\nnanovid1.DestinationURL =  rtmp://localhost/live+myStream ;\nnanovid1.DestinationURL =  c:\\temp\\h264.mp4 ;\nnanovid1.VideoSource = 0;       // Video Capture Device ID\nnanovid1.AudioSource = 0;       // Audio Capture Device ID\nnanovid1.VideoBitrate = 400000;         // Video Bitrate (bits/s)\nnanovid1.AudioBitrate = 32000;          // Audio Bitrate (bits/s)\nnanovid1.VideoWidth = 352;      // Video Pixel Width\nnanovid1.VideoHeight = 288;     // Video Pixel Height\nnanovid1.VideoFrameRate = 15;           // Video FPS\n\n//start the preview from the current camera\nnanovid1.StartPreview();\n\n//Start Encoding/Broadcast\nnanovid1.StartBroadcast();", 
            "title": "List of Properties/Functions with example settings:"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#javascript_helper_functions", 
            "text": "For simple usage, a set of Javascript functions is provided (nanoEncoder.js).  // setup a live stream to a Flash Media/Wowza server\nSetEncodingUrl( rtmp://myServer.com/live/myStream );\nSetVideoBitrate(400000);    // sets the bitrate to 400 kbps\nOnStartPreview();       // calls nanovid1.StartPreview()\nOnStartBroadcast();     // calls nanovid1.StartBroadcast()  Additional Configuration can be set with  nanoSetConfig();  Example:  nanoSetConfig( H264Profile , Baseline );", 
            "title": "Javascript Helper Functions"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#javascript_api_nanoencoderjs", 
            "text": "// SetEncodingUrl()\n// call this to set custom encoding URL here\nfunction SetEncodingUrl(url)\n\n// get current internal encoding url\nfunction GetEncodingUrl()\n\n// SetVideoBitrate()\n// sets encoder bitrate (bits/s)\nfunction SetVideoBitrate(bitrate)\n\nfunction GetVideoBitrate()\n\n// SetVideoResolution()\n// sets video capture resolution (x/y)\n// warning: resolutions are hardware/driver dependent!\nfunction SetVideoResolution(x,y)\n\n// SetVideoFrameRate()\n// sets video capture frames/sec (e.g. 15, 25)\nfunction SetVideoFrameRate(fps)\n\n// Start/Stop Video Capture Preview\nfunction OnStartPreview(doCheckFormat)\nfunction OnStopPreview()\n\n// OnStartBroadcast()\n// starts encoding / network broadcast\nfunction OnStartBroadcast()\nfunction OnStopBroadcast()\n\n// SetAudioSource()\n// sets audio source device id (0...)\nfunction SetAudioSource(audioSource) {\n\n// SetVideoSource()\n// sets video  source device id (0...)\nfunction SetVideoSource(source) {\n\n// event_OnStop\n// called by plugin on stop events\nfunction event_OnStop(e)\n\n// set basic encoding options to init plugin\nfunction nanoSetOptions()\n\n// Set license string to unlock the API\nfunction nanoSetLicense(license) // call this before Init", 
            "title": "Javascript API (nanoEncoder.js)"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#new_functions_for_version_15", 
            "text": "Special configuration data can be sent with the SetConfig method:\\\nnanovid1.SetConfig(property,value);  For some functions wrapper functions are available.  // H264 Encoding Profile ( Baseline  or  Main )\nfunction nanoSetH264Profile(p) {\n    nanoSetConfig( H264Profile ,p);\n}\n\n// H.264 I-Frame Distance\nnanoSetH264IFrameDistance(50);          // Default=50\n\n// special h264 settings\nnanoSetH264Profile(0);          // 0 or  Baseline , 1 or  Main \nnanoSetH264VlcMode(1);              // VLC mode: 0=auto, 1=cavlc, 2=cabac\n\n// Constant/Variable Bit Rate\nnanoSetConfig( RateControl ,0);     // 0=auto, 1=cbr, 2=vbr\n\n// set server authentication (wowza/flash media server)\nfunction nanoSetServerAuth(user,pass) {\n    nanoSetConfig( Auth ,user+pass);\n}\n\n\n// SetVideoResolution()\n// sets video capture resolution (x/y)\n// warning: resolutions are hardware/driver dependent!\nfunction SetVideoResolution(x,y) {\n    nlog( SetVideoResolution  +x+ x +y);\n    nanovid1.VideoWidth = x;\n    nanovid1.VideoHeight = y;\n}\n\n// SetVideoResize()\n// sets video resize resolution (x/y) (output of encoder)\nfunction SetVideoResize(x,y,enableResize) {\n    if(enableResize) {\n        nlog( SetVideoResize  +x+ x +y);\n        nanovid1.VideoResizeWidth = resizeWidth;\n        nanovid1.VideoResizeHeight = resizeHeight;\n        nanovid1.EnableResize = 1;\n    }\n}\n\n// set deinterlacing mode\nnanoSetConfig( DeinterlacingMode , m);      // 0=off, 1=auto, 2=always\nnanoSetConfig( DeinterlacingMethod , m);    // 0=bob/weave, 1=blend, 2=filter, 3=edge", 
            "title": "New functions for Version 1.5"
        }, 
        {
            "location": "/nanostream/web/nanostream_javascript_integration/#new_javascript_functions_for_version_20", 
            "text": "Beginning with nanoStream API 2.0, the Javascript code has been restructured with a surrounding object  nanoStream.api .  Simple example:\\\nIn nanoEncoder.js:  // set one global liveObj\nvar liveObj = nanoStream.api;  HTML usage:\\\nButton with  StartBroadcast  event handler: `html input type=\"button\" value=\"Start BroadCasting\" onclick='liveObj.StartBroadcast()'  See nanoStream.html for an example implementation.  For 2.0, there are a number of additional API functions available which are documented in the separate documentation //LiveVideoEncoder-Plugin-API.", 
            "title": "New Javascript functions for Version 2.0"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/", 
            "text": "This is Markdown.\nvergleiche\nhttp://www.nanocosmos.de/v4/documentation/nanostream_sdk_for_ios_-_developer_documentation\n\n\nnanoStream SDK for iOS - Developer Manual\n\n\nPurpose\n\n\nThis documentation is about the nanoStream Live Video Streaming SDK for iOS and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.\n\n\nRequirements\n\n\n\n\nApple Mac with MacOS 10.9 with XCode 6 or higher\n\n\nApple iPhone with iOS 7 or later (min. iOS 8.1 recommended)\n\n\n\n\nGetting Started\n\n\nPreparation\n\n\nAdd the library \nlibnanostreamAVC.a\n as dependency (Link Binary With Libraries) to your project.\nFurther required dependencies:\n\n\n\n\nlibc++.dylib\n\n\nlibstdc++.dylib\n\n\nAVFoundation.framework\n\n\nAccelerate.framework\n\n\nCoreGraphics.framework\n\n\nCoreMedia.framework\n\n\nCoreVideo.framework\n\n\nFoundation.framework\n\n\nSystemConfiguration.framework\n\n\nVideoToolbox.framework (link as Optional, not as Required)\n\n\nAudioToolbox.framework\n\n\n\n\nInclude the header \nlibnanostreamAVC.h\n in your source code.\n\n\nCheck library version\n\n\nint version = [nanostreamAVC getVersion];\nif(version!=NANOSTREAM_AVC_VERSION)\n{\n    // Handle header and library version mismatch\n}\n\n\n\n\n\nInitialize the library\n\n\nImplement the interface \nnanostreamEventListener\n in your class:\n\n\n@interface SampleLiveViewController : UIViewController \nnanostreamEventListener\n\n...\n@property (nonatomic, strong) nanostreamAVC *nAVC;\n@property (nonatomic, strong) IBOutlet UIView *previewView;\n...\n@end\n\n@implementation SampleLiveViewController\n...\n-(void)nanostreamEventHandlerWithType:(nanostreamEvent)type andLevel:(int)level andDescription:(NSString *)description\n{\n    switch (type) {\n        case StreamStarted:\n            break;\n        case StreamStopped:\n            break;\n        case StreamError:\n            NSLog(@\nnanostreamEventHandlerWithType: StreamError: %@\n, description);\n            break;\n        case StreamErrorConnect:\n            NSLog(@\nnanostreamEventHandlerWithType: StreamErrorConnect: %@\n, description);\n            break;\n        case StreamConnectionStatus:\n            NSLog(@\nnanostreamEventHandlerWithType: RtmpConnectionStatus %@\n, description);\n            break;\n        case GeneralError:\n            break;\n        default:\n            break;\n    }\n}\n...\n@end\n\n\n\n\nConfigure the settings object for the library:\n\n\nnanostreamAVCSettings *nAVCSettings = [[nanostreamAVCSettings alloc] init];\n\n// set the rtmp url, you want to stream to\n[nAVCSettings setUrl: @\nrtmp://localhost/live\n];\n[nAVCSettings setStreamId: @\nmyStream\n];\n\n// set the video settings\n[nAVCSettings setVideoResolution: Resolution640x480];\n[nAVCSettings setVideoBitrate: 512];\n[nAVCSettings setKeyFramerate: 60];\n[nAVCSettings setOrientation: AVCaptureVideoOrientationLandscapeRight];\n[nAVCSettings setCropMode: NoCrop];\n[nAVCSettings setFramerate: 30];\n[nAVCSettings setH264Level: Baseline30];\n\n// set the audio settings\n[nAVCSettings setInitialVolume: 1.0];\n[nAVCSettings setAudioMonoStereo: Stereo];\n[nAVCSettings setAudioSamplerate: 44100.0f];\n\n\n\n\nThen the library itself can be initialized:\n\n\n// nAVC and previewView are properties of the controller class in this example\nself.nAVC = [[nanostreamAVC alloc] initWithSettings: nAVCSettings\n                                          uiPreview: self.previewView\n                                      errorListener: self];\n\n// set the license key (required for streaming)\n[self.nanostream setLicense: @\nnlic:1.2:LiveEnc:1.1:LvApp=1.....288\n];\n\n\n\n\nStart a stream\n\n\n// Start broadcast asynchronously with completion handler\n[self.nAVC start:^(bool success)\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        if (success)\n        {\n            // Handle succesful stream start\n            ...\n        }\n        else\n        {\n            // Handle failure\n            ...\n        }\n    }\n}\n\n\n\n\nStop a running stream\n\n\nIf the parameter \nblocking\n of the stop method is set to YES, all the remaining data (to this moment) will be sent before stopping the stream.\nIf set to NO, the stream will stop immediately, discarding the remaining data.\n\n\n// Stop broadcast asynchronously with completion handler\n[self.nAVC stop:YES withCompletion:^\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        // Handle stream stop\n    }\n}\n\n\n\n\nAdvanced Settings/Usage\n\n\nOrientation\n\n\nThe orientation of the stream can be set to portrait or landscape with the property \norientation\n of the settings object.\n\n\nAs of version 4.4.0.6 the orientation can also be changed after the initialization with the property \norientation\n of the nanostreamAVC object itself.\n\n\nImportant:\n The orientation change will only affect the stream, but not the preview. The orientation for the preview has to be managed on the application level. This can be achieved by using e.g. \nCGAffineTransformMakeRotation\n (\nhttps://developer.apple.com/library/mac/documentation/GraphicsImaging/Reference/CGAffineTransform/\n).\n\n\nStream Type\n\n\nThe SDK supports different streaming modes:\n\n\n\n\nVideo and Audio\n\n\nVideo only\n\n\nAudio only\n\n\n\n\nYou can configure the mode with the property \nstreamType\n of the settings object.\n\n\nServer Authentication\n\n\nIn case authentication is required, the credentials can be set with the method\n\n\n-(void) setAuthentication: (NSString*) user withPassword: (NSString*) password;\n\n\n\n\nThe method has to be invoked before a stream is started.\n\n\nFor example:\n\n\n// set up nAVC object\n...\n[nAVC setAuthentication: @\nMyUser\n withPassword: @\nMyPassword\n];\n...\n// start the stream\n\n\n\n\nCropping\n\n\nThe stream can be transformed to a different format than the input from the camera.\n\n\nThe following example shows how to crop the format to 16:9.\n\n\n[nAVCSettings setCropMode: CropTo16By9];\n\n\n\n\nLocal Recording\n\n\nIt is possible to make a local copy of the stream, on the iOS device.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string \nMP4=2\n.\n\n\nNSString *homeDirectory = [NSHomeDirectory() stringByAppendingPathComponent:@\nDocuments\n];\nNSDateFormatter *dateFormatter=[[NSDateFormatter alloc] init];\n[dateFormatter setDateFormat:@\nyyyy-MM-dd_HH-mm-ss\n];\nNSString *locStr = [homeDirectory stringByAppendingPathComponent: [[dateFormatter stringFromDate:[NSDate date]] stringByAppendingString: @\n.mp4\n]];\n\n[nAVCSettings setLocalRecordingMode:AVCRecordingModeDoubleAtLeastOneMbit];\n[nAVCSettings setLocalRecordingPath:locStr];\n\n\n\n\nThere are three modes available:\n\n\n\n\nAVCRecordingModeStartBitrate: uses the video bitrate set with nanostreamAVCSettings\n\n\nAVCRecordingModeDoubleAtLeastOneMbit: uses double the video bitrate, but at least 1Mbps\n\n\nAVCRecordingMode720p2Mbit: independent of the set video bitrate, always uses 2Mbps and a resolution of 1280x720\n\n\n\n\nThe bitrate for the recording remains constant during a stream. The adaptive bitrate mechanism only influences the bitrate for the stream, but not the bitrate for the recording.\n\n\nThe bitrate for the recording also depends on the video material. If there is a lot of movement in the video the bitrate will be higher than for recordings with little to no movement.\n\n\nAdaptive Bitrate\n\n\nBy using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth.\nThere are two modes available:\n\n\n\n\nAdaptiveBitrateControlModeQualityDegrade: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.\n\n\nAdaptiveBitrateControlModeFrameDrop: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.\n\n\n\n\nMake sure to set the ABC settings before a stream is started.\n\n\n[self.nAVC setAdaptiveBitrateControlMode: AdaptiveBitrateControlModeQualityDegrade];\n\nAdaptiveBitrateControlSettings abr;\nabr.minimumBitrate = 100000;  // 100kb\nabr.minimumFramerate = 15;\nabr.maxPercentBitrateChange = 50;  // if the bitrate drops to less than 50% of the previous bitrate, all buffered data will be discarded\n\n[self.nAVC setAdaptiveBitrateControlSettings: abr];\n\n\n\n\nPossible properties:\n\n\n\n\n\n\n\n\nproperty\n\n\ndefault values\n\n\nrange of values\n\n\noptional\n\n\n\n\n\n\n\n\n\n\nminimumBitrate\n\n\n5000 (50 kb)\n\n\n50000 - 10 000 000\n\n\nYES\n\n\n\n\n\n\nminimumFramerate\n\n\n15 (fps)\n\n\n5 - 60\n\n\nYES\n\n\n\n\n\n\nmaxPercentBitrateChange\n\n\n50 (%)\n\n\n0 - 100\n\n\nYES\n\n\n\n\n\n\n\n\n_\n\n\nFor more information look here at \nnanoStream Documentation for Adaptive Bitrate\n\n\nMeasuring the available bandwidth\n\n\nFor measuring the available bandwidth you can use the method \nrunBandwidthCheck\n. After the check finished, the result can be used to set the bitrate for the nanostreamAVC object.\n\n\nThe check measures the bandwidth by running a test stream to the server.\n\n\nNSXBandwidthCheckSettings *bwSettings = [[NSXBandwidthCheckSettings alloc] init];\n// the URL settings are identical to the URL settings for the nanostreamAVCSettings\n// for testing the bandwidth it is advised to use the same server you want to stream to\n// you might want to use a stream id different from the stream id for the actual stream, to distinguish between a bandwidth check and a real stream\nbwSettings.url = @\nrtmp://localhost/live\n;\nbwSettings.streamId = @\nbwcheck\n;\n// the maxium bitrate that should be tested - if this value is lower than the actual bandwidth, the result will be similar to the maximum bitrate\nbwSettings.maxBitrate = 5000000;  // 5Mb\n\n[self.nAVC runBandwidthCheck: bwSettings withCompletionBlock:^(NSXBandwidthCheckResult* measuredBandwidth){\n    NSLog(@\nmeasuredBandwidth: avg=%i, median=%i, min=%i, max=%i, runTimeMs=%i\n, (int)measuredBandwidth.avgBitrate, (int)measuredBandwidth.medianBitrate, (int)measuredBandwidth.minBitrate, (int)measuredBandwidth.maxBitrate, (int)measuredBandwidth.runTimeMs);\n}];\n\n\n\n\nThe default run time is 10 seconds. The run time can be changed with the property \nrunTime\n.\nIf the bandwidth check should be stopped before it finished on itself, the method \nstopBandwidthCheck\n can be used. This will force the bandwidth check to stop and return the result based on the collected information up to this point.\n\n\n[self.nAVC stopBandwidthCheck];    // stop bw check if still running\n\n\n\n\nThe result of the bandwidth check can be used as bitrate setting for library object. At the moment it is not possible to change the video bitrate after the initialization of the library object, thus the object need to be re-initialized. (This will change in future releases.)\n\n\nSnaphot from the current stream\n\n\nTo get a snaphot (image) of the current preview/stream, the method \ngrabStillImageWithCompletionBlock\n can be used.\n\n\n[self.nAVC grabStillImageWithCompletionBlock:^(UIImage *image, NSError *error) {\n    // do something with the image\n}];\n\n\n\n\nOverlay/Watermark\n\n\nIt is possible to use an overlay (image, text, or both) for a stream. Notice that the CPU usage will be increased slightly when an overlay is used.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string \nOVL=1\n.\n\n\nThe easiest way to use an overlay is to use the class \nAVCFullImageOverlay\n:\n\n\nUIImage *overlayImg = [UIImage imageNamed:@\nbutton\n];  // uses an image from the bundle resources, named \nbutton\n\n\nUIGraphicsBeginImageContextWithOptions(CGSizeMake(640, 480), NO, 1.0);  // assuming the video resolution is set to \nResolution640x480\n\n[overlayImg drawInRect:CGRectMake(200, 200, 240, 80) blendMode:kCGBlendModeNormal alpha:0.5];\nUIFont *font = [UIFont boldSystemFontOfSize:20];\n[[UIColor whiteColor] set];\nNSString *text = @\nWatermark\n;\n[text drawInRect:CGRectMake(200, 300, 100, 50) withFont:font];\nUIImage *finalOverlayImage = UIGraphicsGetImageFromCurrentImageContext();\nUIGraphicsEndImageContext();\n\n[self.nAVC setOverlay: [[AVCFullImageOverlay alloc] initWithImage: finalOverlayImage]];\n\n\n\n\nNotice that the final output resolution can be different, if an option like cropping is used.\nIn this case it is better to implement your own overlay class, which is shown in the following example:\n\n\n@interface NSXWatermark : NSObject \nAVCOverlay\n\n\n@property (assign) AVCOverlayRawBuffer buffer;\n\n@end\n\n@implementation NSXWatermark\n\n@synthesize imageSize;\n@synthesize overlayBoundingRect;\n\n-(AVCOverlayRawBuffer)overlayImageWithStreamTime:(NSTimeInterval)time\n{\n    if (self.buffer.buffer == NULL) {\n        UIImage *image = [NSXWatermark generateWatermarkWithSize:self.imageSize inBoundingRect:self.overlayBoundingRect];\n        self.buffer = [NSXWatermark makeBufferFromUIImage:image];\n    }\n\n    return self.buffer;\n}\n\n+(UIImage *)generateWatermarkWithSize:(CGSize)size inBoundingRect:(CGRect)boundingRect\n{\n    UIImage *watermarkImage = ...  // use your desired UIImage here\n    CGFloat padding = 10.0;\n    CGSize overlaySize = watermarkImage.size;\n\n    CGFloat height = size.height / 3;\n    if (overlaySize.height \n height) {\n        overlaySize.width = height;\n        overlaySize.height = height;\n    }\n\n    CGFloat boundingMaxX = boundingRect.origin.x + boundingRect.size.width;\n    CGFloat boundingMaxY = boundingRect.origin.y + boundingRect.size.height;\n\n    CGRect overlayRect = CGRectMake(boundingMaxX - overlaySize.width, boundingMaxY - overlaySize.height, overlaySize.width, overlaySize.height);\n\n    //  CGRect overlayRect = CGRectMake(size.width - overlaySize.width, size.height - overlaySize.height, overlaySize.width, overlaySize.height);\n    CGRect realRect =  AVMakeRectWithAspectRatioInsideRect(watermarkImage.size, overlayRect);\n\n    realRect.origin.y -= padding;\n    realRect.origin.x -= padding;\n\n    UIGraphicsBeginImageContext(size);\n    [watermarkImage drawInRect:realRect];\n\n    UIImage *overlayImage = UIGraphicsGetImageFromCurrentImageContext();\n\n    UIGraphicsEndImageContext();\n\n    return overlayImage;\n}\n\n+(AVCOverlayRawBuffer)makeBufferFromUIImage:(UIImage *)image\n{\n    CGImageRef rawPic = [image CGImage];\n\n    CGDataProviderRef inProvider = CGImageGetDataProvider(rawPic);\n    CFDataRef inBitmapData = CGDataProviderCopyData(inProvider);\n\n    size_t inBitmapDataBytesPerRow = CGImageGetBytesPerRow(rawPic);\n\n    UInt8 *buffer = (UInt8*)CFDataGetBytePtr(inBitmapData);\n\n    AVCOverlayRawBuffer rawBuf;\n    rawBuf.buffer = buffer;\n    rawBuf.bytesPerRow = (int)inBitmapDataBytesPerRow;\n    rawBuf.bufferType = AVCOverlayBufferTypeBGRA;\n    return rawBuf;\n}\n@end\n\n\n\n\ninitWithSession\n\n\nInstead of letting the SDK manage the video and audio input, you can also do that yourself. This is helpful to supply video and audio samples which are not coming from the standard input devices. Or to modify video and/or audio samples before they are used for the stream.\n\n\nThe SDK provides a separate init method \ninitWithSession\n.\n\n\nAn example for a custom capture session, which supplies CVPixelBufferRef\ns to the SDK:\n\n\n@interface CustomCaptureSession : AVCaptureSession\n...\n@end\n\n@implementation CustomCaptureSession\n\n-(void) addOutput:(AVCaptureOutput )output\n{\n    if ([output isKindOfClass:[AVCaptureVideoDataOutput class]]) {\n        self.myVideoOutput = (AVCaptureVideoDataOutput)output;\n    }else if([output isKindOfClass:[AVCaptureAudioDataOutput class]])\n    {\n        //self.myAudioOutput = (AVCaptureAudioDataOutput*)output; // if you want to use a custom audio capture device\n        [super addOutput: output]; // uses the standard microphone of the iOS device\n    }\n}\n\n-(void) addInput:(AVCaptureInput *)input\n{\n    [super addInput:input]; // this is required, because nanostreamAVC checks the available inputs\n}\n\n-(void) startRunning\n{\n    [super startRunning];\n}\n\n// this method has to be called periodically - e.g. with CADisplayLink\n-(void) supplyCMSampleBufferRef\n{\n    CVPixelBufferRef buffer = [self getCVPixelBufferRef]; // get the CVPixelBufferRef from somewhere\n\n    CMSampleBufferRef newSampleBuffer = NULL;\n    CMSampleTimingInfo timingInfo = kCMTimingInfoInvalid;\n    timingInfo.duration = CMTimeMake(33, 1000);    // assuming 30fps, change if otherwise\n    timingInfo.decodeTimeStamp = CMTimeMake(ts, 1000);    // timestamp information required\n    timingInfo.presentationTimeStamp = timingInfo.decodeTimeStamp;\n\n    CMVideoFormatDescriptionRef videoInfo = NULL;\n    CMVideoFormatDescriptionCreateForImageBuffer(NULL, buffer, \nvideoInfo);\n\n    CMSampleBufferCreateForImageBuffer(kCFAllocatorDefault,buffer,true,NULL,NULL,videoInfo,\ntimingInfo,\nnewSampleBuffer);\n\n    // the following line submits the new CMSampleBufferRef to the nanostreamAVC lib\n    [self.myVideoOutput.sampleBufferDelegate captureOutput:self.myVideoOutput didOutputSampleBuffer:newSampleBuffer fromConnection:nil];\n\n    CFRelease(videoInfo);\n    CFRelease(buffer);\n    CFRelease(newSampleBuffer);\n\n}\n\n@end\n\n// you need to use initWithSession for nanostreamAVC to use your custom session\n...\nsession = [[CustomCaptureSession alloc] init];\n\n// Add input nodes\nif(videoInput != nil)\n{\n    [session addInput: videoInput];\n}\n\nif(audioInput != nil)\n{\n    [session addInput: audioInput]; // if the stream is video only, don't add an audioInput\n}\n\n[session startRunning];\n\n...\nself.stream = [[nanostreamAVC alloc] initWithSession: session settings: nAVCSettings errorListener: self];\n...\n\n\n\n\nPossible Issues\n\n\nGeneral\n\n\nFor older versions of the sdk, without support for arm64, architecture in Xcode has to be set to armv7 and/or armv7s. This works also for newer iOS-Devcies like iPhone 5s.\nThis is not required for newer sdk versions, which also support arm64.\n\n\nCompiler/Linker\n\n\nlibstdc++\n\n\nIf there are linker errors with \nstd::\n: \nsymbol(s) not found for architecture\n, make sure that you added the libraries \nlibstdc++.dylib\n and \nlibc++.dylib\n to your project.\n\n\nDue to a bug in Xcode, depending on the selected Base SDK and deployment target, there might be still linker errors regarding \nstd\n. In this case you need to add a specific version of the libstdc++ to your project, e.g.: libstdc++-6.0.9.dylib instead of libstdc++.dylib\n\n\nUndefined Symbols for Parrot \n DJI\n\n\nThe following part is only relevant for SDK versions from 3.3.x to 4.1.x.\n\nAs of version 4.2.x the drone dependencies are removed from the standard SDK package.\n\n\nIt might be possible that there are linker errors for the classes\n\n\n\n\nParrotBebopCaptureSession or\n\n\nDJIPhantom2CaptureSession\n\n\n\n\nGenerally, if the Parrot \n DJI extensions are not used, the symbols should be stripped automatically by Xcode and you do not need to link the frameworks.\nHowever this is not the case when the linker flag \n-ObjC\n is used in the app project. This causes the linker to load all symbols included in all linked object files (including the Parrot \n DJI symbols). This prevents the automatic stripping.\n\n\nTo use our library without Parrot \n DJI, either remove the \n-ObjC\n linker flag from the project or replace the \n-ObjC\n linker flag with the \n-force_load\n flag for each library that you want to use. Do not use \n-force_load\n with libnanostreamAVC.a.\nFor examples see http://stackoverflow.com/questions/11254269/using-the-force-load-linker-flag-with-restkit-ios\n\n\nBreakpoints\n\n\nIf you debug your application, it is possible that breakpoints are being hit due to internal exceptions. Exceptions on the SDK level are handled in the SDK and do not affect the workflow of your application.\n\n\nYou can prevent the breakpoint from pausing the workflow of your application, if you use the right settings for the breakpoint.\nThe default setting is most likely that every exception causes a break.\nTo change that, use the settings from the following screenshot:\n\n\n\n\nThis way only Objective-C exceptions will be catched and C++ exceptions will be ignored.\n\n\nCrashes\n\n\nCALayerGetDelegate / CALayerGetSuperlayer / Other CALayer\n\n\nIf there are crashes occurring in your app that include above symbols in the stack trace and are otherwise not obvious, check to see if you added a subviews to the preview view. The UIView instance that is passed to\n\n\n[RtmpSourceCaptureSession initWithPreview:andStatusListener:andLogLevel:]\n\n\n\n\nand\n\n\n[nanostreamAVC initWithSettings:uiPreview:errorListener:]\n\n\n\n\ncannot contain any subviews (UIButtons or otherwise).\n\n\nLogging Information\n\n\nIf you encounter a problem with the nanostreamAVC library and you want to report the problem, log files will help us to comprehend the problem.\n\n\nPlease use the following steps to create the log files:\n\n\n\n\nenable logging for the library with the method \nSetLogLevel\n, use LogLevelVerbose:\n\n\n\n\nobjc\n  [self.nAVC SetLogLevel: LogLevelVerbose];  // set the log level before the method \"start\" is invoked\n\n\n\n\ntry to reproduce the problem\n\n\ndownload the app container (for your app) from the iOS device with Xcode, as explained here: \nhttps://developer.apple.com/library/ios/recipes/xcode_help-devices_organizer/articles/manage_containers.html\n\n\nin Finder right click on the downloaded container and select \nShow Package Contents\n\n\nsend us the logfiles located (in the container) in the folder \n/AppData/Library/Caches/Logs/\n\n\n\n\nCrash Logs\n\n\nIf you encounter a crash, please send us the crash log as explained in the following steps:\n\n\n\n\nPlug in the device and open Xcode\n\n\nChoose Window -\n Devices from the menu bar\n\n\nUnder the DEVICES section in the left column, choose the device\n\n\nTo see the device console, click the up-triangle at the bottom left of the right hand panel\n\n\nClick the down arrow on the bottom right to save the console as a file\n\n\nTo see crash logs, select the View Device Logs button under the Device Information section on the right hand panel\n\n\nFind your app in the Process column and select the Crash log to see the contents.\n\n\nTo save a crash log, right click the entry on the left column and choose \nExport Log\n\n\n\n\n(Taken from \nhttps://developer.apple.com/library/ios/qa/qa1747/_index.html\n)", 
            "title": "iOS api"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#nanostream_sdk_for_ios_-_developer_manual", 
            "text": "", 
            "title": "nanoStream SDK for iOS - Developer Manual"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#purpose", 
            "text": "This documentation is about the nanoStream Live Video Streaming SDK for iOS and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.", 
            "title": "Purpose"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#requirements", 
            "text": "Apple Mac with MacOS 10.9 with XCode 6 or higher  Apple iPhone with iOS 7 or later (min. iOS 8.1 recommended)", 
            "title": "Requirements"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#getting_started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#preparation", 
            "text": "Add the library  libnanostreamAVC.a  as dependency (Link Binary With Libraries) to your project.\nFurther required dependencies:   libc++.dylib  libstdc++.dylib  AVFoundation.framework  Accelerate.framework  CoreGraphics.framework  CoreMedia.framework  CoreVideo.framework  Foundation.framework  SystemConfiguration.framework  VideoToolbox.framework (link as Optional, not as Required)  AudioToolbox.framework   Include the header  libnanostreamAVC.h  in your source code.", 
            "title": "Preparation"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#check_library_version", 
            "text": "int version = [nanostreamAVC getVersion];\nif(version!=NANOSTREAM_AVC_VERSION)\n{\n    // Handle header and library version mismatch\n}", 
            "title": "Check library version"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#initialize_the_library", 
            "text": "Implement the interface  nanostreamEventListener  in your class:  @interface SampleLiveViewController : UIViewController  nanostreamEventListener \n...\n@property (nonatomic, strong) nanostreamAVC *nAVC;\n@property (nonatomic, strong) IBOutlet UIView *previewView;\n...\n@end\n\n@implementation SampleLiveViewController\n...\n-(void)nanostreamEventHandlerWithType:(nanostreamEvent)type andLevel:(int)level andDescription:(NSString *)description\n{\n    switch (type) {\n        case StreamStarted:\n            break;\n        case StreamStopped:\n            break;\n        case StreamError:\n            NSLog(@ nanostreamEventHandlerWithType: StreamError: %@ , description);\n            break;\n        case StreamErrorConnect:\n            NSLog(@ nanostreamEventHandlerWithType: StreamErrorConnect: %@ , description);\n            break;\n        case StreamConnectionStatus:\n            NSLog(@ nanostreamEventHandlerWithType: RtmpConnectionStatus %@ , description);\n            break;\n        case GeneralError:\n            break;\n        default:\n            break;\n    }\n}\n...\n@end  Configure the settings object for the library:  nanostreamAVCSettings *nAVCSettings = [[nanostreamAVCSettings alloc] init];\n\n// set the rtmp url, you want to stream to\n[nAVCSettings setUrl: @ rtmp://localhost/live ];\n[nAVCSettings setStreamId: @ myStream ];\n\n// set the video settings\n[nAVCSettings setVideoResolution: Resolution640x480];\n[nAVCSettings setVideoBitrate: 512];\n[nAVCSettings setKeyFramerate: 60];\n[nAVCSettings setOrientation: AVCaptureVideoOrientationLandscapeRight];\n[nAVCSettings setCropMode: NoCrop];\n[nAVCSettings setFramerate: 30];\n[nAVCSettings setH264Level: Baseline30];\n\n// set the audio settings\n[nAVCSettings setInitialVolume: 1.0];\n[nAVCSettings setAudioMonoStereo: Stereo];\n[nAVCSettings setAudioSamplerate: 44100.0f];  Then the library itself can be initialized:  // nAVC and previewView are properties of the controller class in this example\nself.nAVC = [[nanostreamAVC alloc] initWithSettings: nAVCSettings\n                                          uiPreview: self.previewView\n                                      errorListener: self];\n\n// set the license key (required for streaming)\n[self.nanostream setLicense: @ nlic:1.2:LiveEnc:1.1:LvApp=1.....288 ];", 
            "title": "Initialize the library"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#start_a_stream", 
            "text": "// Start broadcast asynchronously with completion handler\n[self.nAVC start:^(bool success)\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        if (success)\n        {\n            // Handle succesful stream start\n            ...\n        }\n        else\n        {\n            // Handle failure\n            ...\n        }\n    }\n}", 
            "title": "Start a stream"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#stop_a_running_stream", 
            "text": "If the parameter  blocking  of the stop method is set to YES, all the remaining data (to this moment) will be sent before stopping the stream.\nIf set to NO, the stream will stop immediately, discarding the remaining data.  // Stop broadcast asynchronously with completion handler\n[self.nAVC stop:YES withCompletion:^\n{\n    // use main queue to change UI related things\n    dispatch_async(dispatch_get_main_queue(), ^\n    {\n        // Handle stream stop\n    }\n}", 
            "title": "Stop a running stream"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#advanced_settingsusage", 
            "text": "", 
            "title": "Advanced Settings/Usage"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#orientation", 
            "text": "The orientation of the stream can be set to portrait or landscape with the property  orientation  of the settings object.  As of version 4.4.0.6 the orientation can also be changed after the initialization with the property  orientation  of the nanostreamAVC object itself.  Important:  The orientation change will only affect the stream, but not the preview. The orientation for the preview has to be managed on the application level. This can be achieved by using e.g.  CGAffineTransformMakeRotation  ( https://developer.apple.com/library/mac/documentation/GraphicsImaging/Reference/CGAffineTransform/ ).", 
            "title": "Orientation"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#stream_type", 
            "text": "The SDK supports different streaming modes:   Video and Audio  Video only  Audio only   You can configure the mode with the property  streamType  of the settings object.", 
            "title": "Stream Type"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#server_authentication", 
            "text": "In case authentication is required, the credentials can be set with the method  -(void) setAuthentication: (NSString*) user withPassword: (NSString*) password;  The method has to be invoked before a stream is started.  For example:  // set up nAVC object\n...\n[nAVC setAuthentication: @ MyUser  withPassword: @ MyPassword ];\n...\n// start the stream", 
            "title": "Server Authentication"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#cropping", 
            "text": "The stream can be transformed to a different format than the input from the camera.  The following example shows how to crop the format to 16:9.  [nAVCSettings setCropMode: CropTo16By9];", 
            "title": "Cropping"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#local_recording", 
            "text": "It is possible to make a local copy of the stream, on the iOS device.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string  MP4=2 .  NSString *homeDirectory = [NSHomeDirectory() stringByAppendingPathComponent:@ Documents ];\nNSDateFormatter *dateFormatter=[[NSDateFormatter alloc] init];\n[dateFormatter setDateFormat:@ yyyy-MM-dd_HH-mm-ss ];\nNSString *locStr = [homeDirectory stringByAppendingPathComponent: [[dateFormatter stringFromDate:[NSDate date]] stringByAppendingString: @ .mp4 ]];\n\n[nAVCSettings setLocalRecordingMode:AVCRecordingModeDoubleAtLeastOneMbit];\n[nAVCSettings setLocalRecordingPath:locStr];  There are three modes available:   AVCRecordingModeStartBitrate: uses the video bitrate set with nanostreamAVCSettings  AVCRecordingModeDoubleAtLeastOneMbit: uses double the video bitrate, but at least 1Mbps  AVCRecordingMode720p2Mbit: independent of the set video bitrate, always uses 2Mbps and a resolution of 1280x720   The bitrate for the recording remains constant during a stream. The adaptive bitrate mechanism only influences the bitrate for the stream, but not the bitrate for the recording.  The bitrate for the recording also depends on the video material. If there is a lot of movement in the video the bitrate will be higher than for recordings with little to no movement.", 
            "title": "Local Recording"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#adaptive_bitrate", 
            "text": "By using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth.\nThere are two modes available:   AdaptiveBitrateControlModeQualityDegrade: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.  AdaptiveBitrateControlModeFrameDrop: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.   Make sure to set the ABC settings before a stream is started.  [self.nAVC setAdaptiveBitrateControlMode: AdaptiveBitrateControlModeQualityDegrade];\n\nAdaptiveBitrateControlSettings abr;\nabr.minimumBitrate = 100000;  // 100kb\nabr.minimumFramerate = 15;\nabr.maxPercentBitrateChange = 50;  // if the bitrate drops to less than 50% of the previous bitrate, all buffered data will be discarded\n\n[self.nAVC setAdaptiveBitrateControlSettings: abr];  Possible properties:     property  default values  range of values  optional      minimumBitrate  5000 (50 kb)  50000 - 10 000 000  YES    minimumFramerate  15 (fps)  5 - 60  YES    maxPercentBitrateChange  50 (%)  0 - 100  YES     _  For more information look here at  nanoStream Documentation for Adaptive Bitrate", 
            "title": "Adaptive Bitrate"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#measuring_the_available_bandwidth", 
            "text": "For measuring the available bandwidth you can use the method  runBandwidthCheck . After the check finished, the result can be used to set the bitrate for the nanostreamAVC object.  The check measures the bandwidth by running a test stream to the server.  NSXBandwidthCheckSettings *bwSettings = [[NSXBandwidthCheckSettings alloc] init];\n// the URL settings are identical to the URL settings for the nanostreamAVCSettings\n// for testing the bandwidth it is advised to use the same server you want to stream to\n// you might want to use a stream id different from the stream id for the actual stream, to distinguish between a bandwidth check and a real stream\nbwSettings.url = @ rtmp://localhost/live ;\nbwSettings.streamId = @ bwcheck ;\n// the maxium bitrate that should be tested - if this value is lower than the actual bandwidth, the result will be similar to the maximum bitrate\nbwSettings.maxBitrate = 5000000;  // 5Mb\n\n[self.nAVC runBandwidthCheck: bwSettings withCompletionBlock:^(NSXBandwidthCheckResult* measuredBandwidth){\n    NSLog(@ measuredBandwidth: avg=%i, median=%i, min=%i, max=%i, runTimeMs=%i , (int)measuredBandwidth.avgBitrate, (int)measuredBandwidth.medianBitrate, (int)measuredBandwidth.minBitrate, (int)measuredBandwidth.maxBitrate, (int)measuredBandwidth.runTimeMs);\n}];  The default run time is 10 seconds. The run time can be changed with the property  runTime .\nIf the bandwidth check should be stopped before it finished on itself, the method  stopBandwidthCheck  can be used. This will force the bandwidth check to stop and return the result based on the collected information up to this point.  [self.nAVC stopBandwidthCheck];    // stop bw check if still running  The result of the bandwidth check can be used as bitrate setting for library object. At the moment it is not possible to change the video bitrate after the initialization of the library object, thus the object need to be re-initialized. (This will change in future releases.)", 
            "title": "Measuring the available bandwidth"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#snaphot_from_the_current_stream", 
            "text": "To get a snaphot (image) of the current preview/stream, the method  grabStillImageWithCompletionBlock  can be used.  [self.nAVC grabStillImageWithCompletionBlock:^(UIImage *image, NSError *error) {\n    // do something with the image\n}];", 
            "title": "Snaphot from the current stream"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#overlaywatermark", 
            "text": "It is possible to use an overlay (image, text, or both) for a stream. Notice that the CPU usage will be increased slightly when an overlay is used.\nThis is an extra feature and needs to be unlocked by the license - the license should contain the string  OVL=1 .  The easiest way to use an overlay is to use the class  AVCFullImageOverlay :  UIImage *overlayImg = [UIImage imageNamed:@ button ];  // uses an image from the bundle resources, named  button \n\nUIGraphicsBeginImageContextWithOptions(CGSizeMake(640, 480), NO, 1.0);  // assuming the video resolution is set to  Resolution640x480 \n[overlayImg drawInRect:CGRectMake(200, 200, 240, 80) blendMode:kCGBlendModeNormal alpha:0.5];\nUIFont *font = [UIFont boldSystemFontOfSize:20];\n[[UIColor whiteColor] set];\nNSString *text = @ Watermark ;\n[text drawInRect:CGRectMake(200, 300, 100, 50) withFont:font];\nUIImage *finalOverlayImage = UIGraphicsGetImageFromCurrentImageContext();\nUIGraphicsEndImageContext();\n\n[self.nAVC setOverlay: [[AVCFullImageOverlay alloc] initWithImage: finalOverlayImage]];  Notice that the final output resolution can be different, if an option like cropping is used.\nIn this case it is better to implement your own overlay class, which is shown in the following example:  @interface NSXWatermark : NSObject  AVCOverlay \n\n@property (assign) AVCOverlayRawBuffer buffer;\n\n@end\n\n@implementation NSXWatermark\n\n@synthesize imageSize;\n@synthesize overlayBoundingRect;\n\n-(AVCOverlayRawBuffer)overlayImageWithStreamTime:(NSTimeInterval)time\n{\n    if (self.buffer.buffer == NULL) {\n        UIImage *image = [NSXWatermark generateWatermarkWithSize:self.imageSize inBoundingRect:self.overlayBoundingRect];\n        self.buffer = [NSXWatermark makeBufferFromUIImage:image];\n    }\n\n    return self.buffer;\n}\n\n+(UIImage *)generateWatermarkWithSize:(CGSize)size inBoundingRect:(CGRect)boundingRect\n{\n    UIImage *watermarkImage = ...  // use your desired UIImage here\n    CGFloat padding = 10.0;\n    CGSize overlaySize = watermarkImage.size;\n\n    CGFloat height = size.height / 3;\n    if (overlaySize.height   height) {\n        overlaySize.width = height;\n        overlaySize.height = height;\n    }\n\n    CGFloat boundingMaxX = boundingRect.origin.x + boundingRect.size.width;\n    CGFloat boundingMaxY = boundingRect.origin.y + boundingRect.size.height;\n\n    CGRect overlayRect = CGRectMake(boundingMaxX - overlaySize.width, boundingMaxY - overlaySize.height, overlaySize.width, overlaySize.height);\n\n    //  CGRect overlayRect = CGRectMake(size.width - overlaySize.width, size.height - overlaySize.height, overlaySize.width, overlaySize.height);\n    CGRect realRect =  AVMakeRectWithAspectRatioInsideRect(watermarkImage.size, overlayRect);\n\n    realRect.origin.y -= padding;\n    realRect.origin.x -= padding;\n\n    UIGraphicsBeginImageContext(size);\n    [watermarkImage drawInRect:realRect];\n\n    UIImage *overlayImage = UIGraphicsGetImageFromCurrentImageContext();\n\n    UIGraphicsEndImageContext();\n\n    return overlayImage;\n}\n\n+(AVCOverlayRawBuffer)makeBufferFromUIImage:(UIImage *)image\n{\n    CGImageRef rawPic = [image CGImage];\n\n    CGDataProviderRef inProvider = CGImageGetDataProvider(rawPic);\n    CFDataRef inBitmapData = CGDataProviderCopyData(inProvider);\n\n    size_t inBitmapDataBytesPerRow = CGImageGetBytesPerRow(rawPic);\n\n    UInt8 *buffer = (UInt8*)CFDataGetBytePtr(inBitmapData);\n\n    AVCOverlayRawBuffer rawBuf;\n    rawBuf.buffer = buffer;\n    rawBuf.bytesPerRow = (int)inBitmapDataBytesPerRow;\n    rawBuf.bufferType = AVCOverlayBufferTypeBGRA;\n    return rawBuf;\n}\n@end", 
            "title": "Overlay/Watermark"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#initwithsession", 
            "text": "Instead of letting the SDK manage the video and audio input, you can also do that yourself. This is helpful to supply video and audio samples which are not coming from the standard input devices. Or to modify video and/or audio samples before they are used for the stream.  The SDK provides a separate init method  initWithSession .  An example for a custom capture session, which supplies CVPixelBufferRef s to the SDK:  @interface CustomCaptureSession : AVCaptureSession\n...\n@end\n\n@implementation CustomCaptureSession\n\n-(void) addOutput:(AVCaptureOutput )output\n{\n    if ([output isKindOfClass:[AVCaptureVideoDataOutput class]]) {\n        self.myVideoOutput = (AVCaptureVideoDataOutput)output;\n    }else if([output isKindOfClass:[AVCaptureAudioDataOutput class]])\n    {\n        //self.myAudioOutput = (AVCaptureAudioDataOutput*)output; // if you want to use a custom audio capture device\n        [super addOutput: output]; // uses the standard microphone of the iOS device\n    }\n}\n\n-(void) addInput:(AVCaptureInput *)input\n{\n    [super addInput:input]; // this is required, because nanostreamAVC checks the available inputs\n}\n\n-(void) startRunning\n{\n    [super startRunning];\n}\n\n// this method has to be called periodically - e.g. with CADisplayLink\n-(void) supplyCMSampleBufferRef\n{\n    CVPixelBufferRef buffer = [self getCVPixelBufferRef]; // get the CVPixelBufferRef from somewhere\n\n    CMSampleBufferRef newSampleBuffer = NULL;\n    CMSampleTimingInfo timingInfo = kCMTimingInfoInvalid;\n    timingInfo.duration = CMTimeMake(33, 1000);    // assuming 30fps, change if otherwise\n    timingInfo.decodeTimeStamp = CMTimeMake(ts, 1000);    // timestamp information required\n    timingInfo.presentationTimeStamp = timingInfo.decodeTimeStamp;\n\n    CMVideoFormatDescriptionRef videoInfo = NULL;\n    CMVideoFormatDescriptionCreateForImageBuffer(NULL, buffer,  videoInfo);\n\n    CMSampleBufferCreateForImageBuffer(kCFAllocatorDefault,buffer,true,NULL,NULL,videoInfo, timingInfo, newSampleBuffer);\n\n    // the following line submits the new CMSampleBufferRef to the nanostreamAVC lib\n    [self.myVideoOutput.sampleBufferDelegate captureOutput:self.myVideoOutput didOutputSampleBuffer:newSampleBuffer fromConnection:nil];\n\n    CFRelease(videoInfo);\n    CFRelease(buffer);\n    CFRelease(newSampleBuffer);\n\n}\n\n@end\n\n// you need to use initWithSession for nanostreamAVC to use your custom session\n...\nsession = [[CustomCaptureSession alloc] init];\n\n// Add input nodes\nif(videoInput != nil)\n{\n    [session addInput: videoInput];\n}\n\nif(audioInput != nil)\n{\n    [session addInput: audioInput]; // if the stream is video only, don't add an audioInput\n}\n\n[session startRunning];\n\n...\nself.stream = [[nanostreamAVC alloc] initWithSession: session settings: nAVCSettings errorListener: self];\n...", 
            "title": "initWithSession"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#possible_issues", 
            "text": "", 
            "title": "Possible Issues"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#general", 
            "text": "For older versions of the sdk, without support for arm64, architecture in Xcode has to be set to armv7 and/or armv7s. This works also for newer iOS-Devcies like iPhone 5s.\nThis is not required for newer sdk versions, which also support arm64.", 
            "title": "General"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#compilerlinker", 
            "text": "", 
            "title": "Compiler/Linker"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#libstdc", 
            "text": "If there are linker errors with  std:: :  symbol(s) not found for architecture , make sure that you added the libraries  libstdc++.dylib  and  libc++.dylib  to your project.  Due to a bug in Xcode, depending on the selected Base SDK and deployment target, there might be still linker errors regarding  std . In this case you need to add a specific version of the libstdc++ to your project, e.g.: libstdc++-6.0.9.dylib instead of libstdc++.dylib", 
            "title": "libstdc++"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#undefined_symbols_for_parrot_dji", 
            "text": "The following part is only relevant for SDK versions from 3.3.x to 4.1.x. \nAs of version 4.2.x the drone dependencies are removed from the standard SDK package.  It might be possible that there are linker errors for the classes   ParrotBebopCaptureSession or  DJIPhantom2CaptureSession   Generally, if the Parrot   DJI extensions are not used, the symbols should be stripped automatically by Xcode and you do not need to link the frameworks.\nHowever this is not the case when the linker flag  -ObjC  is used in the app project. This causes the linker to load all symbols included in all linked object files (including the Parrot   DJI symbols). This prevents the automatic stripping.  To use our library without Parrot   DJI, either remove the  -ObjC  linker flag from the project or replace the  -ObjC  linker flag with the  -force_load  flag for each library that you want to use. Do not use  -force_load  with libnanostreamAVC.a.\nFor examples see http://stackoverflow.com/questions/11254269/using-the-force-load-linker-flag-with-restkit-ios", 
            "title": "Undefined Symbols for Parrot &amp; DJI"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#breakpoints", 
            "text": "If you debug your application, it is possible that breakpoints are being hit due to internal exceptions. Exceptions on the SDK level are handled in the SDK and do not affect the workflow of your application.  You can prevent the breakpoint from pausing the workflow of your application, if you use the right settings for the breakpoint.\nThe default setting is most likely that every exception causes a break.\nTo change that, use the settings from the following screenshot:   This way only Objective-C exceptions will be catched and C++ exceptions will be ignored.", 
            "title": "Breakpoints"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#crashes", 
            "text": "", 
            "title": "Crashes"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#calayergetdelegate_calayergetsuperlayer_other_calayer", 
            "text": "If there are crashes occurring in your app that include above symbols in the stack trace and are otherwise not obvious, check to see if you added a subviews to the preview view. The UIView instance that is passed to  [RtmpSourceCaptureSession initWithPreview:andStatusListener:andLogLevel:]  and  [nanostreamAVC initWithSettings:uiPreview:errorListener:]  cannot contain any subviews (UIButtons or otherwise).", 
            "title": "CALayerGetDelegate / CALayerGetSuperlayer / Other CALayer"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#logging_information", 
            "text": "If you encounter a problem with the nanostreamAVC library and you want to report the problem, log files will help us to comprehend the problem.  Please use the following steps to create the log files:   enable logging for the library with the method  SetLogLevel , use LogLevelVerbose:   objc\n  [self.nAVC SetLogLevel: LogLevelVerbose];  // set the log level before the method \"start\" is invoked   try to reproduce the problem  download the app container (for your app) from the iOS device with Xcode, as explained here:  https://developer.apple.com/library/ios/recipes/xcode_help-devices_organizer/articles/manage_containers.html  in Finder right click on the downloaded container and select  Show Package Contents  send us the logfiles located (in the container) in the folder  /AppData/Library/Caches/Logs/", 
            "title": "Logging Information"
        }, 
        {
            "location": "/nanostream/ios/nanostream-ios-sdk/#crash_logs", 
            "text": "If you encounter a crash, please send us the crash log as explained in the following steps:   Plug in the device and open Xcode  Choose Window -  Devices from the menu bar  Under the DEVICES section in the left column, choose the device  To see the device console, click the up-triangle at the bottom left of the right hand panel  Click the down arrow on the bottom right to save the console as a file  To see crash logs, select the View Device Logs button under the Device Information section on the right hand panel  Find your app in the Process column and select the Crash log to see the contents.  To save a crash log, right click the entry on the left column and choose  Export Log   (Taken from  https://developer.apple.com/library/ios/qa/qa1747/_index.html )", 
            "title": "Crash Logs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/", 
            "text": "nanoStream MacOS API\n\n\nIntro\n\n\nThe nanoStream MacOS dylib API is a video capture and encoding software for streaming live video and audio to internet based media servers and other network clients.\n\n\nThe nanoStream MacOS dylib API supports internet broadcast streaming and local recording at the same time. A lots of video devices are supported, also Blackmagic devices. The resolution, frame rate, samplerate and more can be manipulated. For a full feature list and platform specific features look at the method list below.\n\n\nIt works perfectly together with internet streaming servers like Wowza Media Server and Flash Media Server, streaming to Mobile devices like iPhone, Silverlight and other playback clients is possible.\n\n\n\n\nNote: this is preliminary documentation, please contact us for further information or help.\n\n\n\n\nSetup:\n\n\nThe best way to start is using the C++ sample code included in the SDK.\n\n\nSystem Requirements:\n\n\nMac OSX 10.9 or newer, Windows 7 or newer\n\n\nHardware Requirements:\n\n\nIntel Core2 Duo or later\n\n\nRecommended for HD capture: Intel Core i7 or Xeon\n\n\n\n\n\n\n\n\nMethod Name\n\n\nDescription\n\n\nlibnanoStream.dylib Support\n\n\nMac Plugin Support\n\n\nMac Framework Support\n\n\nANE Support\n\n\n\n\n\n\n\n\n\n\nInitPlugin\n\n\nInitialization of the Plugin\n\n\nnanoStream\n\n\ninitEncoder\n\n\ninit\n\n\n\u2714\n\n\n\n\n\n\nSetXml\n\n\ndeprecated - no functionality\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetVersion\n\n\nGet version number of the SDK\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nSetLicense\n\n\nSet license for nano SDK\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetLicense\n\n\nGet the current license of the SDK\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nSetConfig\n\n\nSet property over Identifier.\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nUpdatePreviewDimensions\n\n\nUpdate preview dimensions of the bmp\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetPreviewDimensions\n\n\nGet the current preview dimensions\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nGetPreviewImage\n\n\nGet the preview image\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nGetPreviewFrame\n\n\nGet current preview Frame\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nStartPreview\n\n\nStart the preview.\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nStopPreview\n\n\nStop the preview.\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nStartBroadcast\n\n\nStart broadcasting.\n\n\n\u2714\n\n\n\u2714\n\n\nstartStream\n\n\n\u2714\n\n\n\n\n\n\nStopBroadcast\n\n\nStop broadcasting.\n\n\n\u2714\n\n\n\u2714\n\n\nstopStream\n\n\n\u2714\n\n\n\n\n\n\nGetNumberOfVideoSources\n\n\nCount video sources with current settings\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetNumberOfAudioSources\n\n\nCount audio sources with current settings\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetVideoSource\n\n\nGet name of the video source as string.\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetAudioSource\n\n\nGet name of the audio source as string.\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetVideoSource\n\n\nSet video source for preview or broadcasting\n\n\n\u2714\n\n\nVideoSource\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetVideoSourceFromURL\n\n\nURL to an mp4 file source or ramp source\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetAudioSource\n\n\nSet audio source for preview or broadcasting\n\n\n\u2714\n\n\nAudioSource\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetVideoWidth\n\n\nSet width of video in pixels\n\n\n\u2714\n\n\nVideoWidth\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetVideoWidth\n\n\nGet width of video in pixels\n\n\n\u2714\n\n\nVideoWidth\n\n\n\n\n\n\n\n\n\n\nSetVideoHeight\n\n\nSet height of video in pixels\n\n\n\u2714\n\n\nVideoHeight\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetVideoHeight\n\n\nGet height of video in pixels\n\n\n\u2714\n\n\nVideoHeight\n\n\n\n\n\n\n\n\n\n\nSetVideoResizeWidth\n\n\nResize width of video in pixels\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetVideoResizeHeight\n\n\nResize height of video in pixels\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetVideoFramerate\n\n\nSet frame rate of video in frames per second\n\n\nSetFramerate\n\n\nVideoFrameRate\n\n\nsetFrameRate\n\n\n\u2714\n\n\n\n\n\n\nSetNumberOfChannels\n\n\nset channel number\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nSetVideoBitrate\n\n\nSet bitrate of video in kbits per second\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetVideoBitrate\n\n\nGet the current video bitrate\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nSetAudioBitrate\n\n\nSet bitrate of audio in kbits per second\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetAudioBitrate\n\n\nGet the current audio bitrate\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nSetAudioSamplerate\n\n\nSet the samplerate of the audio in Hertz\n\n\n\u2714\n\n\n\u2718\n\n\nsetSampleRate\n\n\n\u2714\n\n\n\n\n\n\nGetAudioLevel\n\n\nGet the audio level of a channel\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nSetAudioVolume\n\n\nSet audio volume\n\n\n\u2714\n\n\nAudioVolume\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetAudioPreviewVolume\n\n\nSet audio volume of preview\n\n\n\u2714\n\n\nAudioPreviewVolume\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetColorSpace\n\n\nSet the color space of an input source\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetNumberOfColorspaces\n\n\nGet the count of color spaces\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetColorspace\n\n\nGet color space name as string\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nGetNumberOfResolutions\n\n\nGet count of available resolutions\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetResolution\n\n\nGet count of resolutions\n\n\n\u2714\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetNumberOfFramerates\n\n\nCount of available frame rates as integer value\n\n\nGetNumberOfFrameRates\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetFramerate\n\n\nGet the frame rate of a video source\n\n\n\u2714\n\n\n\u2714\n\n\ngetFrameRate\n\n\n\u2714\n\n\n\n\n\n\nSetDeinterlacing\n\n\nSet deinterlacing mode and method\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nGetNumberOfOutputs\n\n\nGet count of output sources\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nAddOutput\n\n\nAdd new output source with url\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetOutputUrl\n\n\nSet output source with url. Local or rtmp\n\n\n\u2714\n\n\n\u2714\n\n\nsetOutputUrl\n\n\n\u2714\n\n\n\n\n\n\nGetOutputUrl\n\n\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nGetNumberOfOutputUrls\n\n\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nAcceptDataInSampleBuffer\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAddSampleBuffer\n\n\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\nSetFilesourceFilename\n\n\nSet the filename of a local source\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nClearOutputs\n\n\nReset all output sources\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetVideoEffect\n\n\nAdd a video effect.\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetOverlay\n\n\nAdd a overlay to the video\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nShowPropertyPage\n\n\nShow property page\n\n\n\u2718\n\n\n\u2714\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\nSetLog\n\n\nSet log file path and log level.\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\u2714\n\n\n\n\n\n\nSetXmlProfile\n\n\n\n\n\u2714\n\n\n\n\n\n\n\n\n\n\n\n\ndispose():void\n\n\nReset buffer\n\n\n\u2718\n\n\n\u2718\n\n\n\u2718\n\n\n\u2714\n\n\n\n\n\n\n\n\nMethod Description:\n\n\nSetup the Plugin\n\n\nInitPlugin\n\n\nDeclaration\n\n\nInitPlugin(xmlPath:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nxmlPath\n\n\nString\n\n\nPath to the xml file with configuration information, can be local or a url. \n1\n\n\n\n\n\n\n\n\n1\n \n\u2014 deprecated - no functionality\n|\n\n\nReturn Value\n\n\n-1\n if the initialization failed\n\n\nDescription\n\n\nInitialization of the plugin.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetVersion\n\n\nDeclaration\n\n\nGetVersion()\n\n\n\n\nReturn Value\n\n\nVersion number as int value\n\n\nDescription\n\n\nReturn the version number of the SDK as int value\n\n\nAvailability\n\n\nOn Mac OSX\n\n\nSetLicense\n\n\nDeclaration\n\n\nSetLicense(licenseStr:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nlicenseStr\n\n\nString\n\n\nLicense String getting from nano.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet license for nano SDK\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetLicense\n\n\nDeclaration\n\n\nGetLicense()\n\n\n\n\nReturn Value\n\n\nString represantation of the license\n\n\nDescription\n\n\nGet license for nano SDK\n\n\nAvailability\n\n\nOn Mac OSX\n\n\nSetConfig\n\n\nDeclaration\n\n\nSetConfig(property:String, value:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nproperty\n\n\nString\n\n\nProperty identifier as string. See property list for configuration on page 32.\n\n\n\n\n\n\nvalue\n\n\nString\n\n\nValue for property as string representation.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n1\n if call was successful, \n0\n otherwise\n\n\nDescription\n\n\nSet property over Identifier.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nPreview\n\n\nUpdatePreviewDimensions\n\n\nDeclaration\n\n\nUpdatePreviewDimensions():void\n\n\nDescription\n\n\nUpdates the preview with the current width and height.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetPreviewDimensions\n\n\nDeclaration\n\n\nGetPreviewDimensions(long *width, long *height, long *size)\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nwidth\n\n\nlong\n\n\nPointer to return the video width\n\n\n\n\n\n\nheight\n\n\nlong\n\n\nPointer to return the video height\n\n\n\n\n\n\nsize\n\n\nlong\n\n\nPointer to return the video size\n\n\n\n\n\n\n\n\nReturn Value\n\n\n1\n if call failed, \n0\n otherwise\n\n\nDescription\n\n\nGet the current preview dimensions.\n\n\nGetPreviewImage\n\n\nDeclaration\n\n\nGetPreviewImage(char *pixelBuffer, int size)\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\npixelBuffer\n\n\nchar\n\n\npixel buffer\n\n\n\n\n\n\nsize\n\n\nint\n\n\nsize\n\n\n\n\n\n\n\n\nReturn Value\n\n\n1\n if call failed, \n0\n otherwise\n\n\nDescription\n\n\nGet the preview image.\n\n\nGetPreviewFrame\n\n\nDeclaration\n\n\nGetPreviewFrame(options:int = GET\\_FRAME\\_BITMAP):Boolean\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\noptions\n\n\nint\n\n\noption as integer. Default is GET_FRAME_BITMAP = 2. A\\ Also possible: \\ GET_FRAME_RAW_BYTES:int = 4,\\ GET_POWER_OF_2_FRAME_BGRA_BYTES:int = 8\n\n\n\n\n\n\n\n\nReturn Value\n\n\nTrue if new frame was received otherwise false\n\n\nDescription\n\n\nGet current preview Frame.\n\n\nStartPreview\n\n\nDeclaration\n\n\nStartPreview():int\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nStart the preview.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nStopPreview\n\n\nDeclaration\n\n\nStopPreview():int\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nStop the preview.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nBroadcast\n\n\nStartBroadcast\n\n\nDeclaration\n\n\nStartBroadcast():int\n\n\n\n\nReturn Value\n\n\nERROR_SETUP_ENCODER_FAILED = -2\n\n\nERROR_RTMP_OUTPUT_SOURCE1_FAILED = 2\n\n\nERROR_RTMP_OUTPUT_SOURCE2_FAILED = 3\n\n\nDescription\n\n\nStart broadcasting.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nStopBroadcast\n\n\nDeclaration\n\n\nStopBroadcast():int\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nStop broadcasting.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nVideo Source \n Audio Source handling\n\n\nGetNumberOfVideoSources\n\n\nDeclaration\n\n\nGetNumberOfVideoSources():int\n\n\n\n\nReturn Value\n\n\nCount of all available video sources.\n\n\nDescription\n\n\nCount of all available video sources with current settings\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetNumberOfAudioSources\n\n\nDeclaration\n\n\nGetNumberOfAudioSources():int\n\n\n\n\nReturn Value\n\n\nCount of all available audio sources.\n\n\nDescription\n\n\nCount of all available audio sources with current settings\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetVideoSource\n\n\nDeclaration\n\n\nGetVideoSource(index:int):String\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the video source. The index of the video source, from \n0 - GetNumberOfVideoSources -1\n\n\n\n\n\n\n\n\nReturn Value\n\n\nVideo source name as string.\n\n\nDescription\n\n\nGet name of the video source as string. Call \nGetNumberOfVideoSources\n first.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nGetAudioSource\n\n\nDeclaration\n\n\nGetAudioSource(index:int):String\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the audio source. The index of the audio source, from \n0 - GetNumberOfAudioSources -1\n\n\n\n\n\n\n\n\nReturn Value\n\n\nAudio source name as string.\n\n\nDescription\n\n\nGet name of the audio source as string. Call \nGetNumberOfAudioSources\n first.\n\n\nAvailability\n\n\nOn Windows and Mac OSX\n\n\nSetVideoSource\n\n\nDeclaration\n\n\nSetVideoSource(index:int, mixSource:int, mixMode:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the video source. The index of the video source goes from \n0 - GetNumberOfVideoSources -1\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to set only the first video source. \n1\n to set a second video source. \n1\n\n\n\n\n\n\nmixMode\n\n\nint\n\n\nwhen mixSource \n1\n is set, the mix mode to combine two video sources can be chosen here. See available mix modes on page 33.  \n2\n\n\n\n\n\n\n\n\n1\n  \n\u2014 second video source only available on Microsoft Windows\n\n\n2\n  \n\u2014 only available on Microsoft Windows\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet video source for preview or broadcasting over index. Call \nGetNumberOfVideoSources\n first. The mix source defines the video source you want set. The mixSource and mixMode is optional and only available on Microsoft Windows. There with you can combine two videos over the mixMode.\n\n\nAvailability\n\n\nOn Mac OSX only one video source can use. On Microsoft Windows up to two video sources can be used and be combined in different ways.\n\n\nSetVideoSourceFromURL\n\n\nDeclaration\n\n\nSetVideoSourceFromURL(url:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nString\n\n\nURL to use an mp4 file as video source.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nURL to an mp4 file source to stream this file.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows\n\n\nSetAudioSource\n\n\nDeclaration\n\n\nSetAudioSource(index:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the audio source. The index of the audio source, from \n0 - GetNumberOfAudioSources -1\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet audio source for preview or broadcasting over index. Call \nGetNumberOfAudioSources\n first.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX\n\n\nVideo Properties\n\n\nSetVideoWidth\n\n\nDeclaration\n\n\nSetVideoWidth(width:int, mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nwidth\n\n\nint\n\n\nWidth of the video in pixels as integer value\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to set only the first video source. \n1\n to set a second video source. \n1\n\n\n\n\n\n\n\n\n1\n  \n\u2014 second video source only available on Microsoft Windows\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet width of video in pixels. With mixSource the height for two video sources can be set.\n\n\nAvailability\n\n\nSet Width is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.\n\n\nSetVideoHeight\n\n\nDeclaration\n\n\nSetVideoHeight(height:int, mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nheight\n\n\nint\n\n\nHeight of the video in pixels as integer value\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to set only the first video source. \n1\n to set a second video source \n1\n\n\n\n\n\n\n\n\n1\n  \n\u2014 second video source only available on Microsoft Windows\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet height of video in pixels. With mixSource the height for two video sources can be set.\n\n\nAvailability\n\n\nSet Height is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.\n\n\nSetVideoResizeWidth\n\n\nDeclaration\n\n\nSetVideoResizeWidth(width:int, index:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nwidth\n\n\nint\n\n\nresize width of the video in pixels as integer value\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the output. The index of the output, from \n0 - GetNumberOfOutputs -1\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nResize width of video in pixels.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows\n\n\nSetVideoResizeHeight\n\n\nDeclaration\n\n\nSetVideoResizeHeight(height:int, index:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nheight\n\n\nint\n\n\nresize height of the video in pixels as integer value\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the output. The index of the output, from \n0 - GetNumberOfOutputs -1\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nResize height of video in pixels.\n\n\nAvailability\n\n\nOnly supported under Microsoft Windows\n\n\nSetVideoFramerate\n\n\nDeclaration\n\n\nSetVideoFramerate(framerate:Number, mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nframerate\n\n\nNumber\n\n\nFrame rate in frames per Second(FPS) as number value.\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to set only the first video source. \n1\n to set a second video source. \n1\n\n\n\n\n\n\n\n\n1\n  \n\u2014 second video source only available on Microsoft Windows\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet frame rate of video in frames per second (FPS). With mixSource the frame rate for two video sources can be set under Microsoft Windows.\n\n\nAvailability\n\n\nSet video frame rate is supported under Mac OS X and Microsoft Windows. Mix Source is only available under Microsoft Windows.\n\n\nSetNumberOfChannels\n\n\nDeclaration\n\n\nSetNumberOfChannels(int numOfChannels)\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nnumOfChannels\n\n\nint\n\n\nNumber of channels as int value\n\n\n\n\n\n\n\n\nDescription\n\n\nSet channel number\n\n\nAvailability\n\n\nOn Mac OSX\n\n\nSetVideoBitrate\n\n\nDeclaration\n\n\nSetVideoBitrate(bitrate:int, index:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nbitrate\n\n\nint\n\n\nVideo bitrate as integer value.\n\n\n\n\n\n\nindex\n\n\nint\n\n\nindex of output to set the bitrate for multiple encoders. \n1\n\n\n\n\n\n\n\n\n1\n \n\u2014 set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet bitrate of video in kbits per second (kbits/s).\n\n\nAvailability\n\n\nUnder Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.\n\n\nGetVideoBitrate\n\n\nDeclaration\n\n\nGetVideoBitrate(int source)\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nindex of output to get the bitrate for multiple encoders. \n1\n\n\n\n\n\n\n\n\n1\n \n\u2014 set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.\n\n\nReturn Value\n\n\nVideo bitrate as integer value.\n\n\nDescription\n\n\nGet the current video bitrate.\n\n\nAvailability\n\n\nUnder Mac OS X there is only one output available. Under Microsoft Windows several outputs are available over the index parameter.\n\n\nAudio Properties\n\n\nSetAudioBitrate\n\n\nDeclaration\n\n\nSetAudioBitrate(int bitrate, int index): int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nbitrate\n\n\nint\n\n\nAudio bitrate as integer value.\n\n\n\n\n\n\nindex\n\n\nint\n\n\nindex of output to set the bitrate for multiple encoders. \n1\n\n\n\n\n\n\n\n\n1\n \n\u2014 set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.\n |\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet bitrate of audio in kbits per second (kbits/s).\n\n\nAvailability\n\n\nUnder Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.\n\n\nGetAudioBitrate\n\n\nDeclaration\n\n\nGetAudioBitrate(int source): int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nindex of output to get the bitrate for multiple encoders. \n1\n\n\n\n\n\n\n\n\n1\n \n\u2014Get different outputs is only available on Microsoft Windows. On Mac OS X there is only one source available.\n |\n\n\nReturn Value\n\n\nAudio bitrate as integer value.\n\n\nDescription\n\n\nGet the current audio bitrate.\n\n\nSetAudioSamplerate\n\n\nDeclaration\n\n\nSetAudioSamplerate(int samplerate): int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsamplerate\n\n\nint\n\n\nSamplerate of audio as integer value\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet the samplerate of the audio in Hertz (Hz).\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nGetAudioLevel\n\n\nDeclaration\n\n\nGetAudioLevel(channel:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nchannel\n\n\nint\n\n\nchannel id as integer.\n\n\n\n\n\n\n\n\nReturn Value\n\n\nAudiolevel as integer value.\n\n\nDescription\n\n\nGet the audio level of a channel.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetAudioVolume\n\n\nDeclaration\n\n\nSetAudioVolume(volume:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nvolume\n\n\nint\n\n\nvolume as integer value\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet audio volume.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetAudioPreviewVolume\n\n\nDeclaration\n\n\nSetAudioPreviewVolume(volume:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nvolume\n\n\nint\n\n\nvolume as integer value\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet audio volume of preview.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nColor Management\n\n\nSetColorSpace\n\n\nDeclaration\n\n\nSetColorSpace(index:int, mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nindex of the input source.\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to set only the first mixed source. \n1\n to set a second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n \n\u2014second mixed source is only available on Microsoft Windows\n\n\nReturn Value\n\n\n-\n1\n if call failed\n\n\nDescription\n\n\nSet the color space of an input source. Only the firtst source is supported under Mac OS X\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nGetNumberOfColorspaces\n\n\nDeclaration\n\n\nGetNumberOfColorspaces(width:int, height:int, mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nwidth\n\n\nint\n\n\nwidth of the video source\n\n\n\n\n\n\nheight\n\n\nint\n\n\nheight of the video source\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to get the first mixed source. \n1\n to get the second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n  \n\u2014second mixed source is only available on Microsoft Windows\n\n\nReturn Value\n\n\nCount of color spaces as integer value.\n\n\nDescription\n\n\nGet the count of color spaces. Get the color space for the specified with and height.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX mix source is not supported.\n\n\nGetColorspace\n\n\nDeclaration\n\n\nGetColorspace(index:int, mixSource:int):String\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the color spaces. The index of the color spaces, from \n0 - GetNumberOfColorspaces -1\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to get the first mixed source. \n1\n to get the second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n  \n\u2014second mixed source is only available on Microsoft Windows\n  \n\n\nReturn Value\n\n\ncolor space name as String\n\n\nDescription\n\n\nGet color space name as string. First call \nGetNumberOfColorspaces.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nResolution \n Frame rate\n\n\nGetNumberOfResolutions\n\n\nDeclaration\n\n\nGetNumberOfResolutions(mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to get the first mixed source. \n1\n to get the second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n   \n\u2014second mixed source is only available on Microsoft Windows\n\n\nReturn Value\n\n\nCount of resolutions as integer value.\n\n\nDescription\n\n\nGet count of resolutions.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nGetResolution\n\n\nDeclaration\n\n\nGetResolution(index:int, mixSource:int):Object\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the resolutions. The index of the resolutions, from \n0 - GetNumberOfResolutions -1\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to get the first mixed source. \n1\n to get the second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n    \n\u2014second mixed source is only available on Microsoft Windows\n\n\nReturn Value\n\n\nGet resolution of video source. First call \nGetNumberOfResolutions.\n\n\nDescription\n\n\nGet count of resolutions.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nGetNumberOfFramerates\n\n\nDeclaration\n\n\nGetNumberOfFramerates(width:int, height:int, colorspace:String, mixSource:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nwidth\n\n\nint\n\n\nwidth of the video source\n\n\n\n\n\n\nheight\n\n\nint\n\n\nheight of the video source.\n\n\n\n\n\n\ncolorspace\n\n\nString\n\n\nname of the color space get from GetColorspace\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to get the first mixed source. \n1\n to get the second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n    \n\u2014second mixed source is only available on Microsoft Windows\n\n\nReturn Value\n\n\nCount of available frame rates as integer value.\n\n\nDescription\n\n\nGet count of available frame rates.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nGetFramerate\n\n\nDeclaration\n\n\nGetFramerate(index:int, mixSource:int):Number\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the frame rate. The index of the frame rate, from \n0 - GetNumberOfFramerates -1\n\n\n\n\n\n\nmixSource\n\n\nint\n\n\nset \n0\n to to get the first mixed source. \n1\n to get the second mixed source. \n1\n\n\n\n\n\n\n\n\n1\n    \n\u2014second mixed source is only available on Microsoft Windows\n\n\nReturn Value\n\n\nFrame rate (FPS) as number value.\n\n\nDescription\n\n\nGet the frame rate of a video source. Call \nGetNumberOfFramerates\n first.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX. Under Mac OSX only the first mix source is supported.\n\n\nSetDeinterlacing\n\n\nDeclaration\n\n\nSetDeinterlacing(mode:int, method:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmode\n\n\nint\n\n\npossible values: \n0\n=off, \n1\n=auto, \n2\n=on  \\ no auto mode for mac\n\n\n\n\n\n\nmethod\n\n\nint\n\n\npossible values: \n0\n=duplicate field/bob, \n1\n=blend, \n2\n=vertical filter, \n3\n=edge, 4=median, \n5\n=median2\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet deinterlacing mode and method.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nOutputs\n\n\nGetNumberOfOutputs\n\n\nDeclaration\n\n\nGetNumberOfOutputs():int\n\n\n\n\nReturn Value\n\n\nCount of outputs as integer value.\n\n\nDescription\n\n\nGet count of outputs.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nAddOutput\n\n\nDeclaration\n\n\nAddOutput(url:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nString\n\n\nUrl of outputs can be a local mp4 recording or a rtmp source.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nAdd new output source with url.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nSetOutputUrl\n\n\nDeclaration\n\n\nSetOutputUrl(url:String, index:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nString\n\n\nUrl of outputs can be a local mp4 recording or a rtmp server.\n\n\n\n\n\n\nindex\n\n\nint\n\n\nIndex of the output.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet output with url. A local mp4 recording or a rtmp server.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nGetOutputUrl\n\n\nGetNumberOfOutputUrls\n\n\nAcceptDataInSampleBuffer\n\n\nSetFilesourceFilename\n\n\nDeclaration\n\n\nSetFilesourceFilename(url:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nString\n\n\nUrl to the local file\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet the filename of a local source.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nClearOutputs\n\n\nDeclaration\n\n\nClearOutputs():int\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nReset all outputs except the first one.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nVideo Special\n\n\nSetVideoEffect\n\n\nDeclaration\n\n\nSetVideoEffect(mode:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmode\n\n\nint\n\n\nMode of video effect. See possible overlay effects on page 33\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nAdd a video effect. For overlay.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nSetOverlay\n\n\nDeclaration\n\n\nSetOverlay(url:String):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nString\n\n\nUrl of the overlay source. Can be a locale path or server url to a png or txt file. Also can be a txt string.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nAdd a overlay to the video.\n\n\nAvailability\n\n\nOnly Supported under Microsoft Windows.\n\n\nShowPropertyPage\n\n\nDeclaration\n\n\nShowPropertyPage(value:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nvalue\n\n\nint\n\n\n1\n or \n0\n are possible values\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nShow property page. Only used for Blackmagic devices.\n\n\nAvailability\n\n\nOnly supported under Microsoft Windows.\n\n\nLogging\n\n\nSetLog\n\n\nDeclaration\n\n\nSetLog(logFile:String, logLevel:int):int\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nlogFile\n\n\nString\n\n\nlocal path for logfile as string.\n\n\n\n\n\n\nlogLevel\n\n\nint\n\n\nlog level as integer. For possible loglevels 0-9.\n\n\n\n\n\n\n\n\nReturn Value\n\n\n-1\n if call failed\n\n\nDescription\n\n\nSet log file path and log level.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetXmlProfile\n\n\ndispose\n\n\nDeclaration\n\n\ndispose():void\n\n\n\n\nDescription\n\n\nDestructor.\n\n\nAvailability\n\n\nUnder Windows and Mac OSX.\n\n\nSetConfig Properties\n\n\n\n\n\n\n\n\nProperty name\n\n\nDescription\n\n\nValues\n\n\nMac Platform Support\n\n\n\n\n\n\n\n\n\n\nlicense\n\n\nLicense string\n\n\n\n\n\u2714\n\n\n\n\n\n\nXMLPath\n\n\nPath to the XML file with configuration information\n\n\n\n\n\u2714\n\n\n\n\n\n\nRemoteControlPort\n\n\nPort number\n\n\n\n\n\u2714\n\n\n\n\n\n\nLiveSource\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nRemoteIP\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nAVOffsetMs\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nReconnectPeriod/ReconnectInterval\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nReconnectAttempts\n\n\nAuto Reconnect No. of Attempts\n\n\n5\n\n\n\u2714\n\n\n\n\n\n\nUseInternalReconnect\n\n\nUse RTMP Internal Reconnect of the RTMP Filter (do not stop encoder on network errors)\n\n\n0 / 1\n\n\n\u2714\n\n\n\n\n\n\nUseUnlimitedReconnect\n\n\nDon\nt stop reconnecting after a specific number of failed attempts (encoder is not stopped)\n\n\n0 / 1\n\n\n\u2714\n\n\n\n\n\n\nAuth\n\n\nAuthentication for RTMP and RTSP Push streaming\n\n\n\u201cuser:password\u201d\n\n\n\u2714\n\n\n\n\n\n\nRtmpUrlDelimiter\n\n\nSet delimiter for RTMP-url and streamname.\n\n\nExample: \u201d+\u201c will split \n so that \u201cmyStream\u201d is the stream name.\n\n\n\u2714\n\n\n\n\n\n\nDeinterlacingMode\n\n\nDeinterlacing Mode\n\n\n0=off, 1=auto (default), 2=on Note: for some capture devices you need to set this to \u201eon\u201c (2). (Resolutions 480i, 576i, 1080i)\n\n\n\u2714\n\n\n\n\n\n\nDeinterlacingMethod\n\n\nDeinterlacing Method\n\n\n0=duplicate field/bob, 1=blend, 2=vertical filter, 3=edge, 4=median, 5=median2\n\n\n\u2714\n\n\n\n\n\n\nRemoteSendAudioLevelInterval\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nCaptureRegion\n\n\nCapture Region of the input source, example for a input resolution of 640\u00d7480: SetConfig(\u201cCaptureRegion\u201d, \u201c10,630,10,470\u201d) - discards 10 pixels on each side\n\n\nleft,right,top,bottom\n\n\n\u2714\n\n\n\n\n\n\nRTMPPublishMode\n\n\nRTMP Publish/Live/Record on Server (VOD)\n\n\n1=record, 2=append, 0=live (default)\n\n\n\u2714\n\n\n\n\n\n\nVideoAudioInput\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nPreviewNoInvert\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nScreenCapMode\n\n\nScreen Capture Desktop Mode\n\n\n0=Screen, 1=FollowMouse, 2=Region relative, 3=Region absolute, 4=Window, 5=Window overlapping\n\n\n\u2714\n\n\n\n\n\n\nScreenCapWindowIndex\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nApplyDynamicSettings\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nMp4RecordOnTheFlyChangeName\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nMp4RecordOnTheFlyControl\n\n\nIf Mp4RecordOnTheFly is enabled, controls start/stop recording\n\n\n0=stop, 1=start\n\n\n\u2714\n\n\n\n\n\n\nAudioPreview\n\n\nEnables audio preview during preview or broadcast\n\n\n0=no preview, 1=visual preview (default, requires filter AudioVolume), 2=visual and audible preview, 3=audible preview\n\n\n\u2714\n\n\n\n\n\n\nMp4RecordOnTheFly\n\n\nEnables start/stop recording to local file while the broadcast is running\n\n\n0=off (default), 1=on\n\n\n\u2714\n\n\n\n\n\n\nH264Quality\n\n\nH.264 Encoder Quality/Speed Ratio\n\n\n0=worst/fastest 1=default 6=highest/slowest\n\n\n\u2714\n\n\n\n\n\n\nH264IFrameDistance\n\n\nH.264 I Frame / GOP Length in Frames (100 Frames = 4 seconds for 25 fps)\n\n\n100=default, 1 = I-Frame-Only\n\n\n\u2714\n\n\n\n\n\n\nH264PFrameDistance\n\n\nH.264 P/B Frame Distance\n\n\n3 1 = IP-Only (no B-Frames)\n\n\n\u2714\n\n\n\n\n\n\nH264Profile\n\n\nH.264 Encoding Profile\n\n\nBaseline, Main, Extended, High Most compatible but lowest quality is Baseline, (no B-Frames, no CABAC VLC)\n\n\n\u2714\n\n\n\n\n\n\nH264Level\n\n\nH.264 Level\n\n\n10=1.0, 11=1.1, 12=1.2, 13=1.3, 20=2.0, 21=2.1, 22=2.2, 30=3.0, 31=3.1, 32=3.2, 40=4.0, 41=4.1, 42=4.2, 50=5.0, 51=5.1\n\n\n\u2714\n\n\n\n\n\n\nH264VlcMode\n\n\nH.264 VLC Mode (CAVLC/CABAC)\n\n\n=CAVLC, 2=CABAC (not allowed in H.264 Baseline Profile)\n\n\n\u2714\n\n\n\n\n\n\nOutputFrameRate\n\n\nVideo Output (Encoded) Frame Rate\n\n\n5,10,15,20,25,30, OR 23980 OR 29970\n\n\n\u2714\n\n\n\n\n\n\nRTMPWriteTimecode\n\n\nSend timecodes in RTMP streams, If enabled RTMP timecodes are sent in addition to the always sent RTMP packet timestamps\n\n\n0=off (default), 1=on\n\n\n\u2714\n\n\n\n\n\n\nUseSystemTimeAsTimecode\n\n\nSend RTMP/MP4 timecodes as UTC system date time or stream time\n\n\n0=stream time (default), 1=UTC system date time\n\n\n\u2714\n\n\n\n\n\n\nTimecodeInterval\n\n\nRTMP/MP4 timecode interval in milliseconds\n\n\nShould be higher or equal to 1000 (1s)\n\n\n\u2714\n\n\n\n\n\n\nTcpConnectTimeout\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nRTSPSinkMode\n\n\nDetermines if the RTSPSink is running as a server (passive/pull) or as a streamer to a RTSP push capable server (active/push)\n\n\n1=server/pull (default), 2=streamer/push\n\n\n\u2714\n\n\n\n\n\n\nRTSPSDPFileFolder\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nRTSPStreamDescription\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nAudioVolumePerSoftware\n\n\nControl volume with the Audio Volume Filter\n\n\n0=off (default), 1=on\n\n\n\u2714\n\n\n\n\n\n\nAVFShowBlackmagicDevices\n\n\nuse AVFoundation for BlackMagic devices\n\n\n0=off (default), 1=on\n\n\n\u2714\n\n\n\n\n\n\nOverlayRect\n\n\nSets the dimensions for a given overlay-image.\n\n\n\u201cindex,left,top,right,bottom\u201d. index: the overlay-index, beginning with 0. left, top, right and bottom define a rectangle in screen-coordinates.\n\n\n\u2714\n\n\n\n\n\n\nOverlayAlpha\n\n\nSets the alpha-value for overlays.\n\n\nRange: 0-1. 0.0 (not visable), 1 (fully visable).\n\n\n\u2714\n\n\n\n\n\n\nOverlayTextColor\n\n\nText Overlay Color\n\n\nMust be a hexadecimal color-value in BGR-format, e.g.: \u201c0000FF\u201d (255 (0x0000FF) - red)\n\n\n\u2714\n\n\n\n\n\n\nOverlayBackgroundColor\n\n\n\n\nMust be a hexadecimal color-value in BGR-format, e.g.: \u201c000000\u201d (0 (0x000000) - black).\n\n\n\u2714\n\n\n\n\n\n\nOverlaySkipColor\n\n\nSetting skipcolor to a specific value will result in this color to be rendered transparent in the overlays.\n\n\nExample: If OverlayBackgroundColor was set to blue (\u201cFF0000\u201d) setting OverlaySkipColor to blue as well will result in a transparent background. Parameter must be a hexadecimal color-value in BGR-format, e.g.: \u201cFF0000\u201d (blue). Disable: Setting OverlaySkipColor to \u201cFF000000\u201d (ABGR) will disable the usage of skipcolor.\n\n\n\u2714\n\n\n\n\n\n\nAudioDelay\n\n\nStreaming Audio Delay / Offset (ms)\n\n\n\n\n\u2714\n\n\n\n\n\n\nShowPropertyPageForDevice\n\n\nCalls the propertypage for a given device.\n\n\n0 for device with index: 0\n\n\n\u2714\n\n\n\n\n\n\nUseQuicktimeH264Encoder\n\n\n\n\n\n\n\u2714\n\n\n\n\n\n\nRotateDegrees\n\n\nset the degrees by which video should be rotated, only works if UseRotation is set to on, set before StartPreview or StartBroadcast\n\n\n0/90/180/270\n\n\n\u2714\n\n\n\n\n\n\n\n\nMixmode\n\n\nNO_MIXING = 0 (if video mixing is not used)\n\n\nLEFT_RIGHT_FULL = 1\n\n\nLEFT_RIGHT_HALF = 2\n\n\nTOP_BOTTOM = 3\n\n\nINTERLACED_LINES = 4\n\n\nINTERLACED_COLUMN = 5\n\n\nANAGLYPH = 6\n\n\nPIC_IN_PIC_LEFT_TOP = 7\n\n\nPIC_IN_PIC_RIGHT_TOP = 8\n\n\nPIC_IN_PIC_LEFT_BOTTOM = 9\n\n\nPIC_IN_PIC_RIGHT_BOTTOM = 10\n\n\nVIDEO1_ONLY = 11\n\n\nVIDEO2_ONLY = 12\n\n\nREGION = 13\n\n\nMAX = 14\n\n\nOverlay Effects\n\n\nOverlay off = 0\n\n\nLeft Top = 1\n\n\nRight Top = 2\n\n\nLeft Bottom = 3\n\n\nRight bottom = 4\n\n\nFree Postion = 5", 
            "title": "MacOS api"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#nanostream_macos_api", 
            "text": "", 
            "title": "nanoStream MacOS API"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#intro", 
            "text": "The nanoStream MacOS dylib API is a video capture and encoding software for streaming live video and audio to internet based media servers and other network clients.  The nanoStream MacOS dylib API supports internet broadcast streaming and local recording at the same time. A lots of video devices are supported, also Blackmagic devices. The resolution, frame rate, samplerate and more can be manipulated. For a full feature list and platform specific features look at the method list below.  It works perfectly together with internet streaming servers like Wowza Media Server and Flash Media Server, streaming to Mobile devices like iPhone, Silverlight and other playback clients is possible.   Note: this is preliminary documentation, please contact us for further information or help.", 
            "title": "Intro"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setup", 
            "text": "The best way to start is using the C++ sample code included in the SDK.", 
            "title": "Setup:"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#system_requirements", 
            "text": "Mac OSX 10.9 or newer, Windows 7 or newer  Hardware Requirements:  Intel Core2 Duo or later  Recommended for HD capture: Intel Core i7 or Xeon     Method Name  Description  libnanoStream.dylib Support  Mac Plugin Support  Mac Framework Support  ANE Support      InitPlugin  Initialization of the Plugin  nanoStream  initEncoder  init  \u2714    SetXml  deprecated - no functionality  \u2718  \u2718  \u2718  \u2714    GetVersion  Get version number of the SDK  \u2714       SetLicense  Set license for nano SDK  \u2714  \u2714  \u2714  \u2714    GetLicense  Get the current license of the SDK  \u2714       SetConfig  Set property over Identifier.  \u2714  \u2714  \u2714  \u2714    UpdatePreviewDimensions  Update preview dimensions of the bmp  \u2718  \u2718  \u2718  \u2714    GetPreviewDimensions  Get the current preview dimensions  \u2714       GetPreviewImage  Get the preview image  \u2714       GetPreviewFrame  Get current preview Frame  \u2718  \u2718  \u2718  \u2714    StartPreview  Start the preview.  \u2714  \u2714  \u2718  \u2714    StopPreview  Stop the preview.  \u2714  \u2714  \u2718  \u2714    StartBroadcast  Start broadcasting.  \u2714  \u2714  startStream  \u2714    StopBroadcast  Stop broadcasting.  \u2714  \u2714  stopStream  \u2714    GetNumberOfVideoSources  Count video sources with current settings  \u2714  \u2714  \u2714  \u2714    GetNumberOfAudioSources  Count audio sources with current settings  \u2714  \u2714  \u2714  \u2714    GetVideoSource  Get name of the video source as string.  \u2714  \u2714  \u2718  \u2714    GetAudioSource  Get name of the audio source as string.  \u2714  \u2714  \u2718  \u2714    SetVideoSource  Set video source for preview or broadcasting  \u2714  VideoSource  \u2718  \u2714    SetVideoSourceFromURL  URL to an mp4 file source or ramp source  \u2718  \u2718  \u2718  \u2714    SetAudioSource  Set audio source for preview or broadcasting  \u2714  AudioSource  \u2718  \u2714    SetVideoWidth  Set width of video in pixels  \u2714  VideoWidth  \u2714  \u2714    GetVideoWidth  Get width of video in pixels  \u2714  VideoWidth      SetVideoHeight  Set height of video in pixels  \u2714  VideoHeight  \u2714  \u2714    GetVideoHeight  Get height of video in pixels  \u2714  VideoHeight      SetVideoResizeWidth  Resize width of video in pixels  \u2718  \u2714  \u2718  \u2714    SetVideoResizeHeight  Resize height of video in pixels  \u2718  \u2714  \u2718  \u2714    SetVideoFramerate  Set frame rate of video in frames per second  SetFramerate  VideoFrameRate  setFrameRate  \u2714    SetNumberOfChannels  set channel number  \u2714       SetVideoBitrate  Set bitrate of video in kbits per second  \u2714  \u2714  \u2714  \u2714    GetVideoBitrate  Get the current video bitrate  \u2714       SetAudioBitrate  Set bitrate of audio in kbits per second  \u2714  \u2714  \u2714  \u2714    GetAudioBitrate  Get the current audio bitrate  \u2714       SetAudioSamplerate  Set the samplerate of the audio in Hertz  \u2714  \u2718  setSampleRate  \u2714    GetAudioLevel  Get the audio level of a channel  \u2714  \u2714  \u2714  \u2714    SetAudioVolume  Set audio volume  \u2714  AudioVolume  \u2718  \u2714    SetAudioPreviewVolume  Set audio volume of preview  \u2714  AudioPreviewVolume  \u2718  \u2714    SetColorSpace  Set the color space of an input source  \u2714  \u2714  \u2718  \u2714    GetNumberOfColorspaces  Get the count of color spaces  \u2714  \u2714  \u2718  \u2714    GetColorspace  Get color space name as string  \u2714  \u2714  \u2714  \u2714    GetNumberOfResolutions  Get count of available resolutions  \u2714  \u2714  \u2718  \u2714    GetResolution  Get count of resolutions  \u2714  \u2714  \u2718  \u2714    GetNumberOfFramerates  Count of available frame rates as integer value  GetNumberOfFrameRates  \u2714  \u2718  \u2714    GetFramerate  Get the frame rate of a video source  \u2714  \u2714  getFrameRate  \u2714    SetDeinterlacing  Set deinterlacing mode and method  \u2718  \u2718  \u2718  \u2714    GetNumberOfOutputs  Get count of output sources  \u2718  \u2714  \u2718  \u2714    AddOutput  Add new output source with url  \u2718  \u2714  \u2718  \u2714    SetOutputUrl  Set output source with url. Local or rtmp  \u2714  \u2714  setOutputUrl  \u2714    GetOutputUrl   \u2714       GetNumberOfOutputUrls   \u2714       AcceptDataInSampleBuffer  \u2714        AddSampleBuffer   \u2714       SetFilesourceFilename  Set the filename of a local source  \u2718  \u2718  \u2718  \u2714    ClearOutputs  Reset all output sources  \u2718  \u2714  \u2718  \u2714    SetVideoEffect  Add a video effect.  \u2718  \u2714  \u2718  \u2714    SetOverlay  Add a overlay to the video  \u2718  \u2718  \u2718  \u2714    ShowPropertyPage  Show property page  \u2718  \u2714  \u2718  \u2714    SetLog  Set log file path and log level.  \u2714  \u2714  \u2714  \u2714    SetXmlProfile   \u2714       dispose():void  Reset buffer  \u2718  \u2718  \u2718  \u2714", 
            "title": "System Requirements:"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#method_description", 
            "text": "", 
            "title": "Method Description:"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setup_the_plugin", 
            "text": "", 
            "title": "Setup the Plugin"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#initplugin", 
            "text": "", 
            "title": "InitPlugin"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration", 
            "text": "InitPlugin(xmlPath:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters", 
            "text": "Name  Type  Description      xmlPath  String  Path to the xml file with configuration information, can be local or a url.  1     1   \u2014 deprecated - no functionality |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value", 
            "text": "-1  if the initialization failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description", 
            "text": "Initialization of the plugin.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getversion", 
            "text": "", 
            "title": "GetVersion"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_1", 
            "text": "GetVersion()", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_1", 
            "text": "Version number as int value", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_1", 
            "text": "Return the version number of the SDK as int value", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_1", 
            "text": "On Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setlicense", 
            "text": "", 
            "title": "SetLicense"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_2", 
            "text": "SetLicense(licenseStr:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_1", 
            "text": "Name  Type  Description      licenseStr  String  License String getting from nano.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_2", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_2", 
            "text": "Set license for nano SDK", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_2", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getlicense", 
            "text": "", 
            "title": "GetLicense"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_3", 
            "text": "GetLicense()", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_3", 
            "text": "String represantation of the license", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_3", 
            "text": "Get license for nano SDK", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_3", 
            "text": "On Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setconfig", 
            "text": "", 
            "title": "SetConfig"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_4", 
            "text": "SetConfig(property:String, value:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_2", 
            "text": "Name  Type  Description      property  String  Property identifier as string. See property list for configuration on page 32.    value  String  Value for property as string representation.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_4", 
            "text": "1  if call was successful,  0  otherwise", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_4", 
            "text": "Set property over Identifier.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_4", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#preview", 
            "text": "", 
            "title": "Preview"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#updatepreviewdimensions", 
            "text": "", 
            "title": "UpdatePreviewDimensions"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_5", 
            "text": "UpdatePreviewDimensions():void", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_5", 
            "text": "Updates the preview with the current width and height.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_5", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getpreviewdimensions", 
            "text": "", 
            "title": "GetPreviewDimensions"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_6", 
            "text": "GetPreviewDimensions(long *width, long *height, long *size)", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_3", 
            "text": "Name  Type  Description      width  long  Pointer to return the video width    height  long  Pointer to return the video height    size  long  Pointer to return the video size", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_5", 
            "text": "1  if call failed,  0  otherwise", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_6", 
            "text": "Get the current preview dimensions.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getpreviewimage", 
            "text": "", 
            "title": "GetPreviewImage"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_7", 
            "text": "GetPreviewImage(char *pixelBuffer, int size)", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_4", 
            "text": "Name  Type  Description      pixelBuffer  char  pixel buffer    size  int  size", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_6", 
            "text": "1  if call failed,  0  otherwise", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_7", 
            "text": "Get the preview image.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getpreviewframe", 
            "text": "", 
            "title": "GetPreviewFrame"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_8", 
            "text": "GetPreviewFrame(options:int = GET\\_FRAME\\_BITMAP):Boolean", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_5", 
            "text": "Name  Type  Description      options  int  option as integer. Default is GET_FRAME_BITMAP = 2. A\\ Also possible: \\ GET_FRAME_RAW_BYTES:int = 4,\\ GET_POWER_OF_2_FRAME_BGRA_BYTES:int = 8", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_7", 
            "text": "True if new frame was received otherwise false", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_8", 
            "text": "Get current preview Frame.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#startpreview", 
            "text": "", 
            "title": "StartPreview"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_9", 
            "text": "StartPreview():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_8", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_9", 
            "text": "Start the preview.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_6", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#stoppreview", 
            "text": "", 
            "title": "StopPreview"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_10", 
            "text": "StopPreview():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_9", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_10", 
            "text": "Stop the preview.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_7", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#broadcast", 
            "text": "", 
            "title": "Broadcast"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#startbroadcast", 
            "text": "", 
            "title": "StartBroadcast"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_11", 
            "text": "StartBroadcast():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_10", 
            "text": "ERROR_SETUP_ENCODER_FAILED = -2  ERROR_RTMP_OUTPUT_SOURCE1_FAILED = 2  ERROR_RTMP_OUTPUT_SOURCE2_FAILED = 3", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_11", 
            "text": "Start broadcasting.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_8", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#stopbroadcast", 
            "text": "", 
            "title": "StopBroadcast"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_12", 
            "text": "StopBroadcast():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_11", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_12", 
            "text": "Stop broadcasting.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_9", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#video_source_audio_source_handling", 
            "text": "", 
            "title": "Video Source &amp; Audio Source handling"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofvideosources", 
            "text": "", 
            "title": "GetNumberOfVideoSources"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_13", 
            "text": "GetNumberOfVideoSources():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_12", 
            "text": "Count of all available video sources.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_13", 
            "text": "Count of all available video sources with current settings", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_10", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofaudiosources", 
            "text": "", 
            "title": "GetNumberOfAudioSources"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_14", 
            "text": "GetNumberOfAudioSources():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_13", 
            "text": "Count of all available audio sources.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_14", 
            "text": "Count of all available audio sources with current settings", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_11", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getvideosource", 
            "text": "", 
            "title": "GetVideoSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_15", 
            "text": "GetVideoSource(index:int):String", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_6", 
            "text": "Name  Type  Description      index  int  Index of the video source. The index of the video source, from  0 - GetNumberOfVideoSources -1", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_14", 
            "text": "Video source name as string.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_15", 
            "text": "Get name of the video source as string. Call  GetNumberOfVideoSources  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_12", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getaudiosource", 
            "text": "", 
            "title": "GetAudioSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_16", 
            "text": "GetAudioSource(index:int):String", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_7", 
            "text": "Name  Type  Description      index  int  Index of the audio source. The index of the audio source, from  0 - GetNumberOfAudioSources -1", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_15", 
            "text": "Audio source name as string.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_16", 
            "text": "Get name of the audio source as string. Call  GetNumberOfAudioSources  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_13", 
            "text": "On Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideosource", 
            "text": "", 
            "title": "SetVideoSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_17", 
            "text": "SetVideoSource(index:int, mixSource:int, mixMode:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_8", 
            "text": "Name  Type  Description      index  int  Index of the video source. The index of the video source goes from  0 - GetNumberOfVideoSources -1    mixSource  int  set  0  to to set only the first video source.  1  to set a second video source.  1    mixMode  int  when mixSource  1  is set, the mix mode to combine two video sources can be chosen here. See available mix modes on page 33.   2     1    \u2014 second video source only available on Microsoft Windows  2    \u2014 only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_16", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_17", 
            "text": "Set video source for preview or broadcasting over index. Call  GetNumberOfVideoSources  first. The mix source defines the video source you want set. The mixSource and mixMode is optional and only available on Microsoft Windows. There with you can combine two videos over the mixMode.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_14", 
            "text": "On Mac OSX only one video source can use. On Microsoft Windows up to two video sources can be used and be combined in different ways.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideosourcefromurl", 
            "text": "", 
            "title": "SetVideoSourceFromURL"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_18", 
            "text": "SetVideoSourceFromURL(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_9", 
            "text": "Name  Type  Description      url  String  URL to use an mp4 file as video source.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_17", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_18", 
            "text": "URL to an mp4 file source to stream this file.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_15", 
            "text": "Only Supported under Microsoft Windows", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiosource", 
            "text": "", 
            "title": "SetAudioSource"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_19", 
            "text": "SetAudioSource(index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_10", 
            "text": "Name  Type  Description      index  int  Index of the audio source. The index of the audio source, from  0 - GetNumberOfAudioSources -1", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_18", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_19", 
            "text": "Set audio source for preview or broadcasting over index. Call  GetNumberOfAudioSources  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_16", 
            "text": "Under Windows and Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#video_properties", 
            "text": "", 
            "title": "Video Properties"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideowidth", 
            "text": "", 
            "title": "SetVideoWidth"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_20", 
            "text": "SetVideoWidth(width:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_11", 
            "text": "Name  Type  Description      width  int  Width of the video in pixels as integer value    mixSource  int  set  0  to to set only the first video source.  1  to set a second video source.  1     1    \u2014 second video source only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_19", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_20", 
            "text": "Set width of video in pixels. With mixSource the height for two video sources can be set.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_17", 
            "text": "Set Width is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoheight", 
            "text": "", 
            "title": "SetVideoHeight"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_21", 
            "text": "SetVideoHeight(height:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_12", 
            "text": "Name  Type  Description      height  int  Height of the video in pixels as integer value    mixSource  int  set  0  to to set only the first video source.  1  to set a second video source  1     1    \u2014 second video source only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_20", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_21", 
            "text": "Set height of video in pixels. With mixSource the height for two video sources can be set.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_18", 
            "text": "Set Height is supported under Mac OS X and Microsoft Windows. The second mix source is only available under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoresizewidth", 
            "text": "", 
            "title": "SetVideoResizeWidth"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_22", 
            "text": "SetVideoResizeWidth(width:int, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_13", 
            "text": "Name  Type  Description      width  int  resize width of the video in pixels as integer value    index  int  Index of the output. The index of the output, from  0 - GetNumberOfOutputs -1", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_21", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_22", 
            "text": "Resize width of video in pixels.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_19", 
            "text": "Only Supported under Microsoft Windows", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoresizeheight", 
            "text": "", 
            "title": "SetVideoResizeHeight"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_23", 
            "text": "SetVideoResizeHeight(height:int, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_14", 
            "text": "Name  Type  Description      height  int  resize height of the video in pixels as integer value    index  int  Index of the output. The index of the output, from  0 - GetNumberOfOutputs -1", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_22", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_23", 
            "text": "Resize height of video in pixels.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_20", 
            "text": "Only supported under Microsoft Windows", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoframerate", 
            "text": "", 
            "title": "SetVideoFramerate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_24", 
            "text": "SetVideoFramerate(framerate:Number, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_15", 
            "text": "Name  Type  Description      framerate  Number  Frame rate in frames per Second(FPS) as number value.    mixSource  int  set  0  to to set only the first video source.  1  to set a second video source.  1     1    \u2014 second video source only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_23", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_24", 
            "text": "Set frame rate of video in frames per second (FPS). With mixSource the frame rate for two video sources can be set under Microsoft Windows.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_21", 
            "text": "Set video frame rate is supported under Mac OS X and Microsoft Windows. Mix Source is only available under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setnumberofchannels", 
            "text": "", 
            "title": "SetNumberOfChannels"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_25", 
            "text": "SetNumberOfChannels(int numOfChannels)", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_16", 
            "text": "Name  Type  Description      numOfChannels  int  Number of channels as int value", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_25", 
            "text": "Set channel number", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_22", 
            "text": "On Mac OSX", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideobitrate", 
            "text": "", 
            "title": "SetVideoBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_26", 
            "text": "SetVideoBitrate(bitrate:int, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_17", 
            "text": "Name  Type  Description      bitrate  int  Video bitrate as integer value.    index  int  index of output to set the bitrate for multiple encoders.  1     1   \u2014 set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_24", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_26", 
            "text": "Set bitrate of video in kbits per second (kbits/s).", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_23", 
            "text": "Under Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getvideobitrate", 
            "text": "", 
            "title": "GetVideoBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_27", 
            "text": "GetVideoBitrate(int source)", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_18", 
            "text": "Name  Type  Description      index  int  index of output to get the bitrate for multiple encoders.  1     1   \u2014 set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_25", 
            "text": "Video bitrate as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_27", 
            "text": "Get the current video bitrate.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_24", 
            "text": "Under Mac OS X there is only one output available. Under Microsoft Windows several outputs are available over the index parameter.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#audio_properties", 
            "text": "", 
            "title": "Audio Properties"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiobitrate", 
            "text": "", 
            "title": "SetAudioBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_28", 
            "text": "SetAudioBitrate(int bitrate, int index): int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_19", 
            "text": "Name  Type  Description      bitrate  int  Audio bitrate as integer value.    index  int  index of output to set the bitrate for multiple encoders.  1     1   \u2014 set different outputs is only available on Microsoft Windows. On Mac OS X the same bitrate is set to all outputs.  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_26", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_28", 
            "text": "Set bitrate of audio in kbits per second (kbits/s).", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_25", 
            "text": "Under Mac OS X the same bitrate is set to all outputs. Under Microsoft Windows every output can be set to another bitrate.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getaudiobitrate", 
            "text": "", 
            "title": "GetAudioBitrate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_29", 
            "text": "GetAudioBitrate(int source): int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_20", 
            "text": "Name  Type  Description      index  int  index of output to get the bitrate for multiple encoders.  1     1   \u2014Get different outputs is only available on Microsoft Windows. On Mac OS X there is only one source available.  |", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_27", 
            "text": "Audio bitrate as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_29", 
            "text": "Get the current audio bitrate.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiosamplerate", 
            "text": "", 
            "title": "SetAudioSamplerate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_30", 
            "text": "SetAudioSamplerate(int samplerate): int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_21", 
            "text": "Name  Type  Description      samplerate  int  Samplerate of audio as integer value", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_28", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_30", 
            "text": "Set the samplerate of the audio in Hertz (Hz).", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_26", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getaudiolevel", 
            "text": "", 
            "title": "GetAudioLevel"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_31", 
            "text": "GetAudioLevel(channel:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_22", 
            "text": "Name  Type  Description      channel  int  channel id as integer.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_29", 
            "text": "Audiolevel as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_31", 
            "text": "Get the audio level of a channel.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_27", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiovolume", 
            "text": "", 
            "title": "SetAudioVolume"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_32", 
            "text": "SetAudioVolume(volume:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_23", 
            "text": "Name  Type  Description      volume  int  volume as integer value", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_30", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_32", 
            "text": "Set audio volume.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_28", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setaudiopreviewvolume", 
            "text": "", 
            "title": "SetAudioPreviewVolume"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_33", 
            "text": "SetAudioPreviewVolume(volume:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_24", 
            "text": "Name  Type  Description      volume  int  volume as integer value", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_31", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_33", 
            "text": "Set audio volume of preview.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_29", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#color_management", 
            "text": "", 
            "title": "Color Management"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setcolorspace", 
            "text": "", 
            "title": "SetColorSpace"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_34", 
            "text": "SetColorSpace(index:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_25", 
            "text": "Name  Type  Description      index  int  index of the input source.    mixSource  int  set  0  to to set only the first mixed source.  1  to set a second mixed source.  1     1   \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_32", 
            "text": "- 1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_34", 
            "text": "Set the color space of an input source. Only the firtst source is supported under Mac OS X", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_30", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofcolorspaces", 
            "text": "", 
            "title": "GetNumberOfColorspaces"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_35", 
            "text": "GetNumberOfColorspaces(width:int, height:int, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_26", 
            "text": "Name  Type  Description      width  int  width of the video source    height  int  height of the video source    mixSource  int  set  0  to to get the first mixed source.  1  to get the second mixed source.  1     1    \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_33", 
            "text": "Count of color spaces as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_35", 
            "text": "Get the count of color spaces. Get the color space for the specified with and height.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_31", 
            "text": "Under Windows and Mac OSX. Under Mac OSX mix source is not supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getcolorspace", 
            "text": "", 
            "title": "GetColorspace"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_36", 
            "text": "GetColorspace(index:int, mixSource:int):String", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_27", 
            "text": "Name  Type  Description      index  int  Index of the color spaces. The index of the color spaces, from  0 - GetNumberOfColorspaces -1    mixSource  int  set  0  to to get the first mixed source.  1  to get the second mixed source.  1     1    \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_34", 
            "text": "color space name as String", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_36", 
            "text": "Get color space name as string. First call  GetNumberOfColorspaces.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_32", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#resolution_frame_rate", 
            "text": "", 
            "title": "Resolution &amp; Frame rate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofresolutions", 
            "text": "", 
            "title": "GetNumberOfResolutions"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_37", 
            "text": "GetNumberOfResolutions(mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_28", 
            "text": "Name  Type  Description      mixSource  int  set  0  to to get the first mixed source.  1  to get the second mixed source.  1     1     \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_35", 
            "text": "Count of resolutions as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_37", 
            "text": "Get count of resolutions.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_33", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getresolution", 
            "text": "", 
            "title": "GetResolution"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_38", 
            "text": "GetResolution(index:int, mixSource:int):Object", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_29", 
            "text": "Name  Type  Description      index  int  Index of the resolutions. The index of the resolutions, from  0 - GetNumberOfResolutions -1    mixSource  int  set  0  to to get the first mixed source.  1  to get the second mixed source.  1     1      \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_36", 
            "text": "Get resolution of video source. First call  GetNumberOfResolutions.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_38", 
            "text": "Get count of resolutions.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_34", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofframerates", 
            "text": "", 
            "title": "GetNumberOfFramerates"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_39", 
            "text": "GetNumberOfFramerates(width:int, height:int, colorspace:String, mixSource:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_30", 
            "text": "Name  Type  Description      width  int  width of the video source    height  int  height of the video source.    colorspace  String  name of the color space get from GetColorspace    mixSource  int  set  0  to to get the first mixed source.  1  to get the second mixed source.  1     1      \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_37", 
            "text": "Count of available frame rates as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_39", 
            "text": "Get count of available frame rates.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_35", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getframerate", 
            "text": "", 
            "title": "GetFramerate"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_40", 
            "text": "GetFramerate(index:int, mixSource:int):Number", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_31", 
            "text": "Name  Type  Description      index  int  Index of the frame rate. The index of the frame rate, from  0 - GetNumberOfFramerates -1    mixSource  int  set  0  to to get the first mixed source.  1  to get the second mixed source.  1     1      \u2014second mixed source is only available on Microsoft Windows", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_38", 
            "text": "Frame rate (FPS) as number value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_40", 
            "text": "Get the frame rate of a video source. Call  GetNumberOfFramerates  first.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_36", 
            "text": "Under Windows and Mac OSX. Under Mac OSX only the first mix source is supported.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setdeinterlacing", 
            "text": "", 
            "title": "SetDeinterlacing"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_41", 
            "text": "SetDeinterlacing(mode:int, method:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_32", 
            "text": "Name  Type  Description      mode  int  possible values:  0 =off,  1 =auto,  2 =on  \\ no auto mode for mac    method  int  possible values:  0 =duplicate field/bob,  1 =blend,  2 =vertical filter,  3 =edge, 4=median,  5 =median2", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_39", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_41", 
            "text": "Set deinterlacing mode and method.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_37", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#outputs", 
            "text": "", 
            "title": "Outputs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofoutputs", 
            "text": "", 
            "title": "GetNumberOfOutputs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_42", 
            "text": "GetNumberOfOutputs():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_40", 
            "text": "Count of outputs as integer value.", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_42", 
            "text": "Get count of outputs.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_38", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#addoutput", 
            "text": "", 
            "title": "AddOutput"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_43", 
            "text": "AddOutput(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_33", 
            "text": "Name  Type  Description      url  String  Url of outputs can be a local mp4 recording or a rtmp source.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_41", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_43", 
            "text": "Add new output source with url.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_39", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setoutputurl", 
            "text": "", 
            "title": "SetOutputUrl"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_44", 
            "text": "SetOutputUrl(url:String, index:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_34", 
            "text": "Name  Type  Description      url  String  Url of outputs can be a local mp4 recording or a rtmp server.    index  int  Index of the output.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_42", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_44", 
            "text": "Set output with url. A local mp4 recording or a rtmp server.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_40", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getoutputurl", 
            "text": "", 
            "title": "GetOutputUrl"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#getnumberofoutputurls", 
            "text": "", 
            "title": "GetNumberOfOutputUrls"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#acceptdatainsamplebuffer", 
            "text": "", 
            "title": "AcceptDataInSampleBuffer"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setfilesourcefilename", 
            "text": "", 
            "title": "SetFilesourceFilename"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_45", 
            "text": "SetFilesourceFilename(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_35", 
            "text": "Name  Type  Description      url  String  Url to the local file", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_43", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_45", 
            "text": "Set the filename of a local source.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_41", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#clearoutputs", 
            "text": "", 
            "title": "ClearOutputs"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_46", 
            "text": "ClearOutputs():int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_44", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_46", 
            "text": "Reset all outputs except the first one.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_42", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#video_special", 
            "text": "", 
            "title": "Video Special"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setvideoeffect", 
            "text": "", 
            "title": "SetVideoEffect"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_47", 
            "text": "SetVideoEffect(mode:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_36", 
            "text": "Name  Type  Description      mode  int  Mode of video effect. See possible overlay effects on page 33", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_45", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_47", 
            "text": "Add a video effect. For overlay.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_43", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setoverlay", 
            "text": "", 
            "title": "SetOverlay"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_48", 
            "text": "SetOverlay(url:String):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_37", 
            "text": "Name  Type  Description      url  String  Url of the overlay source. Can be a locale path or server url to a png or txt file. Also can be a txt string.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_46", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_48", 
            "text": "Add a overlay to the video.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_44", 
            "text": "Only Supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#showpropertypage", 
            "text": "", 
            "title": "ShowPropertyPage"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_49", 
            "text": "ShowPropertyPage(value:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_38", 
            "text": "Name  Type  Description      value  int  1  or  0  are possible values", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_47", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_49", 
            "text": "Show property page. Only used for Blackmagic devices.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_45", 
            "text": "Only supported under Microsoft Windows.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#logging", 
            "text": "", 
            "title": "Logging"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setlog", 
            "text": "", 
            "title": "SetLog"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_50", 
            "text": "SetLog(logFile:String, logLevel:int):int", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#parameters_39", 
            "text": "Name  Type  Description      logFile  String  local path for logfile as string.    logLevel  int  log level as integer. For possible loglevels 0-9.", 
            "title": "Parameters"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#return_value_48", 
            "text": "-1  if call failed", 
            "title": "Return Value"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_50", 
            "text": "Set log file path and log level.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_46", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_47", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setxmlprofile", 
            "text": "", 
            "title": "SetXmlProfile"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#dispose", 
            "text": "", 
            "title": "dispose"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#declaration_51", 
            "text": "dispose():void", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#description_51", 
            "text": "Destructor.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#availability_48", 
            "text": "Under Windows and Mac OSX.", 
            "title": "Availability"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#setconfig_properties", 
            "text": "Property name  Description  Values  Mac Platform Support      license  License string   \u2714    XMLPath  Path to the XML file with configuration information   \u2714    RemoteControlPort  Port number   \u2714    LiveSource    \u2714    RemoteIP    \u2714    AVOffsetMs    \u2714    ReconnectPeriod/ReconnectInterval    \u2714    ReconnectAttempts  Auto Reconnect No. of Attempts  5  \u2714    UseInternalReconnect  Use RTMP Internal Reconnect of the RTMP Filter (do not stop encoder on network errors)  0 / 1  \u2714    UseUnlimitedReconnect  Don t stop reconnecting after a specific number of failed attempts (encoder is not stopped)  0 / 1  \u2714    Auth  Authentication for RTMP and RTSP Push streaming  \u201cuser:password\u201d  \u2714    RtmpUrlDelimiter  Set delimiter for RTMP-url and streamname.  Example: \u201d+\u201c will split   so that \u201cmyStream\u201d is the stream name.  \u2714    DeinterlacingMode  Deinterlacing Mode  0=off, 1=auto (default), 2=on Note: for some capture devices you need to set this to \u201eon\u201c (2). (Resolutions 480i, 576i, 1080i)  \u2714    DeinterlacingMethod  Deinterlacing Method  0=duplicate field/bob, 1=blend, 2=vertical filter, 3=edge, 4=median, 5=median2  \u2714    RemoteSendAudioLevelInterval    \u2714    CaptureRegion  Capture Region of the input source, example for a input resolution of 640\u00d7480: SetConfig(\u201cCaptureRegion\u201d, \u201c10,630,10,470\u201d) - discards 10 pixels on each side  left,right,top,bottom  \u2714    RTMPPublishMode  RTMP Publish/Live/Record on Server (VOD)  1=record, 2=append, 0=live (default)  \u2714    VideoAudioInput    \u2714    PreviewNoInvert    \u2714    ScreenCapMode  Screen Capture Desktop Mode  0=Screen, 1=FollowMouse, 2=Region relative, 3=Region absolute, 4=Window, 5=Window overlapping  \u2714    ScreenCapWindowIndex    \u2714    ApplyDynamicSettings    \u2714    Mp4RecordOnTheFlyChangeName    \u2714    Mp4RecordOnTheFlyControl  If Mp4RecordOnTheFly is enabled, controls start/stop recording  0=stop, 1=start  \u2714    AudioPreview  Enables audio preview during preview or broadcast  0=no preview, 1=visual preview (default, requires filter AudioVolume), 2=visual and audible preview, 3=audible preview  \u2714    Mp4RecordOnTheFly  Enables start/stop recording to local file while the broadcast is running  0=off (default), 1=on  \u2714    H264Quality  H.264 Encoder Quality/Speed Ratio  0=worst/fastest 1=default 6=highest/slowest  \u2714    H264IFrameDistance  H.264 I Frame / GOP Length in Frames (100 Frames = 4 seconds for 25 fps)  100=default, 1 = I-Frame-Only  \u2714    H264PFrameDistance  H.264 P/B Frame Distance  3 1 = IP-Only (no B-Frames)  \u2714    H264Profile  H.264 Encoding Profile  Baseline, Main, Extended, High Most compatible but lowest quality is Baseline, (no B-Frames, no CABAC VLC)  \u2714    H264Level  H.264 Level  10=1.0, 11=1.1, 12=1.2, 13=1.3, 20=2.0, 21=2.1, 22=2.2, 30=3.0, 31=3.1, 32=3.2, 40=4.0, 41=4.1, 42=4.2, 50=5.0, 51=5.1  \u2714    H264VlcMode  H.264 VLC Mode (CAVLC/CABAC)  =CAVLC, 2=CABAC (not allowed in H.264 Baseline Profile)  \u2714    OutputFrameRate  Video Output (Encoded) Frame Rate  5,10,15,20,25,30, OR 23980 OR 29970  \u2714    RTMPWriteTimecode  Send timecodes in RTMP streams, If enabled RTMP timecodes are sent in addition to the always sent RTMP packet timestamps  0=off (default), 1=on  \u2714    UseSystemTimeAsTimecode  Send RTMP/MP4 timecodes as UTC system date time or stream time  0=stream time (default), 1=UTC system date time  \u2714    TimecodeInterval  RTMP/MP4 timecode interval in milliseconds  Should be higher or equal to 1000 (1s)  \u2714    TcpConnectTimeout    \u2714    RTSPSinkMode  Determines if the RTSPSink is running as a server (passive/pull) or as a streamer to a RTSP push capable server (active/push)  1=server/pull (default), 2=streamer/push  \u2714    RTSPSDPFileFolder    \u2714    RTSPStreamDescription    \u2714    AudioVolumePerSoftware  Control volume with the Audio Volume Filter  0=off (default), 1=on  \u2714    AVFShowBlackmagicDevices  use AVFoundation for BlackMagic devices  0=off (default), 1=on  \u2714    OverlayRect  Sets the dimensions for a given overlay-image.  \u201cindex,left,top,right,bottom\u201d. index: the overlay-index, beginning with 0. left, top, right and bottom define a rectangle in screen-coordinates.  \u2714    OverlayAlpha  Sets the alpha-value for overlays.  Range: 0-1. 0.0 (not visable), 1 (fully visable).  \u2714    OverlayTextColor  Text Overlay Color  Must be a hexadecimal color-value in BGR-format, e.g.: \u201c0000FF\u201d (255 (0x0000FF) - red)  \u2714    OverlayBackgroundColor   Must be a hexadecimal color-value in BGR-format, e.g.: \u201c000000\u201d (0 (0x000000) - black).  \u2714    OverlaySkipColor  Setting skipcolor to a specific value will result in this color to be rendered transparent in the overlays.  Example: If OverlayBackgroundColor was set to blue (\u201cFF0000\u201d) setting OverlaySkipColor to blue as well will result in a transparent background. Parameter must be a hexadecimal color-value in BGR-format, e.g.: \u201cFF0000\u201d (blue). Disable: Setting OverlaySkipColor to \u201cFF000000\u201d (ABGR) will disable the usage of skipcolor.  \u2714    AudioDelay  Streaming Audio Delay / Offset (ms)   \u2714    ShowPropertyPageForDevice  Calls the propertypage for a given device.  0 for device with index: 0  \u2714    UseQuicktimeH264Encoder    \u2714    RotateDegrees  set the degrees by which video should be rotated, only works if UseRotation is set to on, set before StartPreview or StartBroadcast  0/90/180/270  \u2714", 
            "title": "SetConfig Properties"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#mixmode", 
            "text": "NO_MIXING = 0 (if video mixing is not used)  LEFT_RIGHT_FULL = 1  LEFT_RIGHT_HALF = 2  TOP_BOTTOM = 3  INTERLACED_LINES = 4  INTERLACED_COLUMN = 5  ANAGLYPH = 6  PIC_IN_PIC_LEFT_TOP = 7  PIC_IN_PIC_RIGHT_TOP = 8  PIC_IN_PIC_LEFT_BOTTOM = 9  PIC_IN_PIC_RIGHT_BOTTOM = 10  VIDEO1_ONLY = 11  VIDEO2_ONLY = 12  REGION = 13  MAX = 14", 
            "title": "Mixmode"
        }, 
        {
            "location": "/nanostream/macos/nanostream-macos-sdk/#overlay_effects", 
            "text": "Overlay off = 0  Left Top = 1  Right Top = 2  Left Bottom = 3  Right bottom = 4  Free Postion = 5", 
            "title": "Overlay Effects"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/", 
            "text": "nanoStream SDK Android: Streaming Developer Manual\n\n\nIntroduction\n\n\nPurpose\n\n\nThis documentation is about the nanoStream Live Video Streaming SDK for Android and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.\n\n\nRequirements\n\n\n\n\nAndroid 4.1+ (API Level 16)\n\n\n\n\nRequired permissions:\n\n\nThe nanoStream SDK for android does not request any permissions by itself.\nHowever, it needs a few permissions to work.\n\n\nThe needed permissions are :\n\n android.permission.INTERNET - This is needed since the stream should be sent over a network.\n\n android.permission.RECORD_AUDIO - In case your stream is not video-only the app needs this permission to record audio data using the microphone.\n\n android.permission.RECORD_VIDEO - In case your stream is not audio-only the app needs this permission to record image data using the camera.\n\n android.permission.WRITE_EXTERNAL_STORAGE - In case the encoded stream should be written on the phone\ns memory.\n\n\nHow these permissions should be requested depends on the used version of android.\n\n\nOn devices with android versions prior to Android 6.0 the permissions are getting requested once per app installation. They just need to be configured within the AndroidManifest.xml file, so that the user can give the permission while installing the app.\n\n\nOn devices with android versions from 6.0 upwards the permissions should be requested at run time when needed. It can be checked whether a permission is already granted or not. Afterwards, the needed permissions can be requested. This will create a pop-up, which asks the user to grant the needed permissions. If you are working with our BinutStreamer-Sample, an example of this can be found in the CheckAppPermission-Class.\n\n\nGetting Started\n\n\nCopy the SDK libraries into your Android Studio project\n\n\nAdd the \nnet.nanocosmos.nanoStream.jar\n java component to your Android Studio project by copying \n[SDK]/libs/net.nanocosmos.nanoStream.jar\n to the folder \n[projectpath]/app/libs/net.nanocosmos.nanoStream.jar\n Add the \nnanoStream.so\n native components to the Android Studio project by copying the 5 folders \n[SDK]/libs/[platform]/libRTMPStream.so\n to [projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so`\n\n\nPlatforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips\n\n\nAdd the nanoStream to the gradle file\n\n\nOpen the build.gradle file (Module:app) and add\n\n\ncompile files('libs/net.nanocosmos.nanoStream.jar')\n\n\n\n\nto the dependencies section.\n\n\nCheck library version\n\n\nString nanoStreamVersion = nanoStream.getVersion().fullVersion;\n\n\n\n\nInitialize the library\n\n\nImplement the interface \nnanoStreamEventListener\n in your class:\n\n\npublic class StreamActivity extends Activity implements NanostreamEventListener {\n  // implement your class\n\n  private class NotificationRunable implements Runnable {\n     private NanostreamEvent m_event;\n\n     public NotificationRunable(NanostreamEvent event) {\n      m_event = event;\n     }\n\n     @Override\n     public void run() {\n       Toast.makeText(getApplicationContext(), m_event.GetDescription(), Toast.LENGTH_SHORT).show();\n     }\n   }\n\n  @Override\n  public void onNanostreamEvent(NanostreamEvent event) {\n    if (event.GetType() != NanostreamEvent.TYPE_RTMP_QUALITY) {\n      this.runOnUiThread(new NotificationRunable(event));\n    }\n  }\n}\n\n\n\n\nConfigure the nanoStreamSettings object for the library:\n\n\n  private String license = \n--- add your nanoStream license here ---\n;\n  private String serverUrl = \nrtmp://example.org/live\n;\n  private String streamName = \nmyStream\n;\n  private nanoStream streamLib = null;\n\n  void initStreamLib() {\n    if(null == streamLib) {\n      nanoStreamSettings nss = new nanoStreamSettings();\n      nss.setLicense(license);\n      nss.setLogSettings(logSettings);\n      nss.setStreamUrl(serverUrl);\n      nss.setStreamName(streamName);\n      nss.setEventListener(this);\n\n      try {\n        streamLib = new nanoStream(nss);\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      }\n\n      if(null != streamLib) {\n        try {\n          streamLib.init();\n        } catch (NanostreamException e) {\n          Toast.makeText(getApplicationContext(), e.toString(), Toast.LENGTH_LONG).show();\n        } catch (IllegalArgumentException e) {\n          e.printStackTrace();\n        }\n      }\n    }\n  }\n\n\n\n\nStart/Stop the Stream:\n\n\npublic void toggleStreaming(View clicked) {\n  if (null == streamLib) {\n    Toast.makeText(getApplicationContext(), \nnanoStream failed to initialize\n, Toast.LENGTH_LONG).show();\n    return;\n  }\n\n  if (!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n    Toast.makeText(getApplicationContext(), \nStarting...\n, Toast.LENGTH_SHORT).show();\n\n    if (streamLib.hasState(nanoStream.EncoderState.STOPPED) || streamLib.hasState(nanoStream.EncoderState.CREATED)) {\n      try {\n        Logging.log(Logging.LogLevel.DEBUG, TAG, \ntoggleStreaming init nanoStream\n);\n        streamLib.init();\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n        return;\n      }\n    }\n\n    try {\n      streamLib.start();\n    } catch (NanostreamException en) {\n      Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      return;\n    }\n  } else {\n    Toast.makeText(getApplicationContext(), \nStopping...\n, Toast.LENGTH_SHORT).show();\n    streamLib.stop();\n  }\n}\n\n\n\n\nResolution, Aspect Ratio and Orientation\n\n\nResolution\n\n\nResolution means the native resolution of the camera (input). In the most situations this will be the same for the output. To set the resolution there is a function in the VideoSettings object called setResolution(Resolution res). If you set a resolution that the device doesn\nt support, nanoStream will automatically switch to the nearest resolution available on the device. A list of supported resolutions for the current video source can be obtained from getCapabilities().listAvailableVideoResolutions() on the nanoStream object.\n\n\nAspect ratio\n\n\nAspect ratio means the aspect ratio of the outgoing stream. The aspect ratio determines if the input video needs to be cropped. The aspect ratio can be set through the setAspectRatio(AspectRatio aspectRatio) function on the VideoSettings object.\n\n\nSupported Aspect ratios\n\n\n\n\n\n\n\n\nAspect Ratio\n\n\nAspectRatio value\n\n\n\n\n\n\n\n\n\n\nKeep Input\n\n\nAspectRatio.RATIOKEEPINPUT\n\n\n\n\n\n\n1:1\n\n\nAspectRatio.RATIO11\n\n\n\n\n\n\n4:3\n\n\nAspectRatio.RATIO43\n\n\n\n\n\n\n16:9\n\n\nAspectRatio.RATIO169\n\n\n\n\n\n\n3:4\n\n\nAspectRatio.RATIO34\n\n\n\n\n\n\n9:16\n\n\nAspectRatio.RATIO_9_16\n\n\n\n\n\n\n\n\nOrientation\n\n\nThe default stream orientation is landscape. If you switch to portrait the resolution will swap width and height, e.g. from 640\u00d7480 to 480\u00d7640. You can set the stream orientation on the nanoStream object with the setStreamRotation function. The stream orientation needs to be set before starting the stream, it is not possible to switch the orientation during the\n\n\nSupported Orientations\n\n\n\n\n\n\n\n\nOrientation\n\n\nRotation Value\n\n\n\n\n\n\n\n\n\n\nLandscape\n\n\nRotation.ROTATION_0\n\n\n\n\n\n\nPortrait\n\n\nRotation.ROTATION_90\n\n\n\n\n\n\nLandscape Upside Down\n\n\nRotation.ROTATION_180\n\n\n\n\n\n\nPortrait Upside Down\n\n\nRotation.ROTATION_270\n\n\n\n\n\n\n\n\nExample Combinations of Aspect Ratios and Orientations\n\n\nThe input resolution is set to 640x480 here. The red rectangle marks up the active area that is included in the output stream.\n\n\n\n\n\n\n\n\nOrientation\n\n\nAspect Ratio\n\n\nStream Area\n\n\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\nKeep Input\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n4:3\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n3:4\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n16:9\n\n\n\n\n\n\n\n\nPortrait\n1\n\n\n9:16\n\n\n\n\n\n\n\n\nLandscape\n\n\nKeep Input\n\n\n\n\n\n\n\n\nLandscape\n\n\n4:3\n\n\n\n\n\n\n\n\nLandscape\n\n\n3:4\n\n\n\n\n\n\n\n\nLandscape\n\n\n16:9\n\n\n\n\n\n\n\n\nLandscape\n\n\n9:16\n\n\n\n\n\n\n\n\n\n\n1\n: In this sample APP we crop the preview so it doesn\nt look ugly, so the stream is actually larger then the preview.\n\n\nExample\n\n\nIf you want to stream with a resolution of 640x360 but your device doesn\nt supports this resolution, you need to crop the resolution from 640x480 (this resolution is supported by the most devices) to 640x360. This can be done through the aspect ratio, so you need to set the aspect ratio to 16:9 to stream with a resolution of 640x360.\n\n\nImplementation Example\n\n\npublic class MainActifity {\n    ...\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n      super.onCreate(savedInstanceState);\n      nanoStreamSettings nss = new nanoStreamSettings();\n      VideoSettings vs = new VideoSettings();\n      ...\n      vs.setResolution(new Resolution(640, 480)); // default value\n      vs.setAspectRatio(AspectRatio.RATIO_16_9); // default value is AspectRatio.KEEP_INPUT\n      ...\n      streamLib = new nanoStream(nss);\n      streaLib.init();\n\n      streamLib.setStreamRotation(Rotation.ROTATION_0); // default value\n      ...\n    }\n    ...\n}\n\n\n\n\nRotationHelper Class\n\n\nDescription\n\n\nWith the nanoStream SDK 4.3.1 release we added a \nRotationHelper\n Class, this Class improves the Rotation handling.\n\n\nRotationHelper\n\n\nThe RotationHelper class has two static Methods, \ngetDeviceDefaultOrientation(Context context)\n and \ngetRotation(int orientation, boolean isDefaultOrientationLandscape)\n.\n\n\ngetDeviceDefaultOrientation\n\n\nThe return values are one of the following\n\n \nConfiguration.ORIENTATION_LANDSCAPE\n\n\n \nConfiguration.ORIENTATION_PORTRAIT\n\n\ngetRotation\n\n\nParameter\n\n\nThe \norientation\n parameter of the \ngetRoation\n Method is one of the following:\n\n \nActivityInfo.SCREEN_ORIENTATION_PORTRAIT\n\n\n \nActivityInfo.SCREEN_ORIENTATION_LANDSCAPE\n\n\n \nActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT\n\n\n \nActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE\n\n\nThe \nisDefaultOrientationLandscape\n parameter is true or false.\n\n\nReturn values\n\n\nThe return values given from \nRotationHelper.getRoation\n can be used as a Parameter for \nsetStreamRotation\n and \nsetPreviewRotation\n. is the \norientation\n parameter non of the above described the \ngetRotation\n Method returns \nnull\n.\n\n\nImplementation Example\n\n\nimport net.nanocosmos.nanoStream.streamer.Rotation;\nimport net.nanocosmos.nanoStream.streamer.RotationHelper;\n\npublic class MainActivity extends Activity {\n  // ...\n  private boolean isDefaultOrientationLandscape = false;\n  private CustomOrientationEventListener orientation = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    // ...\n    streamLib = new nanoStream(/*settings*/);\n\n    isDefaultOrientationLandscape = (RotationHelper.getDeviceDefaultOrientation(this) == android.content.res.Configuration.ORIENTATION_LANDSCAPE);\n    orientation = new CustomOrientationEventListener(this, SensorManager.SENSOR_DELAY_UI);\n    orientation.enable();\n  }\n\n  private class CustomOrientationEventListener extends OrientationEventListener {\n    private int lastScreenOrientation = 0;\n    public CustomOrientationEventListener(Context context, int rate) {\n      super(context, rate);\n    }\n\n    @Override\n    public void onOrientationChanged(int orientation) {\n      if (null != streamLib) {\n        if(!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n          if (isDefaultOrientationLandscape) {\n              orientation -= 90;\n\n              if (orientation \n 0) {\n                  orientation += 360;\n              }\n          }\n          int screenOrientation = -1;\n\n          if (orientation \n 70 \n orientation \n 110) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE;\n          } else if (orientation \n 160 \n orientation \n 200) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT;\n          } else if (orientation \n 250 \n orientation \n 290) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE;\n          } else if ((orientation \n 340 \n orientation \n= 360) || (orientation \n= 0 \n orientation \n 20)) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_PORTRAIT;\n          }\n\n          if (screenOrientation != lastScreenOrientation) {\n            Rotation rotation = RotationHelper.getRotation(screenOrientation, isDefaultOrientationLandscape);\n            if (null != rotation) {\n              try {\n                streamLib.setPreviewRotation(rotation);\n                streamLib.setStreamRotation(rotation);\n                streamLib.setAspectRatio(videoAspectRatio);\n              } catch (IllegalStateException e) {\n                Logging.log(Logging.LogLevel.ERROR, TAG, \nCamera rotate failed\n, e);\n              }\n            }\n            lastScreenOrientation = screenOrientation;\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\n\nStream Type\n\n\nThe SDK supports differnet streaming modes:\n\n\n\n\nVideo and Audio\n\n\nVideo only\n\n\nAudio only\n\n\n\n\nYou can en/disable Video/Audio in the \nnanoStreamSettings\n.\n\n\nImplementation Example\n\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setHaveVideo(true); // false\nnss.setHaveAudio(true); // false\n\n\n\n\nServer Authentication\n\n\nIn case authentication is required, the credentials can be set on the \nnanoStreamSettings\n object.\n\n\nImplementation Example\n\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setAuthUser(\nuser\n);\nnss.setAuthPassword(\npassword\n);\n\n\n\n\nAndroid MP4 Recording\n\n\nDescription\n\n\nThe nanoStream Android SDK supports, MP4 recording to do this there needs to be set a valid Path to the nanoStreamSettings object. And the MP4 Recording needs to be enabled. This feature allows you to record the current stream to the Device internal/external sd card.\n\n\nEnable MP4 recording\n\n\nTo enable the MP4 recording there are tow functions in the nanoStreamSettings Class.\n\n\n\n\nsetRecordMp4(boolean)\n\n\nsetMp4Path(String)\n\n\n\n\nsetRecordMp4(boolean)\n\n\nThe setRecordMp4 function takes a boolean as parameter, this is to enable/disable the recording function.\n\n\nsetMp4Path(String)\n\n\nThe setMp4Path function takes a String as parameter, this string needs to be a valid file path (e.g. /sdcard/test.mp4). Much better is to use the getExternalStoragePublicDirectory from the \nEnvironment\n Android API, and add a file name to this directory Path.\n\n\nAndroid permission\n\n\nTo write to an external File Path your Android App needs the following permission (Add this to your AndroidMainfest.xml).\n\n\nuses-permission android:name=\nandroid.permission.WRITE_EXTERNAL_STORAGE\n /\n\n\nuses-permission android:name=\nandroid.permission.STORAGE\n /\n\n\n\n\n\nAndroid 6.0\n\n\nDue to the new Permission handling it is possible that you can\nt write in external Directorys if the user isn\nt granted this permission, you can always write in your own data directory (/Android/data/com.companyname.appname/)\n\n\nImplementation Example\n\n\nFile externalFilePath = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM);\nFile filePath = new File(externalFilePath, \nmyMp4File.mp4\n);\nString mp4FilePath = filePath.getAbsolutePath();\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setRecordMp4(true);\nnss.setMp4Path(mp4FilePath);\n\n\n\n\nSnapshot\n\n\nTo get a snapshot (image) of the current preview/stream, the method \ntakeSnapshot\n can be used. This is a non blocking function, for the result you need to implement the SnapshotCallback interface. The snapshot returns as a base64 encoded JPEG\n\n\nImplementation Example\n\n\nprivate class CustomSnapshotCallback implements SnapshotCallback {\n  @Override\n  void onSuccess(String arg0){\n    // do something with the base64 encoded JPEG.\n  }\n\n  @Override\n void onFailure(){\n   Log.d(TAG, \ntakeSnapshot() failed!\n)\n }\n}\nprivate void shapshot() {\n  streamLib.takeSnapshot(new CustomSnapshotCallback());\n}\n\n\n\n\nAdaptive Bitrate Streaming\n\n\nBy using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth. There are four modes available:\n\n\n\n\nDISABLED: The Adaptive Bitrate Control is disabled.\n\n\nQUALITY_DEGRADE: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.\n\n\nFRAME_DROP: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.\n\n\nQUALITY_DEGRADE_AND_FRAME_DROP: The video quality and the framerate (FPS) decreased if the not enough bandwidth is available.\n\n\n\n\nMake sure to set the ABC settings before a stream is started.\n\n\nImplementation Example\n\n\nprivate AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode abcMode = AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode.QUALITY_DEGRADE_AND_FRAME_DROP;\nprivate int videoBitrate = 500000;\n\nprivate void initStreamLib() {\n  AdaptiveBitrateControlSettings abcSettings = new AdaptiveBitrateControlSettings(abcMode);\n  abcSettings.SetMaximumBitrate((int)(videoBitrate * 1.5));\n\n  nanoStreamSettings nss = new nanoStreamSettings();\n  nss.setAbcSettings(abcSettings);\n}\n\n\n\n\nMeasuring the available bandwidth\n\n\nFor measuring the available bandwidth you can use the method \nrunBandwidthCheck\n. After the check finished, the result can be used to set the bitrate for the nanoStream object.\nThe check measures the bandwidth by running a test stream to the server.\nThe BandwidthCheck Class has three public functions:\n\n\n\n\nrunBandwidthCheck(BandwidthCheckSettings settings, BandwidthCheckResultCallback callback()\n\n\nforceStop()\n\n\nabort()\n\n\n\n\nThere is a BandwidthCheckSettings Class, the constructor creates a standard object of BandwidthCheckSettings, with the following settings:\n\n\n\n\n\n\n\n\nproperty\n\n\ndefault values\n\n\nmeaning\n\n\n\n\n\n\n\n\n\n\nprerollSeconds\n\n\n1 (in sec.)\n\n\nthis is the pre roll time to connect to the server\n\n\n\n\n\n\nrunTime\n\n\n5 (in sec.)\n\n\nthe run time of the bandwidth check\n\n\n\n\n\n\nmaxBitrate\n\n\n3000000 (bit/s = 3 MBit/s)\n\n\nthe maximum bit rate for the bandwidth check\n\n\n\n\n\n\nrtmpUrl\n\n\nempty\n\n\nthe rtmp url for the bandwidth check\n\n\n\n\n\n\nstreamId\n\n\nempty\n\n\nthe stream id for the bandwidth check\n\n\n\n\n\n\n\n\nWith this settings you can call the runBandwidthCheck methode, the second parameter is the callback for the results. This callback class has a finished method that will be called after bandwidth check is done.\nThe finished method has one parameter from type BandwidthCheckResult, this object has 6 getter methods:\n\n\n\n\ngetAverageBitrate() // the average measured bandwidth\n\n\ngetMedianBitrate() // the median measured bandwidth\n\n\ngetMaxBitrate() // the maximum measured bandwidth\n\n\ngetMinBitrate() // the minimum measured bandwidth\n\n\ngetRunTimeMS() // the run time in ms\n\n\ngetErrorCode() // the error code if all is ok this is nanoResults.N_OK (all error codes can be found in the nanoStream API Reference documentation for nanoResults)\n\n\n\n\nThe forceStop call stops the bandwidth check and will return the results that where measured until then. The abort call stops the bandwidth check but don\nt return any results.\n\n\nThe bandwidth check, sends a special type of metadata that will not be recorded on the Streaming Server.\n\n\nImplementation Example\n\n\nprivate BandwidthCheck bwCheck = null;\n\nprivate class CustomBandwidthCheckResultCallback implements BandwidthCheckResultCallback {\n  @Override\n  public void finished(final BandwidthCheckResult bandwidthCheckResult) {\n    Log.d(TAG, \nBandwidthCheck results: \n +\n      \n\\n\\tAverage Bitrate (kBit/s): \n + bandwidthCheckResult.getAverageBitrate() / 1000 +\n      \n\\n\\tMedian Bitrate  (kBit/s): \n + bandwidthCheckResult.getMedianBitrate() / 1000 +\n      \n\\n\\tMax Bitrate     (kBit/s): \n + bandwidthCheckResult.getMaxBitrate() / 1000 +\n      \n\\n\\tMin Bitrate     (kBit/s): \n + bandwidthCheckResult.getMinBitrate() / 1000 +\n      \n\\n\\tRun Time        (ms)    : \n + bandwidthCheckResult.getRunTimeMS());\n  }\n}\n\nprivate void initBandwidthCheck() {\n  if(null == bwCheck) {\n    BandwidthCheckSettings settings = new BandwidthCheckSettings();\n    settings.setRtmpUrl(serverUrl);\n    settings.setStreamId(streamName);\n    bwCheck = new BandwidthCheck();\n    bwCheck.runBandwidthCheck(settings, new CustomBandwidthCheckResultCallback());\n  }\n}\n\n\n\n\nRTMP Quality Statistics\n\n\nDescription\n\n\nThe RTMP Module provides the current RTMP Quality over the \nNanostreamEventListener\n. These includes the \noutput bit rate\n, \nbuffer fullness\n, \nbit rate\n and \nframe rate\n.\n\n\nImplementation Example\n\n\npublic class MainActivity extends Activity implements NanostreamEventListener {\n  private LinearLayout qualityView = null;\n    private TextView outputBitrate = null;\n    private TextView bufferFullness = null;\n    private TextView bitrate = null;\n    private TextView framerate = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    qualityView = (LinearLayout) findViewById(R.id.qualityView);\n        outputBitrate = (TextView) findViewById(R.id.outputBitrateText);\n        bufferFullness = (TextView) findViewById(R.id.bufferfillnessText);\n        bitrate = (TextView) findViewById(R.id.bitrateText);\n        framerate = (TextView) findViewById(R.id.framerateText);\n\n    // Init nanoStream\n  }\n\n  @Override\n    public void onNanostreamEvent(NanostreamEvent event)\n    {\n        if (event.GetType() == NanostreamEvent.TYPE_RTMP_QUALITY)\n        {\n            this.runOnUiThread(new ViewQualityRunnable(event));\n        }\n    }\n\n  private class ViewQualityRunnable implements Runnable\n    {\n        private NanostreamEvent m_event;\n        private DecimalFormat format;\n\n        public ViewQualityRunnable(NanostreamEvent m_event)\n        {\n            super();\n            this.m_event = m_event;\n            format = new DecimalFormat(\n#0.00\n);\n        }\n\n        @Override\n        public void run()\n        {\n            if (qualityView.getAlpha() == 0 \n m_event.GetParam1() != 0 \n m_event.GetParam2() != 0 \n m_event.GetParam3() != 0 \n m_event.GetParam4() != 0)\n            {\n                qualityView.setAlpha(0.5f);\n            }\n            int qualityColor = Color.YELLOW;\n            if (m_event.GetParam2() \n= 1000)\n            {\n                qualityColor = Color.rgb(255, 0, 0);\n            } else if (m_event.GetParam2() \n= 750)\n            {\n                qualityColor = Color.YELLOW;\n            } else if (m_event.GetParam2() \n= 750)\n            {\n                qualityColor = Color.GREEN;\n            }\n\n            outputBitrate.setText(Long.toString(m_event.GetParam1() / 1000) + \nkbit/s\n);\n            outputBitrate.setTextColor(qualityColor);\n            bufferFullness.setText(format.format(((double) m_event.GetParam2() / 100.0)) + \n%\n);\n            bufferFullness.setTextColor(qualityColor);\n            bitrate.setText(Long.toString(m_event.GetParam3() / 1000) + \nkbit/s\n);\n            framerate.setText(m_event.GetParam4() + \nfps\n);\n\n        }\n    }\n}\n\n\n\n\nCamera Zoom\n\n\nDescription\n\n\nThe nanoStream Android SDK supports camera zoom, if the internal camera supports it. Therefor there are a few functions, the most important are:\n\n\n\n\n\n\n\n\nFunction\n\n\nReturn Type\n\n\nreturns\n\n\n\n\n\n\n\n\n\n\nhasZoom()\n\n\nboolean\n\n\ntrue if zoom is supported by the video source/ device\n\n\n\n\n\n\ngetZoomRatios()\n\n\nList\n\n\nlist with of ale zoom ratios\n\n\n\n\n\n\ngetZoom()\n\n\nint\n\n\nthe index of the List\n that returned from getZoomRatios()\n\n\n\n\n\n\nsetZoom(int)\n\n\nint\n\n\nthe new index of the List\n that returned from getZoomRatios()\n\n\n\n\n\n\n\n\nIt is recommended to use pinch to zoom, therefor you need to implement a ScaleGestureDetector.SimpleOnScaleGestureListener, and a pinch2zoom function, that takes the scalefactor from the SimpleOnScaleGestureListener as a int parameter, take a look at the \nImplementation Example\n.\n\n\ngetZoomRatios()\n\n\ngetZoomRatios() returns a List of Integer values, this values are the zoom ratios in 1/100 increments (e.g. a zoom of 3.2x is returned as 320).\n\n\nsetZoom(int)\n\n\nThe int parameter from setZoom(int zoom) is the index of zoom ratios that returns getZoomRatios().\n\n\nZoom Behavior on Camera Switch\n\n\nDuring a camera switch (e.g. from back to front) the zoom remains unaffected.\n\n\n Implementation Example\n\n\npublic class MainActivity extends Activity {\n  private ScaleGestureDetector scaleGestureDetector;\n  private List\nInteger\n mZoomRatios = null;\n\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n\n    nanoStreamSettings nss = new nanoStreamSettings();\n    // configure nanoStreamSettings\n\n    streamLib = new nanoStream(nss);\n\n    if(streamLib.hasZoom()) {\n      mZoomRatios = streamLib.getZoomRatio();\n    }\n\n    if(null == scaleGestureDetector) {\n      scaleGestureDetector = new ScaleGestureDetector(this, new ScaleGestureListener());\n    }\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (scaleGestureDetector != null)\n    {\n      scaleGestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n\n  private class ScaleGestureListener extends ScaleGestureDetector.SimpleOnScaleGestureListener {\n    @Override\n    public boolean onScale(ScaleGestureDetector detector) {\n      if(null != streamLib) {\n        if (streamLib.hasZoom()) {\n          pinch2Zoom(detector.getScaleFactor());\n        }\n      }\n      return true;\n    }\n  }\n\n  public void pinch2Zoom(float scaleFactor) {\n    if (streamLib.hasZoom() \n null != mZoomRatios) {\n      int zoomFactor = streamLib.getZoom();\n      float zoomRatio = mZoomRatios.get(zoomFactor) / 100f;\n      zoomRatio *= scaleFactor;\n      if (zoomRatio \n 1.0f) {\n        if (scaleFactor \n 1.0f) {\n          for (int i = zoomFactor; i \n mZoomRatios.size(); i++) {\n            Double zoom = mZoomRatios.get(i) / 100.0;\n            if (zoom \n= zoomRatio) {\n              streamLib.setZoom(i);\n              break;\n            }\n          }\n        } else {\n          for (int i = zoomFactor; i \n 0; i--) {\n            Double zoom = mZoomRatios.get(i) / 100.0;\n            if (zoom \n= zoomRatio) {\n              streamLib.setZoom(i);\n              break;\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\n\nCamera Focus\n\n\nDescription\n\n\nThe nanoStream Android SDK supports Camera focus and focus lock, if the the internal cameras supports them. There are two nonblocking functions\n\n\nsetFocusArea(int focusWidth, int focusHeight, float areaMultiple, int x, int y, int previewWidth, int previewHeight, int weigh)\nsetFocusLockArea(int focusWidth, int focusHeight, float areaMultiple, int x, int y, int previewWidth, int previewHeight, int weigh)\n\n\n\n\nthrough the\n\n\naddFocusCalback(FocusCallback callback)\nremoveFocusCalback(FocusCallback callback)\n\n\n\n\nyou can attach or remove a FocusCallback listener.\nTo check if your device Supports focus you can call\n\n\nisFocusSupported()\n\n\n\n\nthis will return true or false\n\n\nParameter List\n\n\n\n\n\n\n\n\nParameter name\n\n\nmeaning\n\n\n\n\n\n\n\n\n\n\nfocusWidth\n\n\nthe focus Area width\n\n\n\n\n\n\nfocusHeight\n\n\nthe focus Area height\n\n\n\n\n\n\nareaMultiple\n\n\na Multiple for the focus area (default: 1f)\n\n\n\n\n\n\nx\n\n\nthe x position on the Screen\n\n\n\n\n\n\ny\n\n\nthe y position on the Screen\n\n\n\n\n\n\npreviewWidth\n\n\nthe width of the preview\n\n\n\n\n\n\npreviewHeight\n\n\nthe height of the preview\n\n\n\n\n\n\nweight\n\n\nthe weight of the area must be range from 1 to 1000\n\n\n\n\n\n\n\n\nFocusCallback interface\n\n\nThe FocusCallback interface has three abstract functions\n\n\nonSuccess()\nonSuccess(Rect rect, Boolean focusLock)\nonFailure()\n\n\n\n\nImplementation Example\n\n\npublic class MainActifity extens Actifity implements FocusCallback {\n  private GestureDetector gestureDetector;\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    streamLib = new nanoStream(new nanoStreamSettings());\n    if(streamLib.isFocusSupported()) {\n      gestureDetector = new GestureDetector(this, new GestureListener());\n    }\n    ...\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (gestureDetector != null)\n    {\n        gestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n  ....\n  private class GestureListener implements OnGestureListener {\n\n     @Override\n     public boolean onSingleTapUp(MotionEvent e)\n     {\n         if (streamLib != null)\n         {\n             streamLib.setFocusArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n         }\n         return true;\n     }\n\n    @Override\n     public void onLongPress(MotionEvent e)\n     {\n         if (streamLib != null)\n         {\n             streamLib.setFocusLockArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n         }\n     }\n   }\n\n   @Override\n    public void onSuccess(Rect rect, Boolean aBoolean) {\n      Log.i(TAG, \nfocus success\n);\n    }\n\n    @Override\n    public void onFailure() {\n      Log.i(TAG, \nfocus failed\n);\n    }\n}\n\n\n\n\nDevicesProperties\n\n\nBefore Android 4.3 there was no obligation for Android hardware manufacturers to pass the video related parts of the CTS (Compatibility Test Suite).\nTherefore some Android 4.1 and 4.2 Devices show non standard behaviour in regard to color format definitions and representation of video frames in memory.\nThis could lead to issues in the video stream like switched red and blue colors, dislocated color components or a green bar at the bottom of the video frame.\nnanoStream Android now provides the functionality to detect and compensate common issues related to this.\n\n\nDescription\n\n\nnanoStream.getDeviceProperties() is a static function that is running a test on the device hardware to detect non standard behaviour and returning a DeviceProperties object containing the result.\nDeviceProperties.getFlags() is returning the test result as an integer value that can be stored in the application preferences, to avoid running the device test on every app start.\nThe DeviceProperties can be applied to a new nanoStream instance by calling nanoStream.setDeviceProperties(DeviceProperties).\nWe recommend to call getDeviceProperties() in a background thread during the first app start on a pre 4.3 device, because the call is blocking and might last up to 5 seconds on older/weaker devices.\nWe also recommend to store the OS version in the preferences, to be able to detect OS updates and to eventually rerun the device test or stop setting the DeviceProperties if the new OS is 4.3 or higher.\n\n\nImplementation Example\n\n\npublic class App extends Application\n{\n    private static DeviceProperties deviceProp = null;\n\n    public void onCreate()\n    {\n        super.onCreate();\n\n        Thread chkThread = new Thread(new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                try\n                {\n                    SharedPreferences prefs = PreferenceManager.getDefaultSharedPreferences(getApplicationContext());\n                    int curApiVer = android.os.Build.VERSION.SDK_INT;\n                    int curAppVer = getPackageManager().getPackageInfo(getPackageName(), 0).versionCode;\n                    int curEncVer = DeviceProperties.VERSION;\n\n                    int oldApiVer = prefs.getInt(\nPref_Android_API\n, 0);\n                    int oldAppVer = prefs.getInt(\nPref_App_Version\n, 0);\n                    int oldChkVer = prefs.getInt(\nPref_Check_Version\n, 0);\n                    int oldChkResult = prefs.getInt(\nPref_Check_Result\n, -1);\n\n                    if (((oldApiVer * oldAppVer * oldApiVer) == 0)\n                    || (oldApiVer \n curApiVer)\n                    || (oldAppVer \n curAppVer)\n                    || (oldChkVer \n curEncVer)\n                    || oldChkResult \n 0)\n                    {\n\n                        Editor edit = prefs.edit();\n                        edit.putInt(\nPref_Android_API\n, curApiVer);\n                        edit.putInt(\nPref_App_Version\n, curAppVer);\n\n                        /* Run  device check */\n                        try\n                        {\n                            deviceProp = nanoStream.getDeviceProperties();\n\n                            edit.putInt(\nPref_Check_Result\n, deviceProp.getFlags());\n                            edit.putInt(\nPref_Check_Version\n, deviceProp.getVersion());\n                            edit.commit();\n                        }\n                        catch (RuntimeException e)\n                        {\n                            Log.d(\nDevice Check failed\n, e.toString());\n                            edit.putInt(\nPref_Check_Result\n, -1);\n                            edit.putInt(\nPref_Check_Version\n, 0);\n                            edit.commit();\n                        }\n\n                    }\n                    else\n                    {\n                        deviceProp = new DeviceProperties(oldChkResult);\n                    }\n\n                    Log.d(\nDevice Properties: \n, deviceProp.toString());\n                }\n                catch (Exception e)\n                {\n                    Log.d(this.getClass().getName(), \nDevice Check Runnable\n);\n                    e.printStackTrace();\n                }\n            }\n        });\n\n        if (android.os.Build.VERSION.SDK_INT \n 18)\n        {\n            chkThread.start();\n        }\n\n        ...\n    }\n\n    public static DeviceProperties getDeviceProperties()\n    {\n        return deviceProp;\n    }\n}\n\n\n\n\npublic class MainActivity extends Activity implements NanostreamEventListener\n{\n    ...\n    @Override\n    protected void onCreate(Bundle savedInstanceState)\n    {\n        try\n        {\n            nanoStreamSettings nss = new nanoStreamSettings();\n\n            streamLib = new nanoStream(nss);\n\n            DeviceProperties deviceProperties = App.getDeviceProperties();\n\n            if(null != streamLib \n null != deviceProperties)\n            {\n                streamLib.setDeviceProperties(deviceProperties);\n            }\n        }\n        catch(NanostreamException en)\n        {\n            Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n        }\n    }\n    ...\n}\n}\n\n\n\n\nFurther questions?\n\n\nWould you like a feature not available yet?\n\n\nWe can make it work for you based on our consulting and development / implementation services. \nContact us\n\n\nCrash Logs\n\n\nIf you encounter a crash, please send us the crash log as explained in the following steps:\n\n\n\n\nPlug in the device and open Android Studio\n\n\nIn Android Studios Android Monitor\n\n\nClear the logcat output\n\n\nSet the Log Level to \nVerbose\n\n\nSet the filter to \nNo Filters\n\n\n\n\n\n\nRun the critical section\n\n\nMark the entire logcat output\n\n\nRight click in the logcat View and \nCopy as Plain Text\n\n\nOpen an editor of your choice\n\n\nPaste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Streaming Developer Manual"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#nanostream_sdk_android_streaming_developer_manual", 
            "text": "", 
            "title": "nanoStream SDK Android: Streaming Developer Manual"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#introduction", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#purpose", 
            "text": "This documentation is about the nanoStream Live Video Streaming SDK for Android and can be used by software developers to integrate nanoStream Live Video Encoding into custom apps.", 
            "title": "Purpose"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#requirements", 
            "text": "Android 4.1+ (API Level 16)", 
            "title": "Requirements"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#required_permissions", 
            "text": "The nanoStream SDK for android does not request any permissions by itself.\nHowever, it needs a few permissions to work.  The needed permissions are :  android.permission.INTERNET - This is needed since the stream should be sent over a network.  android.permission.RECORD_AUDIO - In case your stream is not video-only the app needs this permission to record audio data using the microphone.  android.permission.RECORD_VIDEO - In case your stream is not audio-only the app needs this permission to record image data using the camera.  android.permission.WRITE_EXTERNAL_STORAGE - In case the encoded stream should be written on the phone s memory.  How these permissions should be requested depends on the used version of android.  On devices with android versions prior to Android 6.0 the permissions are getting requested once per app installation. They just need to be configured within the AndroidManifest.xml file, so that the user can give the permission while installing the app.  On devices with android versions from 6.0 upwards the permissions should be requested at run time when needed. It can be checked whether a permission is already granted or not. Afterwards, the needed permissions can be requested. This will create a pop-up, which asks the user to grant the needed permissions. If you are working with our BinutStreamer-Sample, an example of this can be found in the CheckAppPermission-Class.", 
            "title": "Required permissions:"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#getting_started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#copy_the_sdk_libraries_into_your_android_studio_project", 
            "text": "Add the  net.nanocosmos.nanoStream.jar  java component to your Android Studio project by copying  [SDK]/libs/net.nanocosmos.nanoStream.jar  to the folder  [projectpath]/app/libs/net.nanocosmos.nanoStream.jar  Add the  nanoStream.so  native components to the Android Studio project by copying the 5 folders  [SDK]/libs/[platform]/libRTMPStream.so  to [projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so`  Platforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips", 
            "title": "Copy the SDK libraries into your Android Studio project"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#add_the_nanostream_to_the_gradle_file", 
            "text": "Open the build.gradle file (Module:app) and add  compile files('libs/net.nanocosmos.nanoStream.jar')  to the dependencies section.", 
            "title": "Add the nanoStream to the gradle file"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#check_library_version", 
            "text": "String nanoStreamVersion = nanoStream.getVersion().fullVersion;", 
            "title": "Check library version"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#initialize_the_library", 
            "text": "Implement the interface  nanoStreamEventListener  in your class:  public class StreamActivity extends Activity implements NanostreamEventListener {\n  // implement your class\n\n  private class NotificationRunable implements Runnable {\n     private NanostreamEvent m_event;\n\n     public NotificationRunable(NanostreamEvent event) {\n      m_event = event;\n     }\n\n     @Override\n     public void run() {\n       Toast.makeText(getApplicationContext(), m_event.GetDescription(), Toast.LENGTH_SHORT).show();\n     }\n   }\n\n  @Override\n  public void onNanostreamEvent(NanostreamEvent event) {\n    if (event.GetType() != NanostreamEvent.TYPE_RTMP_QUALITY) {\n      this.runOnUiThread(new NotificationRunable(event));\n    }\n  }\n}  Configure the nanoStreamSettings object for the library:    private String license =  --- add your nanoStream license here --- ;\n  private String serverUrl =  rtmp://example.org/live ;\n  private String streamName =  myStream ;\n  private nanoStream streamLib = null;\n\n  void initStreamLib() {\n    if(null == streamLib) {\n      nanoStreamSettings nss = new nanoStreamSettings();\n      nss.setLicense(license);\n      nss.setLogSettings(logSettings);\n      nss.setStreamUrl(serverUrl);\n      nss.setStreamName(streamName);\n      nss.setEventListener(this);\n\n      try {\n        streamLib = new nanoStream(nss);\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      }\n\n      if(null != streamLib) {\n        try {\n          streamLib.init();\n        } catch (NanostreamException e) {\n          Toast.makeText(getApplicationContext(), e.toString(), Toast.LENGTH_LONG).show();\n        } catch (IllegalArgumentException e) {\n          e.printStackTrace();\n        }\n      }\n    }\n  }  Start/Stop the Stream:  public void toggleStreaming(View clicked) {\n  if (null == streamLib) {\n    Toast.makeText(getApplicationContext(),  nanoStream failed to initialize , Toast.LENGTH_LONG).show();\n    return;\n  }\n\n  if (!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n    Toast.makeText(getApplicationContext(),  Starting... , Toast.LENGTH_SHORT).show();\n\n    if (streamLib.hasState(nanoStream.EncoderState.STOPPED) || streamLib.hasState(nanoStream.EncoderState.CREATED)) {\n      try {\n        Logging.log(Logging.LogLevel.DEBUG, TAG,  toggleStreaming init nanoStream );\n        streamLib.init();\n      } catch (NanostreamException en) {\n        Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n        return;\n      }\n    }\n\n    try {\n      streamLib.start();\n    } catch (NanostreamException en) {\n      Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n      return;\n    }\n  } else {\n    Toast.makeText(getApplicationContext(),  Stopping... , Toast.LENGTH_SHORT).show();\n    streamLib.stop();\n  }\n}", 
            "title": "Initialize the library"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#resolution_aspect_ratio_and_orientation", 
            "text": "", 
            "title": "Resolution, Aspect Ratio and Orientation"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#resolution", 
            "text": "Resolution means the native resolution of the camera (input). In the most situations this will be the same for the output. To set the resolution there is a function in the VideoSettings object called setResolution(Resolution res). If you set a resolution that the device doesn t support, nanoStream will automatically switch to the nearest resolution available on the device. A list of supported resolutions for the current video source can be obtained from getCapabilities().listAvailableVideoResolutions() on the nanoStream object.", 
            "title": "Resolution"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#aspect_ratio", 
            "text": "Aspect ratio means the aspect ratio of the outgoing stream. The aspect ratio determines if the input video needs to be cropped. The aspect ratio can be set through the setAspectRatio(AspectRatio aspectRatio) function on the VideoSettings object.", 
            "title": "Aspect ratio"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#supported_aspect_ratios", 
            "text": "Aspect Ratio  AspectRatio value      Keep Input  AspectRatio.RATIOKEEPINPUT    1:1  AspectRatio.RATIO11    4:3  AspectRatio.RATIO43    16:9  AspectRatio.RATIO169    3:4  AspectRatio.RATIO34    9:16  AspectRatio.RATIO_9_16", 
            "title": "Supported Aspect ratios"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#orientation", 
            "text": "The default stream orientation is landscape. If you switch to portrait the resolution will swap width and height, e.g. from 640\u00d7480 to 480\u00d7640. You can set the stream orientation on the nanoStream object with the setStreamRotation function. The stream orientation needs to be set before starting the stream, it is not possible to switch the orientation during the", 
            "title": "Orientation"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#supported_orientations", 
            "text": "Orientation  Rotation Value      Landscape  Rotation.ROTATION_0    Portrait  Rotation.ROTATION_90    Landscape Upside Down  Rotation.ROTATION_180    Portrait Upside Down  Rotation.ROTATION_270", 
            "title": "Supported Orientations"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#example_combinations_of_aspect_ratios_and_orientations", 
            "text": "The input resolution is set to 640x480 here. The red rectangle marks up the active area that is included in the output stream.     Orientation  Aspect Ratio  Stream Area      Portrait 1  Keep Input     Portrait 1  4:3     Portrait 1  3:4     Portrait 1  16:9     Portrait 1  9:16     Landscape  Keep Input     Landscape  4:3     Landscape  3:4     Landscape  16:9     Landscape  9:16      1 : In this sample APP we crop the preview so it doesn t look ugly, so the stream is actually larger then the preview.", 
            "title": "Example Combinations of Aspect Ratios and Orientations"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#example", 
            "text": "If you want to stream with a resolution of 640x360 but your device doesn t supports this resolution, you need to crop the resolution from 640x480 (this resolution is supported by the most devices) to 640x360. This can be done through the aspect ratio, so you need to set the aspect ratio to 16:9 to stream with a resolution of 640x360.", 
            "title": "Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example", 
            "text": "public class MainActifity {\n    ...\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n      super.onCreate(savedInstanceState);\n      nanoStreamSettings nss = new nanoStreamSettings();\n      VideoSettings vs = new VideoSettings();\n      ...\n      vs.setResolution(new Resolution(640, 480)); // default value\n      vs.setAspectRatio(AspectRatio.RATIO_16_9); // default value is AspectRatio.KEEP_INPUT\n      ...\n      streamLib = new nanoStream(nss);\n      streaLib.init();\n\n      streamLib.setStreamRotation(Rotation.ROTATION_0); // default value\n      ...\n    }\n    ...\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#rotationhelper_class", 
            "text": "", 
            "title": "RotationHelper Class"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#description", 
            "text": "With the nanoStream SDK 4.3.1 release we added a  RotationHelper  Class, this Class improves the Rotation handling.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#rotationhelper", 
            "text": "The RotationHelper class has two static Methods,  getDeviceDefaultOrientation(Context context)  and  getRotation(int orientation, boolean isDefaultOrientationLandscape) .", 
            "title": "RotationHelper"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#getdevicedefaultorientation", 
            "text": "The return values are one of the following   Configuration.ORIENTATION_LANDSCAPE    Configuration.ORIENTATION_PORTRAIT", 
            "title": "getDeviceDefaultOrientation"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#getrotation", 
            "text": "", 
            "title": "getRotation"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#parameter", 
            "text": "The  orientation  parameter of the  getRoation  Method is one of the following:   ActivityInfo.SCREEN_ORIENTATION_PORTRAIT    ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE    ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT    ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE  The  isDefaultOrientationLandscape  parameter is true or false.", 
            "title": "Parameter"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#return_values", 
            "text": "The return values given from  RotationHelper.getRoation  can be used as a Parameter for  setStreamRotation  and  setPreviewRotation . is the  orientation  parameter non of the above described the  getRotation  Method returns  null .", 
            "title": "Return values"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_1", 
            "text": "import net.nanocosmos.nanoStream.streamer.Rotation;\nimport net.nanocosmos.nanoStream.streamer.RotationHelper;\n\npublic class MainActivity extends Activity {\n  // ...\n  private boolean isDefaultOrientationLandscape = false;\n  private CustomOrientationEventListener orientation = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    // ...\n    streamLib = new nanoStream(/*settings*/);\n\n    isDefaultOrientationLandscape = (RotationHelper.getDeviceDefaultOrientation(this) == android.content.res.Configuration.ORIENTATION_LANDSCAPE);\n    orientation = new CustomOrientationEventListener(this, SensorManager.SENSOR_DELAY_UI);\n    orientation.enable();\n  }\n\n  private class CustomOrientationEventListener extends OrientationEventListener {\n    private int lastScreenOrientation = 0;\n    public CustomOrientationEventListener(Context context, int rate) {\n      super(context, rate);\n    }\n\n    @Override\n    public void onOrientationChanged(int orientation) {\n      if (null != streamLib) {\n        if(!streamLib.hasState(nanoStream.EncoderState.RUNNING)) {\n          if (isDefaultOrientationLandscape) {\n              orientation -= 90;\n\n              if (orientation   0) {\n                  orientation += 360;\n              }\n          }\n          int screenOrientation = -1;\n\n          if (orientation   70   orientation   110) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE;\n          } else if (orientation   160   orientation   200) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT;\n          } else if (orientation   250   orientation   290) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE;\n          } else if ((orientation   340   orientation  = 360) || (orientation  = 0   orientation   20)) {\n            setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);\n            screenOrientation = ActivityInfo.SCREEN_ORIENTATION_PORTRAIT;\n          }\n\n          if (screenOrientation != lastScreenOrientation) {\n            Rotation rotation = RotationHelper.getRotation(screenOrientation, isDefaultOrientationLandscape);\n            if (null != rotation) {\n              try {\n                streamLib.setPreviewRotation(rotation);\n                streamLib.setStreamRotation(rotation);\n                streamLib.setAspectRatio(videoAspectRatio);\n              } catch (IllegalStateException e) {\n                Logging.log(Logging.LogLevel.ERROR, TAG,  Camera rotate failed , e);\n              }\n            }\n            lastScreenOrientation = screenOrientation;\n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#stream_type", 
            "text": "The SDK supports differnet streaming modes:   Video and Audio  Video only  Audio only   You can en/disable Video/Audio in the  nanoStreamSettings .", 
            "title": "Stream Type"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_2", 
            "text": "nanoStreamSettings nss = new nanoStreamSettings();\nnss.setHaveVideo(true); // false\nnss.setHaveAudio(true); // false", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#server_authentication", 
            "text": "In case authentication is required, the credentials can be set on the  nanoStreamSettings  object.", 
            "title": "Server Authentication"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_3", 
            "text": "nanoStreamSettings nss = new nanoStreamSettings();\nnss.setAuthUser( user );\nnss.setAuthPassword( password );", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#android_mp4_recording", 
            "text": "", 
            "title": "Android MP4 Recording"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#description_1", 
            "text": "The nanoStream Android SDK supports, MP4 recording to do this there needs to be set a valid Path to the nanoStreamSettings object. And the MP4 Recording needs to be enabled. This feature allows you to record the current stream to the Device internal/external sd card.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#enable_mp4_recording", 
            "text": "To enable the MP4 recording there are tow functions in the nanoStreamSettings Class.   setRecordMp4(boolean)  setMp4Path(String)", 
            "title": "Enable MP4 recording"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#setrecordmp4boolean", 
            "text": "The setRecordMp4 function takes a boolean as parameter, this is to enable/disable the recording function.", 
            "title": "setRecordMp4(boolean)"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#setmp4pathstring", 
            "text": "The setMp4Path function takes a String as parameter, this string needs to be a valid file path (e.g. /sdcard/test.mp4). Much better is to use the getExternalStoragePublicDirectory from the  Environment  Android API, and add a file name to this directory Path.", 
            "title": "setMp4Path(String)"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#android_permission", 
            "text": "To write to an external File Path your Android App needs the following permission (Add this to your AndroidMainfest.xml).  uses-permission android:name= android.permission.WRITE_EXTERNAL_STORAGE  /  uses-permission android:name= android.permission.STORAGE  /", 
            "title": "Android permission"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#android_60", 
            "text": "Due to the new Permission handling it is possible that you can t write in external Directorys if the user isn t granted this permission, you can always write in your own data directory (/Android/data/com.companyname.appname/)", 
            "title": "Android 6.0"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_4", 
            "text": "File externalFilePath = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM);\nFile filePath = new File(externalFilePath,  myMp4File.mp4 );\nString mp4FilePath = filePath.getAbsolutePath();\n\nnanoStreamSettings nss = new nanoStreamSettings();\nnss.setRecordMp4(true);\nnss.setMp4Path(mp4FilePath);", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#snapshot", 
            "text": "To get a snapshot (image) of the current preview/stream, the method  takeSnapshot  can be used. This is a non blocking function, for the result you need to implement the SnapshotCallback interface. The snapshot returns as a base64 encoded JPEG", 
            "title": "Snapshot"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_5", 
            "text": "private class CustomSnapshotCallback implements SnapshotCallback {\n  @Override\n  void onSuccess(String arg0){\n    // do something with the base64 encoded JPEG.\n  }\n\n  @Override\n void onFailure(){\n   Log.d(TAG,  takeSnapshot() failed! )\n }\n}\nprivate void shapshot() {\n  streamLib.takeSnapshot(new CustomSnapshotCallback());\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#adaptive_bitrate_streaming", 
            "text": "By using the Adaptive Bitrate Control (ABC) the stream will automatically adjust to changes of the bandwidth. There are four modes available:   DISABLED: The Adaptive Bitrate Control is disabled.  QUALITY_DEGRADE: The video quality will be changed if the bandwidth changes. For instance, if not enough bandwidth is available, the video bitrate will be decreased, which in turn degrades the video quality.  FRAME_DROP: Low bandwidth is compensated by decreasing the framerate (FPS), but maintaining the video qualtiy.  QUALITY_DEGRADE_AND_FRAME_DROP: The video quality and the framerate (FPS) decreased if the not enough bandwidth is available.   Make sure to set the ABC settings before a stream is started.", 
            "title": "Adaptive Bitrate Streaming"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_6", 
            "text": "private AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode abcMode = AdaptiveBitrateControlSettings.AdaptiveBitrateControlMode.QUALITY_DEGRADE_AND_FRAME_DROP;\nprivate int videoBitrate = 500000;\n\nprivate void initStreamLib() {\n  AdaptiveBitrateControlSettings abcSettings = new AdaptiveBitrateControlSettings(abcMode);\n  abcSettings.SetMaximumBitrate((int)(videoBitrate * 1.5));\n\n  nanoStreamSettings nss = new nanoStreamSettings();\n  nss.setAbcSettings(abcSettings);\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#measuring_the_available_bandwidth", 
            "text": "For measuring the available bandwidth you can use the method  runBandwidthCheck . After the check finished, the result can be used to set the bitrate for the nanoStream object.\nThe check measures the bandwidth by running a test stream to the server.\nThe BandwidthCheck Class has three public functions:   runBandwidthCheck(BandwidthCheckSettings settings, BandwidthCheckResultCallback callback()  forceStop()  abort()   There is a BandwidthCheckSettings Class, the constructor creates a standard object of BandwidthCheckSettings, with the following settings:     property  default values  meaning      prerollSeconds  1 (in sec.)  this is the pre roll time to connect to the server    runTime  5 (in sec.)  the run time of the bandwidth check    maxBitrate  3000000 (bit/s = 3 MBit/s)  the maximum bit rate for the bandwidth check    rtmpUrl  empty  the rtmp url for the bandwidth check    streamId  empty  the stream id for the bandwidth check     With this settings you can call the runBandwidthCheck methode, the second parameter is the callback for the results. This callback class has a finished method that will be called after bandwidth check is done.\nThe finished method has one parameter from type BandwidthCheckResult, this object has 6 getter methods:   getAverageBitrate() // the average measured bandwidth  getMedianBitrate() // the median measured bandwidth  getMaxBitrate() // the maximum measured bandwidth  getMinBitrate() // the minimum measured bandwidth  getRunTimeMS() // the run time in ms  getErrorCode() // the error code if all is ok this is nanoResults.N_OK (all error codes can be found in the nanoStream API Reference documentation for nanoResults)   The forceStop call stops the bandwidth check and will return the results that where measured until then. The abort call stops the bandwidth check but don t return any results.  The bandwidth check, sends a special type of metadata that will not be recorded on the Streaming Server.", 
            "title": "Measuring the available bandwidth"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_7", 
            "text": "private BandwidthCheck bwCheck = null;\n\nprivate class CustomBandwidthCheckResultCallback implements BandwidthCheckResultCallback {\n  @Override\n  public void finished(final BandwidthCheckResult bandwidthCheckResult) {\n    Log.d(TAG,  BandwidthCheck results:   +\n       \\n\\tAverage Bitrate (kBit/s):   + bandwidthCheckResult.getAverageBitrate() / 1000 +\n       \\n\\tMedian Bitrate  (kBit/s):   + bandwidthCheckResult.getMedianBitrate() / 1000 +\n       \\n\\tMax Bitrate     (kBit/s):   + bandwidthCheckResult.getMaxBitrate() / 1000 +\n       \\n\\tMin Bitrate     (kBit/s):   + bandwidthCheckResult.getMinBitrate() / 1000 +\n       \\n\\tRun Time        (ms)    :   + bandwidthCheckResult.getRunTimeMS());\n  }\n}\n\nprivate void initBandwidthCheck() {\n  if(null == bwCheck) {\n    BandwidthCheckSettings settings = new BandwidthCheckSettings();\n    settings.setRtmpUrl(serverUrl);\n    settings.setStreamId(streamName);\n    bwCheck = new BandwidthCheck();\n    bwCheck.runBandwidthCheck(settings, new CustomBandwidthCheckResultCallback());\n  }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#rtmp_quality_statistics", 
            "text": "", 
            "title": "RTMP Quality Statistics"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#description_2", 
            "text": "The RTMP Module provides the current RTMP Quality over the  NanostreamEventListener . These includes the  output bit rate ,  buffer fullness ,  bit rate  and  frame rate .", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_8", 
            "text": "public class MainActivity extends Activity implements NanostreamEventListener {\n  private LinearLayout qualityView = null;\n    private TextView outputBitrate = null;\n    private TextView bufferFullness = null;\n    private TextView bitrate = null;\n    private TextView framerate = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    qualityView = (LinearLayout) findViewById(R.id.qualityView);\n        outputBitrate = (TextView) findViewById(R.id.outputBitrateText);\n        bufferFullness = (TextView) findViewById(R.id.bufferfillnessText);\n        bitrate = (TextView) findViewById(R.id.bitrateText);\n        framerate = (TextView) findViewById(R.id.framerateText);\n\n    // Init nanoStream\n  }\n\n  @Override\n    public void onNanostreamEvent(NanostreamEvent event)\n    {\n        if (event.GetType() == NanostreamEvent.TYPE_RTMP_QUALITY)\n        {\n            this.runOnUiThread(new ViewQualityRunnable(event));\n        }\n    }\n\n  private class ViewQualityRunnable implements Runnable\n    {\n        private NanostreamEvent m_event;\n        private DecimalFormat format;\n\n        public ViewQualityRunnable(NanostreamEvent m_event)\n        {\n            super();\n            this.m_event = m_event;\n            format = new DecimalFormat( #0.00 );\n        }\n\n        @Override\n        public void run()\n        {\n            if (qualityView.getAlpha() == 0   m_event.GetParam1() != 0   m_event.GetParam2() != 0   m_event.GetParam3() != 0   m_event.GetParam4() != 0)\n            {\n                qualityView.setAlpha(0.5f);\n            }\n            int qualityColor = Color.YELLOW;\n            if (m_event.GetParam2()  = 1000)\n            {\n                qualityColor = Color.rgb(255, 0, 0);\n            } else if (m_event.GetParam2()  = 750)\n            {\n                qualityColor = Color.YELLOW;\n            } else if (m_event.GetParam2()  = 750)\n            {\n                qualityColor = Color.GREEN;\n            }\n\n            outputBitrate.setText(Long.toString(m_event.GetParam1() / 1000) +  kbit/s );\n            outputBitrate.setTextColor(qualityColor);\n            bufferFullness.setText(format.format(((double) m_event.GetParam2() / 100.0)) +  % );\n            bufferFullness.setTextColor(qualityColor);\n            bitrate.setText(Long.toString(m_event.GetParam3() / 1000) +  kbit/s );\n            framerate.setText(m_event.GetParam4() +  fps );\n\n        }\n    }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#camera_zoom", 
            "text": "", 
            "title": "Camera Zoom"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#description_3", 
            "text": "The nanoStream Android SDK supports camera zoom, if the internal camera supports it. Therefor there are a few functions, the most important are:     Function  Return Type  returns      hasZoom()  boolean  true if zoom is supported by the video source/ device    getZoomRatios()  List  list with of ale zoom ratios    getZoom()  int  the index of the List  that returned from getZoomRatios()    setZoom(int)  int  the new index of the List  that returned from getZoomRatios()     It is recommended to use pinch to zoom, therefor you need to implement a ScaleGestureDetector.SimpleOnScaleGestureListener, and a pinch2zoom function, that takes the scalefactor from the SimpleOnScaleGestureListener as a int parameter, take a look at the  Implementation Example .", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#getzoomratios", 
            "text": "getZoomRatios() returns a List of Integer values, this values are the zoom ratios in 1/100 increments (e.g. a zoom of 3.2x is returned as 320).", 
            "title": "getZoomRatios()"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#setzoomint", 
            "text": "The int parameter from setZoom(int zoom) is the index of zoom ratios that returns getZoomRatios().", 
            "title": "setZoom(int)"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#zoom_behavior_on_camera_switch", 
            "text": "During a camera switch (e.g. from back to front) the zoom remains unaffected.", 
            "title": "Zoom Behavior on Camera Switch"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#camera_focus", 
            "text": "", 
            "title": "Camera Focus"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#description_4", 
            "text": "The nanoStream Android SDK supports Camera focus and focus lock, if the the internal cameras supports them. There are two nonblocking functions  setFocusArea(int focusWidth, int focusHeight, float areaMultiple, int x, int y, int previewWidth, int previewHeight, int weigh)\nsetFocusLockArea(int focusWidth, int focusHeight, float areaMultiple, int x, int y, int previewWidth, int previewHeight, int weigh)  through the  addFocusCalback(FocusCallback callback)\nremoveFocusCalback(FocusCallback callback)  you can attach or remove a FocusCallback listener.\nTo check if your device Supports focus you can call  isFocusSupported()  this will return true or false", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#parameter_list", 
            "text": "Parameter name  meaning      focusWidth  the focus Area width    focusHeight  the focus Area height    areaMultiple  a Multiple for the focus area (default: 1f)    x  the x position on the Screen    y  the y position on the Screen    previewWidth  the width of the preview    previewHeight  the height of the preview    weight  the weight of the area must be range from 1 to 1000", 
            "title": "Parameter List"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#focuscallback_interface", 
            "text": "The FocusCallback interface has three abstract functions  onSuccess()\nonSuccess(Rect rect, Boolean focusLock)\nonFailure()", 
            "title": "FocusCallback interface"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_10", 
            "text": "public class MainActifity extens Actifity implements FocusCallback {\n  private GestureDetector gestureDetector;\n  private nanoStream streamLib = null;\n\n  @Override\n  protected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    streamLib = new nanoStream(new nanoStreamSettings());\n    if(streamLib.isFocusSupported()) {\n      gestureDetector = new GestureDetector(this, new GestureListener());\n    }\n    ...\n  }\n\n  @Override\n  public boolean onTouchEvent(MotionEvent event)\n  {\n    if (gestureDetector != null)\n    {\n        gestureDetector.onTouchEvent(event);\n    }\n    return true;\n  }\n  ....\n  private class GestureListener implements OnGestureListener {\n\n     @Override\n     public boolean onSingleTapUp(MotionEvent e)\n     {\n         if (streamLib != null)\n         {\n             streamLib.setFocusArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n         }\n         return true;\n     }\n\n    @Override\n     public void onLongPress(MotionEvent e)\n     {\n         if (streamLib != null)\n         {\n             streamLib.setFocusLockArea(300, 300, 1f, (int) e.getX(), (int) e.getY(), surface.getWidth(), surface.getHeight(), 1000);\n         }\n     }\n   }\n\n   @Override\n    public void onSuccess(Rect rect, Boolean aBoolean) {\n      Log.i(TAG,  focus success );\n    }\n\n    @Override\n    public void onFailure() {\n      Log.i(TAG,  focus failed );\n    }\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#devicesproperties", 
            "text": "Before Android 4.3 there was no obligation for Android hardware manufacturers to pass the video related parts of the CTS (Compatibility Test Suite).\nTherefore some Android 4.1 and 4.2 Devices show non standard behaviour in regard to color format definitions and representation of video frames in memory.\nThis could lead to issues in the video stream like switched red and blue colors, dislocated color components or a green bar at the bottom of the video frame.\nnanoStream Android now provides the functionality to detect and compensate common issues related to this.", 
            "title": "DevicesProperties"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#description_5", 
            "text": "nanoStream.getDeviceProperties() is a static function that is running a test on the device hardware to detect non standard behaviour and returning a DeviceProperties object containing the result.\nDeviceProperties.getFlags() is returning the test result as an integer value that can be stored in the application preferences, to avoid running the device test on every app start.\nThe DeviceProperties can be applied to a new nanoStream instance by calling nanoStream.setDeviceProperties(DeviceProperties).\nWe recommend to call getDeviceProperties() in a background thread during the first app start on a pre 4.3 device, because the call is blocking and might last up to 5 seconds on older/weaker devices.\nWe also recommend to store the OS version in the preferences, to be able to detect OS updates and to eventually rerun the device test or stop setting the DeviceProperties if the new OS is 4.3 or higher.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#implementation_example_11", 
            "text": "public class App extends Application\n{\n    private static DeviceProperties deviceProp = null;\n\n    public void onCreate()\n    {\n        super.onCreate();\n\n        Thread chkThread = new Thread(new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                try\n                {\n                    SharedPreferences prefs = PreferenceManager.getDefaultSharedPreferences(getApplicationContext());\n                    int curApiVer = android.os.Build.VERSION.SDK_INT;\n                    int curAppVer = getPackageManager().getPackageInfo(getPackageName(), 0).versionCode;\n                    int curEncVer = DeviceProperties.VERSION;\n\n                    int oldApiVer = prefs.getInt( Pref_Android_API , 0);\n                    int oldAppVer = prefs.getInt( Pref_App_Version , 0);\n                    int oldChkVer = prefs.getInt( Pref_Check_Version , 0);\n                    int oldChkResult = prefs.getInt( Pref_Check_Result , -1);\n\n                    if (((oldApiVer * oldAppVer * oldApiVer) == 0)\n                    || (oldApiVer   curApiVer)\n                    || (oldAppVer   curAppVer)\n                    || (oldChkVer   curEncVer)\n                    || oldChkResult   0)\n                    {\n\n                        Editor edit = prefs.edit();\n                        edit.putInt( Pref_Android_API , curApiVer);\n                        edit.putInt( Pref_App_Version , curAppVer);\n\n                        /* Run  device check */\n                        try\n                        {\n                            deviceProp = nanoStream.getDeviceProperties();\n\n                            edit.putInt( Pref_Check_Result , deviceProp.getFlags());\n                            edit.putInt( Pref_Check_Version , deviceProp.getVersion());\n                            edit.commit();\n                        }\n                        catch (RuntimeException e)\n                        {\n                            Log.d( Device Check failed , e.toString());\n                            edit.putInt( Pref_Check_Result , -1);\n                            edit.putInt( Pref_Check_Version , 0);\n                            edit.commit();\n                        }\n\n                    }\n                    else\n                    {\n                        deviceProp = new DeviceProperties(oldChkResult);\n                    }\n\n                    Log.d( Device Properties:  , deviceProp.toString());\n                }\n                catch (Exception e)\n                {\n                    Log.d(this.getClass().getName(),  Device Check Runnable );\n                    e.printStackTrace();\n                }\n            }\n        });\n\n        if (android.os.Build.VERSION.SDK_INT   18)\n        {\n            chkThread.start();\n        }\n\n        ...\n    }\n\n    public static DeviceProperties getDeviceProperties()\n    {\n        return deviceProp;\n    }\n}  public class MainActivity extends Activity implements NanostreamEventListener\n{\n    ...\n    @Override\n    protected void onCreate(Bundle savedInstanceState)\n    {\n        try\n        {\n            nanoStreamSettings nss = new nanoStreamSettings();\n\n            streamLib = new nanoStream(nss);\n\n            DeviceProperties deviceProperties = App.getDeviceProperties();\n\n            if(null != streamLib   null != deviceProperties)\n            {\n                streamLib.setDeviceProperties(deviceProperties);\n            }\n        }\n        catch(NanostreamException en)\n        {\n            Toast.makeText(getApplicationContext(), en.toString(), Toast.LENGTH_LONG).show();\n        }\n    }\n    ...\n}\n}", 
            "title": "Implementation Example"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#further_questions", 
            "text": "Would you like a feature not available yet?  We can make it work for you based on our consulting and development / implementation services.  Contact us", 
            "title": "Further questions?"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_streaming/#crash_logs", 
            "text": "If you encounter a crash, please send us the crash log as explained in the following steps:   Plug in the device and open Android Studio  In Android Studios Android Monitor  Clear the logcat output  Set the Log Level to  Verbose  Set the filter to  No Filters    Run the critical section  Mark the entire logcat output  Right click in the logcat View and  Copy as Plain Text  Open an editor of your choice  Paste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Crash Logs"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/", 
            "text": "nanoStream SDK Android: Playback Developer Manual\n\n\nIntroduction\n\n\nDescription \n\n\nRTMP Playback Component enables application developers to add playback of RTMP live and on demand streams to their apps.\n\n\nSupported codecs are H.264 Video, AAC and MP3 Audio.\n\n\nVideo streams are decoded and rendered on a Surface that is hold by the application, usually connected to a \nSurfaceView\n.\n\n\nAudio streams are decoded and rendered to system audio using the Android AudioSession/AudioTrack API.\n\n\nThe interface and usage are similar to the Android MediaPlayer. The Android MediaPlayerControl interface is implemented to enable control through an \nandroid.widget.MediaController\n instance.\n\n\nRequirements\n\n\nRelated nanoStream SDK Version: 4.1\n\n\nMinimum supported Android OS/API: 4.1/API 16\n\n\nRequired application permissions:\n\n\n\n\nandroid.permission.INTERNET\n\n\nandroid.permission.RECORD_AUDIO\n\n\nandroid.permission.RECORD_VIDEO\n\n\nandroid.permission.MODIFY_AUDIO_SETTINGS\n\n\n\n\nLicense\n\n\nThe playback component requires a special feature flag to be enabled in your nanoStream license key. It not necessarily included in nanoStream Android SDK licenses.\n\n\nInterface \n\n\nPackage name\n\n\nnet.nanocosmos.nanoStream.streamer\n\n\nDeclaration\n\n\npublic abstract class NanostreamPlayer implements MediaPlayercontrol, Surfaceholder.Callback\n\n\nFunction Life Cycle\n\n\n\n\n\n\n\n\nInstance Handling\n\n\nInitialization\n\n\nCapabilities\n\n\nQueries\n\n\nPlayback Control\n\n\nSupported by RTMP Player\n\n\n\n\n\n\n\n\n\n\ncreateNanostreamPlayer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsetSettings\n\n\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\nsetPlayerEventListener\n\n\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanPrepare\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanPrepareAsync\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanPause\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanSeekBackward\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncanSeekForward\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\ngetState\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\nisPlaying\n\n\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\ngetCurrentPosition\n\n\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\ngetDuration\n\n\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprepare\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprepareAsync\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstart\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npause\n\n\nyes  \n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nseekTo\n\n\nyes    \n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstop\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstart\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstop\n\n\nyes\n\n\n\n\n\n\n\n\nclose\n\n\n\n\n\n\n\n\nno\n\n\n\n\n\n\n\n\nrelease\n\n\n\n\n\n\n\n\nyes\n\n\n\n\n\n\n\n\nCreating an Instance\n\n\nNanostreamPlayer\n instances can be created through the static factory function \ncreateNanostreamPlayer\n at the top level \nnanoStream class\n. NanostreamPlayer is designed to support multiple player instances. The number of parallel instances can be limited by system resources such as codec,surfaces,memory, network connections and bandwidth.\n\n\nConfiguration and Settings\n\n\nInitial player settings are wrapped by the \nNanostreamPlayer.PlayerSettings\n class. The settings can be applied by calling \nNanostreamPlayer.setSettings\n.\n\n\nPlayerSettings:\n\n\n\n\n\n\n\n\nSetting\n\n\nFunctions\n\n\nDescription\n\n\nType\n\n\nDefault Values\n\n\n\n\n\n\n\n\n\n\nLicense\n\n\ngetLicense/setLicense\n\n\nnanoStream license key\n\n\nString\n\n\nempty\n\n\n\n\n\n\nUrl\n\n\ngetUrl/setUrl\n\n\nRTMP url\n\n\nString\n\n\nempty\n\n\n\n\n\n\nStream Name\n\n\ngetStreamname/setStreamname\n\n\nRTMP stream name\n\n\nString\n\n\nempty\n\n\n\n\n\n\nUser Name\n\n\ngetUsername/setUsername\n\n\nUser name if RTMP authentication is required\n\n\nString\n\n\nempty\n\n\n\n\n\n\nPassword\n\n\ngetPassword/setPassword Password if RTMP authentication is required\n\n\nString\n\n\nempty\n\n\n\n\n\n\n\n\nBuffer Time\n\n\ngetBufferTimeMs/setBufferTimeMs\n\n\nLength of the stream buffer in milliseconds\n\n\nInteger\n\n\n2000ms/2s\n\n\n\n\n\n\nFrame Dropping Mode\n\n\ngetFrameDroppingMode/setFrameDroppingMode\n\n\nConfiguration of the dropping mode regarding different droppable frame types\n\n\nFrameDroppingMode\n\n\nDROP_NO_FRAMES\n\n\n\n\n\n\nStream Playback\n\n\ngetVideoPlayback/getAudioPlayback/setStreamPlayback\n\n\nEnable stream types to be decoded and played\n\n\nboolean\n\n\nvideo:true, audio:true\n\n\n\n\n\n\nTrackTimout\n\n\ngetTrackTimeout/setTrackTimeout\n\n\nTimeout to waiting for Track info\n\n\nlong\n\n\n10000\n\n\n\n\n\n\nEndlessMode\n\n\ngetEndlessMode/setEndlessMode\n\n\nReopen the stream until stop call\n\n\nboolean\n\n\nfalse\n\n\n\n\n\n\n\n\nPlayer State\n\n\nThe player stat can be queried through the \ngetState()\n function\n\n\n/**\n*\n* The different states of the player instance.\n*\n*/\npublic enum PlayerState\n{\n    IDLE, INITIALIZED, PREPARED, STARTED, PAUSED, SEEKING, BUFFERING, RECONNECTING, PLAYBACKCOMPLETED, STOPPING, STOPPED;\n}\n\n\n\n\n\n\n\n\n\n\nState\n\n\nDescription\n\n\nSupported by RTMP Player\n\n\n\n\n\n\n\n\n\n\nPlayerState.IDLE\n\n\nInitial state. Player has not yet been initialized or has been closed.\n\n\nyes\n\n\n\n\n\n\nPlayerState.INITIALIZED\n\n\nPlayer has been initialized with license and settings.\n\n\nyes\n\n\n\n\n\n\nPlayerState.PREPARED\n\n\nPlayer has been prepared and is ready to start.\n\n\nno\n\n\n\n\n\n\nPlayerState.STARTED\n\n\nPlayback has been started.\n\n\nyes\n\n\n\n\n\n\nPlayerState.PAUSED\n\n\nPlayback has been paused.\n\n\nyes   \n2\n\n\n\n\n\n\nPlayerState.SEEKING\n\n\nPlayer is Seeking\n\n\nyes       \n1\n\n\n\n\n\n\nPlayerState.BUFFERING\n\n\nPlayer is buffering stream data.\n\n\nyes\n\n\n\n\n\n\nPlayerState.RECONNECTING\n\n\nPlayer is performing a reconnect\n\n\nno\n\n\n\n\n\n\nPlayerState.PLAYBACKCOMPLETED\n\n\nPlayback has ended due to end of stream.\n\n\nyes\n\n\n\n\n\n\nPlayerState.STOPPING\n\n\nPlayer is stopping\n\n\nyes\n\n\n\n\n\n\nPlayerState.STOPPED\n\n\nPlayer is stopped\n\n\nyes\n\n\n\n\n\n\n\n\nEvent Notification\n\n\nEvent notifications can be received through the \nNanostreamPlayer.PlayerEventListener\n interface. Derive your listener from this interface and add it to the player by calling \nsetPlayerEventListener()\n.\n\n\nStatus Events\n\n\nEvent Type : \nTYPE_RTMP_STATUS\n\n\n\n\n\n\n\n\nEvent Code\n\n\nDescription\n\n\nCorresponding State\n\n\n\n\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_STARTED\n\n\nPlayback has been started.\n\n\nPlayerState.STARTED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_STOPPING\n\n\nPlayback will stop.\n\n\nPlayerState.STOPPING\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_STOPPED\n\n\nPlayback has been stopped.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_ERROR_CONNECT\n\n\nThe connect to the stream url failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_BUFFERING\n\n\nPlayer is buffering stream data\n\n\nPlayerState.BUFFERING\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_PLAYBACKCOMPLETED\n\n\nPlayback has ended due to end of stream.\n\n\nPlayerState.PLAYBACKCOMPLETED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_NOT_FOUND\n\n\nThe specified stream could not be found.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_SEEKING    \n1\n\n\nThe Stream is seeking.\n\n\nPlayerState.SEEKING\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_PAUSED   \n2\n\n\nThe Stream is paused\n\n\nPlayerState.PAUSED\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_VIDEO_FORMAT_AVAILABLE  \n1\n\n\nThe Stream has a MediaFormat for the Video Track\n\n\n\n\n\n\n\n\nNanostreamEvent.CODE_STREAM_AUDIO_FORMAT_AVAILABLE  \n1\n\n\nThe Stream has a MediaFormat for the Audio Track\n\n\n\n\n\n\n\n\n\n\nResults and Error Events\n\n\nEvent Type : \nTYPENANORESULTS\n Event Codes : Values of type nanoResults\n\n\n\n\n\n\n\n\nEvent Code\n\n\nDescription\n\n\nCorresponding State\n\n\n\n\n\n\n\n\n\n\nnanoResults.N_NOT_INITIALIZED\n\n\nThe RTMP library has not been initialized properly.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_ALLOCATEDATA_FAILED_RTMP_SRC\n\n\nMemory allocation failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_LICENSE_INVALID\n\n\nLicense check failed - License invalid.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_LICENSE_INVALID_RTMP_SRC\n\n\nLicense check failed - RTMP playback is not included.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_LICENSE_EXPIRED\n\n\nLicense check failed - The license period has ended.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_TCP_CONNECT_FAILED\n\n\nTCP connect failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_HANDSHAKE_FAILED\n\n\nRTMP handshake failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_CONNECT_FAILED\n\n\nRTMP connect failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_AUTH_FAILED\n\n\nRTMP authentication is required and failed.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_APP_INVALID\n\n\nThe application part of the url is invalid and has been rejected.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_STATUS_PLAY_STREAM_NOT_FOUND\n\n\nThe stream name could not be found.\n\n\nPlayerState.STOPPED\n\n\n\n\n\n\nnanoResults.N_RTMP_STATUS_PLAY_STREAM_SEEK    \n1\n\n\nThe player is seeking.\n\n\nPlayerState.SEEKING\n\n\n\n\n\n\nnanoResults.N_RTMP_SEEK_NOT_AVAILABLE  \n1\n\n\nThe stream can not seek.\n\n\n\n\n\n\n\n\nnanoResults.N_RTMP_SEEK_FAILED   \n1\n\n\nThe stream can not seek.\n\n\n\n\n\n\n\n\n\n\nAudio / Video Format\n\n\nAfter the \nNanostreamEvent.CODE_STREAM_AUDIO/VIDEO_FORMAT_AVAILABLE\n event, you can get the MediaFormat Object with the \ngetAudio/VideoFormat()\n1\n function call.\n\n\nWe added two custom Fields for the Video MediaFormat:\n\n\n\n\nNanostreamPlayer.KEY_ASPECT_RATIO_WIDTH\n\n\nNanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT\n\n\n\n\nWith these custom fields you can get the aspect ratio width and height.\n\n\nMediaFormat videoFormat = mPlayer.getVideoFormat();\n\nint aspectRatioWidth = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_WIDTH);\nint aspectRatioHeight = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT);\n\n\n\n\nImplementation Example \n\n\npublic class PlayerActivity extends Activity implements PlayerEventListener, SurfaceHolder.Callback {\n    ...\n    private NanostreamPlayer mPlayer = null;\n    private String license = \nYOUR LICENSE CODE\n;\n\n    private String strStreamUrl = \nrtmp://192.168.1.100/vod\n;\n    private String strStreamname = \nmp4:file.mp4\n;\n\n    private LinearLayout root;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        root = new LinearLayout(this);\n        root.setOrientation(LinearLayout.VERTICAL);\n        root.setLayoutParams(containerParams);\n        root.setBackgroundColor(Color.BLACK);\n\n        ...\n\n        mPlayer = nanoStream.createNanostreamPlayer();\n\n        PlayerSettings settings = mPlayer.new PlayerSettings();\n\n        settings.setLicense(license);\n        settings.setUrl(strStreamUrl);\n        settings.setStreamname(strStreamname);\n        settings.setAuthUsername(\n);\n        settings.setAuthPassword(\n);\n        settings.setBufferTimeMs(2000);\n\n        mPlayer.setSettings(settings);\n        mPlayer.setPlayerEventListener(this);\n\n        ...\n        // we need a surface Callback for the application\n        LinearLayout.LayoutParams surfaceParams = new LinearLayout.LayoutParams(ViewGroup.LayoutParams.FILL_PARENT, ViewGroup.LayoutParams.FILL_PARENT, 0.5F);\n        surfaceParams.gravity = Gravity.CENTER;\n        surfaceParams.weight = 0.5f;\n\n        SurfaceView surfaceView = new SurfaceView(this);\n        surfaceView.setLayoutParams(surfaceParams);\n        surfaceView.getHolder.addCallback(this);\n\n        root.addView(surfaceView);\n        setContentView(root);\n    }\n\n    ...\n\n    @Override\n    public void onPlayerEvent(NanostreamEvent event, NanostreamPlayer instance) {\n        final String msg = event.GetDescription();\n        Log.d(this.getClass().getName(), event.GetDescription());\n    }\n\n    @Override\n    public void surfaceCreated(SurfaceHolder holder) {\n        mPlayer.surfaceCreated(holder);\n\n        try {\n            if (!mPlayer.getState().equals(PlayerState.STARTED)) {\n                mPlayer.start();\n            }\n        } catch (IllegalStateException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {\n        mPlayer.surfaceChanged(holder, format, width, height);\n    }\n\n    @Override\n    public void surfaceDestroyed(SurfaceHolder holder) {\n        mPlayer.surfaceDestroyed(holder);\n    }\n}\n\n\n\n\n1\n: since nanoStream Android SDK 3.2\n\n2\n: since nanoStream Android SDK 3.3\n\n\nFurther questions?\n\n\nWould you like a feature not available yet?\n\n\nWe can make it work for you based on our consulting and development / implementation services. \nContact us\n\n\nCrash Logs\n\n\nIf you encounter a crash, please send us the crash log as explained in the following steps:\n\n\n\n\nPlug in the device and open Android Studio\n\n\nIn Android Studios Android Monitor\n\n\nClear the logcat output\n\n\nSet the Log Level to \nVerbose\n\n\nSet the filter to \nNo Filters\n\n\n\n\n\n\nRun the critical section\n\n\nMark the entire logcat output\n\n\nRight click in the logcat View and \nCopy as Plain Text\n\n\nOpen an editor of your choice\n\n\nPaste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Playback Developer Manual"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#nanostream_sdk_android_playback_developer_manual", 
            "text": "", 
            "title": "nanoStream SDK Android: Playback Developer Manual"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#introduction", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#description", 
            "text": "RTMP Playback Component enables application developers to add playback of RTMP live and on demand streams to their apps.  Supported codecs are H.264 Video, AAC and MP3 Audio.  Video streams are decoded and rendered on a Surface that is hold by the application, usually connected to a  SurfaceView .  Audio streams are decoded and rendered to system audio using the Android AudioSession/AudioTrack API.  The interface and usage are similar to the Android MediaPlayer. The Android MediaPlayerControl interface is implemented to enable control through an  android.widget.MediaController  instance.", 
            "title": "Description "
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#requirements", 
            "text": "Related nanoStream SDK Version: 4.1  Minimum supported Android OS/API: 4.1/API 16  Required application permissions:   android.permission.INTERNET  android.permission.RECORD_AUDIO  android.permission.RECORD_VIDEO  android.permission.MODIFY_AUDIO_SETTINGS", 
            "title": "Requirements"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#license", 
            "text": "The playback component requires a special feature flag to be enabled in your nanoStream license key. It not necessarily included in nanoStream Android SDK licenses.", 
            "title": "License"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#interface", 
            "text": "", 
            "title": "Interface "
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#package_name", 
            "text": "net.nanocosmos.nanoStream.streamer", 
            "title": "Package name"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#declaration", 
            "text": "public abstract class NanostreamPlayer implements MediaPlayercontrol, Surfaceholder.Callback", 
            "title": "Declaration"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#function_life_cycle", 
            "text": "Instance Handling  Initialization  Capabilities  Queries  Playback Control  Supported by RTMP Player      createNanostreamPlayer          setSettings     yes     setPlayerEventListener     yes      canPrepare    yes      canPrepareAsync    yes      canPause    yes      canSeekBackward    yes      canSeekForward    yes       getState   yes       isPlaying   yes       getCurrentPosition   no       getDuration   no        prepare  no        prepareAsync  no        start  yes        pause  yes   2        seekTo  yes     1        stop  yes        start  yes        stop  yes     close     no     release     yes", 
            "title": "Function Life Cycle"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#creating_an_instance", 
            "text": "NanostreamPlayer  instances can be created through the static factory function  createNanostreamPlayer  at the top level  nanoStream class . NanostreamPlayer is designed to support multiple player instances. The number of parallel instances can be limited by system resources such as codec,surfaces,memory, network connections and bandwidth.", 
            "title": "Creating an Instance"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#configuration_and_settings", 
            "text": "Initial player settings are wrapped by the  NanostreamPlayer.PlayerSettings  class. The settings can be applied by calling  NanostreamPlayer.setSettings .", 
            "title": "Configuration and Settings"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#playersettings", 
            "text": "Setting  Functions  Description  Type  Default Values      License  getLicense/setLicense  nanoStream license key  String  empty    Url  getUrl/setUrl  RTMP url  String  empty    Stream Name  getStreamname/setStreamname  RTMP stream name  String  empty    User Name  getUsername/setUsername  User name if RTMP authentication is required  String  empty    Password  getPassword/setPassword Password if RTMP authentication is required  String  empty     Buffer Time  getBufferTimeMs/setBufferTimeMs  Length of the stream buffer in milliseconds  Integer  2000ms/2s    Frame Dropping Mode  getFrameDroppingMode/setFrameDroppingMode  Configuration of the dropping mode regarding different droppable frame types  FrameDroppingMode  DROP_NO_FRAMES    Stream Playback  getVideoPlayback/getAudioPlayback/setStreamPlayback  Enable stream types to be decoded and played  boolean  video:true, audio:true    TrackTimout  getTrackTimeout/setTrackTimeout  Timeout to waiting for Track info  long  10000    EndlessMode  getEndlessMode/setEndlessMode  Reopen the stream until stop call  boolean  false", 
            "title": "PlayerSettings:"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#player_state", 
            "text": "The player stat can be queried through the  getState()  function  /**\n*\n* The different states of the player instance.\n*\n*/\npublic enum PlayerState\n{\n    IDLE, INITIALIZED, PREPARED, STARTED, PAUSED, SEEKING, BUFFERING, RECONNECTING, PLAYBACKCOMPLETED, STOPPING, STOPPED;\n}     State  Description  Supported by RTMP Player      PlayerState.IDLE  Initial state. Player has not yet been initialized or has been closed.  yes    PlayerState.INITIALIZED  Player has been initialized with license and settings.  yes    PlayerState.PREPARED  Player has been prepared and is ready to start.  no    PlayerState.STARTED  Playback has been started.  yes    PlayerState.PAUSED  Playback has been paused.  yes    2    PlayerState.SEEKING  Player is Seeking  yes        1    PlayerState.BUFFERING  Player is buffering stream data.  yes    PlayerState.RECONNECTING  Player is performing a reconnect  no    PlayerState.PLAYBACKCOMPLETED  Playback has ended due to end of stream.  yes    PlayerState.STOPPING  Player is stopping  yes    PlayerState.STOPPED  Player is stopped  yes", 
            "title": "Player State"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#event_notification", 
            "text": "Event notifications can be received through the  NanostreamPlayer.PlayerEventListener  interface. Derive your listener from this interface and add it to the player by calling  setPlayerEventListener() .", 
            "title": "Event Notification"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#status_events", 
            "text": "Event Type :  TYPE_RTMP_STATUS     Event Code  Description  Corresponding State      NanostreamEvent.CODE_STREAM_STARTED  Playback has been started.  PlayerState.STARTED    NanostreamEvent.CODE_STREAM_STOPPING  Playback will stop.  PlayerState.STOPPING    NanostreamEvent.CODE_STREAM_STOPPED  Playback has been stopped.  PlayerState.STOPPED    NanostreamEvent.CODE_STREAM_ERROR_CONNECT  The connect to the stream url failed.  PlayerState.STOPPED    NanostreamEvent.CODE_STREAM_BUFFERING  Player is buffering stream data  PlayerState.BUFFERING    NanostreamEvent.CODE_STREAM_PLAYBACKCOMPLETED  Playback has ended due to end of stream.  PlayerState.PLAYBACKCOMPLETED    NanostreamEvent.CODE_STREAM_NOT_FOUND  The specified stream could not be found.  PlayerState.STOPPED    NanostreamEvent.CODE_STREAM_SEEKING     1  The Stream is seeking.  PlayerState.SEEKING    NanostreamEvent.CODE_STREAM_PAUSED    2  The Stream is paused  PlayerState.PAUSED    NanostreamEvent.CODE_STREAM_VIDEO_FORMAT_AVAILABLE   1  The Stream has a MediaFormat for the Video Track     NanostreamEvent.CODE_STREAM_AUDIO_FORMAT_AVAILABLE   1  The Stream has a MediaFormat for the Audio Track", 
            "title": "Status Events"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#results_and_error_events", 
            "text": "Event Type :  TYPENANORESULTS  Event Codes : Values of type nanoResults     Event Code  Description  Corresponding State      nanoResults.N_NOT_INITIALIZED  The RTMP library has not been initialized properly.  PlayerState.STOPPED    nanoResults.N_ALLOCATEDATA_FAILED_RTMP_SRC  Memory allocation failed.  PlayerState.STOPPED    nanoResults.N_LICENSE_INVALID  License check failed - License invalid.  PlayerState.STOPPED    nanoResults.N_LICENSE_INVALID_RTMP_SRC  License check failed - RTMP playback is not included.  PlayerState.STOPPED    nanoResults.N_LICENSE_EXPIRED  License check failed - The license period has ended.  PlayerState.STOPPED    nanoResults.N_TCP_CONNECT_FAILED  TCP connect failed.  PlayerState.STOPPED    nanoResults.N_RTMP_HANDSHAKE_FAILED  RTMP handshake failed.  PlayerState.STOPPED    nanoResults.N_RTMP_CONNECT_FAILED  RTMP connect failed.  PlayerState.STOPPED    nanoResults.N_RTMP_AUTH_FAILED  RTMP authentication is required and failed.  PlayerState.STOPPED    nanoResults.N_RTMP_APP_INVALID  The application part of the url is invalid and has been rejected.  PlayerState.STOPPED    nanoResults.N_RTMP_STATUS_PLAY_STREAM_NOT_FOUND  The stream name could not be found.  PlayerState.STOPPED    nanoResults.N_RTMP_STATUS_PLAY_STREAM_SEEK     1  The player is seeking.  PlayerState.SEEKING    nanoResults.N_RTMP_SEEK_NOT_AVAILABLE   1  The stream can not seek.     nanoResults.N_RTMP_SEEK_FAILED    1  The stream can not seek.", 
            "title": "Results and Error Events"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#audio_video_format", 
            "text": "After the  NanostreamEvent.CODE_STREAM_AUDIO/VIDEO_FORMAT_AVAILABLE  event, you can get the MediaFormat Object with the  getAudio/VideoFormat() 1  function call.  We added two custom Fields for the Video MediaFormat:   NanostreamPlayer.KEY_ASPECT_RATIO_WIDTH  NanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT   With these custom fields you can get the aspect ratio width and height.  MediaFormat videoFormat = mPlayer.getVideoFormat();\n\nint aspectRatioWidth = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_WIDTH);\nint aspectRatioHeight = videoFormat.getInteger(NanostreamPlayer.KEY_ASPECT_RATIO_HEIGHT);", 
            "title": "Audio / Video Format"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#implementation_example", 
            "text": "public class PlayerActivity extends Activity implements PlayerEventListener, SurfaceHolder.Callback {\n    ...\n    private NanostreamPlayer mPlayer = null;\n    private String license =  YOUR LICENSE CODE ;\n\n    private String strStreamUrl =  rtmp://192.168.1.100/vod ;\n    private String strStreamname =  mp4:file.mp4 ;\n\n    private LinearLayout root;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        root = new LinearLayout(this);\n        root.setOrientation(LinearLayout.VERTICAL);\n        root.setLayoutParams(containerParams);\n        root.setBackgroundColor(Color.BLACK);\n\n        ...\n\n        mPlayer = nanoStream.createNanostreamPlayer();\n\n        PlayerSettings settings = mPlayer.new PlayerSettings();\n\n        settings.setLicense(license);\n        settings.setUrl(strStreamUrl);\n        settings.setStreamname(strStreamname);\n        settings.setAuthUsername( );\n        settings.setAuthPassword( );\n        settings.setBufferTimeMs(2000);\n\n        mPlayer.setSettings(settings);\n        mPlayer.setPlayerEventListener(this);\n\n        ...\n        // we need a surface Callback for the application\n        LinearLayout.LayoutParams surfaceParams = new LinearLayout.LayoutParams(ViewGroup.LayoutParams.FILL_PARENT, ViewGroup.LayoutParams.FILL_PARENT, 0.5F);\n        surfaceParams.gravity = Gravity.CENTER;\n        surfaceParams.weight = 0.5f;\n\n        SurfaceView surfaceView = new SurfaceView(this);\n        surfaceView.setLayoutParams(surfaceParams);\n        surfaceView.getHolder.addCallback(this);\n\n        root.addView(surfaceView);\n        setContentView(root);\n    }\n\n    ...\n\n    @Override\n    public void onPlayerEvent(NanostreamEvent event, NanostreamPlayer instance) {\n        final String msg = event.GetDescription();\n        Log.d(this.getClass().getName(), event.GetDescription());\n    }\n\n    @Override\n    public void surfaceCreated(SurfaceHolder holder) {\n        mPlayer.surfaceCreated(holder);\n\n        try {\n            if (!mPlayer.getState().equals(PlayerState.STARTED)) {\n                mPlayer.start();\n            }\n        } catch (IllegalStateException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {\n        mPlayer.surfaceChanged(holder, format, width, height);\n    }\n\n    @Override\n    public void surfaceDestroyed(SurfaceHolder holder) {\n        mPlayer.surfaceDestroyed(holder);\n    }\n}  1 : since nanoStream Android SDK 3.2 2 : since nanoStream Android SDK 3.3", 
            "title": "Implementation Example "
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#further_questions", 
            "text": "Would you like a feature not available yet?  We can make it work for you based on our consulting and development / implementation services.  Contact us", 
            "title": "Further questions?"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_playback/#crash_logs", 
            "text": "If you encounter a crash, please send us the crash log as explained in the following steps:   Plug in the device and open Android Studio  In Android Studios Android Monitor  Clear the logcat output  Set the Log Level to  Verbose  Set the filter to  No Filters    Run the critical section  Mark the entire logcat output  Right click in the logcat View and  Copy as Plain Text  Open an editor of your choice  Paste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Crash Logs"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/", 
            "text": "nanoStream SDK Android: Sample Developer Manual\n\n\nThe \nnanoStream SDK\n contains libraries for developing streaming apps for Android devices or for incorporating streaming capabilities in your existing Android applications.\n\n\nThree samples are\u00a0included\u00a0to show\u00a0the basic usage of the nanoStream SDK (Android-BasicStreamer, Android-StreamerSample and Android-Player). \u00a0You will need to download and install the latest version of Android Studio. Visit the \nDownload Page\n\u00a0of Nanocosmos to download\u00a0a trial version of\u00a0the nanoStream SDK\u00a0(version 4.3.0 supports \u00a0Android API-Level from 16 up to 23). Contact Nanocosmos for obtaining a licence longer than the trial period.\n\n\nAndroid-BasicStreamer\n: this sample contains a single java file that starts and stops a stream.\u00a0How-to\u00a0start running the sample.\n\n\nAndroid-StreamerSample\n: this sample contains a single java file that starts and stops a stream and includes options for adjusting the quality of the stream.\n\n\nAndroid-Player\n: this sample contains a single java file that starts and stops playing a stream from a remote source.\n\n\n\n\n\n\nnanoStream SDK: Streamer Sample\n\n\nnanoStream Live Video Encoder and Player for Android\n(c) 2015 nanocosmos gmbh, \nhttp://www.nanocosmos.de\n\n\nDescription\n\n\nThis sample shows the basic usage of the nanoStream Android SDK for streaming apps.\n\n\nUsage\n\n\nStep 1: Unzip the sample project to the desired project path\n\n\nStep 2: Copy the SDK libraries into the Android Studio project\n\n\nBefore runnig the sample, six libraries have to copied from the SDK library folder:\nAdd the \nnet.nanocosmos.nanoStream.jar\n java component to the Android Studio project by copying \n[SDK]/libs/net.nanocosmos.nanoStream.jar\n to the folder\n[projectpath]/app/libs/net.nanocosmos.nanoStream.jar\n\n\nAdd the nanoStream.so native components to the Android Studio project by copying the 5 folders \n[SDK]/libs/[platform]/libRTMPStream.so\n to\n\n[projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so\n\n\nPlatforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips\n\n\nStep 3: Open the MainActivity.java in the Android Studio Code Editor\n\nThe MainActivity contains the main application code. The location is:\n[projectpath]/app/src/main/java/net/nanocosmos/nanoStream/demo/basicstreamer\n\n\nYour window should look like this:\n\n\n\n\n\n\nStep 4: Enter your license in the MainActivity\n\n\nJust replace the placeholder with your license key.\n\n\n// TODO: REPLACE WITH YOUR LICENSE\nprivate String license = \n--- ADD YOUR LICENSE HERE ---\n;\n\n\n\n\nStep 5: Enter your stream configuration in the MainActivity\n\n\nReplace the server url and the stream name with yours.\nThe server url usually has this pattern : \n[Protocol]://[Adresse]/[Application]\n.\nWith the stream name your streaming server identifies each stream.\n\n\n// TODO: REPLACE THE RTMP URL AND STREAM NAME\nprivate static final String strStreamUrl = \n--- INSERT THE STREAMING SERVER URL ---\n;\nprivate static final String strStreamname = \n--- INSERT THE STREAM NAME OR FILE NAME ---\n;\n\n\n\n\n\n\nStep 6: Connect an Android device, build and run the application\n\n\nAbout\n\n\nVersion\n : nanoStream SDK 4.3.0\n\n\nCompatible with\n : Android API-Level from 16 up to 23\n\n\nnanoStream SDK: Player Sample\n\n\nnanoStream Live Video Encoder and Player for Android\n(c) 2015 nanocosmos gmbh, \nhttp://www.nanocosmos.de\n\n\nDescription\n\n\nThis sample shows the basic usage of the nanoStream Android SDK for player apps.\n\n\nUsage\n\n\nStep 1: Unzip the sample project to the desired project path\n\n\nStep 2: Copy the SDK libraries into the Android Studio project\n\n\nBefore runnig the sample, six libraries have to copied from the SDK library folder:\nAdd the \nnet.nanocosmos.nanoStream.jar\n java component to the Android Studio project by copying \n[SDK]/libs/net.nanocosmos.nanoStream.jar\n to the folder\n[projectpath]/app/libs/net.nanocosmos.nanoStream.jar\n\n\nAdd the nanoStream.so native components to the Android Studio project by copying the 5 folders \n[SDK]/libs/[platform]/libRTMPStream.so\n to\n\n[projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so\n\n\nPlatforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips\n\n\nStep 3: Open the PlayerActivity.java in the Android Studio Code Editor\n\nThe PlayerActivity contains the main application code. The location is:\n[projectpath]/app/src/main/java/net/nanocosmos/nanoStream/demo/player\n\n\nYour window should look like this:\n\n\n\n\nStep 4: Enter your license in the PlayerActivity\n\n\nJust replace the placeholder with your license key.\n\n\n// TODO: REPLACE WITH YOUR LICENSE\nprivate String license = \n--- ADD YOUR LICENSE HERE ---\n;\n\n\n\n\n\n\nStep 5: Enter your stream configuration in the MainActivity\n\n\nReplace the server url and the stream name with yours.\nThe server url usually has this pattern : \n[Protocol]://[Adresse]/[Application]\n.\nWith the stream name your streaming server identifies each stream.\n\n\n// TODO: REPLACE THE RTMP URL AND STREAM NAME\nprivate static final String strStreamUrl = \n--- INSERT THE STREAMING SERVER URL ---\n;\nprivate static final String strStreamname = \n--- INSERT THE STREAM NAME OR FILE NAME ---\n;\n\n\n\n\n\n\nStep 6: Connect an Android device, build and run the application\n\n\nAbout\n\n\nVersion\n : nanoStream SDK 4.3.0\n\n\nCompatible with\n : Android API-Level from 16 up to 23\n\n\n\n\nFurther questions?\n\n\nWould you like a feature not available yet?\n\n\nWe can make it work for you based on our consulting and development / implementation services. \nContact us\n\n\nCrash Logs\n\n\nIf you encounter a crash, please send us the crash log as explained in the following steps:\n\n\n\n\nPlug in the device and open Android Studio\n\n\nIn Android Studios Android Monitor\n\n\nClear the logcat output\n\n\nSet the Log Level to \nVerbose\n\n\nSet the filter to \nNo Filters\n\n\n\n\n\n\nRun the critical section\n\n\nMark the entire logcat output\n\n\nRight click in the logcat View and \nCopy as Plain Text\n\n\nOpen an editor of your choice\n\n\nPaste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Sample Developer Manual"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#nanostream_sdk_android_sample_developer_manual", 
            "text": "The  nanoStream SDK  contains libraries for developing streaming apps for Android devices or for incorporating streaming capabilities in your existing Android applications.  Three samples are\u00a0included\u00a0to show\u00a0the basic usage of the nanoStream SDK (Android-BasicStreamer, Android-StreamerSample and Android-Player). \u00a0You will need to download and install the latest version of Android Studio. Visit the  Download Page \u00a0of Nanocosmos to download\u00a0a trial version of\u00a0the nanoStream SDK\u00a0(version 4.3.0 supports \u00a0Android API-Level from 16 up to 23). Contact Nanocosmos for obtaining a licence longer than the trial period.  Android-BasicStreamer : this sample contains a single java file that starts and stops a stream.\u00a0How-to\u00a0start running the sample.  Android-StreamerSample : this sample contains a single java file that starts and stops a stream and includes options for adjusting the quality of the stream.  Android-Player : this sample contains a single java file that starts and stops playing a stream from a remote source.", 
            "title": "nanoStream SDK Android: Sample Developer Manual"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#nanostream_sdk_streamer_sample", 
            "text": "nanoStream Live Video Encoder and Player for Android\n(c) 2015 nanocosmos gmbh,  http://www.nanocosmos.de", 
            "title": "nanoStream SDK: Streamer Sample"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#description", 
            "text": "This sample shows the basic usage of the nanoStream Android SDK for streaming apps.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#usage", 
            "text": "Step 1: Unzip the sample project to the desired project path  Step 2: Copy the SDK libraries into the Android Studio project  Before runnig the sample, six libraries have to copied from the SDK library folder:\nAdd the  net.nanocosmos.nanoStream.jar  java component to the Android Studio project by copying  [SDK]/libs/net.nanocosmos.nanoStream.jar  to the folder [projectpath]/app/libs/net.nanocosmos.nanoStream.jar  Add the nanoStream.so native components to the Android Studio project by copying the 5 folders  [SDK]/libs/[platform]/libRTMPStream.so  to [projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so  Platforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips  Step 3: Open the MainActivity.java in the Android Studio Code Editor \nThe MainActivity contains the main application code. The location is:\n[projectpath]/app/src/main/java/net/nanocosmos/nanoStream/demo/basicstreamer  Your window should look like this:    Step 4: Enter your license in the MainActivity  Just replace the placeholder with your license key.  // TODO: REPLACE WITH YOUR LICENSE\nprivate String license =  --- ADD YOUR LICENSE HERE --- ;  Step 5: Enter your stream configuration in the MainActivity  Replace the server url and the stream name with yours.\nThe server url usually has this pattern :  [Protocol]://[Adresse]/[Application] .\nWith the stream name your streaming server identifies each stream.  // TODO: REPLACE THE RTMP URL AND STREAM NAME\nprivate static final String strStreamUrl =  --- INSERT THE STREAMING SERVER URL --- ;\nprivate static final String strStreamname =  --- INSERT THE STREAM NAME OR FILE NAME --- ;   Step 6: Connect an Android device, build and run the application", 
            "title": "Usage"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#about", 
            "text": "Version  : nanoStream SDK 4.3.0  Compatible with  : Android API-Level from 16 up to 23", 
            "title": "About"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#nanostream_sdk_player_sample", 
            "text": "nanoStream Live Video Encoder and Player for Android\n(c) 2015 nanocosmos gmbh,  http://www.nanocosmos.de", 
            "title": "nanoStream SDK: Player Sample"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#description_1", 
            "text": "This sample shows the basic usage of the nanoStream Android SDK for player apps.", 
            "title": "Description"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#usage_1", 
            "text": "Step 1: Unzip the sample project to the desired project path  Step 2: Copy the SDK libraries into the Android Studio project  Before runnig the sample, six libraries have to copied from the SDK library folder:\nAdd the  net.nanocosmos.nanoStream.jar  java component to the Android Studio project by copying  [SDK]/libs/net.nanocosmos.nanoStream.jar  to the folder [projectpath]/app/libs/net.nanocosmos.nanoStream.jar  Add the nanoStream.so native components to the Android Studio project by copying the 5 folders  [SDK]/libs/[platform]/libRTMPStream.so  to [projectpath]/app/src/main/jniLibs/[platform]/libRTMPStream.so  Platforms are armeabi, armeabi-v7a, arm64-v8a, x86, mips  Step 3: Open the PlayerActivity.java in the Android Studio Code Editor \nThe PlayerActivity contains the main application code. The location is:\n[projectpath]/app/src/main/java/net/nanocosmos/nanoStream/demo/player  Your window should look like this:   Step 4: Enter your license in the PlayerActivity  Just replace the placeholder with your license key.  // TODO: REPLACE WITH YOUR LICENSE\nprivate String license =  --- ADD YOUR LICENSE HERE --- ;   Step 5: Enter your stream configuration in the MainActivity  Replace the server url and the stream name with yours.\nThe server url usually has this pattern :  [Protocol]://[Adresse]/[Application] .\nWith the stream name your streaming server identifies each stream.  // TODO: REPLACE THE RTMP URL AND STREAM NAME\nprivate static final String strStreamUrl =  --- INSERT THE STREAMING SERVER URL --- ;\nprivate static final String strStreamname =  --- INSERT THE STREAM NAME OR FILE NAME --- ;   Step 6: Connect an Android device, build and run the application", 
            "title": "Usage"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#about_1", 
            "text": "Version  : nanoStream SDK 4.3.0  Compatible with  : Android API-Level from 16 up to 23", 
            "title": "About"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#further_questions", 
            "text": "Would you like a feature not available yet?  We can make it work for you based on our consulting and development / implementation services.  Contact us", 
            "title": "Further questions?"
        }, 
        {
            "location": "/nanostream/android/android_developer_manual_sample/#crash_logs", 
            "text": "If you encounter a crash, please send us the crash log as explained in the following steps:   Plug in the device and open Android Studio  In Android Studios Android Monitor  Clear the logcat output  Set the Log Level to  Verbose  Set the filter to  No Filters    Run the critical section  Mark the entire logcat output  Right click in the logcat View and  Copy as Plain Text  Open an editor of your choice  Paste the logcat output into the editor and Save the logcat output as .txt file", 
            "title": "Crash Logs"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/", 
            "text": "Windows nanoStream SDK components\n\n\nNote: Not all modules are contained in all configurations. Please ask for availability and prices.\n\n\nLive Video Capture Active-X Control (npvidcap.ax)\n\n\nActive-X-Control compatible with Internet Explorer and other ActiveX technologies\nAPI compatible to Javascript, C/C++, NET/C#, VisualBasic, Delphi, and others\n\n\nLive Video Capture NP Plugin (np_vidcap.dll)\n\n\nPlugin for Mozilla/Netscape based browsers, Javascript interface (Firefox, Safari)\n\n\nnanocosmos H.264 video encoder (Filename: nh264enc.ax)\n\n\nDirectShow video encoder filter for encoding live video to H.264\n\n\nnanocosmos AAC audio encoder (Filename: naacenc.ax)\n\n\nDirectShow audio encoder filter for encoding live audio to AAC\n\n\nnanocosmos MP4 File Writer\n\n\nDirectShow filter for creating MP4 files with H.264 support\n\n\nnanocosmos RTMP Network Writer (Filename: nRtmpRenderer.ax)\n\n\nDirectShow filter for streaming to Wowza and Flash Media Servers\nExample URL: rtmp://localhost/live+myStream\n\n\nHD / UDP Streaming Filters\n\n\nDirectShow Streaming components for HD video streaming in Local Area Networks:\nPoint-to-Point, Broadcast, Multicast support\nExample URL: udp://localhost:1234\n\n\nWindowsMedia Encoding and Streaming\n\n\nStreaming component compatible to Microsoft WindowsMedia Video Formats:\n\n\nAdditional Extensions:\n\n\n\n\nnanocosmos Stereoscopic 3D-Video Mixer supporting Side-by-side/Interlaced/Color Anaglyph\nmodes\n\n\nVideo Resizer for resizing and deinterlacing video\n\n\nOverlay Filter for blending of, Texts, Bitmaps, Tickers, etc.\n\n\nDesktop Capture / Screen Grabber Filter for Application Streaming e.g. Games (upon request)\n\n\nRemote Control Function for Keyboard Feedback\n\n\nPlayer/Clients for DirectShow/Applications or Browser-Plugin or Flash based\n\n\nLive Video Encoder Application\nReference Application to show functionality in a simple end user program\n\n\n\n\nDirectShow Filter usage with GraphEdit / GraphStudioNext\n\n\nAll Live Video Encoder components are available as DirectShow filters and may be used within DirectShow applications.\n\n\nWe recommend using \nGraphStudio\n as a replacement for GraphEdit, as RTMP URLs may be set easily with this software.\n\n\n\n\nSetting DirectShow properties from C++\n\n\nThe H.264 parameters may be set by calling the \nInanoCodecOpts\n interface. The RTMP output path may be set by calling the \nSetFileName()\n method of the default DirectShow \nFileSinkFilter\n interface.", 
            "title": "Developer Manual"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#windows_nanostream_sdk_components", 
            "text": "Note: Not all modules are contained in all configurations. Please ask for availability and prices.", 
            "title": "Windows nanoStream SDK components"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#live_video_capture_active-x_control_npvidcapax", 
            "text": "Active-X-Control compatible with Internet Explorer and other ActiveX technologies\nAPI compatible to Javascript, C/C++, NET/C#, VisualBasic, Delphi, and others", 
            "title": "Live Video Capture Active-X Control (npvidcap.ax)"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#live_video_capture_np_plugin_np_vidcapdll", 
            "text": "Plugin for Mozilla/Netscape based browsers, Javascript interface (Firefox, Safari)", 
            "title": "Live Video Capture NP Plugin (np_vidcap.dll)"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#nanocosmos_h264_video_encoder_filename_nh264encax", 
            "text": "DirectShow video encoder filter for encoding live video to H.264", 
            "title": "nanocosmos H.264 video encoder (Filename: nh264enc.ax)"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#nanocosmos_aac_audio_encoder_filename_naacencax", 
            "text": "DirectShow audio encoder filter for encoding live audio to AAC", 
            "title": "nanocosmos AAC audio encoder (Filename: naacenc.ax)"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#nanocosmos_mp4_file_writer", 
            "text": "DirectShow filter for creating MP4 files with H.264 support", 
            "title": "nanocosmos MP4 File Writer"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#nanocosmos_rtmp_network_writer_filename_nrtmprendererax", 
            "text": "DirectShow filter for streaming to Wowza and Flash Media Servers\nExample URL: rtmp://localhost/live+myStream", 
            "title": "nanocosmos RTMP Network Writer (Filename: nRtmpRenderer.ax)"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#hd_udp_streaming_filters", 
            "text": "DirectShow Streaming components for HD video streaming in Local Area Networks:\nPoint-to-Point, Broadcast, Multicast support\nExample URL: udp://localhost:1234", 
            "title": "HD / UDP Streaming Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#windowsmedia_encoding_and_streaming", 
            "text": "Streaming component compatible to Microsoft WindowsMedia Video Formats:", 
            "title": "WindowsMedia Encoding and Streaming"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#additional_extensions", 
            "text": "nanocosmos Stereoscopic 3D-Video Mixer supporting Side-by-side/Interlaced/Color Anaglyph\nmodes  Video Resizer for resizing and deinterlacing video  Overlay Filter for blending of, Texts, Bitmaps, Tickers, etc.  Desktop Capture / Screen Grabber Filter for Application Streaming e.g. Games (upon request)  Remote Control Function for Keyboard Feedback  Player/Clients for DirectShow/Applications or Browser-Plugin or Flash based  Live Video Encoder Application\nReference Application to show functionality in a simple end user program", 
            "title": "Additional Extensions:"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#directshow_filter_usage_with_graphedit_graphstudionext", 
            "text": "All Live Video Encoder components are available as DirectShow filters and may be used within DirectShow applications.  We recommend using  GraphStudio  as a replacement for GraphEdit, as RTMP URLs may be set easily with this software.", 
            "title": "DirectShow Filter usage with GraphEdit / GraphStudioNext"
        }, 
        {
            "location": "/nanostream/windows/windows_developer_manual/#setting_directshow_properties_from_c", 
            "text": "The H.264 parameters may be set by calling the  InanoCodecOpts  interface. The RTMP output path may be set by calling the  SetFileName()  method of the default DirectShow  FileSinkFilter  interface.", 
            "title": "Setting DirectShow properties from C++"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/", 
            "text": "nanoStream Live Video Encoder - Binary Modules for Windows\n\n\nThis list covers the Windows binaries.\n\nNOTES:\n\nYou require a distribution license agreement to use any specific module for distributing it to 3rd parties\nUsually it is recommended and best practice to use our nanostream-plugins setup for redistribution\nA typical distribution license does NOT include the application files (exe)\nNot all combinations of modules will work out of the box.\n\nnanoStream Runtime Installer\n\nFor Windows and MacOS, you usually should use the \nruntime installer\n to deploy nanoStream components.\n\n\nApplications\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nLiveEnc.exe\n\n\nnanoStream Live Video Encoder (GUI)\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nLiveEncCmd.exe\n\n\nnanoStream Live Video Encoder (Command Line)\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnanoLicenseTool.exe\n\n\n\n\n\n\n\n\n\n\n\n\nPlugins\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnanoStream.ax\n\n\nnanoStream Plugin for ActiveX and Internet Explorer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnp_nanoStream.dll\n\n\nnanoStream Plugin for Mozilla\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nMPEG-2 Based DirectShow Filters\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnmpeg2enc.ax\n\n\nnanocosmos MPEG-2 Video Encoder\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnmpeg2dec.ax\n\n\nnanocosmos MPEG-2 Video Decoder\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnmpaenc.ax\n\n\nnanocosmos MPEG Audio Encoder\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnmpegsplitter.ax\n\n\nnanocosmos MPEG Splitter\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnanotswriter.ax\n\n\nnanocosmos MPEG Multiplexer for Transport Stream\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nMPEG-4/H.264 Based DirectShow Filters\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnh264enc.ax\n\n\nnanocosmos H.264 Video Encoder\n\n\nnanoATLServer.dll, libiomp5md.dll\n\n\n\n\n\n\nnh264dec.ax\n\n\nnanocosmos H.264 Video Decoder\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnaacenc.ax\n\n\nnanocosmos AAC Audio Encoder\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnaacdec.ax\n\n\nnanocosmos AAC Audio Decoder\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnmp4splitter.ax\n\n\nnanocosmos MP4 Splitter\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnmp4mux.ax\n\n\nnanocosmos MP4 Multiplexer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nStreaming DirectShow Filters\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnRTMPSource.ax\n\n\nnanocosmos RTMP Source\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnRTMPRenderer.ax\n\n\nnanocosmos RTMP Writer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnRTSPSource.ax\n\n\nnanocosmos RTSP Source\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnRTSPSink.ax\n\n\nnanocosmos RTSP Writer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnanoNetSource.ax\n\n\nnanocosmos UDP Source\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnanoNetSink.ax\n\n\nnanocosmos UDP Writer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nCapture DirectShow Filters\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnscreencap.ax\n\n\nnanocosmos Live Screen Capture\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nVoiceCaptureFilter.dll\n\n\nnanocosmos AEC Voice Capture Source\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nImage Processing DirectShow Filters\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnVideoMixer.ax\n\n\nnanocosmos Video Mixer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnVideoMixer2.ax\n\n\nnanocosmos Video Mixer 2\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnremixer3d.ax\n\n\nnanocosmos Video Remixer 3D\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnVideoOverlay.ax\n\n\nnanocosmos Video Overlay\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnresizer2.ax\n\n\nnanocosmos Video Resizer 2\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nncolconv.ax\n\n\nnanocosmos Color Space Converter\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nOther DirectShow Filters\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnanodump.ax\n\n\nnanocosmos File Dump\n\n\nnanoATLServer.dll\n\n\n\n\n\n\nnAudioVolume.ax\n\n\nnanocosmos Audio Volume\n\n\n\n\n\n\n\n\nnWavWriter.ax\n\n\nnanocosmos Wave Writer\n\n\nnanoATLServer.dll\n\n\n\n\n\n\n\n\nRelated Modules\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnMediaBridge.ax\n\n\nnanocosmos Media Bridge - \nadd support for seemless switch / live encoding / file streaming\n\n\n\n\n\n\n\n\n\n\nDependencies\n\n\nNote:\n Only the nanoATLServer.dll is mandatory. The Intel and MS files may be optional, dependent on your OS.\n\n\n\n\n\n\n\n\nModule\n\n\nDescription\n\n\nDependencies\n\n\n\n\n\n\n\n\n\n\nnanoATLServer.dll\n\n\nnanocosmos License Server\n\n\n\n\n\n\n\n\nlibiomp5md.dll\n\n\nIntel OpenMP Library\n\n\n\n\n\n\n\n\nvcomp90.dll\n\n\nMS OpenMP Library", 
            "title": "Binary Modules"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#nanostream_live_video_encoder_-_binary_modules_for_windows", 
            "text": "This list covers the Windows binaries. NOTES: \nYou require a distribution license agreement to use any specific module for distributing it to 3rd parties\nUsually it is recommended and best practice to use our nanostream-plugins setup for redistribution\nA typical distribution license does NOT include the application files (exe)\nNot all combinations of modules will work out of the box. nanoStream Runtime Installer \nFor Windows and MacOS, you usually should use the  runtime installer  to deploy nanoStream components.", 
            "title": "nanoStream Live Video Encoder - Binary Modules for Windows"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#applications", 
            "text": "Module  Description  Dependencies      LiveEnc.exe  nanoStream Live Video Encoder (GUI)  nanoATLServer.dll    LiveEncCmd.exe  nanoStream Live Video Encoder (Command Line)  nanoATLServer.dll    nanoLicenseTool.exe", 
            "title": "Applications"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#plugins", 
            "text": "Module  Description  Dependencies      nanoStream.ax  nanoStream Plugin for ActiveX and Internet Explorer  nanoATLServer.dll    np_nanoStream.dll  nanoStream Plugin for Mozilla  nanoATLServer.dll", 
            "title": "Plugins"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#mpeg-2_based_directshow_filters", 
            "text": "Module  Description  Dependencies      nmpeg2enc.ax  nanocosmos MPEG-2 Video Encoder  nanoATLServer.dll    nmpeg2dec.ax  nanocosmos MPEG-2 Video Decoder  nanoATLServer.dll    nmpaenc.ax  nanocosmos MPEG Audio Encoder  nanoATLServer.dll    nmpegsplitter.ax  nanocosmos MPEG Splitter  nanoATLServer.dll    nanotswriter.ax  nanocosmos MPEG Multiplexer for Transport Stream  nanoATLServer.dll", 
            "title": "MPEG-2 Based DirectShow Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#mpeg-4h264_based_directshow_filters", 
            "text": "Module  Description  Dependencies      nh264enc.ax  nanocosmos H.264 Video Encoder  nanoATLServer.dll, libiomp5md.dll    nh264dec.ax  nanocosmos H.264 Video Decoder  nanoATLServer.dll    naacenc.ax  nanocosmos AAC Audio Encoder  nanoATLServer.dll    naacdec.ax  nanocosmos AAC Audio Decoder  nanoATLServer.dll    nmp4splitter.ax  nanocosmos MP4 Splitter  nanoATLServer.dll    nmp4mux.ax  nanocosmos MP4 Multiplexer  nanoATLServer.dll", 
            "title": "MPEG-4/H.264 Based DirectShow Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#streaming_directshow_filters", 
            "text": "Module  Description  Dependencies      nRTMPSource.ax  nanocosmos RTMP Source  nanoATLServer.dll    nRTMPRenderer.ax  nanocosmos RTMP Writer  nanoATLServer.dll    nRTSPSource.ax  nanocosmos RTSP Source  nanoATLServer.dll    nRTSPSink.ax  nanocosmos RTSP Writer  nanoATLServer.dll    nanoNetSource.ax  nanocosmos UDP Source  nanoATLServer.dll    nanoNetSink.ax  nanocosmos UDP Writer  nanoATLServer.dll", 
            "title": "Streaming DirectShow Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#capture_directshow_filters", 
            "text": "Module  Description  Dependencies      nscreencap.ax  nanocosmos Live Screen Capture  nanoATLServer.dll    VoiceCaptureFilter.dll  nanocosmos AEC Voice Capture Source  nanoATLServer.dll", 
            "title": "Capture DirectShow Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#image_processing_directshow_filters", 
            "text": "Module  Description  Dependencies      nVideoMixer.ax  nanocosmos Video Mixer  nanoATLServer.dll    nVideoMixer2.ax  nanocosmos Video Mixer 2  nanoATLServer.dll    nremixer3d.ax  nanocosmos Video Remixer 3D  nanoATLServer.dll    nVideoOverlay.ax  nanocosmos Video Overlay  nanoATLServer.dll    nresizer2.ax  nanocosmos Video Resizer 2  nanoATLServer.dll    ncolconv.ax  nanocosmos Color Space Converter  nanoATLServer.dll", 
            "title": "Image Processing DirectShow Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#other_directshow_filters", 
            "text": "Module  Description  Dependencies      nanodump.ax  nanocosmos File Dump  nanoATLServer.dll    nAudioVolume.ax  nanocosmos Audio Volume     nWavWriter.ax  nanocosmos Wave Writer  nanoATLServer.dll", 
            "title": "Other DirectShow Filters"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#related_modules", 
            "text": "Module  Description  Dependencies      nMediaBridge.ax  nanocosmos Media Bridge -  add support for seemless switch / live encoding / file streaming", 
            "title": "Related Modules"
        }, 
        {
            "location": "/nanostream/windows/windows_binares/#dependencies", 
            "text": "Note:  Only the nanoATLServer.dll is mandatory. The Intel and MS files may be optional, dependent on your OS.     Module  Description  Dependencies      nanoATLServer.dll  nanocosmos License Server     libiomp5md.dll  Intel OpenMP Library     vcomp90.dll  MS OpenMP Library", 
            "title": "Dependencies"
        }, 
        {
            "location": "/nanostream/windows/windows_license_help/", 
            "text": "Setting the license key during setup (License Tool starts automatically):\n\n\n\n\nSelect \u201cLicense Tool\u201d at the end of the Setup.\n\n\nSelect Application/Product\n\n\nPaste your License Key from the Clipboard (displayed in the download page or delivered to you by email)\n\n\n\n\nSetting or updating the License Key by manually starting the License Tool:\n\n\n\n\nGo to the \nStart\n - \nAll Programs\n - \nnanocosmos\n - \nLiveVideoEncoder\n - \nTools\n - \nLicense Tool\n\n\nSelect Application/Product\n\n\nPaste your License Key from the Clipboard\n\n\n\n\nSetting the license key in the registry\n\n\nThe registry contains previous licenses (if any), you can place a new or an updated license in one\nof the following locations:\n1. Windows XP/7 32 bit, local machine global key:\n\nHKEY_LOCAL_MACHINE\\SOFTWARE\\nanocosmos\\LiveVideoEncoder\n\n\u201cLicense\u201d=\u201cnlic:1.0:nanoLiveEnc:\u2026\u201d\n2. Windows XP/7 32 bit, local user key:\n\nHKEY_CURRENT_USER\\SOFTWARE\\nanocosmos\\LiveVideoEncoder\n\n\u201cLicense\u201d=\u201cnlic:1.0:nanoLiveEnc:\u2026\u201d\n3. Windows XP/7 64 bit, Wow64 key\n\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\nanocosmos\\LiveVideoEncoder\n\n\u201cLicense\u201d=\u201cnlic:1.0:nanoLiveEnc:\u2026\u201d", 
            "title": "License Help"
        }, 
        {
            "location": "/nanostream/windows/windows_license_help/#setting_the_license_key_during_setup_license_tool_starts_automatically", 
            "text": "Select \u201cLicense Tool\u201d at the end of the Setup.  Select Application/Product  Paste your License Key from the Clipboard (displayed in the download page or delivered to you by email)", 
            "title": "Setting the license key during setup (License Tool starts automatically):"
        }, 
        {
            "location": "/nanostream/windows/windows_license_help/#setting_or_updating_the_license_key_by_manually_starting_the_license_tool", 
            "text": "Go to the  Start  -  All Programs  -  nanocosmos  -  LiveVideoEncoder  -  Tools  -  License Tool  Select Application/Product  Paste your License Key from the Clipboard", 
            "title": "Setting or updating the License Key by manually starting the License Tool:"
        }, 
        {
            "location": "/nanostream/windows/windows_license_help/#setting_the_license_key_in_the_registry", 
            "text": "The registry contains previous licenses (if any), you can place a new or an updated license in one\nof the following locations:\n1. Windows XP/7 32 bit, local machine global key: HKEY_LOCAL_MACHINE\\SOFTWARE\\nanocosmos\\LiveVideoEncoder \n\u201cLicense\u201d=\u201cnlic:1.0:nanoLiveEnc:\u2026\u201d\n2. Windows XP/7 32 bit, local user key: HKEY_CURRENT_USER\\SOFTWARE\\nanocosmos\\LiveVideoEncoder \n\u201cLicense\u201d=\u201cnlic:1.0:nanoLiveEnc:\u2026\u201d\n3. Windows XP/7 64 bit, Wow64 key HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\nanocosmos\\LiveVideoEncoder \n\u201cLicense\u201d=\u201cnlic:1.0:nanoLiveEnc:\u2026\u201d", 
            "title": "Setting the license key in the registry"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/", 
            "text": "RTMP Network Renderer \n Writer\n\n\nPurpose\n\n\nWriting RTMP compatible video/audio streams over a network connection\n- DirectShow filter for streaming to Wowza and Flash Media Servers\n- Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n- Supported Formats: H.264 + AAC\n\n\nModule / Version\n\n\nnanocosmos RTMP Network Writer\nnRtmpRenderer.ax Version 3.0.3.1\n\n\nDirectShow Connectivity\n\n\nThe RTMP Writer is implemented as a \u201cRenderer Filter\u201d, which means it only has 2 input pins for compressed video and audio and no output pin.\nThe input is accepting connections matching the following media types:\n\n\n\n\nPin 1 Media Types:\n\n\nMEDIATYPE_Video\n\nnbsp; - Pin 1 Media Subtypes:\n\nnbsp; - FourCCs: H264, h264\n\n\nPin 1 Formats:\n\n\nFORMAT_MPEG2_VIDEO,\n\n\nFORMAT_NONE\n\n\nPin 2 Major Media Types:\n\n\nMEDIATYPE_Audio\n\n\nPin 2 Media Subtypes:\n\n\nMEDIASUBTYPE_AAC, FourCC: 0x000000FF\n\n\nPin 2 Formats:\n\n\nFORMAT_WaveFormatEx,\n\n\nFORMAT_NONE\n\n\n\n\n\n\nThe filter\ns property page offers a subset of encoding parameters, containing the most important options.\nURL formatting:\n\nrtmp: [hostname / IP address]/[application]+[stream name] for example:\n\n\nrtmp:127.0.0.1/live+myStream\n\nwith:\n\nIP address: 127.0.0.1\n\nApplication name: live, Stream name: myStream\n\n\nConnection Test\n\n\nConnect/Disconnect buttons. Allows to connect before starting the graph and disconnect during the streaming (this stops the running graph).\n\n\nRTMP Authentication\n\n\nRTMP Authentication expects a user name and a password for unlocking access to the Media Server. This has been verified with Flash Media Server (3.x and 4) and Wowza Media Server (2.x). CDNs are supported on a case-by-case basis. Special tuning as been made for some CDN access (e.g. Limelight).\n\n\nAutomatic Reconnection:\n\n\nAttempts to restore network connection after n seconds to the server in case of network interrupts. During the reconnect attempts the graph still playing. 0 means no attempts to reconnect to server.\n\n\nAdvanced Configuration Options\n\n\nThe advanced options should be handled carefully. They can severely affect network and streaming performance. Contact support if you want to fine tune any settings.\n\nBuffering:\n\nData Flow: RTMP multiplexed data \u2192 application buffer \u2192 socket buffer \u2192 network.\nThere are 2 buffer types:\n1. Socket level buffer: Size of the network socket buffer, much dependent on the underlying network architecture\n2. Application level buffer (Output Buffer Size, Output packet size), 0=no buffer Affects bandwidth utilization, prevents bitrate changes and puts the sending process to a separate thread.\n\n\nAdvanced Settings\n\n\n\n\nLive Mode: Turns on/off blocking of input pins. (should be off by default)\n\n\nTCP No Delay: Activates the TCP_NODELAY option for TCP transmission (\nNagle Algorithm\n)\n\n\nTimecode Options: Sends Time Code in RTMP Meta Data\n\n\nAllow B Frames: should be on, it reduces the buffer/delay in H.264 Main Profile without B Frames. No effect in Baseline Mode.\n\n\nTimecode Options: send Time Code in RTMP Meta Data\n\n\n\n\nConnection Status Notification\n\n\nThere are two possibilities to get the status of the connection to the server:\n- Event messages are sent via IMediaEventSink with the event code EC_NANO_RTMP_WRITER_STATUS declared in RTMPWriterOptions.h (#define EC_NANO_RTMP_WRITER_STATUS EC_USER+181). A message is sent when the connection state changes. The different states are represented by (also declared in RTMPWriterOptions.h):\n- RTMPWriterConnected=0\n- RTMPWriterDisconnected=1\n- RTMPWriterReconnecting=2\n- Using a callback function, which is called when the connection state changes:\n- Query for the interface IRTMPStatusNotify\n- Set the callback function via SetStatusNotifyHandler()\n\n\nRtmp Writer Filter crashes when using SetStatusNotifyHandler()\n\n\nThis problem is probably caused by calling a function declared with one calling convention with a function pointer declared with a different calling convention. Here is a good explanation of the problem:\n\nVisual Studio Runtime Error\n\n\nRun Time Check Failure\n\n\nConclusion: Make sure you use \nstdcall\n in your declaration\n\n\nLog / Debug Configuration Registry Settings\n\n\nKey: HKEYCURRENTUSER\\Software\\DebugNano\\ nRtmpRenderer.ax\n\n\nFile name\n\n\nSets the output file name. The folder must exist.\nValue name: LogToFile\nValue type: REG_SZ / String\nValid values: a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed.\n\n\nValue name: TRACE\n\n\nValue type: REG_DWORD\n\n\nValid values: 0 (minimal logging) - 9 (maximal logging)", 
            "title": "RTMP Network Render & Writer"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#rtmp_network_renderer_writer", 
            "text": "", 
            "title": "RTMP Network Renderer &amp; Writer"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#purpose", 
            "text": "Writing RTMP compatible video/audio streams over a network connection\n- DirectShow filter for streaming to Wowza and Flash Media Servers\n- Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n- Supported Formats: H.264 + AAC", 
            "title": "Purpose"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#module_version", 
            "text": "nanocosmos RTMP Network Writer\nnRtmpRenderer.ax Version 3.0.3.1", 
            "title": "Module / Version"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#directshow_connectivity", 
            "text": "The RTMP Writer is implemented as a \u201cRenderer Filter\u201d, which means it only has 2 input pins for compressed video and audio and no output pin.\nThe input is accepting connections matching the following media types:   Pin 1 Media Types:  MEDIATYPE_Video nbsp; - Pin 1 Media Subtypes: nbsp; - FourCCs: H264, h264  Pin 1 Formats:  FORMAT_MPEG2_VIDEO,  FORMAT_NONE  Pin 2 Major Media Types:  MEDIATYPE_Audio  Pin 2 Media Subtypes:  MEDIASUBTYPE_AAC, FourCC: 0x000000FF  Pin 2 Formats:  FORMAT_WaveFormatEx,  FORMAT_NONE    The filter s property page offers a subset of encoding parameters, containing the most important options.\nURL formatting: rtmp: [hostname / IP address]/[application]+[stream name] for example:  rtmp:127.0.0.1/live+myStream \nwith: IP address: 127.0.0.1 \nApplication name: live, Stream name: myStream", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#connection_test", 
            "text": "Connect/Disconnect buttons. Allows to connect before starting the graph and disconnect during the streaming (this stops the running graph).", 
            "title": "Connection Test"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#rtmp_authentication", 
            "text": "RTMP Authentication expects a user name and a password for unlocking access to the Media Server. This has been verified with Flash Media Server (3.x and 4) and Wowza Media Server (2.x). CDNs are supported on a case-by-case basis. Special tuning as been made for some CDN access (e.g. Limelight).", 
            "title": "RTMP Authentication"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#automatic_reconnection", 
            "text": "Attempts to restore network connection after n seconds to the server in case of network interrupts. During the reconnect attempts the graph still playing. 0 means no attempts to reconnect to server.", 
            "title": "Automatic Reconnection:"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#advanced_configuration_options", 
            "text": "The advanced options should be handled carefully. They can severely affect network and streaming performance. Contact support if you want to fine tune any settings. Buffering: \nData Flow: RTMP multiplexed data \u2192 application buffer \u2192 socket buffer \u2192 network.\nThere are 2 buffer types:\n1. Socket level buffer: Size of the network socket buffer, much dependent on the underlying network architecture\n2. Application level buffer (Output Buffer Size, Output packet size), 0=no buffer Affects bandwidth utilization, prevents bitrate changes and puts the sending process to a separate thread.", 
            "title": "Advanced Configuration Options"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#advanced_settings", 
            "text": "Live Mode: Turns on/off blocking of input pins. (should be off by default)  TCP No Delay: Activates the TCP_NODELAY option for TCP transmission ( Nagle Algorithm )  Timecode Options: Sends Time Code in RTMP Meta Data  Allow B Frames: should be on, it reduces the buffer/delay in H.264 Main Profile without B Frames. No effect in Baseline Mode.  Timecode Options: send Time Code in RTMP Meta Data", 
            "title": "Advanced Settings"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#connection_status_notification", 
            "text": "There are two possibilities to get the status of the connection to the server:\n- Event messages are sent via IMediaEventSink with the event code EC_NANO_RTMP_WRITER_STATUS declared in RTMPWriterOptions.h (#define EC_NANO_RTMP_WRITER_STATUS EC_USER+181). A message is sent when the connection state changes. The different states are represented by (also declared in RTMPWriterOptions.h):\n- RTMPWriterConnected=0\n- RTMPWriterDisconnected=1\n- RTMPWriterReconnecting=2\n- Using a callback function, which is called when the connection state changes:\n- Query for the interface IRTMPStatusNotify\n- Set the callback function via SetStatusNotifyHandler()", 
            "title": "Connection Status Notification"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#rtmp_writer_filter_crashes_when_using_setstatusnotifyhandler", 
            "text": "This problem is probably caused by calling a function declared with one calling convention with a function pointer declared with a different calling convention. Here is a good explanation of the problem: Visual Studio Runtime Error  Run Time Check Failure  Conclusion: Make sure you use  stdcall  in your declaration", 
            "title": "Rtmp Writer Filter crashes when using SetStatusNotifyHandler()"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#log_debug_configuration_registry_settings", 
            "text": "Key: HKEYCURRENTUSER\\Software\\DebugNano\\ nRtmpRenderer.ax", 
            "title": "Log / Debug Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#file_name", 
            "text": "Sets the output file name. The folder must exist.\nValue name: LogToFile\nValue type: REG_SZ / String\nValid values: a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/windows/windows_networkwriter/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed.  Value name: TRACE  Value type: REG_DWORD  Valid values: 0 (minimal logging) - 9 (maximal logging)", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/", 
            "text": "nanoStream C++ Integration\n\n\nThe C++ plugin interface is similar to the plugin property/method interface, but has separate methods for \u201cgetting\u201d and \u201csetting\u201d the properties.\n\nNOTE: SDK / Developer license is needed for this functionality.\n\n\ncppMIDL_INTERFACE(\"65E7065E-43B5-46e4-9766-4E01ACAE530C\")\nIRTMPActiveXCommands : public IDispatch\n\n\n\n\nInitialization and Configuration:\n\n\nInitEncoder( )\nget_PluginVersion( /* [retval][out] */ LONG *pVal)```\n\nnbsp;\n\n## License Key String\n```cpp\nget_License( /* [retval][out] */ BSTR *pVal)\nput_License( /* [in] */ BSTR newVal)\nget_EnablePreview(/* [retval][out] */ LONG *pVal)\nput_EnablePreview( /* [in] */ LONG newVal)\n\n\n\n\n\n\nDestination File Name or Stream URL\n\n\nExample destination\u00a0URL:\nrtmp://localhost/live+myStream\n\n\nget_DestinationURL( /* [retval][out] */ BSTR *pVal)\nput_DestinationURL( /* [in] */ BSTR newVal)```\n\nnbsp;\n\n## Video and Audio Capture Devices (0 \u2026 n)\n```cpp\nget_NumberOfVideoSources( /* [retval][out] */ LONG *pVal)\nget_NumberOfAudioSources( /* [retval][out] */ LONG *pVal)\nGetVideoSource( /* [in] */ LONG num, /* [retval][out] */ BSTR *pVal)\nGetAudioSource( /* [in] */ LONG num, /* [retval][out] */ BSTR *pVal)\nget_VideoSource( /* [retval][out] */ LONG *pVal)\nput_VideoSource( /* [in] */ LONG newVal)\nget_AudioSource( /* [retval][out] */ LONG *pVal)\nput_AudioSource( /* [in] */ LONG newVal)\nget_VideoFormat( /* [retval][out] */ BSTR *pVal)\nput_VideoFormat( /* [in] */ BSTR newVal)\nget_AudioFormat( /* [retval][out] */ BSTR *pVal)\nput_AudioFormat( /* [in] */ BSTR newVal)\n\n\n\n\n\n\nVideo and Audio Encoding Bitrates (Quality in Bits/s)\n\n\nget_VideoBitrate( /* [retval][out] */ LONG *pVal)\nput_VideoBitrate( /* [in] */ LONG newVal)\nget_AudioBitrate( /* [retval][out] */ LONG *pVal)\nput_AudioBitrate( /* [in] */ LONG newVal)\n\n\n\n\n\n\nVideo Capture Frame Size and Frame Rate\n\n\nget_VideoWidth( /* [retval][out] */ LONG *pVal)\nput_VideoWidth( /* [in] */ LONG newVal)\nget_VideoHeight( /* [retval][out] */ LONG *pVal)\nput_VideoHeight( /* [in] */ LONG newVal)\nget_VideoFrameRate(/* [retval][out] */ DOUBLE *pVal)\nput_VideoFrameRate(/* [in] */ DOUBLE newVal)\nget_OutputFormat( /* [retval][out] */ LONG *pVal)\nput_OutputFormat( /* [in] */ LONG newVal)\nget_CaptureWidth( /* [retval][out] */ LONG *pVal)\nput_CaptureWidth( /* [in] */ LONG newVal)\nget_CaptureHeight( /* [retval][out] */ LONG *pVal)\nput_CaptureHeight( /* [in] */ LONG newVal)\nCheckVideoFormat( )\n\n\n\n\n\n\nEncoder / Stream Control:\n\n\nStartPreview( )\nStartBroadcast( )\nStopPreview( )\nStopBroadcast( )\n\n\n\n\n\n\nScreen Capture Area:\n\n\nget_ScreenRegionLeft( /* [retval][out] */ LONG *pVal)\nput_ScreenRegionLeft( /* [in] */ LONG newVal)\nget_ScreenRegionTop( /* [retval][out] */ LONG *pVal)\nput_ScreenRegionTop( /* [in] */ LONG newVal)\nget_ScreenRegionRight( /* [retval][out] */ LONG *pVal)\nput_ScreenRegionRight( /* [in] */ LONG newVal)\nget_ScreenRegionBottom(/* [retval][out] */ LONG *pVal)\nput_ScreenRegionBottom(/* [in] */ LONG newVal)\n\n\n\n\n\n\nResize Video\n\n\nget_EnableResize( /* [retval][out] */ LONG *pVal)\nput_EnableResize( /* [in] */ LONG newVal)\nget_VideoResizeWidth( /* [retval][out] */ LONG *pVal)\nput_VideoResizeWidth( /* [in] */ LONG newVal)\nget_VideoResizeHeight( /* [retval][out] */ LONG *pVal)\nput_VideoResizeHeight( /* [in] */ LONG newVal)\n\n\n\n\n\n\nVideo Effects, Mix, Overlay, 3D\n\n\nget_VideoMixer(/* [retval][out] */ LONG *pVal)\nput_VideoMixer(/* [in] */ LONG newVal)\nget_VideoSource2( /* [retval][out] */ LONG *pVal)\nput_VideoSource2( /* [in] */ LONG newVal)\nget_TextOverlayText(/* [retval][out] */ BSTR *pVal)\nput_TextOverlayText(/* [in] */ BSTR newVal)\nget_VideoEffect( /* [retval][out] */ LONG *pVal)\nput_VideoEffect( /* [in] */ LONG newVal)\n\n\n\n\n\n\nAudio Control\n\n\nget_AudioDelay( /* [retval][out] */ DOUBLE *pVal)\nput_AudioDelay( /* [in] */ DOUBLE newVal)\nget_AudioVolume(/* [retval][out] */ LONG *pVal)\nput_AudioVolume(/* [in] */ LONG pVal)\nGetConfig( /* [in] */ BSTR prop, /* [retval][out] */ BSTR *pVal)\nSetConfig( /* [in] */ BSTR prop, /* [in] */ BSTR pVal)\nget_XMLProfile( /* [retval][out] */ BSTR *pVal)\nput_XMLProfile( /* [in] */ BSTR pVal)\n\n\n\n\n\n\nMiscellaneous\n\n\nget_ActivateKeyServer( /* [retval][out] */ LONG *pVal)\nput_ActivateKeyServer( /* [in] */ LONG newVal)\nget_FileSourceFilename(/* [retval][out] */ BSTR *pVal)\nput_FileSourceFilename(/* [in] */ BSTR newVal)\nget_FileSource2Filename(/* [retval][out] */ BSTR *pVal)\nput_FileSource2Filename(/* [in] */ BSTR newVal)\nget_MP4MuxMode( /* [retval][out] */ LONG *pVal)\nput_MP4MuxMode( /* [in] */ LONG newVal)\nget_OriginalVideoSize(/* [retval][out] */ LONG *pVal)\nput_OriginalVideoSize( /* [in] */ LONG newVal)\nget_ShowPropertyPage( /* [retval][out] */ LONG *pVal)\nput_ShowPropertyPage( /* [in] */ LONG newVal)", 
            "title": "C++"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#nanostream_c_integration", 
            "text": "The C++ plugin interface is similar to the plugin property/method interface, but has separate methods for \u201cgetting\u201d and \u201csetting\u201d the properties. NOTE: SDK / Developer license is needed for this functionality.  cppMIDL_INTERFACE(\"65E7065E-43B5-46e4-9766-4E01ACAE530C\")\nIRTMPActiveXCommands : public IDispatch", 
            "title": "nanoStream C++ Integration"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#initialization_and_configuration", 
            "text": "InitEncoder( )\nget_PluginVersion( /* [retval][out] */ LONG *pVal)``` nbsp;\n\n## License Key String\n```cpp\nget_License( /* [retval][out] */ BSTR *pVal)\nput_License( /* [in] */ BSTR newVal)\nget_EnablePreview(/* [retval][out] */ LONG *pVal)\nput_EnablePreview( /* [in] */ LONG newVal)", 
            "title": "Initialization and Configuration:"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#destination_file_name_or_stream_url", 
            "text": "Example destination\u00a0URL: rtmp://localhost/live+myStream  get_DestinationURL( /* [retval][out] */ BSTR *pVal)\nput_DestinationURL( /* [in] */ BSTR newVal)``` nbsp;\n\n## Video and Audio Capture Devices (0 \u2026 n)\n```cpp\nget_NumberOfVideoSources( /* [retval][out] */ LONG *pVal)\nget_NumberOfAudioSources( /* [retval][out] */ LONG *pVal)\nGetVideoSource( /* [in] */ LONG num, /* [retval][out] */ BSTR *pVal)\nGetAudioSource( /* [in] */ LONG num, /* [retval][out] */ BSTR *pVal)\nget_VideoSource( /* [retval][out] */ LONG *pVal)\nput_VideoSource( /* [in] */ LONG newVal)\nget_AudioSource( /* [retval][out] */ LONG *pVal)\nput_AudioSource( /* [in] */ LONG newVal)\nget_VideoFormat( /* [retval][out] */ BSTR *pVal)\nput_VideoFormat( /* [in] */ BSTR newVal)\nget_AudioFormat( /* [retval][out] */ BSTR *pVal)\nput_AudioFormat( /* [in] */ BSTR newVal)", 
            "title": "Destination File Name or Stream URL"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#video_and_audio_encoding_bitrates_quality_in_bitss", 
            "text": "get_VideoBitrate( /* [retval][out] */ LONG *pVal)\nput_VideoBitrate( /* [in] */ LONG newVal)\nget_AudioBitrate( /* [retval][out] */ LONG *pVal)\nput_AudioBitrate( /* [in] */ LONG newVal)", 
            "title": "Video and Audio Encoding Bitrates (Quality in Bits/s)"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#video_capture_frame_size_and_frame_rate", 
            "text": "get_VideoWidth( /* [retval][out] */ LONG *pVal)\nput_VideoWidth( /* [in] */ LONG newVal)\nget_VideoHeight( /* [retval][out] */ LONG *pVal)\nput_VideoHeight( /* [in] */ LONG newVal)\nget_VideoFrameRate(/* [retval][out] */ DOUBLE *pVal)\nput_VideoFrameRate(/* [in] */ DOUBLE newVal)\nget_OutputFormat( /* [retval][out] */ LONG *pVal)\nput_OutputFormat( /* [in] */ LONG newVal)\nget_CaptureWidth( /* [retval][out] */ LONG *pVal)\nput_CaptureWidth( /* [in] */ LONG newVal)\nget_CaptureHeight( /* [retval][out] */ LONG *pVal)\nput_CaptureHeight( /* [in] */ LONG newVal)\nCheckVideoFormat( )", 
            "title": "Video Capture Frame Size and Frame Rate"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#encoder_stream_control", 
            "text": "StartPreview( )\nStartBroadcast( )\nStopPreview( )\nStopBroadcast( )", 
            "title": "Encoder / Stream Control:"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#screen_capture_area", 
            "text": "get_ScreenRegionLeft( /* [retval][out] */ LONG *pVal)\nput_ScreenRegionLeft( /* [in] */ LONG newVal)\nget_ScreenRegionTop( /* [retval][out] */ LONG *pVal)\nput_ScreenRegionTop( /* [in] */ LONG newVal)\nget_ScreenRegionRight( /* [retval][out] */ LONG *pVal)\nput_ScreenRegionRight( /* [in] */ LONG newVal)\nget_ScreenRegionBottom(/* [retval][out] */ LONG *pVal)\nput_ScreenRegionBottom(/* [in] */ LONG newVal)", 
            "title": "Screen Capture Area:"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#resize_video", 
            "text": "get_EnableResize( /* [retval][out] */ LONG *pVal)\nput_EnableResize( /* [in] */ LONG newVal)\nget_VideoResizeWidth( /* [retval][out] */ LONG *pVal)\nput_VideoResizeWidth( /* [in] */ LONG newVal)\nget_VideoResizeHeight( /* [retval][out] */ LONG *pVal)\nput_VideoResizeHeight( /* [in] */ LONG newVal)", 
            "title": "Resize Video"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#video_effects_mix_overlay_3d", 
            "text": "get_VideoMixer(/* [retval][out] */ LONG *pVal)\nput_VideoMixer(/* [in] */ LONG newVal)\nget_VideoSource2( /* [retval][out] */ LONG *pVal)\nput_VideoSource2( /* [in] */ LONG newVal)\nget_TextOverlayText(/* [retval][out] */ BSTR *pVal)\nput_TextOverlayText(/* [in] */ BSTR newVal)\nget_VideoEffect( /* [retval][out] */ LONG *pVal)\nput_VideoEffect( /* [in] */ LONG newVal)", 
            "title": "Video Effects, Mix, Overlay, 3D"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#audio_control", 
            "text": "get_AudioDelay( /* [retval][out] */ DOUBLE *pVal)\nput_AudioDelay( /* [in] */ DOUBLE newVal)\nget_AudioVolume(/* [retval][out] */ LONG *pVal)\nput_AudioVolume(/* [in] */ LONG pVal)\nGetConfig( /* [in] */ BSTR prop, /* [retval][out] */ BSTR *pVal)\nSetConfig( /* [in] */ BSTR prop, /* [in] */ BSTR pVal)\nget_XMLProfile( /* [retval][out] */ BSTR *pVal)\nput_XMLProfile( /* [in] */ BSTR pVal)", 
            "title": "Audio Control"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_cpp_integration/#miscellaneous", 
            "text": "get_ActivateKeyServer( /* [retval][out] */ LONG *pVal)\nput_ActivateKeyServer( /* [in] */ LONG newVal)\nget_FileSourceFilename(/* [retval][out] */ BSTR *pVal)\nput_FileSourceFilename(/* [in] */ BSTR newVal)\nget_FileSource2Filename(/* [retval][out] */ BSTR *pVal)\nput_FileSource2Filename(/* [in] */ BSTR newVal)\nget_MP4MuxMode( /* [retval][out] */ LONG *pVal)\nput_MP4MuxMode( /* [in] */ LONG newVal)\nget_OriginalVideoSize(/* [retval][out] */ LONG *pVal)\nput_OriginalVideoSize( /* [in] */ LONG newVal)\nget_ShowPropertyPage( /* [retval][out] */ LONG *pVal)\nput_ShowPropertyPage( /* [in] */ LONG newVal)", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_csharp_integration/", 
            "text": "nanoStream Visual C# Integration\n\n\nAdd a New Visual C# Project / Windows Forms application\n\n\n\n\nMove mouse to the left to the \nToolbox\n list, search for \nGeneral\n and right click to select \nChoose Items\u2026\n\n\n\n\nSelect tab \nCOM Components\n under \nName\n nanoStream RTMPActiveX Class.\n\n\n\n\nDrag the \nnanoStream\n Object Icon from the Toolbox onto your Form, and drag a Button onto your Form.\n\n\n\n\nDouble Click the \u201cButton\u201d to add source code:\n\n\nprivate void button1_Click(object sender, EventArgs e)\n{\naxRTMPActiveX1.InitEncoder();\naxRTMPActiveX1.StartPreview();\n}\n\n\n\n\nRun the application and press the button. You should see a video image from your default camera.\n\n\n\n\nAdditional Options\n\n\nVideo Device\n\n\naxRTMPActiveX1.VideoSource = 0; // may be 1,2,\u2026 dependent on your devices", 
            "title": "C#"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_csharp_integration/#nanostream_visual_c_integration", 
            "text": "Add a New Visual C# Project / Windows Forms application   Move mouse to the left to the  Toolbox  list, search for  General  and right click to select  Choose Items\u2026   Select tab  COM Components  under  Name  nanoStream RTMPActiveX Class.   Drag the  nanoStream  Object Icon from the Toolbox onto your Form, and drag a Button onto your Form.   Double Click the \u201cButton\u201d to add source code:  private void button1_Click(object sender, EventArgs e)\n{\naxRTMPActiveX1.InitEncoder();\naxRTMPActiveX1.StartPreview();\n}  Run the application and press the button. You should see a video image from your default camera.", 
            "title": "nanoStream Visual C# Integration"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_csharp_integration/#additional_options", 
            "text": "Video Device  axRTMPActiveX1.VideoSource = 0; // may be 1,2,\u2026 dependent on your devices", 
            "title": "Additional Options"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_delphi_integration/", 
            "text": "nanoStream Delphi Integration\n\n\nnanoStream plugins are based on ActiveX Controls, which can be used from within any development environment.\nThis document describes how to use the nanoStream plugins from within the Delphi Development IDE.\n\n\nIn a Delphi Project, first \nImport ActiveX Control\n under the \nComponent\n tab\n\n\n\n\nSearch for nanoStream Live Video Encoder.\n\n\n\n\nCreate a \nRTMP ActiveX\n Unit.\n\n\n\n\nOn the resulting form, pull an area with the mouse.\n\n\n\n\nThen add a standard button to test nanoStream:\n\n\n\n\nDouble Click the button and add this code:\n\n\nprocedure TForm1.Button1Click(Sender: TObject);\nbegin\nRTMPActiveX1.InitEncoder;\nRTMPActiveX1.StartPreview;\nend;\n\n\n\n\nRun the project.\nClick on the button.\nYou should see nanoStream running in camera preview mode then.\nAdd Streaming / Broadcasting to a Media Server\n\n\nRTMPActiveX1.DestinationURL := 'rtmp://example.com/live+delphi123';\nRTMPActiveX1.VideoBitrate := 200000;\nRTMPActiveX1.StartBroadcast;", 
            "title": "Delphi"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_delphi_integration/#nanostream_delphi_integration", 
            "text": "nanoStream plugins are based on ActiveX Controls, which can be used from within any development environment.\nThis document describes how to use the nanoStream plugins from within the Delphi Development IDE.  In a Delphi Project, first  Import ActiveX Control  under the  Component  tab   Search for nanoStream Live Video Encoder.   Create a  RTMP ActiveX  Unit.   On the resulting form, pull an area with the mouse.   Then add a standard button to test nanoStream:   Double Click the button and add this code:  procedure TForm1.Button1Click(Sender: TObject);\nbegin\nRTMPActiveX1.InitEncoder;\nRTMPActiveX1.StartPreview;\nend;  Run the project.\nClick on the button.\nYou should see nanoStream running in camera preview mode then.\nAdd Streaming / Broadcasting to a Media Server  RTMPActiveX1.DestinationURL := 'rtmp://example.com/live+delphi123';\nRTMPActiveX1.VideoBitrate := 200000;\nRTMPActiveX1.StartBroadcast;", 
            "title": "nanoStream Delphi Integration"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_activex_visualcpp/", 
            "text": "nanoStream Visual C++ Integration\n\n\nThis tutorial shows how to create a custom Live Encoding and Streaming application with the nanoStream plugins, based on VisualStudio and C++ for a simple console application.\n\nThis tutorial was created with VisualStudio 2008 but should work similar with VS 2010.\n\nCreate a new Win32 Console Application Project (File/New Project)\n\n\n\n\n\n\nLeave all options to default and press \u201cFinish\u201d", 
            "title": "VisualC"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_activex_visualcpp/#nanostream_visual_c_integration", 
            "text": "This tutorial shows how to create a custom Live Encoding and Streaming application with the nanoStream plugins, based on VisualStudio and C++ for a simple console application. This tutorial was created with VisualStudio 2008 but should work similar with VS 2010. \nCreate a new Win32 Console Application Project (File/New Project)    Leave all options to default and press \u201cFinish\u201d", 
            "title": "nanoStream Visual C++ Integration"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_activex_visualcpp_mfc/", 
            "text": "nanoStream VisualC++ MFC Integration\n\n\nThis tutorial shows how to create a custom Live Encoding and Streaming application with the nanoStream plugins, based on VisualStudio, C++ and MFC.\nThis tutorial was created with VisualStudio 2008 but should work similar with VS 2010.\nCreate a new MFC Application Project (File/New Project)\n\n\n\n\n\n\nIn the following MFC Application Wizard, select \u201cDialog Based Application\u201d\n\n\n\n\nSelect all default values for the rest and Finish\n\n\n\n\n\n\nA new project solution is created based on an empty dialog.\n\n\nRight-click on the dialog and select \u201cInsert ActiveX Control\u2026\u201d\n\n\n\n\n\n\nSelect \u201cnanoStream RTMPActiveX Class\u201d\n\n\n\n\n\n\nPosition and resize the control window accordingly.\n\n\nThe window will show a live camera preview later.\n\n\n\n\n\n\nCreate a class member variable for the control for simpler access:\n\n\n\n\n\n\nNow let us create a button to create a camera preview.\n\n\nFrom the Toolbox, select \u201cButton\u201d and place the button on the dialog.\n\n\n\n\n\n\nDouble-Click on the button to edit the new source code event handler:\n\n\n\n\n\n\nThis is the complete code which shows the camera preview:\n\n\nvoid CnanoStreamTestDlg::OnBnClickedButton1()\n{\n//nanoStream Live Video Encoder Plugin\nm_nanoStream.InitEncoder(); // Init Encoder\nm_nanoStream.put_VideoSource(0); // Select Video Capture Source\nm_nanoStream.StartPreview(); // Start Camera Preview in Window\n}\n\n\n\n\n\n\nNow add another button to start a real encoded stream.\nAdd the following code to the button:\n\n\nvoid CnanoStreamTestDlg::OnBnClickedButton2()\n{\n// nanoStream Live Video Encoder Plugin\n// Live Encoding/Streaming to RTMP Server\nm_nanoStream.put_License(_T(\nnlic:1.0:nanoLiveEncDemo:1.1:LivePlgDemo=1,MP4=1,RTMP=1,.....\n));\nm_nanoStream.InitEncoder(); // Init Encoder\nm_nanoStream.put_VideoSource(0); // Select Video Capture Source\nm_nanoStream.put_VideoBitrate(500000); // 500 kBit/s encoded bitrate\n\n// URL to Flash Media Server / Wowza Media Server\n// Syntax: rtmp://\nlt;server\ngt;/\nlt;app\ngt;+\nlt;stream\ngt;\nm_nanoStream.put_DestinationURL(_T(\nrtmp://ws1.3p0.de/live+mfcStream01\n));\nm_nanoStream.StartBroadcast(); // Start Camera Preview in Window\n}\n\n\n\n\nWhen pressing button2 / broadcast, the live encoding will be started.", 
            "title": "MFC"
        }, 
        {
            "location": "/nanostream/windows/language_integration/nanostream_activex_visualcpp_mfc/#nanostream_visualc_mfc_integration", 
            "text": "This tutorial shows how to create a custom Live Encoding and Streaming application with the nanoStream plugins, based on VisualStudio, C++ and MFC.\nThis tutorial was created with VisualStudio 2008 but should work similar with VS 2010.\nCreate a new MFC Application Project (File/New Project)    In the following MFC Application Wizard, select \u201cDialog Based Application\u201d   Select all default values for the rest and Finish    A new project solution is created based on an empty dialog.  Right-click on the dialog and select \u201cInsert ActiveX Control\u2026\u201d    Select \u201cnanoStream RTMPActiveX Class\u201d    Position and resize the control window accordingly.  The window will show a live camera preview later.    Create a class member variable for the control for simpler access:    Now let us create a button to create a camera preview.  From the Toolbox, select \u201cButton\u201d and place the button on the dialog.    Double-Click on the button to edit the new source code event handler:    This is the complete code which shows the camera preview:  void CnanoStreamTestDlg::OnBnClickedButton1()\n{\n//nanoStream Live Video Encoder Plugin\nm_nanoStream.InitEncoder(); // Init Encoder\nm_nanoStream.put_VideoSource(0); // Select Video Capture Source\nm_nanoStream.StartPreview(); // Start Camera Preview in Window\n}   Now add another button to start a real encoded stream.\nAdd the following code to the button:  void CnanoStreamTestDlg::OnBnClickedButton2()\n{\n// nanoStream Live Video Encoder Plugin\n// Live Encoding/Streaming to RTMP Server\nm_nanoStream.put_License(_T( nlic:1.0:nanoLiveEncDemo:1.1:LivePlgDemo=1,MP4=1,RTMP=1,..... ));\nm_nanoStream.InitEncoder(); // Init Encoder\nm_nanoStream.put_VideoSource(0); // Select Video Capture Source\nm_nanoStream.put_VideoBitrate(500000); // 500 kBit/s encoded bitrate\n\n// URL to Flash Media Server / Wowza Media Server\n// Syntax: rtmp:// lt;server gt;/ lt;app gt;+ lt;stream gt;\nm_nanoStream.put_DestinationURL(_T( rtmp://ws1.3p0.de/live+mfcStream01 ));\nm_nanoStream.StartBroadcast(); // Start Camera Preview in Window\n}  When pressing button2 / broadcast, the live encoding will be started.", 
            "title": "nanoStream VisualC++ MFC Integration"
        }, 
        {
            "location": "/nanostream/directshow/directshow_audio_volume/", 
            "text": "Mix to mono\n\n\nThe filter is able to mix all channels to a mono channel.\nThis feature can be configured by using the interface IAudioVolumeMix.\nHere is a short sample code for c++:\n\n\nCComQIPtr\nIAudioVolumeMix, \nIID_IAudioVolumeMix\n pAudioVolMix = m_pAudioVol;\nif(pAudioVolMix)\n{\n   pAudioVolMix-\nMixToMono(true); // true==mix all channels to one\n}\n...\n\n\n\n\nNotice that the option \nMixToMono\n has to be set before the output pin of the Audio Volume filter is connected to another filter.", 
            "title": "Audio Volume"
        }, 
        {
            "location": "/nanostream/directshow/directshow_audio_volume/#mix_to_mono", 
            "text": "The filter is able to mix all channels to a mono channel.\nThis feature can be configured by using the interface IAudioVolumeMix.\nHere is a short sample code for c++:  CComQIPtr IAudioVolumeMix,  IID_IAudioVolumeMix  pAudioVolMix = m_pAudioVol;\nif(pAudioVolMix)\n{\n   pAudioVolMix- MixToMono(true); // true==mix all channels to one\n}\n...  Notice that the option  MixToMono  has to be set before the output pin of the Audio Volume filter is connected to another filter.", 
            "title": "Mix to mono"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/", 
            "text": "AVC/H.264 Video Codec / SDK\n\n\nHigh Quality and High Performance Video Coding\n\n\nnanocosmos AVC/H.264 video codec is a high performance video codec for the latest generation MPEG-AVC / H.264 video coding standards. It may be licensed by Professional and OEM customers for integration into custom applications.\n\n\nMajor Features\n\n\n\n\nMost advanced video coding standard H.264 (MPEG-AVC)\n\n\nHighly optimized software coding with support for latest CPU generations (Multicore / Core i7)\n\n\nWide range of applications from Mobile Phones (3GP), Portable Devices (iPod etc.) up to HDTV\n\n\nFull HD 1080i and 1080p support\n\n\nX-HD support for Custom Applications (Dome Cinema, Projections), up to 2k/4k (4096 x 4096)\n\n\nSupport for realtime Full HD 1080 encoding and decoding of dual channel video (stereo video / 3d)\n\n\nBaseline Profile, Main Profile and HDTV modes supported\n\n\nCompatible to ISO Mp4 and Flash Media Streaming Server and Wowza\n\n\n\n\nArchitecture and Availability\n\n\nThe Codec is available for Windows platforms based on DirectShow filters. For MacOS and Linux, custom based solutions are available.\n\n\nComponents\n\n\n\n\nAVC/H.264 Video Encoder and Decoder, MP4 splitter and multiplexer\n\n\nMPEG audio and AAC audio codecs.\n\n\nMP4, 3GP and optionally Quicktime and AVI file format writers\n\n\n\n\nLicensing model\n\n\nWe offer several licensing models, dependent on customer requirements.\n\n\n\n\nDeveloper License (SDK)\\  With the Developer License, you will get a documented SDK including shared library objects (DLLs), interface specifications, header files and source code samples to develop video coding applications.\n\n\nRedistribution License (Royalties)\\  For redistributing video coding modules with your application, a per-item additional royalty license is needed. You may also get flat fees for high sales volumes. Please contact us for further information.\n\n\nCustomization and flat fees are possible\n\n\n\n\nH.264 / AVC Video Encoder\n\n\nThe Video Encoder produces compatible streams according to ITU H.264 / ISO MPEG/AVC Reference Model JM9.2, as well as MP4 file format output.\n\n\nDual channel encoding for stereo video is supported.\n\n\nThe encoder accepts the following parameters:\n  * GOP Structure (I-frame distance / P-frame distance)\n  * Bit rate\n  * Profile/Level (baseline, main, extended, high)\n  * Field Structure (Interlaced/Progressive)\n  * Frame rate (15, 24, 25, 30, 50, 60)\n  * chroma_format / aux_format (monochrome, 4:2:0)\n  * misc. rate controls (fixed quantization, vbr, cbr)\n  * Motion Estimation method\n  * full pel, half pel and quarter pel motion vectors\n  * SVC chroma deblocking filter mode\n  * transform_8x8_mode\n  * Frame Size from Mobile to HDTV (64x64 to 4096x2048)\n\n\nH.264/AVC Video Decoder\n\n\nThe decoder supports decoding of files created by JM9.2 compliant encoders or later, as well as MP4 file format input. The decoder supports baseline, main, extended and high profiles features, including HD, e.g. 1080i.\n\n\nAudio, Multiplexer and File Formats\n\n\n\n\nElementary Files, MP4 file format, 3GP file format, Quicktime\n\n\nRTMP streaming for Flash compatible streaming servers\n\n\nMPEG audio and AAC formats are available.\n\n\n\n\nOther codec types\n\n\nAsk for special configurations and custom codec development, e.g. for IMX, DVCPRO-HD XDCAM.", 
            "title": "AVC/H.264 Video Codec"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#avch264_video_codec_sdk", 
            "text": "", 
            "title": "AVC/H.264 Video Codec / SDK"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#high_quality_and_high_performance_video_coding", 
            "text": "nanocosmos AVC/H.264 video codec is a high performance video codec for the latest generation MPEG-AVC / H.264 video coding standards. It may be licensed by Professional and OEM customers for integration into custom applications.", 
            "title": "High Quality and High Performance Video Coding"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#major_features", 
            "text": "Most advanced video coding standard H.264 (MPEG-AVC)  Highly optimized software coding with support for latest CPU generations (Multicore / Core i7)  Wide range of applications from Mobile Phones (3GP), Portable Devices (iPod etc.) up to HDTV  Full HD 1080i and 1080p support  X-HD support for Custom Applications (Dome Cinema, Projections), up to 2k/4k (4096 x 4096)  Support for realtime Full HD 1080 encoding and decoding of dual channel video (stereo video / 3d)  Baseline Profile, Main Profile and HDTV modes supported  Compatible to ISO Mp4 and Flash Media Streaming Server and Wowza", 
            "title": "Major Features"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#architecture_and_availability", 
            "text": "The Codec is available for Windows platforms based on DirectShow filters. For MacOS and Linux, custom based solutions are available.", 
            "title": "Architecture and Availability"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#components", 
            "text": "AVC/H.264 Video Encoder and Decoder, MP4 splitter and multiplexer  MPEG audio and AAC audio codecs.  MP4, 3GP and optionally Quicktime and AVI file format writers", 
            "title": "Components"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#licensing_model", 
            "text": "We offer several licensing models, dependent on customer requirements.   Developer License (SDK)\\  With the Developer License, you will get a documented SDK including shared library objects (DLLs), interface specifications, header files and source code samples to develop video coding applications.  Redistribution License (Royalties)\\  For redistributing video coding modules with your application, a per-item additional royalty license is needed. You may also get flat fees for high sales volumes. Please contact us for further information.  Customization and flat fees are possible", 
            "title": "Licensing model"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#h264_avc_video_encoder", 
            "text": "The Video Encoder produces compatible streams according to ITU H.264 / ISO MPEG/AVC Reference Model JM9.2, as well as MP4 file format output.  Dual channel encoding for stereo video is supported.  The encoder accepts the following parameters:\n  * GOP Structure (I-frame distance / P-frame distance)\n  * Bit rate\n  * Profile/Level (baseline, main, extended, high)\n  * Field Structure (Interlaced/Progressive)\n  * Frame rate (15, 24, 25, 30, 50, 60)\n  * chroma_format / aux_format (monochrome, 4:2:0)\n  * misc. rate controls (fixed quantization, vbr, cbr)\n  * Motion Estimation method\n  * full pel, half pel and quarter pel motion vectors\n  * SVC chroma deblocking filter mode\n  * transform_8x8_mode\n  * Frame Size from Mobile to HDTV (64x64 to 4096x2048)", 
            "title": "H.264 / AVC Video Encoder"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#h264avc_video_decoder", 
            "text": "The decoder supports decoding of files created by JM9.2 compliant encoders or later, as well as MP4 file format input. The decoder supports baseline, main, extended and high profiles features, including HD, e.g. 1080i.", 
            "title": "H.264/AVC Video Decoder"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#audio_multiplexer_and_file_formats", 
            "text": "Elementary Files, MP4 file format, 3GP file format, Quicktime  RTMP streaming for Flash compatible streaming servers  MPEG audio and AAC formats are available.", 
            "title": "Audio, Multiplexer and File Formats"
        }, 
        {
            "location": "/nanostream/directshow/directshow_avc_h264/#other_codec_types", 
            "text": "Ask for special configurations and custom codec development, e.g. for IMX, DVCPRO-HD XDCAM.", 
            "title": "Other codec types"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/", 
            "text": "nanoAVC/H.264 DirectShow Decoding SDK\n\n\nIntroduction\n\n\nnanoAVC/H.264 Direct Show Decoding SDK enables you to decode/play back\nAVC/H.264 video and AAC audio from MP4/3GP or transport stream (TS) sources\nwithin Windows Media Player and custom applications based on Microsoft DirectShow Framework.\n\n\nThe nanocosmos H.264/AVC Video Decoder supports streams in baseline, main and high profile. It is highly optimized for use on hyper-threading and multi core systems.\n\n\nFilter components\n\n\n\n\n\n\nnanocosmos AVC/H.264 Video Decoder\n\n\n\n\nModule:       nh264dec.ax\n\n\nCLSID:        {264DA7DD-CE74-472D-A2FD-796A1F0A379C}\n\n\n\n\n\n\n\n\nnanocosmos AAC Audio Decoder\n\n\n\n\nModule:       naacdec.ax\n\n\nCLSID:        {AEED2B3D-6DA1-4C84-A85D-83547FA90486}\n\n\n\n\n\n\n\n\nnanocosmos MP4 Stream Splitter\n\n\n\n\nModule:       nmp4splitter.ax\n\n\nCLSID:        {22F493C4-B51B-4767-BE55-ADFA34D6A205}\n\n\n\n\n\n\n\n\nnanocosmos MPEG PS/TS Stream Splitter\n\n\n\n\nModule:       nmpegsplitter.ax\n\n\nCLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}\n\n\n\n\n\n\n\n\n\n\nFigure 1.  Example playback filtergraph\n\n\nRegistering and unregistering components in the DirectShow framework\n\n\nIn order to use them, filters must be registered in the DirectShow framework. After installation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.\n\n\nEvaluation mode and filter activation\n\n\nFilters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module\ns documents.\\\nIf filters run in evaluation mode, an overlay logo will be shown on video.\n\n\nEmbedding / Customizing nanocosmos technology\n\n\nNanocosmos also offers special OEM and customization service. Dependent on your needs, we may offer different models of licensing or application development.", 
            "title": "nanoAVC/H.264 DirectShow Decoding"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/#nanoavch264_directshow_decoding_sdk", 
            "text": "", 
            "title": "nanoAVC/H.264 DirectShow Decoding SDK"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/#introduction", 
            "text": "nanoAVC/H.264 Direct Show Decoding SDK enables you to decode/play back\nAVC/H.264 video and AAC audio from MP4/3GP or transport stream (TS) sources\nwithin Windows Media Player and custom applications based on Microsoft DirectShow Framework.  The nanocosmos H.264/AVC Video Decoder supports streams in baseline, main and high profile. It is highly optimized for use on hyper-threading and multi core systems.", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/#filter_components", 
            "text": "nanocosmos AVC/H.264 Video Decoder   Module:       nh264dec.ax  CLSID:        {264DA7DD-CE74-472D-A2FD-796A1F0A379C}     nanocosmos AAC Audio Decoder   Module:       naacdec.ax  CLSID:        {AEED2B3D-6DA1-4C84-A85D-83547FA90486}     nanocosmos MP4 Stream Splitter   Module:       nmp4splitter.ax  CLSID:        {22F493C4-B51B-4767-BE55-ADFA34D6A205}     nanocosmos MPEG PS/TS Stream Splitter   Module:       nmpegsplitter.ax  CLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}      Figure 1.  Example playback filtergraph", 
            "title": "Filter components"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/#registering_and_unregistering_components_in_the_directshow_framework", 
            "text": "In order to use them, filters must be registered in the DirectShow framework. After installation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.", 
            "title": "Registering and unregistering components in the DirectShow framework"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/#evaluation_mode_and_filter_activation", 
            "text": "Filters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module s documents.\\\nIf filters run in evaluation mode, an overlay logo will be shown on video.", 
            "title": "Evaluation mode and filter activation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_decoding_sdk/#embedding_customizing_nanocosmos_technology", 
            "text": "Nanocosmos also offers special OEM and customization service. Dependent on your needs, we may offer different models of licensing or application development.", 
            "title": "Embedding / Customizing nanocosmos technology"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/", 
            "text": "nanoAVC/H.264 DirectShow Encoding SDK\n\n\nIntroduction\n\n\nnanoAVC/H.264 Direct Show Encoding SDK enables you to perform high quality and high performance video coding for the latest generation video and audio coding standards. It is intended to develop  video encoding / transcoding applications based on Microsoft(R) DirectX/DirectShow(R) technology.\n\n\nMajor Features\n\n\n\n\nISO 14496 Part 10 (MPEG-AVC) / ITU H.264 compliance for many profiles and levels\n\n\nEncoding of H.264 video streams in Baseline, Main, Extended and High profile\n\n\nEncoding of AAC-LC/LTP/MAIN/HE(aacPlus) audio streams with up to 6 channels\n\n\nEncoding of AMR-NB audio streams\n\n\nHighly optimized software coding with support for latest CPU  technology by Intel and AMD (SSE2/SSE3/SSE4 and Dual-Core/Core-Duo, AMD Athlon64\n\n\nReal-time Encoding from Capture cards is supported\n\n\nWide range of applications from Mobile Phones (3GP), Portable Devices (iPod, iPhone, Sony PSP etc) up to Professional HDTV\n\n\nMultiplexer for MP4, MOV and 3GP\n\n\n\n\nDocumentation\n\n\nThe SDK\\doc folder contains the following further documents:\n\n\n\n\nH.264/AVC Video Decoder\n\n\nH.264/AVC Video Encoder\n\n\nAAC Audio Encoder\n\n\nAMR-NB Audio Encoder\n\n\nMP4/3GP Multiplexer\n\n\n\n\nFilter components\n\n\n\n\n\n\nnanocosmos AVC/H.264 Video Encoder\n\n\n\n\nModule:       nh264enc.ax\n\n\nCLSID:        {A88889A8-3C2A-4A32-8EAA-755D491D02A0}\n\n\n\n\n\n\n\n\nnanocosmos AAC Audio Encoder\n\n\n\n\nModule:       naacenc.ax\n\n\nCLSID:        {0296CC21-B78D-416D-846C-45E26CA46A4A}\n\n\n\n\n\n\n\n\nnanocosmos AMR-NB Audio Encoder\n\n\n\n\nModule:       namrnbenc.ax\n\n\nCLSID:        {10CAB930-E019-41DF-83B7-60D723706B8F}\n\n\n\n\n\n\n\n\nnanocosmos MP4 Multiplexer\n\n\n\n\nModule:       nmp4mux.ax\n\n\nCLSID:        {78D670BF-49B5-4A3B-BB8C-E2A36E688FCF}\n\n\n\n\n\n\n\n\nnanocosmos File Dump Filter\n\n\n\n\nModule:       nanodump.ax\n\n\nCLSID:        {DA67A541-8FEA-11D4-A908-00105A6758CF}\n\n\n\n\n\n\n\n\nnanocosmos AVC/H.264 Video Decoder\n\n\n\n\nModule:       nh264dec.ax\n\n\nCLSID:        {264DA7DD-CE74-472D-A2FD-796A1F0A379C}\n\n\n\n\n\n\n\n\nnanocosmos AAC Audio Decoder\n\n\n\n\nModule:       naacdec.ax\n\n\nCLSID:        {AEED2B3D-6DA1-4C84-A85D-83547FA90486}\n\n\n\n\n\n\n\n\nnanocosmos MP4 Stream Splitter\n\n\n\n\nModule:       nmp4splitter.ax\n\n\nCLSID:        {22F493C4-B51B-4767-BE55-ADFA34D6A205}\n\n\n\n\n\n\n\n\nnanocosmos MPEG PS/TS Stream Splitter\n\n\n\n\nModule:       nmpegsplitter.ax\n\n\nCLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}\n\n\n\n\n\n\n\n\nnanocosmos Color Space Converter\n\n\n\n\nModule:       ncolconv.ax\n\n\nCLSID:        {E855821E-C055-4C85-B04F-19F65D5D50FD}\n\n\n\n\n\n\n\n\nnanocosmos MPEG TS Writer\n\n\n\n\nModule:       nanoTsWriter.ax\n\n\nCLSID:        {2C6E92AB-523E-4C90-8A01-394FC0FC273C}\n\n\n\n\n\n\n\n\n\n\nFigure 1.  Example  filtergraph\n\n\nRegistering and unregistering components in the DirectShow framework\n\n\nIn order to use them, filters must be registered in the DirectShow framework. After installation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.\n\n\nEvaluation mode and filter activation\n\n\nFilters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module\ns documents.\\\nIf filters run in evaluation mode, an overlay logo will be shown on video.\n\n\nEmbedding / Customizing nanoPEG technology\n\n\nNanocosmos also offers special OEM and customization service. Dependent on your needs, we may offer different models of licensing or application development.", 
            "title": "nanoAVC/H.264 DirectShow Encoding"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#nanoavch264_directshow_encoding_sdk", 
            "text": "", 
            "title": "nanoAVC/H.264 DirectShow Encoding SDK"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#introduction", 
            "text": "nanoAVC/H.264 Direct Show Encoding SDK enables you to perform high quality and high performance video coding for the latest generation video and audio coding standards. It is intended to develop  video encoding / transcoding applications based on Microsoft(R) DirectX/DirectShow(R) technology.", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#major_features", 
            "text": "ISO 14496 Part 10 (MPEG-AVC) / ITU H.264 compliance for many profiles and levels  Encoding of H.264 video streams in Baseline, Main, Extended and High profile  Encoding of AAC-LC/LTP/MAIN/HE(aacPlus) audio streams with up to 6 channels  Encoding of AMR-NB audio streams  Highly optimized software coding with support for latest CPU  technology by Intel and AMD (SSE2/SSE3/SSE4 and Dual-Core/Core-Duo, AMD Athlon64  Real-time Encoding from Capture cards is supported  Wide range of applications from Mobile Phones (3GP), Portable Devices (iPod, iPhone, Sony PSP etc) up to Professional HDTV  Multiplexer for MP4, MOV and 3GP", 
            "title": "Major Features"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#documentation", 
            "text": "The SDK\\doc folder contains the following further documents:   H.264/AVC Video Decoder  H.264/AVC Video Encoder  AAC Audio Encoder  AMR-NB Audio Encoder  MP4/3GP Multiplexer", 
            "title": "Documentation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#filter_components", 
            "text": "nanocosmos AVC/H.264 Video Encoder   Module:       nh264enc.ax  CLSID:        {A88889A8-3C2A-4A32-8EAA-755D491D02A0}     nanocosmos AAC Audio Encoder   Module:       naacenc.ax  CLSID:        {0296CC21-B78D-416D-846C-45E26CA46A4A}     nanocosmos AMR-NB Audio Encoder   Module:       namrnbenc.ax  CLSID:        {10CAB930-E019-41DF-83B7-60D723706B8F}     nanocosmos MP4 Multiplexer   Module:       nmp4mux.ax  CLSID:        {78D670BF-49B5-4A3B-BB8C-E2A36E688FCF}     nanocosmos File Dump Filter   Module:       nanodump.ax  CLSID:        {DA67A541-8FEA-11D4-A908-00105A6758CF}     nanocosmos AVC/H.264 Video Decoder   Module:       nh264dec.ax  CLSID:        {264DA7DD-CE74-472D-A2FD-796A1F0A379C}     nanocosmos AAC Audio Decoder   Module:       naacdec.ax  CLSID:        {AEED2B3D-6DA1-4C84-A85D-83547FA90486}     nanocosmos MP4 Stream Splitter   Module:       nmp4splitter.ax  CLSID:        {22F493C4-B51B-4767-BE55-ADFA34D6A205}     nanocosmos MPEG PS/TS Stream Splitter   Module:       nmpegsplitter.ax  CLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}     nanocosmos Color Space Converter   Module:       ncolconv.ax  CLSID:        {E855821E-C055-4C85-B04F-19F65D5D50FD}     nanocosmos MPEG TS Writer   Module:       nanoTsWriter.ax  CLSID:        {2C6E92AB-523E-4C90-8A01-394FC0FC273C}      Figure 1.  Example  filtergraph", 
            "title": "Filter components"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#registering_and_unregistering_components_in_the_directshow_framework", 
            "text": "In order to use them, filters must be registered in the DirectShow framework. After installation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.", 
            "title": "Registering and unregistering components in the DirectShow framework"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#evaluation_mode_and_filter_activation", 
            "text": "Filters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module s documents.\\\nIf filters run in evaluation mode, an overlay logo will be shown on video.", 
            "title": "Evaluation mode and filter activation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_nanoAVC_encoding_sdk/#embedding_customizing_nanopeg_technology", 
            "text": "Nanocosmos also offers special OEM and customization service. Dependent on your needs, we may offer different models of licensing or application development.", 
            "title": "Embedding / Customizing nanoPEG technology"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/", 
            "text": "nanocosmos H.264 Video Decoder Filter\n\n\nModule / Version\n\n\nnanocosmos H.264/AVC Direct Show Video Decoder Filter\\\nnh264dec.ax  Version 2.5.2.4\n\n\nThe nanocosmos H.264/AVC Video Decoder support streams in baseline, main and high profile. It is highly optimized for use on hyper-threading and multi core systems.\n\n\nConnectivity\n\n\nThe input is accepting connections to splitter filters or combined source/splitter filters matching the following media types:\n\n\nMajor types:\n  * MEDIATYPE_Video\n\n\nSubtypes:\n  * FourCCs:\n    * H264, h264,\n    * AVC1, avc1,\n    * X264, x264,\n    * VSSH, vssh,\n    * MEDIASUBTYPE_H264: {8D2D71CB-243F-45E3-B2D8-5FD7967EC09B}\n\n\nFormats:\n  * FORMAT_VideoInfo,\n  * FORMAT_VideoInfo2,\n  * FORMAT_MPEG2_VIDEO\n\n\nThe output supports these media types:\n\n\nMajor types:\n  * MEDIATYPE_Video\n\n\nSubtypes:\n  * MEDIASUBTYPE_YV12,\n  * MEDIASUBTYPE_I420,\n  * MEDIASUBTYPE_IYUV,\n  * MEDIASUBTYPE_YUY2,\n  * MEDIASUBTYPE_RGB24,\n  * MEDIASUBTYPE_RGB32,\n  * MEDIASUBTYPE_ARGB32,\n  * MEDIASUBTYPE_RGB565,\n\n\nFormats:\n  * FORMAT_VideoInfo\n  * FORMAT_VideoInfo2\n\n\nFilter GUIDs\n\n\n//%% Filter GUID\n//%% {264DA7DD-CE74-472d-A2FD-796A1F0A379C}\nDEFINE_GUID(CLSID_NANO_H264_DECODER, 0x264DA7DD, 0xCE74, 0x472d, 0xA2, 0xFD, 0x79, 0x6A, 0x1F, 0x0A, 0x37, 0x9C);\n\n//%% Configuration interface ICodecProp\n//%% {0F817204-82C8-4c12-884A-F45FB2F33A6E}\nDEFINE_GUID(IID_ICodecProp, 0xf817204, 0x82c8, 0x4c12, 0x88, 0x4a, 0xf4, 0x5f, 0xb2, 0xf3, 0x3a, 0x6e);\n\n//%% ICodecProp: IID_nanoPeg_LicenseString\n//%% type: BSTR / Unicode string\n//%% Set license string to unlock filter\n//%% {1788F0B0-5985-4a19-B7FE-8AAC1BFC14B3}\nDEFINE_GUID(IID_nanoPeg_LicenseString, 0x1788f0b0, 0x5985, 0x4a19, 0xb7, 0xfe, 0x8a, 0xac, 0x1b, 0xfc, 0x14, 0xb3);\n\n\n\n\n\nSetting the license to unlock filter\n\n\nThe filter can be unlocked either through a license key entry in the windows registry or\nby setting the license key through COM interface ICodecProp::SetProperty with the\nproperty \nIID_nanoPeg_LicenseString\n as first parameter. The second license parameter\nhas to be a wide/unicode string!\n\n\nDecoder Configuration Registry Settings\n\n\nThe decoder is able to perform an adaptive frame dropping and deblocking depending on the quality / delay messages received from the downstream renderer filter.\n\n\nKey: HKEY_CURRENT_USER\\Software\\nanocosmos\\nh264dec\n\n\nFrame dropping / skipping mode\n\n\nDetermines the behaviour in the case of timing / performance problems.\n  * Value name:     DroppingMode\n  * Value type:             REG_DWORD\n  * Valid values:\n    * 0 - no frames are skipped\n    * 1 - skip non reference frames only (B-frames)\n    * 2 - skip non intra frames only (P- and B-frames), \ndefault value\n\n\nDeblocking mode\n\n\nDetermines the deblocking behaviour.\n  * Value name:     DeblockingMode\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - disable deblocking\n    * 1 - auto, decoder will reduce deblocking temporarily in the case of performance problems, \ndefault value\n\n    * 2 - always perform full deblocking\n    * 3 - always perform deblocking on reference frames only\n\n\nOutput color space selection\n\n\nForces the filter to use a desired output color format. If no or no valid value is set, the output color format will be negotiated with the downstream renderer filter (usually YV12).\n  * Value name:     ForceOutputFourCC\n  * Value type:         REG_SZ / String\n  * Valid values:\n    * YV12,\n    * I420,\n    * IYUV,\n    * YUY2,\n    * RGB32,\n    * RGB24,\n    * RGB565,\n    * ARGB32\n\n\nDeinterlacing Mode\n\n\nDetermines the deinterlacing behaviour.\n  * Value name:        DeinterlacingMode\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 0 - disabled\n    * 1 - duplicate, \ndefault value\n\n    * 2 - blend\n    * 3 - median\n    * 4 - edge detection\n    * 5 - median threshold\n    * 6 - content adaptive vertical temporal\n\n\nDirectShow Editing Services (DES) Return Mode\n\n\nReceive returns HRESULT error values if Deliver fails. Needs to be enabled for DES.\n  * Value name:        DESReturnMode\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 0 - disabled, \ndefault value\n\n    * 1 - enabled\n\n\nThreading Mode\n\n\nDetermines the threading behaviour. Auto detection or number of decoding threads.\n  * Value name:        DESReturnMode\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 0 - auto detect number of cpus, \ndefault value\n\n    * 1-8 - set number of decoding threads\n\n\nOutput resolution alignment\n\n\nDetermines the alignment of the output resolution,\nto adjust it to multiples of this value.\n  * Value name:        OutputAlignment\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 1-16, \ndefault value:\n 4\n\n\nDebug-Log Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\nh264dec.ax\n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\n  * Value name:     LogToFile\n  * Value type:     REG_SZ / String\n  * Valid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed.\n  * Value name:     TRACE\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - minimal logging\n    * \u2026\n    * 9 - maximal logging", 
            "title": "H.264 Video Decoder Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#nanocosmos_h264_video_decoder_filter", 
            "text": "", 
            "title": "nanocosmos H.264 Video Decoder Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#module_version", 
            "text": "nanocosmos H.264/AVC Direct Show Video Decoder Filter\\\nnh264dec.ax  Version 2.5.2.4  The nanocosmos H.264/AVC Video Decoder support streams in baseline, main and high profile. It is highly optimized for use on hyper-threading and multi core systems.", 
            "title": "Module / Version"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#connectivity", 
            "text": "The input is accepting connections to splitter filters or combined source/splitter filters matching the following media types:  Major types:\n  * MEDIATYPE_Video  Subtypes:\n  * FourCCs:\n    * H264, h264,\n    * AVC1, avc1,\n    * X264, x264,\n    * VSSH, vssh,\n    * MEDIASUBTYPE_H264: {8D2D71CB-243F-45E3-B2D8-5FD7967EC09B}  Formats:\n  * FORMAT_VideoInfo,\n  * FORMAT_VideoInfo2,\n  * FORMAT_MPEG2_VIDEO  The output supports these media types:  Major types:\n  * MEDIATYPE_Video  Subtypes:\n  * MEDIASUBTYPE_YV12,\n  * MEDIASUBTYPE_I420,\n  * MEDIASUBTYPE_IYUV,\n  * MEDIASUBTYPE_YUY2,\n  * MEDIASUBTYPE_RGB24,\n  * MEDIASUBTYPE_RGB32,\n  * MEDIASUBTYPE_ARGB32,\n  * MEDIASUBTYPE_RGB565,  Formats:\n  * FORMAT_VideoInfo\n  * FORMAT_VideoInfo2", 
            "title": "Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#filter_guids", 
            "text": "//%% Filter GUID\n//%% {264DA7DD-CE74-472d-A2FD-796A1F0A379C}\nDEFINE_GUID(CLSID_NANO_H264_DECODER, 0x264DA7DD, 0xCE74, 0x472d, 0xA2, 0xFD, 0x79, 0x6A, 0x1F, 0x0A, 0x37, 0x9C);\n\n//%% Configuration interface ICodecProp\n//%% {0F817204-82C8-4c12-884A-F45FB2F33A6E}\nDEFINE_GUID(IID_ICodecProp, 0xf817204, 0x82c8, 0x4c12, 0x88, 0x4a, 0xf4, 0x5f, 0xb2, 0xf3, 0x3a, 0x6e);\n\n//%% ICodecProp: IID_nanoPeg_LicenseString\n//%% type: BSTR / Unicode string\n//%% Set license string to unlock filter\n//%% {1788F0B0-5985-4a19-B7FE-8AAC1BFC14B3}\nDEFINE_GUID(IID_nanoPeg_LicenseString, 0x1788f0b0, 0x5985, 0x4a19, 0xb7, 0xfe, 0x8a, 0xac, 0x1b, 0xfc, 0x14, 0xb3);", 
            "title": "Filter GUIDs"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#setting_the_license_to_unlock_filter", 
            "text": "The filter can be unlocked either through a license key entry in the windows registry or\nby setting the license key through COM interface ICodecProp::SetProperty with the\nproperty  IID_nanoPeg_LicenseString  as first parameter. The second license parameter\nhas to be a wide/unicode string!", 
            "title": "Setting the license to unlock filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#decoder_configuration_registry_settings", 
            "text": "The decoder is able to perform an adaptive frame dropping and deblocking depending on the quality / delay messages received from the downstream renderer filter.  Key: HKEY_CURRENT_USER\\Software\\nanocosmos\\nh264dec", 
            "title": "Decoder Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#frame_dropping_skipping_mode", 
            "text": "Determines the behaviour in the case of timing / performance problems.\n  * Value name:     DroppingMode\n  * Value type:             REG_DWORD\n  * Valid values:\n    * 0 - no frames are skipped\n    * 1 - skip non reference frames only (B-frames)\n    * 2 - skip non intra frames only (P- and B-frames),  default value", 
            "title": "Frame dropping / skipping mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#deblocking_mode", 
            "text": "Determines the deblocking behaviour.\n  * Value name:     DeblockingMode\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - disable deblocking\n    * 1 - auto, decoder will reduce deblocking temporarily in the case of performance problems,  default value \n    * 2 - always perform full deblocking\n    * 3 - always perform deblocking on reference frames only", 
            "title": "Deblocking mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#output_color_space_selection", 
            "text": "Forces the filter to use a desired output color format. If no or no valid value is set, the output color format will be negotiated with the downstream renderer filter (usually YV12).\n  * Value name:     ForceOutputFourCC\n  * Value type:         REG_SZ / String\n  * Valid values:\n    * YV12,\n    * I420,\n    * IYUV,\n    * YUY2,\n    * RGB32,\n    * RGB24,\n    * RGB565,\n    * ARGB32", 
            "title": "Output color space selection"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#deinterlacing_mode", 
            "text": "Determines the deinterlacing behaviour.\n  * Value name:        DeinterlacingMode\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 0 - disabled\n    * 1 - duplicate,  default value \n    * 2 - blend\n    * 3 - median\n    * 4 - edge detection\n    * 5 - median threshold\n    * 6 - content adaptive vertical temporal", 
            "title": "Deinterlacing Mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#directshow_editing_services_des_return_mode", 
            "text": "Receive returns HRESULT error values if Deliver fails. Needs to be enabled for DES.\n  * Value name:        DESReturnMode\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 0 - disabled,  default value \n    * 1 - enabled", 
            "title": "DirectShow Editing Services (DES) Return Mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#threading_mode", 
            "text": "Determines the threading behaviour. Auto detection or number of decoding threads.\n  * Value name:        DESReturnMode\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 0 - auto detect number of cpus,  default value \n    * 1-8 - set number of decoding threads", 
            "title": "Threading Mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#output_resolution_alignment", 
            "text": "Determines the alignment of the output resolution,\nto adjust it to multiples of this value.\n  * Value name:        OutputAlignment\n  * Value type:          REG_DWORD\n  * Valid values:\n    * 1-16,  default value:  4", 
            "title": "Output resolution alignment"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#debug-log_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\nh264dec.ax", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\n  * Value name:     LogToFile\n  * Value type:     REG_SZ / String\n  * Valid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_decoder/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed.\n  * Value name:     TRACE\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - minimal logging\n    * \u2026\n    * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/", 
            "text": "nanocosmos MPEG-2 Broadcast DirectShow SDK\n\n\nIntroduction\n\n\nNanocosmos MPEG-2 Broadcast DirectShow  SDK enables you to perform high quality and high performance video coding for the latest generation video and audio coding standards. It is intended to develop video encoding / transcoding applications based on Microsoft DirectShow technology.\\  \n\n\nMajor Features\n\n\n\n\nEncoding of MPEG-2 video streams in Main and High profile\n\n\nHighly optimized software coding with support for latest CPU  technology by Intel and AMD (SSE2/SSE3/SSE4 and Dual-Core/Core-Duo, AMD Athlon64\n\n\nReal-time Encoding from Capture cards is supported\n\n\nFile Reader for MOV and MXF\n\n\nFile Writer for MOV and MXF\n\n\n\n\nDocumentation\n\n\nThe SDK\\doc folder contains further documentation for the following filters:\n\n\n\n\nMPEG-2 Video Decoder\n\n\nMPEG-2 Video Encoder\n\n\nQuickTime Source\n\n\nQuickTime Writer\n\n\nMXF Reader\n\n\nMXF Writer\n\n\n\n\n//Contact us for additional modules for MPEG Audio Encoding and Multiplexing//\n\n\nFilter components\n\n\n\n\n\n\nnanocosmos MPEG-2 Video Decoder\n\n\n\n\nModule:       nmpeg2dec.ax\n\n\nCLSID:        {223784F1-4D9F-45A5-8281-8F9AFCABD904}\n\n\n\n\n\n\n\n\nnanocosmos MPEG-2 Video Encoder\n\n\n\n\nModule:       nmpeg2enc.ax\n\n\nCLSID:        {2327A344-BECC-4F4F-89C6-DABDC5143832}\n\n\n\n\n\n\n\n\nnanocosmos QuickTime Source Filter\n\n\n\n\nModule:       nqtsource.ax\n\n\nCLSID:        {53718C99-F067-4609-8184-A8A92A241A5A}\n\n\n\n\n\n\n\n\nnanocosmos Quicktime Writer (MPEG2/Broadcast)\n\n\n\n\nModule:       nmp4mux.ax\n\n\nCLSID:        {C2FB362B-CE6C-4797-BC16-F81976DFEF61}\n\n\n\n\n\n\n\n\nnanocosmos MXF Reader\n\n\n\n\nModule:       nh264dec.ax\n\n\nCLSID:        {A3462D0F-3BD0-48A2-BD91-A1366CFC35BB}\n\n\n\n\n\n\n\n\nnanocosmos MXF Writer\n\n\n\n\nModule:       nh264dec.ax\n\n\nCLSID:        {C1C2C181-EBDA-421F-895F-638A4C5F132B}\n\n\n\n\n\n\n\n\nnanocosmos MPEG PS/TS Stream Splitter\n\n\n\n\nModule:       nmpegsplitter.ax\n\n\nCLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}\n\n\n\n\n\n\n\n\nnanocosmos File Dump Filter\n\n\n\n\nModule:       nanodump.ax\n\n\nCLSID:        {DA67A541-8FEA-11D4-A908-00105A6758CF}\n\n\n\n\n\n\n\n\nRegistering and unregistering components in the DirectShow framework\n\n\nIn order to use them, filters must be registered in the DirectShow framework. After\ninstallation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.\n\n\nFilter activation\n\n\nFilters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module\ns documents.", 
            "title": "H.264 Video Encoder Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#nanocosmos_mpeg-2_broadcast_directshow_sdk", 
            "text": "", 
            "title": "nanocosmos MPEG-2 Broadcast DirectShow SDK"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#introduction", 
            "text": "Nanocosmos MPEG-2 Broadcast DirectShow  SDK enables you to perform high quality and high performance video coding for the latest generation video and audio coding standards. It is intended to develop video encoding / transcoding applications based on Microsoft DirectShow technology.\\", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#major_features", 
            "text": "Encoding of MPEG-2 video streams in Main and High profile  Highly optimized software coding with support for latest CPU  technology by Intel and AMD (SSE2/SSE3/SSE4 and Dual-Core/Core-Duo, AMD Athlon64  Real-time Encoding from Capture cards is supported  File Reader for MOV and MXF  File Writer for MOV and MXF", 
            "title": "Major Features"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#documentation", 
            "text": "The SDK\\doc folder contains further documentation for the following filters:   MPEG-2 Video Decoder  MPEG-2 Video Encoder  QuickTime Source  QuickTime Writer  MXF Reader  MXF Writer   //Contact us for additional modules for MPEG Audio Encoding and Multiplexing//", 
            "title": "Documentation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#filter_components", 
            "text": "nanocosmos MPEG-2 Video Decoder   Module:       nmpeg2dec.ax  CLSID:        {223784F1-4D9F-45A5-8281-8F9AFCABD904}     nanocosmos MPEG-2 Video Encoder   Module:       nmpeg2enc.ax  CLSID:        {2327A344-BECC-4F4F-89C6-DABDC5143832}     nanocosmos QuickTime Source Filter   Module:       nqtsource.ax  CLSID:        {53718C99-F067-4609-8184-A8A92A241A5A}     nanocosmos Quicktime Writer (MPEG2/Broadcast)   Module:       nmp4mux.ax  CLSID:        {C2FB362B-CE6C-4797-BC16-F81976DFEF61}     nanocosmos MXF Reader   Module:       nh264dec.ax  CLSID:        {A3462D0F-3BD0-48A2-BD91-A1366CFC35BB}     nanocosmos MXF Writer   Module:       nh264dec.ax  CLSID:        {C1C2C181-EBDA-421F-895F-638A4C5F132B}     nanocosmos MPEG PS/TS Stream Splitter   Module:       nmpegsplitter.ax  CLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}     nanocosmos File Dump Filter   Module:       nanodump.ax  CLSID:        {DA67A541-8FEA-11D4-A908-00105A6758CF}", 
            "title": "Filter components"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#registering_and_unregistering_components_in_the_directshow_framework", 
            "text": "In order to use them, filters must be registered in the DirectShow framework. After\ninstallation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.", 
            "title": "Registering and unregistering components in the DirectShow framework"
        }, 
        {
            "location": "/nanostream/directshow/directshow_h264_video_encoder/#filter_activation", 
            "text": "Filters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module s documents.", 
            "title": "Filter activation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/", 
            "text": "nanocosmos MPEG-2 Broadcast DirectShow SDK\n\n\nIntroduction\n\n\nNanocosmos MPEG-2 Broadcast DirectShow  SDK enables you to perform high quality and high performance video coding for the latest generation video and audio coding standards. It is intended to develop video encoding / transcoding applications based on Microsoft DirectShow technology.\\  \n\n\nMajor Features\n\n\n\n\nEncoding of MPEG-2 video streams in Main and High profile\n\n\nHighly optimized software coding with support for latest CPU  technology by Intel and AMD (SSE2/SSE3/SSE4 and Dual-Core/Core-Duo, AMD Athlon64\n\n\nReal-time Encoding from Capture cards is supported\n\n\nFile Reader for MOV and MXF\n\n\nFile Writer for MOV and MXF\n\n\n\n\nDocumentation\n\n\nThe SDK\\doc folder contains further documentation for the following filters:\n\n\n\n\nMPEG-2 Video Decoder\n\n\nMPEG-2 Video Encoder\n\n\nQuickTime Source\n\n\nQuickTime Writer\n\n\nMXF Reader\n\n\nMXF Writer\n\n\n\n\n//Contact us for additional modules for MPEG Audio Encoding and Multiplexing//\n\n\nFilter components\n\n\n\n\n\n\nnanocosmos MPEG-2 Video Decoder\n\n\n\n\nModule:       nmpeg2dec.ax\n\n\nCLSID:        {223784F1-4D9F-45A5-8281-8F9AFCABD904}\n\n\n\n\n\n\n\n\nnanocosmos MPEG-2 Video Encoder\n\n\n\n\nModule:     nmpeg2enc.ax\n\n\n\n\nCLSID:      {2327A344-BECC-4F4F-89C6-DABDC5143832}\n\n\n\n\n\n\nnanocosmos QuickTime Source Filter\n\n\n\n\nModule:       nqtsource.ax\n\n\nCLSID:        {53718C99-F067-4609-8184-A8A92A241A5A}\n\n\n\n\n\n\n\n\nnanocosmos Quicktime Writer (MPEG2/Broadcast)\n\n\n\n\nModule:       nmp4mux.ax\n\n\nCLSID:        {C2FB362B-CE6C-4797-BC16-F81976DFEF61}\n\n\n\n\n\n\n\n\nnanocosmos MXF Reader\n\n\n\n\nModule:       nh264dec.ax\n\n\nCLSID:        {A3462D0F-3BD0-48A2-BD91-A1366CFC35BB}\n\n\n\n\n\n\n\n\nnanocosmos MXF Writer\n\n\n\n\nModule:       nh264dec.ax\n\n\nCLSID:        {C1C2C181-EBDA-421F-895F-638A4C5F132B}\n\n\n\n\n\n\n\n\nnanocosmos MPEG PS/TS Stream Splitter\n\n\n\n\nModule:       nmpegsplitter.ax\n\n\nCLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}\n\n\n\n\n\n\n\n\nnanocosmos File Dump Filter\n\n\n\n\nModule:       nanodump.ax\n\n\nCLSID:        {DA67A541-8FEA-11D4-A908-00105A6758CF}\n\n\n\n\n\n\n\n\nRegistering and unregistering components in the DirectShow framework\n\n\nIn order to use them, filters must be registered in the DirectShow framework. After\ninstallation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.\n\n\nFilter activation\n\n\nFilters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module\ns documents.", 
            "title": "MPEG2 Broadcast SDK"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#nanocosmos_mpeg-2_broadcast_directshow_sdk", 
            "text": "", 
            "title": "nanocosmos MPEG-2 Broadcast DirectShow SDK"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#introduction", 
            "text": "Nanocosmos MPEG-2 Broadcast DirectShow  SDK enables you to perform high quality and high performance video coding for the latest generation video and audio coding standards. It is intended to develop video encoding / transcoding applications based on Microsoft DirectShow technology.\\", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#major_features", 
            "text": "Encoding of MPEG-2 video streams in Main and High profile  Highly optimized software coding with support for latest CPU  technology by Intel and AMD (SSE2/SSE3/SSE4 and Dual-Core/Core-Duo, AMD Athlon64  Real-time Encoding from Capture cards is supported  File Reader for MOV and MXF  File Writer for MOV and MXF", 
            "title": "Major Features"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#documentation", 
            "text": "The SDK\\doc folder contains further documentation for the following filters:   MPEG-2 Video Decoder  MPEG-2 Video Encoder  QuickTime Source  QuickTime Writer  MXF Reader  MXF Writer   //Contact us for additional modules for MPEG Audio Encoding and Multiplexing//", 
            "title": "Documentation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#filter_components", 
            "text": "nanocosmos MPEG-2 Video Decoder   Module:       nmpeg2dec.ax  CLSID:        {223784F1-4D9F-45A5-8281-8F9AFCABD904}     nanocosmos MPEG-2 Video Encoder   Module:     nmpeg2enc.ax   CLSID:      {2327A344-BECC-4F4F-89C6-DABDC5143832}    nanocosmos QuickTime Source Filter   Module:       nqtsource.ax  CLSID:        {53718C99-F067-4609-8184-A8A92A241A5A}     nanocosmos Quicktime Writer (MPEG2/Broadcast)   Module:       nmp4mux.ax  CLSID:        {C2FB362B-CE6C-4797-BC16-F81976DFEF61}     nanocosmos MXF Reader   Module:       nh264dec.ax  CLSID:        {A3462D0F-3BD0-48A2-BD91-A1366CFC35BB}     nanocosmos MXF Writer   Module:       nh264dec.ax  CLSID:        {C1C2C181-EBDA-421F-895F-638A4C5F132B}     nanocosmos MPEG PS/TS Stream Splitter   Module:       nmpegsplitter.ax  CLSID:        {0994D1E8-B697-47DE-B1E3-36D26937D5B4}     nanocosmos File Dump Filter   Module:       nanodump.ax  CLSID:        {DA67A541-8FEA-11D4-A908-00105A6758CF}", 
            "title": "Filter components"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#registering_and_unregistering_components_in_the_directshow_framework", 
            "text": "In order to use them, filters must be registered in the DirectShow framework. After\ninstallation all filters are registered. To re-register or unregister components, execute the RegisterFilters.bat or UnregisterFilters.bat batch files from the SDK/bin folder.", 
            "title": "Registering and unregistering components in the DirectShow framework"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_broadcast_sdk/#filter_activation", 
            "text": "Filters can be activated by installing a license key to windows registry or programmatically by setting a license key through the software interface of a filter instance. How to set license keys to unlock filters is described in the module s documents.", 
            "title": "Filter activation"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/", 
            "text": "nanocosmos MPEG-2 HD/SD Video Decoder Filter\n\n\nDirectShow Filter / Module\n\n\nnanocosmos MPEG-2 HD/SD Video Decoder\\\nModule Name: nmpeg2dec.ax\n\n\nConnectivity\n\n\nThe input is accepting connections to splitter filters or combined source/splitter filters matching the following media types:\n\n\nMajor types:\n  * MEDIATYPE_Video\n\n\nSubtypes:\n  * MEDIASUBTYPE_MPEG2\n\n\nFormats:\n  * FORMAT_VideoInfo,\n  * FORMAT_VideoInfo2,\n  * FORMAT_MPEG2_VIDEO\n\n\nThe output supports these media types:\n\n\nMajor types:\n  * MEDIATYPE_Video\n\n\nSubtypes:\n  * MEDIASUBTYPE_YV12,\n  * MEDIASUBTYPE_I420,\n  * MEDIASUBTYPE_IYUV,\n  * MEDIASUBTYPE_YUY2,\n  * MEDIASUBTYPE_RGB24,\n  * MEDIASUBTYPE_RGB32,\n  * MEDIASUBTYPE_ARGB32,\n  * MEDIASUBTYPE_RGB565,\n\n\nFormats:\n  * FORMAT_VideoInfo\n  * FORMAT_VideoInfo2\n\n\nFilter GUIDs\n\n\n// Filter GUID\n// {223784F1-4D9F-45a5-8281-8F9AFCABD904}\nDEFINE_GUID(CLSID_NANO_MPEG2_DECODER, 0x223784f1, 0x4d9f, 0x45a5, 0x82, 0x81, 0x8f, 0x9a, 0xfc, 0xab, 0xd9, 0x4);\n\n// Configuration interface ICodecProp\n// {0F817204-82C8-4c12-884A-F45FB2F33A6E}\nDEFINE_GUID(IID_ICodecProp, 0xf817204, 0x82c8, 0x4c12, 0x88, 0x4a, 0xf4, 0x5f, 0xb2, 0xf3, 0x3a, 0x6e);\n\n// ICodecProp: IID_nanoPeg_LicenseString\n// type: BSTR / Unicode string\n// Set license string to unlock filter\n// {1788F0B0-5985-4a19-B7FE-8AAC1BFC14B3}\nDEFINE_GUID(IID_nanoPeg_LicenseString, 0x1788f0b0, 0x5985, 0x4a19, 0xb7, 0xfe, 0x8a, 0xac, 0x1b, 0xfc, 0x14, 0xb3);\n\n\n\n\nSetting the license to unlock filter\n\n\nThe filter can be unlocked either through a license key entry in the windows registry or\nby setting the license key through COM interface ICodecProp::SetProperty with the\nproperty \nIID_nanoPeg_LicenseString\n as first parameter. The second license parameter\nhas to be a wide/unicode string!\n\n\nDecoder Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\nanocosmos\\nmpeg2dec\n\n\nFrame dropping / skipping mode\n\n\nDetermines the behaviour in the case of timing / performance problems.\n  * Value name:     DroppingMode\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - disabled\n    * 1 - enabled, \ndefault value\n\n\nOutput color space selection\n\n\nForces the filter to use a desired output color format. If no or no valid value is set, the output color format will be negotiated with the downstream renderer filter (usually YV12).\n  * Value name:     ForceOutputFourCC\n  * Value type:             REG_SZ / String\n  * Valid values:\n    * YV12,\n    * I420,\n    * IYUV,\n    * YUY2,\n    * RGB32,\n    * RGB24,\n    * RGB565,\n    * ARGB32\n\n\nDeinterlacing Mode\n\n\nDetermines the deinterlacing behaviour.\n  * Value name: DeinterlacingMode\n  * Value type:   REG_DWORD\n  * Valid values:\n    * 0 - disabled\n    * 1 - duplicate, \ndefault value\n\n    * 2 - blend\n    * 3 - median\n    * 4 - edge detection\n    * 5 - median threshold\n    * 6 - content adaptive vertical temporal\n\n\nDirectShow Editing Services (DES) Return Mode\n\n\nReceive returns HRESULT error values if Deliver fails.\\\nNeeds to be enabled for DES.\n  * Value name: DESReturnMode\n  * Value type: REG_DWORD\n  * Valid values:\n    * 0 - disabled, \ndefault value\n\n    * 1 - enabled\n\n\nThreading Mode\n\n\nDetermines the threading behaviour.\\\nAuto detection or number of decoding threads.\n  * Value name: DESReturnMode\n  * Value type: REG_DWORD\n  * Valid values:\n    * 0 - auto detect number of cpus, \ndefault value\n\n    * 1-8 - set number of decoding threads\n\n\nOutput resolution alignment\n\n\nDetermines the alignment of the output resolution,\nto adjust it to multiples of this value.\n  * Value name: OutputAlignment\n  * Value type: REG_DWORD\n  * Valid values:\n    * 1-16, \ndefault value:\n 4\n\n\nDebug-Log Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\nmpeg2dec.ax\n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\n  * Value name:     LogToFile\n  * Value type:             REG_SZ / String\n  * Valid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed.\n  * Value name:     TRACE\n  * Value type:             REG_DWORD\n  * Valid values:\n    * 0 - minimal logging\n    * \u2026\n    * 9 - maximal logging", 
            "title": "MPEG2 Video Decoder"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#nanocosmos_mpeg-2_hdsd_video_decoder_filter", 
            "text": "", 
            "title": "nanocosmos MPEG-2 HD/SD Video Decoder Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#directshow_filter_module", 
            "text": "nanocosmos MPEG-2 HD/SD Video Decoder\\\nModule Name: nmpeg2dec.ax", 
            "title": "DirectShow Filter / Module"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#connectivity", 
            "text": "The input is accepting connections to splitter filters or combined source/splitter filters matching the following media types:  Major types:\n  * MEDIATYPE_Video  Subtypes:\n  * MEDIASUBTYPE_MPEG2  Formats:\n  * FORMAT_VideoInfo,\n  * FORMAT_VideoInfo2,\n  * FORMAT_MPEG2_VIDEO  The output supports these media types:  Major types:\n  * MEDIATYPE_Video  Subtypes:\n  * MEDIASUBTYPE_YV12,\n  * MEDIASUBTYPE_I420,\n  * MEDIASUBTYPE_IYUV,\n  * MEDIASUBTYPE_YUY2,\n  * MEDIASUBTYPE_RGB24,\n  * MEDIASUBTYPE_RGB32,\n  * MEDIASUBTYPE_ARGB32,\n  * MEDIASUBTYPE_RGB565,  Formats:\n  * FORMAT_VideoInfo\n  * FORMAT_VideoInfo2", 
            "title": "Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#filter_guids", 
            "text": "// Filter GUID\n// {223784F1-4D9F-45a5-8281-8F9AFCABD904}\nDEFINE_GUID(CLSID_NANO_MPEG2_DECODER, 0x223784f1, 0x4d9f, 0x45a5, 0x82, 0x81, 0x8f, 0x9a, 0xfc, 0xab, 0xd9, 0x4);\n\n// Configuration interface ICodecProp\n// {0F817204-82C8-4c12-884A-F45FB2F33A6E}\nDEFINE_GUID(IID_ICodecProp, 0xf817204, 0x82c8, 0x4c12, 0x88, 0x4a, 0xf4, 0x5f, 0xb2, 0xf3, 0x3a, 0x6e);\n\n// ICodecProp: IID_nanoPeg_LicenseString\n// type: BSTR / Unicode string\n// Set license string to unlock filter\n// {1788F0B0-5985-4a19-B7FE-8AAC1BFC14B3}\nDEFINE_GUID(IID_nanoPeg_LicenseString, 0x1788f0b0, 0x5985, 0x4a19, 0xb7, 0xfe, 0x8a, 0xac, 0x1b, 0xfc, 0x14, 0xb3);", 
            "title": "Filter GUIDs"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#setting_the_license_to_unlock_filter", 
            "text": "The filter can be unlocked either through a license key entry in the windows registry or\nby setting the license key through COM interface ICodecProp::SetProperty with the\nproperty  IID_nanoPeg_LicenseString  as first parameter. The second license parameter\nhas to be a wide/unicode string!", 
            "title": "Setting the license to unlock filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#decoder_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\nanocosmos\\nmpeg2dec", 
            "title": "Decoder Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#frame_dropping_skipping_mode", 
            "text": "Determines the behaviour in the case of timing / performance problems.\n  * Value name:     DroppingMode\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - disabled\n    * 1 - enabled,  default value", 
            "title": "Frame dropping / skipping mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#output_color_space_selection", 
            "text": "Forces the filter to use a desired output color format. If no or no valid value is set, the output color format will be negotiated with the downstream renderer filter (usually YV12).\n  * Value name:     ForceOutputFourCC\n  * Value type:             REG_SZ / String\n  * Valid values:\n    * YV12,\n    * I420,\n    * IYUV,\n    * YUY2,\n    * RGB32,\n    * RGB24,\n    * RGB565,\n    * ARGB32", 
            "title": "Output color space selection"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#deinterlacing_mode", 
            "text": "Determines the deinterlacing behaviour.\n  * Value name: DeinterlacingMode\n  * Value type:   REG_DWORD\n  * Valid values:\n    * 0 - disabled\n    * 1 - duplicate,  default value \n    * 2 - blend\n    * 3 - median\n    * 4 - edge detection\n    * 5 - median threshold\n    * 6 - content adaptive vertical temporal", 
            "title": "Deinterlacing Mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#directshow_editing_services_des_return_mode", 
            "text": "Receive returns HRESULT error values if Deliver fails.\\\nNeeds to be enabled for DES.\n  * Value name: DESReturnMode\n  * Value type: REG_DWORD\n  * Valid values:\n    * 0 - disabled,  default value \n    * 1 - enabled", 
            "title": "DirectShow Editing Services (DES) Return Mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#threading_mode", 
            "text": "Determines the threading behaviour.\\\nAuto detection or number of decoding threads.\n  * Value name: DESReturnMode\n  * Value type: REG_DWORD\n  * Valid values:\n    * 0 - auto detect number of cpus,  default value \n    * 1-8 - set number of decoding threads", 
            "title": "Threading Mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#output_resolution_alignment", 
            "text": "Determines the alignment of the output resolution,\nto adjust it to multiples of this value.\n  * Value name: OutputAlignment\n  * Value type: REG_DWORD\n  * Valid values:\n    * 1-16,  default value:  4", 
            "title": "Output resolution alignment"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#debug-log_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\nmpeg2dec.ax", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\n  * Value name:     LogToFile\n  * Value type:             REG_SZ / String\n  * Valid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_decoder/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed.\n  * Value name:     TRACE\n  * Value type:             REG_DWORD\n  * Valid values:\n    * 0 - minimal logging\n    * \u2026\n    * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/", 
            "text": "nanocosmos MPEG-2 Video Encoder Filter\n\n\nDirectShow Filter / Module\n\n\nnanocosmos MPEG-2 Video Encoder\\\nModule Name: nmpeg2enc.ax\n\n\nDirectShow Connectivity\n\n\nThe input is accepting connections to video source, capture and decoder filters matching the following media types:\n\n\nMajor types:\n  * MEDIATYPE_Video\n\n\nSubtypes:\n  * MEDIASUBTYPE_YV12,\n  * MEDIASUBTYPE_I420,\n  * MEDIASUBTYPE_YUY2,\n  * MEDIASUBTYPE_UYVY,\n  * MEDIASUBTYPE_HDYC,\n  * MEDIASUBTYPE_RGB24,\n  * MEDIASUBTYPE_RGB32,\n  * MEDIASUBTYPE_ARGB32,\n  * MEDIASUBTYPE_RGB565,\n\n\nFormats:\n  * FORMAT_VideoInfo\n  * FORMAT_VideoInfo2\n\n\nThe output supports these media types:\n\n\nMajor types:\n  * MEDIATYPE_Video\n\n\nSubtypes:\n  * MEDIASUBTYPE_MPEG2_VIDEO,\n  * MEDIASUBTYPE_mpgv\n\n\nFormats:\n  * FORMAT_MPEG2_VIDEO,\n  * FORMAT_NONE\n\n\nConfiguration\n\n\nThe encoding configuration may be set by using either the property page or the COM Interface INanoCodecOpts as declared in header file INanoCodecOpts.h .\n\n\n// Filter GUID\n// {2327A344-BECC-4f4f-89C6-DABDC5143832}\nDEFINE_GUID(CLSID_NANO_MPEG2_ENCODER, 0x2327a344, 0xbecc, 0x4f4f, 0x89, 0xc6, 0xda, 0xbd, 0xc5, 0x14, 0x38, 0x32);\n\n// Property Page GUID\n// {8A84396A-277A-4835-9EB5-719863194DC9}\nDEFINE_GUID(CLSID_NANO_MPEG2_ENCODER_PROPPAGE, 0x8a84396a, 0x277a, 0x4835, 0x9e, 0xb5, 0x71, 0x98, 0x63, 0x19, 0x4d, 0xc9);\n\n// Configuration Interface GUID\n// {698E0F57-B828-4c40-8867-095FF49F77D6}\nDEFINE_GUID(IID_INanoCodecOpts, 0x698e0f57, 0xb828, 0x4c40, 0x88, 0x67, 0x9, 0x5f, 0xf4, 0x9f, 0x77, 0xd6);\n\n// Configuration interface ICodecProp\n// {0F817204-82C8-4c12-884A-F45FB2F33A6E}\nDEFINE_GUID(IID_ICodecProp, 0xf817204, 0x82c8, 0x4c12, 0x88, 0x4a, 0xf4, 0x5f, 0xb2, 0xf3, 0x3a, 0x6e);\n\n// ICodecProp: IID_nanoPeg_LicenseString\n// type: BSTR / Unicode string\n// Set license string to unlock filter\n// {1788F0B0-5985-4a19-B7FE-8AAC1BFC14B3}\nDEFINE_GUID(IID_nanoPeg_LicenseString, 0x1788f0b0, 0x5985, 0x4a19, 0xb7, 0xfe, 0x8a, 0xac, 0x1b, 0xfc, 0x14, 0xb3);\n\n\n\n\nSetting the license to unlock filter\n\n\nThe filter can be unlocked either through a license key entry in the windows registry or\nby setting the license key through COM interface ICodecProp::SetProperty with the\nproperty \nIID_nanoPeg_LicenseString\n as first parameter. The second license parameter\nhas to be a wide/unicode string!\n\n\nCommon Encoder Settings\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault values\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nprofile, level\n\n\nMain Profile, Main Level\n\n\nMPEG-2 Profile and Level\n\n\n\n\n\n\nbase_video.bitrate_kb\n\n\nProfile and Level dependend\n\n\nVideo Bitrate in kBits/second\n\n\n\n\n\n\nbase_video.resolution.width\n\n\n0 - use input width\n\n\nPicture Coding Width\n\n\n\n\n\n\nbase_video.resolution.height\n\n\n0 - use input height\n\n\nPicture Coding Height\n\n\n\n\n\n\nchroma_format_idc\n\n\n0 - I420, 1 - I422\n\n\n[0,1] Chroma Format\n\n\n\n\n\n\nrate_method\n\n\n0 - CBR, 1 - VBR\n\n\n[0,1] Rate Control Mode\n\n\n\n\n\n\ndistance_i\n\n\n12\n\n\nIntra Frame Distance / GOP len.\n\n\n\n\n\n\ndistance_p\n\n\n3\n\n\nP Frame Distance\n\n\n\n\n\n\n\n\nConfiguration through INanoCodecOpts interface\n\n\n\n\nVersion check by calling //GetCodecOptsVersion//// //(optional)\n\n\nInstanciating a parameter structure of type //MPDX4_MPEG2EncoderParams//\n\n\nInitializing the parameter struct by calling //InitCodecOptions// will set all parameters to default values for the selected profile and level\n\n\nSetting custom values for resolution and bitrate\n\n\nApplying settings by calling //SetCodecOptions//\n\n\n\n\nHere a code snippet without error handling to show configuration for IMX 50 format:\n\n\n#include \nmpeg2_enc_params.h\n\n\nHRESULT hr = S_OK;\n\n// Query INanoCodecOpts interface from IBaseFilter interface\n// of MPEG-2 Encoder filter\nCComQIPtr\nINanoCodecOpts\n pNanoCodecOpts = pBaseFilter;\n\nMPDX4_MPEG2EncoderParams mpeg2EncParams;\nmemset(\nmpeg2EncParams, 0, sizeof(MPDX4_MPEG2EncoderParams));\n\n// Set desired profile and level values\nmpeg2EncParams.profile = MPDX4_MPEG2_PROFILE_422IMX;\nmpeg2EncParams.level = MPDX4_MPEG2_LEVEL_MAIN;\n\n// Intialize the parameter struct according to profile and level set\nhr = pNanoCodecOpts-\nInitCodecOptions((MPDX4_BaseCodecOpts*) \nmpeg2EncParams, INANOCODECOPTS_VERSION);\n\n// Set custom parameter values\n// Bitrate\nmpeg2EncParams.base_video.bitrate_kb = 50000; // IMX 50\n// If resize is needed\nmpeg2EncParams.base_video.resolution.width = 720;\nmpeg2EncParams.base_video.resolution.height = 608;\n\n// Apply settings and finish configuration\nhr = pNanoCodecOpts-\nSetCodecOptions((MPDX4_BaseCodecOpts*) \nmpeg2EncParams, INANOCODECOPTS_VERSION);\n\n\n\n\nConfiguration through DirectShow  filter property page\n\n\nThe filter\ns property page offers a subset of encoding parameters, containing the most important options.\n\n\n\n\nDebug-Log Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\nmpeg2enc.ax\n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\n  * Value name:     LogToFile\n  * Value type:            REG_SZ / String\n  * Valid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed.\n  * Value name:     TRACE\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - minimal logging\n    * \u2026\n    * 9 - maximal logging", 
            "title": "MPEG2 Video Encoder"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#nanocosmos_mpeg-2_video_encoder_filter", 
            "text": "", 
            "title": "nanocosmos MPEG-2 Video Encoder Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#directshow_filter_module", 
            "text": "nanocosmos MPEG-2 Video Encoder\\\nModule Name: nmpeg2enc.ax", 
            "title": "DirectShow Filter / Module"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#directshow_connectivity", 
            "text": "The input is accepting connections to video source, capture and decoder filters matching the following media types:  Major types:\n  * MEDIATYPE_Video  Subtypes:\n  * MEDIASUBTYPE_YV12,\n  * MEDIASUBTYPE_I420,\n  * MEDIASUBTYPE_YUY2,\n  * MEDIASUBTYPE_UYVY,\n  * MEDIASUBTYPE_HDYC,\n  * MEDIASUBTYPE_RGB24,\n  * MEDIASUBTYPE_RGB32,\n  * MEDIASUBTYPE_ARGB32,\n  * MEDIASUBTYPE_RGB565,  Formats:\n  * FORMAT_VideoInfo\n  * FORMAT_VideoInfo2  The output supports these media types:  Major types:\n  * MEDIATYPE_Video  Subtypes:\n  * MEDIASUBTYPE_MPEG2_VIDEO,\n  * MEDIASUBTYPE_mpgv  Formats:\n  * FORMAT_MPEG2_VIDEO,\n  * FORMAT_NONE", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#configuration", 
            "text": "The encoding configuration may be set by using either the property page or the COM Interface INanoCodecOpts as declared in header file INanoCodecOpts.h .  // Filter GUID\n// {2327A344-BECC-4f4f-89C6-DABDC5143832}\nDEFINE_GUID(CLSID_NANO_MPEG2_ENCODER, 0x2327a344, 0xbecc, 0x4f4f, 0x89, 0xc6, 0xda, 0xbd, 0xc5, 0x14, 0x38, 0x32);\n\n// Property Page GUID\n// {8A84396A-277A-4835-9EB5-719863194DC9}\nDEFINE_GUID(CLSID_NANO_MPEG2_ENCODER_PROPPAGE, 0x8a84396a, 0x277a, 0x4835, 0x9e, 0xb5, 0x71, 0x98, 0x63, 0x19, 0x4d, 0xc9);\n\n// Configuration Interface GUID\n// {698E0F57-B828-4c40-8867-095FF49F77D6}\nDEFINE_GUID(IID_INanoCodecOpts, 0x698e0f57, 0xb828, 0x4c40, 0x88, 0x67, 0x9, 0x5f, 0xf4, 0x9f, 0x77, 0xd6);\n\n// Configuration interface ICodecProp\n// {0F817204-82C8-4c12-884A-F45FB2F33A6E}\nDEFINE_GUID(IID_ICodecProp, 0xf817204, 0x82c8, 0x4c12, 0x88, 0x4a, 0xf4, 0x5f, 0xb2, 0xf3, 0x3a, 0x6e);\n\n// ICodecProp: IID_nanoPeg_LicenseString\n// type: BSTR / Unicode string\n// Set license string to unlock filter\n// {1788F0B0-5985-4a19-B7FE-8AAC1BFC14B3}\nDEFINE_GUID(IID_nanoPeg_LicenseString, 0x1788f0b0, 0x5985, 0x4a19, 0xb7, 0xfe, 0x8a, 0xac, 0x1b, 0xfc, 0x14, 0xb3);", 
            "title": "Configuration"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#setting_the_license_to_unlock_filter", 
            "text": "The filter can be unlocked either through a license key entry in the windows registry or\nby setting the license key through COM interface ICodecProp::SetProperty with the\nproperty  IID_nanoPeg_LicenseString  as first parameter. The second license parameter\nhas to be a wide/unicode string!", 
            "title": "Setting the license to unlock filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#common_encoder_settings", 
            "text": "Parameter  Default values  Description      profile, level  Main Profile, Main Level  MPEG-2 Profile and Level    base_video.bitrate_kb  Profile and Level dependend  Video Bitrate in kBits/second    base_video.resolution.width  0 - use input width  Picture Coding Width    base_video.resolution.height  0 - use input height  Picture Coding Height    chroma_format_idc  0 - I420, 1 - I422  [0,1] Chroma Format    rate_method  0 - CBR, 1 - VBR  [0,1] Rate Control Mode    distance_i  12  Intra Frame Distance / GOP len.    distance_p  3  P Frame Distance", 
            "title": "Common Encoder Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#configuration_through_inanocodecopts_interface", 
            "text": "Version check by calling //GetCodecOptsVersion//// //(optional)  Instanciating a parameter structure of type //MPDX4_MPEG2EncoderParams//  Initializing the parameter struct by calling //InitCodecOptions// will set all parameters to default values for the selected profile and level  Setting custom values for resolution and bitrate  Applying settings by calling //SetCodecOptions//   Here a code snippet without error handling to show configuration for IMX 50 format:  #include  mpeg2_enc_params.h \n\nHRESULT hr = S_OK;\n\n// Query INanoCodecOpts interface from IBaseFilter interface\n// of MPEG-2 Encoder filter\nCComQIPtr INanoCodecOpts  pNanoCodecOpts = pBaseFilter;\n\nMPDX4_MPEG2EncoderParams mpeg2EncParams;\nmemset( mpeg2EncParams, 0, sizeof(MPDX4_MPEG2EncoderParams));\n\n// Set desired profile and level values\nmpeg2EncParams.profile = MPDX4_MPEG2_PROFILE_422IMX;\nmpeg2EncParams.level = MPDX4_MPEG2_LEVEL_MAIN;\n\n// Intialize the parameter struct according to profile and level set\nhr = pNanoCodecOpts- InitCodecOptions((MPDX4_BaseCodecOpts*)  mpeg2EncParams, INANOCODECOPTS_VERSION);\n\n// Set custom parameter values\n// Bitrate\nmpeg2EncParams.base_video.bitrate_kb = 50000; // IMX 50\n// If resize is needed\nmpeg2EncParams.base_video.resolution.width = 720;\nmpeg2EncParams.base_video.resolution.height = 608;\n\n// Apply settings and finish configuration\nhr = pNanoCodecOpts- SetCodecOptions((MPDX4_BaseCodecOpts*)  mpeg2EncParams, INANOCODECOPTS_VERSION);", 
            "title": "Configuration through INanoCodecOpts interface"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#configuration_through_directshow_filter_property_page", 
            "text": "The filter s property page offers a subset of encoding parameters, containing the most important options.", 
            "title": "Configuration through DirectShow  filter property page"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#debug-log_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\nmpeg2enc.ax", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\n  * Value name:     LogToFile\n  * Value type:            REG_SZ / String\n  * Valid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg2_video_encoder/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed.\n  * Value name:     TRACE\n  * Value type:     REG_DWORD\n  * Valid values:\n    * 0 - minimal logging\n    * \u2026\n    * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg_audio_encoder/", 
            "text": "Configure encoder settings\n\n\nHere is a pseudo sample code, showing how to set the bitrate for the encoder - m_pEncMpegA is the instance of the mpeg audio encoder:\n\n\nICodecAPI* encoderInt;\nm_pEncMpegA-\nQueryInterface(IID_ICodecAPI, (void **) \nencoderInt);\nVARIANT v;\nv.vt = VT_INT;\nv.intVal = 128000;    // 128 kb\nencoderInt-\nSetValue(\nPROPID_nanoMPAEBitrate, \nvt);\n...\nencoderInt-\nRelease();\n\n/code", 
            "title": "MPEG Audio Encoder"
        }, 
        {
            "location": "/nanostream/directshow/directshow_mpeg_audio_encoder/#configure_encoder_settings", 
            "text": "Here is a pseudo sample code, showing how to set the bitrate for the encoder - m_pEncMpegA is the instance of the mpeg audio encoder:  ICodecAPI* encoderInt;\nm_pEncMpegA- QueryInterface(IID_ICodecAPI, (void **)  encoderInt);\nVARIANT v;\nv.vt = VT_INT;\nv.intVal = 128000;    // 128 kb\nencoderInt- SetValue( PROPID_nanoMPAEBitrate,  vt);\n...\nencoderInt- Release(); /code", 
            "title": "Configure encoder settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/", 
            "text": "QuickTime IMX Video Playback Components\n\n\nFor QuickTime und DirectShow\n\n\nThe QuickTime IMX Playback components allow easy playback of QuickTime IMX video files with Windows or MacOS systems.\\\nIMX is also known as SMPTE D-10 and is based on the MPEG compression technology.\n\n\nThe Codec Packet contains the following components:\n  * QuickTime IMX Source Direct Show Package\n  * QuickTime IMX Codec for Quicktime Player\n\n\nQuickTime IMX Source Direct Show Package\n\n\nThe QuickTime IMX Source DirectShow Package allows playback of QuickTime IMX video files with all WindowsMediaPlayer-/DirectShow based applications. Installation of the Quicktime System is not required.\\\nDirect Show Filters included:\n\n\nFile Reader for QuickTime IMX Video Files\n\n\nOutput Media Types:\n\n\n\n\nMajortype:\n\n\nVideo,\n\n\n\n\n\n\n\n\nSub Type:\n\n\n\n\nMPEG2_Video\n\n\n\n\n\n\n\n\nMajortype:\n\n\n\n\nAudio:\n\n\n\n\n\n\nSub Type:\n\n\nPCMAudio\n\n\n\n\n\n\n\n\nIMX Video Decoder Filter\n\n\nFormats:\n  * MPEG-2 IMX 30 (FourCC: mx3p)\n  * MPEG-2 IMX 40 (FourCC: mx4p)\n  * MPEG-2 IMX 50 (FourCC: mx5p)\n\n\n\n\nDirect Show Example\n\n\nQuickTime IMX Decoder for Quicktime Player\n\n\nQuickTime IMX Codec Package can be used in all Quicktime based applications, for example QuickTime Player.\n\n\nSupported input Formats:\n\n\n\n\nQuickTime Movie File\n\n\nIMX Compression (MPEG-2 IMX 30 (FourCC: mx3p)\n\n\nMPEG-2 IMX 40 (FourCC: mx4p)\n\n\nMPEG-2 IMX 50 (FourCC: mx5p))\n\n\n\n\nSupported Decoding Parameters:\n\n\n\n\nBitrates from up to 100 mbps\n\n\nFrame Rates: 23.976, 24, 25, 29.97, and 30 frames/sec up to 60 fields/sec.\n\n\n\n\nThe Codec is a QuickTime Decoder Component developed by nanocosmos.\n\n\n\n\nQuicktime IMX Example\n\n\nSupported input Formats:\n\n\n\n\nQuickTime Movie File\n\n\nIMX Compression (MPEG-2 IMX 30 (FourCC: mx3p)\n\n\nMPEG-2 IMX 40 (FourCC: \nmx4p\n)\n\n\nMPEG-2 IMX 50 (FourCC: mx5p))\n\n\n\n\n\n\n\n\nSupported Decoding Parameters:\n\n\n\n\nBitrates from up to 100 mbps\n\n\nFrame Rates: 23.976, 24, 25, 29.97, and 30 frames/sec up to 60 fields/sec.", 
            "title": "Quicktime IMX Playback"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#quicktime_imx_video_playback_components", 
            "text": "For QuickTime und DirectShow  The QuickTime IMX Playback components allow easy playback of QuickTime IMX video files with Windows or MacOS systems.\\\nIMX is also known as SMPTE D-10 and is based on the MPEG compression technology.  The Codec Packet contains the following components:\n  * QuickTime IMX Source Direct Show Package\n  * QuickTime IMX Codec for Quicktime Player", 
            "title": "QuickTime IMX Video Playback Components"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#quicktime_imx_source_direct_show_package", 
            "text": "The QuickTime IMX Source DirectShow Package allows playback of QuickTime IMX video files with all WindowsMediaPlayer-/DirectShow based applications. Installation of the Quicktime System is not required.\\\nDirect Show Filters included:", 
            "title": "QuickTime IMX Source Direct Show Package"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#file_reader_for_quicktime_imx_video_files", 
            "text": "Output Media Types:   Majortype:  Video,     Sub Type:   MPEG2_Video     Majortype:   Audio:    Sub Type:  PCMAudio", 
            "title": "File Reader for QuickTime IMX Video Files"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#imx_video_decoder_filter", 
            "text": "Formats:\n  * MPEG-2 IMX 30 (FourCC: mx3p)\n  * MPEG-2 IMX 40 (FourCC: mx4p)\n  * MPEG-2 IMX 50 (FourCC: mx5p)   Direct Show Example", 
            "title": "IMX Video Decoder Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#quicktime_imx_decoder_for_quicktime_player", 
            "text": "QuickTime IMX Codec Package can be used in all Quicktime based applications, for example QuickTime Player.", 
            "title": "QuickTime IMX Decoder for Quicktime Player"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#supported_input_formats", 
            "text": "QuickTime Movie File  IMX Compression (MPEG-2 IMX 30 (FourCC: mx3p)  MPEG-2 IMX 40 (FourCC: mx4p)  MPEG-2 IMX 50 (FourCC: mx5p))", 
            "title": "Supported input Formats:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#supported_decoding_parameters", 
            "text": "Bitrates from up to 100 mbps  Frame Rates: 23.976, 24, 25, 29.97, and 30 frames/sec up to 60 fields/sec.   The Codec is a QuickTime Decoder Component developed by nanocosmos.   Quicktime IMX Example", 
            "title": "Supported Decoding Parameters:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#supported_input_formats_1", 
            "text": "QuickTime Movie File  IMX Compression (MPEG-2 IMX 30 (FourCC: mx3p)  MPEG-2 IMX 40 (FourCC:  mx4p )  MPEG-2 IMX 50 (FourCC: mx5p))", 
            "title": "Supported input Formats:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_quicktime_imx/#supported_decoding_parameters_1", 
            "text": "Bitrates from up to 100 mbps  Frame Rates: 23.976, 24, 25, 29.97, and 30 frames/sec up to 60 fields/sec.", 
            "title": "Supported Decoding Parameters:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/", 
            "text": "nanocosmos RTMP Source Filter\n\n\nIntroduction\n\n\n\n\nDirectShow filter for RTMP Downstreaming / Playback\n\n\nSupported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n\n\nSupported Formats: H.264 + AAC + MP3\n\n\n\n\nModule Name / Version\n\n\nModule: nRTMPSource.ax \\\nVersion: 1.3.1.1\n\n\nDirectShow Connectivity\n\n\nThe output pins are accepting connections matching the following media types:\n\n\n\n\nMajor types:\n\n\nMEDIATYPE_Video\n\n\n\n\n\n\nSubtypes:\n\n\nFourCCs: H264, h264\n\n\n\n\n\n\nFormats:\n\n\nFORMAT_MPEG2_VIDEO,\n\n\nFORMAT_NONE\n\n\n\n\n\n\nMajor types:\n\n\nAAC:     MEDIATYPE_Audio\n\n\nMP3:     MEDIATYPE_Audio\n\n\nSPEEX: MEDIATYPE Ogg Stream\n\n\n\n\n\n\nSubtypes:\n\n\nAAC:    MEDIASUBTYPE_AAC,  FourCC: 0x000000FF,\n\n\nMP3:     MEDIASUBTYPE_MP3,  FourCC: 0x00000055\n\n\nSPEEX:  MEDIASUBTYPE_None\n\n\n\n\n\n\nFormats:\n\n\nAAC, MP3:   FORMAT_WaveFormatEx,\n\n\nSPEEX:  FORMAT_Speex\n\n\n\n\nFilter GUIDs\n\n\n// Filter GUID\n// {440E11F2-FB35-4699-809B-157C390E9238}\nDEFINE_GUID(CLSID_NANO_RTMP_SOURCE, 0x440e11f2, 0xfb35, 0x4699, 0x80, 0x9b, 0x15, 0x7c, 0x39, 0xe, 0x92, 0x38);\n\n// Property Page GUID\n// {7A05E2F3-9258-4952-920A-54F6AE6A0D66}\nDEFINE_GUID(CLSID_NANO_RTMP_SOURCE_PROPPAGE, 0x7a05e2f3, 0x9258, 0x4952, 0x92, 0xa, 0x54, 0xf6, 0xae, 0x6a, 0xd, 0x66);\n\n\n\n\nConfiguration through COM Interface\n\n\nThe streaming url can be set by using standard DirectShow interface IFileSourceFilter .\n\n\nURL format\n\n\nrtmp:%%//%% [ IP:port ]/[ application name]/[ stream name]\\\nIf no port is specified, standard rtmp port 1935 will be used.\n\n\nExample:\\\nrtmp:%%//%%127.0.0.1:1935/live/myStream\n\n\nFollowing options can be set by using standard DirectShow interface ICodecAPI.\nSee DirectShow documentation for usage of ICodecAPI interface.\n\n\nConnect to nanocosmos decoder filters only\n\n\nValue Type:     Integer, Variant::intVal, VT_INT\\\nValid values:   yes: 1, no: 0 \\\nGUID:\n\n\n// {FB5005A0-3231-4171-A218-A3A3431D7790}\nDEFINE_GUID(PROPID_nanoSourceConnectToNanoDecodersOnly, 0xfb5005a0, 0x3231, 0x4171, 0xa2, 0x18, 0xa3, 0xa3, 0x43, 0x1d, 0x77, 0x90);\n\n\n\n\nBuffering delay in milliseconds\n\n\nUnder low bandwidth conditions a higher value leads to smoother playback.\n\n\nValue Type:     Integer, Variant::intVal, VT_INT\\\nValid values:   0\nINT32_MAX\\\nGUID:\n\n\n// {3641DC07-82CD-40b0-9293-DCBE25E0C274}\nDEFINE_GUID(PROPID_nanoSourceBufferingDelay, 0x3641dc07, 0x82cd, 0x40b0, 0x92, 0x93, 0xdc, 0xbe, 0x25, 0xe0, 0xc2, 0x74);\n\n\n\n\nBuffering mode\n\n\nUse this GUID to configure the buffering mode\\\nValue Type:     VT_I4 / VARIANT::intVal, get/set \\\nValid values:   0 - Fill buffer once on start, 1 - Refill buffer always if empty\\\nDefault value: 1\\\n\n\n// {AB91A1D9-6701-4133-8733-6EB3A20E9583}\nDEFINE_GUID(PROPID_nanoSourceBufferingMode, 0xab91a1d9, 0x6701, 0x4133, 0x87, 0x33, 0x6e, 0xb3, 0xa2, 0xe, 0x95, 0x83);\n\n\n\n\nReceive timeout in milliseconds\n\n\nA stream is stopped if no data is present for this amount of time Overrides registry value ReceiveTimeout\nValue Type:      Integer, Variant::intVal, VT_I4\\\nValid values:   1000\nINT (1-30 seconds), default: 5000 (5 seconds)\\\nGUID:\n\n\n// {767B756C-A55B-4fd9-88F8-159B338207ED}\nDEFINE_GUID(PROPID_nanoRTMPReceiveTimeoutMs, 0x767b756c, 0xa55b, 0x4fd9, 0x88, 0xf8, 0x15, 0x9b, 0x33, 0x82, 0x7, 0xed);\n\n\n\n\nStream format detection timeout in milliseconds\n\n\nThe detection is stopped after this amount of time, even if less than 2 streams found Overrides registry value DetectStreamFormatTimeout\nValue Type:     Integer, Variant::intVal, VT_I4\\\nValid values:   1000\nINT32_MAX, default: 10000 (10 seconds)\\\nGUID:\n\n\n// {7400166F-8140-4b81-8B3E-C97CB7D972DF}\nDEFINE_GUID(PROPID_nanoRTMPDetectStreamFormatTimeoutMs, 0x7400166f, 0x8140, 0x4b81, 0x8b, 0x3e, 0xc9, 0x7c, 0xb7, 0xd9, 0x72, 0xdf);\n\n\n\n\nConfiguration through DirectShow filter property page\n\n\n\n\nConfiguration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\nanocosmos\\nRTMPSource\n\n\nReceive timeout\n\n\nA stream is stopped if no data is present for this this amount of time\\\nValue name:     DetectStreamFormatTimeout\\\nValue type:     REG_DWORD\\\nValid values:   1 second - 30 seconds, default: 5 seconds\n\n\nStream format detection mode\n\n\nDetermines if stream format settings are detected from the RTMP network stream or from registry preset values below.\\\nValue name:     DetectStreamFormatMode\\\nValue type:     REG_DWORD\\\nValid values:   0: Detect from stream (default), 1: Use registry preset\\\n\n\nStream format detection timeout\n\n\nTimeout for format detection in seconds\\\nValue name:     DetectStreamFormatTimeout\\\nValue type:     REG_DWORD\\\nValid values:   1 second - 30 seconds, default: 10 seconds\n\n\nAudio Codec\n\n\nSets the audio codec if DetectStreamFormatMode = 1.\\\nValue name:     AudioCodec\\\nValue type:     REG_DWORD\\\nValid values:   0: Auto/Default(AAC), 1: AAC, 2: MP3, 3: SPEEX\n\n\nAudio Channels\n\n\nSets the number of audio channels if DetectStreamFormatMode = 1.\\\nValue name:     AudioChannels\\\nValue type:     REG_DWORD\\\nValid values:   0: Auto/Default(Stereo), 1: Mono, 2: Stereo\n\n\nAudio Bitlength\n\n\nSets the number of bits per audio sample if DetectStreamFormatMode = 1.\\\nValue name:     AudioBitlength\\\nValue type:     REG_DWORD\\\nValid values:   0: Auto/Default(16 Bit), 1: 8 Bit, 2: 16 Bit\n\n\nAudio Samplerate\n\n\nSets the audio samplerate if DetectStreamFormatMode = 1.\\\nCodecs support different sampling rates and have different default values!!!\\\nValue name:     AudioRate\\\nValue type:     REG_DWORD\\\n\n\nValid values AAC:\n\n\n\n\n0: Auto/Default(44100),\n\n\n1: 8000 ,\n\n\n2: 11025,\n\n\n3: 12000,\n\n\n4: 16000,\n\n\n5: 22050,\n\n\n6: 24000\n\n\n7: 32000,\n\n\n8: 44100,\n\n\n9: 48000,\n\n\n10: 64000,\n\n\n11: 88200,\n\n\n12: 96000\n\n\n\n\nValid values MP3:\n\n\n\n\n0: Auto/Default(44100),\n\n\n1: 5500 ,\n\n\n2: 11025,\n\n\n3: 22050,\n\n\n4: 44100\n\n\n\n\nValid values SPEEX:\n\n\n\n\n0: Auto/Default(16000),\n\n\n1: 8000 ,\n\n\n2: 16000,\n\n\n3: 32000,\n\n\n4: 44100\nSPEEX internal sampling is usually 16000 (wideband).\nIt differs from flash\ns Microphone::rate value!\n\n\n\n\nDebug-Log Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\nRTMPSource.ax  \n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "RTMP Source"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#nanocosmos_rtmp_source_filter", 
            "text": "", 
            "title": "nanocosmos RTMP Source Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#introduction", 
            "text": "DirectShow filter for RTMP Downstreaming / Playback  Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server  Supported Formats: H.264 + AAC + MP3", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#module_name_version", 
            "text": "Module: nRTMPSource.ax \\\nVersion: 1.3.1.1", 
            "title": "Module Name / Version"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#directshow_connectivity", 
            "text": "The output pins are accepting connections matching the following media types:   Major types:  MEDIATYPE_Video    Subtypes:  FourCCs: H264, h264    Formats:  FORMAT_MPEG2_VIDEO,  FORMAT_NONE    Major types:  AAC:     MEDIATYPE_Audio  MP3:     MEDIATYPE_Audio  SPEEX: MEDIATYPE Ogg Stream    Subtypes:  AAC:    MEDIASUBTYPE_AAC,  FourCC: 0x000000FF,  MP3:     MEDIASUBTYPE_MP3,  FourCC: 0x00000055  SPEEX:  MEDIASUBTYPE_None    Formats:  AAC, MP3:   FORMAT_WaveFormatEx,  SPEEX:  FORMAT_Speex", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#filter_guids", 
            "text": "// Filter GUID\n// {440E11F2-FB35-4699-809B-157C390E9238}\nDEFINE_GUID(CLSID_NANO_RTMP_SOURCE, 0x440e11f2, 0xfb35, 0x4699, 0x80, 0x9b, 0x15, 0x7c, 0x39, 0xe, 0x92, 0x38);\n\n// Property Page GUID\n// {7A05E2F3-9258-4952-920A-54F6AE6A0D66}\nDEFINE_GUID(CLSID_NANO_RTMP_SOURCE_PROPPAGE, 0x7a05e2f3, 0x9258, 0x4952, 0x92, 0xa, 0x54, 0xf6, 0xae, 0x6a, 0xd, 0x66);", 
            "title": "Filter GUIDs"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#configuration_through_com_interface", 
            "text": "The streaming url can be set by using standard DirectShow interface IFileSourceFilter .", 
            "title": "Configuration through COM Interface"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#url_format", 
            "text": "rtmp:%%//%% [ IP:port ]/[ application name]/[ stream name]\\\nIf no port is specified, standard rtmp port 1935 will be used.  Example:\\\nrtmp:%%//%%127.0.0.1:1935/live/myStream  Following options can be set by using standard DirectShow interface ICodecAPI.\nSee DirectShow documentation for usage of ICodecAPI interface.", 
            "title": "URL format"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#connect_to_nanocosmos_decoder_filters_only", 
            "text": "Value Type:     Integer, Variant::intVal, VT_INT\\\nValid values:   yes: 1, no: 0 \\\nGUID:  // {FB5005A0-3231-4171-A218-A3A3431D7790}\nDEFINE_GUID(PROPID_nanoSourceConnectToNanoDecodersOnly, 0xfb5005a0, 0x3231, 0x4171, 0xa2, 0x18, 0xa3, 0xa3, 0x43, 0x1d, 0x77, 0x90);", 
            "title": "Connect to nanocosmos decoder filters only"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#buffering_delay_in_milliseconds", 
            "text": "Under low bandwidth conditions a higher value leads to smoother playback.  Value Type:     Integer, Variant::intVal, VT_INT\\\nValid values:   0 INT32_MAX\\\nGUID:  // {3641DC07-82CD-40b0-9293-DCBE25E0C274}\nDEFINE_GUID(PROPID_nanoSourceBufferingDelay, 0x3641dc07, 0x82cd, 0x40b0, 0x92, 0x93, 0xdc, 0xbe, 0x25, 0xe0, 0xc2, 0x74);", 
            "title": "Buffering delay in milliseconds"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#buffering_mode", 
            "text": "Use this GUID to configure the buffering mode\\\nValue Type:     VT_I4 / VARIANT::intVal, get/set \\\nValid values:   0 - Fill buffer once on start, 1 - Refill buffer always if empty\\\nDefault value: 1\\  // {AB91A1D9-6701-4133-8733-6EB3A20E9583}\nDEFINE_GUID(PROPID_nanoSourceBufferingMode, 0xab91a1d9, 0x6701, 0x4133, 0x87, 0x33, 0x6e, 0xb3, 0xa2, 0xe, 0x95, 0x83);", 
            "title": "Buffering mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#receive_timeout_in_milliseconds", 
            "text": "A stream is stopped if no data is present for this amount of time Overrides registry value ReceiveTimeout\nValue Type:      Integer, Variant::intVal, VT_I4\\\nValid values:   1000 INT (1-30 seconds), default: 5000 (5 seconds)\\\nGUID:  // {767B756C-A55B-4fd9-88F8-159B338207ED}\nDEFINE_GUID(PROPID_nanoRTMPReceiveTimeoutMs, 0x767b756c, 0xa55b, 0x4fd9, 0x88, 0xf8, 0x15, 0x9b, 0x33, 0x82, 0x7, 0xed);", 
            "title": "Receive timeout in milliseconds"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#stream_format_detection_timeout_in_milliseconds", 
            "text": "The detection is stopped after this amount of time, even if less than 2 streams found Overrides registry value DetectStreamFormatTimeout\nValue Type:     Integer, Variant::intVal, VT_I4\\\nValid values:   1000 INT32_MAX, default: 10000 (10 seconds)\\\nGUID:  // {7400166F-8140-4b81-8B3E-C97CB7D972DF}\nDEFINE_GUID(PROPID_nanoRTMPDetectStreamFormatTimeoutMs, 0x7400166f, 0x8140, 0x4b81, 0x8b, 0x3e, 0xc9, 0x7c, 0xb7, 0xd9, 0x72, 0xdf);", 
            "title": "Stream format detection timeout in milliseconds"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#configuration_through_directshow_filter_property_page", 
            "text": "", 
            "title": "Configuration through DirectShow filter property page"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\nanocosmos\\nRTMPSource", 
            "title": "Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#receive_timeout", 
            "text": "A stream is stopped if no data is present for this this amount of time\\\nValue name:     DetectStreamFormatTimeout\\\nValue type:     REG_DWORD\\\nValid values:   1 second - 30 seconds, default: 5 seconds", 
            "title": "Receive timeout"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#stream_format_detection_mode", 
            "text": "Determines if stream format settings are detected from the RTMP network stream or from registry preset values below.\\\nValue name:     DetectStreamFormatMode\\\nValue type:     REG_DWORD\\\nValid values:   0: Detect from stream (default), 1: Use registry preset\\", 
            "title": "Stream format detection mode"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#stream_format_detection_timeout", 
            "text": "Timeout for format detection in seconds\\\nValue name:     DetectStreamFormatTimeout\\\nValue type:     REG_DWORD\\\nValid values:   1 second - 30 seconds, default: 10 seconds", 
            "title": "Stream format detection timeout"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#audio_codec", 
            "text": "Sets the audio codec if DetectStreamFormatMode = 1.\\\nValue name:     AudioCodec\\\nValue type:     REG_DWORD\\\nValid values:   0: Auto/Default(AAC), 1: AAC, 2: MP3, 3: SPEEX", 
            "title": "Audio Codec"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#audio_channels", 
            "text": "Sets the number of audio channels if DetectStreamFormatMode = 1.\\\nValue name:     AudioChannels\\\nValue type:     REG_DWORD\\\nValid values:   0: Auto/Default(Stereo), 1: Mono, 2: Stereo", 
            "title": "Audio Channels"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#audio_bitlength", 
            "text": "Sets the number of bits per audio sample if DetectStreamFormatMode = 1.\\\nValue name:     AudioBitlength\\\nValue type:     REG_DWORD\\\nValid values:   0: Auto/Default(16 Bit), 1: 8 Bit, 2: 16 Bit", 
            "title": "Audio Bitlength"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#audio_samplerate", 
            "text": "Sets the audio samplerate if DetectStreamFormatMode = 1.\\\nCodecs support different sampling rates and have different default values!!!\\\nValue name:     AudioRate\\\nValue type:     REG_DWORD\\", 
            "title": "Audio Samplerate"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#valid_values_aac", 
            "text": "0: Auto/Default(44100),  1: 8000 ,  2: 11025,  3: 12000,  4: 16000,  5: 22050,  6: 24000  7: 32000,  8: 44100,  9: 48000,  10: 64000,  11: 88200,  12: 96000", 
            "title": "Valid values AAC:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#valid_values_mp3", 
            "text": "0: Auto/Default(44100),  1: 5500 ,  2: 11025,  3: 22050,  4: 44100", 
            "title": "Valid values MP3:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#valid_values_speex", 
            "text": "0: Auto/Default(16000),  1: 8000 ,  2: 16000,  3: 32000,  4: 44100\nSPEEX internal sampling is usually 16000 (wideband).\nIt differs from flash s Microphone::rate value!", 
            "title": "Valid values SPEEX:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#debug-log_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\nRTMPSource.ax", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_source/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/", 
            "text": "RTMP Network Renderer \n Writer\n\n\nPurpose\n\n\nWriting RTMP compatible video/audio streams over a network connection\n\n\nDirectShow filter for streaming to Wowza and Flash Media Servers\n\n\n\n\nSupported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n\n\nSupported Formats: H.264 + AAC\n\n\n\n\nModule / Version\n\n\nnanocosmos RTMP Network Writer \\\nnRtmpRenderer.ax  Version 3.0.3.1\n\n\nDirectShow Connectivity\n\n\nThe RTMP Writer is implemented as a \nRenderer Filter\n, which means it only has 2 input pins for compressed video and audio and no output pin.\\\nThe input is accepting connections matching the following media types:\n\n\n\n\nPin 1 Media Types:\n\n\nMEDIATYPE_Video\n\n\n\n\n\n\nPin 1 Media Subtypes:\n\n\nFourCCs: H264, h264\n\n\n\n\n\n\nPin 1 Formats:\n\n\nFORMAT_MPEG2_VIDEO,\n\n\nFORMAT_NONE\n\n\n\n\n\n\nPin 2 Major Media Types:\n\n\nMEDIATYPE_Audio\n\n\n\n\n\n\nPin 2 Media Subtypes:\n\n\nMEDIASUBTYPE_AAC,  FourCC: 0x000000FF\n\n\n\n\n\n\nPin 2 Formats:\n\n\nFORMAT_WaveFormatEx,\n\n\nFORMAT_NONE\n\n\n\n\n\n\n\n\nConfiguration\n\n\nThe configuration may be set by using either the property page or the COM-Interface IRTMPOptions as declared in header file RTMPWriterOptions.h.\n\n\n// Filter Guids\n// {B4FB59C5-983B-4d96-9204-F8B0E46704EE}\nDEFINE_GUID(CLSID_NANO_RTMP_WRITER,  0xb4fb59c5, 0x983b, 0x4d96, 0x92, 0x4, 0xf8, 0xb0, 0xe4, 0x67, 0x4, 0xee);\n\n// Property Page GUID\n// {EFC673DE-E20E-4699-8331-9522C5DF7A6D}\nDEFINE_GUID(CLSID_NANO_RTMP_WRITER_PROPPAGE, 0xefc673de, 0xe20e, 0x4699, 0x83, 0x31, 0x95, 0x22, 0xc5, 0xdf, 0x7a, 0x6d);\n\n// Configuration Interface GUID\n// IID_IRTMPOptions interface\n// {B8AF4593-BE31-449c-8485-3E6D65CBC1FE}\nDEFINE_GUID(IID_IRTMPOptions, 0xb8af4593, 0xbe31, 0x449c, 0x84, 0x85, 0x3e, 0x6d, 0x65, 0xcb, 0xc1, 0xfe)\n\n\n\n\nThe streaming url can be set by using standard DirectShow interface IFileSinkFilter .\n\n\nConfiguration with DirectShow filter property page\n\n\n\n\nThe filter\ns property page offers a subset of encoding parameters, containing the most important options.\n\n\nURL formatting:\\\nrtmp:// [hostname / IP address]/[application]+[stream name]\n\n\nfor example:\\\nrtmp://127.0.0.1/live+myStream\n\n\nwith:\\\nIP address: 127.0.0.1\\\nApplication name: live,   Stream name: myStream\n\n\nConnection Test\n\n\nConnect/Disconnect buttons. Allows to connect before starting the graph and disconnect during the streaming (this stops the running graph).\n\n\nRTMP Authentication\n\n\nRTMP Authentication expects a user name and a password for unlocking access to the Media Server.\nThis has been verified with Flash Media Server (3.x and 4) and Wowza Media Server (2.x).\nCDNs are supported on a case-by-case basis.\nSpecial tuning as been made for some CDN access\n(e.g. Limelight).\n\n\nAutomatic Reconnection:\n\n\nAttempts to restore network connection after n seconds to the server in case of network interrupts. During the reconnect attempts the graph still playing. 0 means no attempts to reconnect to server.\n\n\nAdvanced Configuration Options\n\n\nThe advanced options should be handled carefully. They can severely affect network and streaming performance. Contact support if you want to fine tune any settings.\n\n\n//\nBuffering:\n//\n\n\nData Flow:  RTMP multiplexed data -\n application buffer -\n socket buffer -\n network.\n\n\nThere are 2 buffer types:\n  * Socket level buffer\nSize of the network socket buffer, much dependent on the underlying network architecture\n\n\n\n\nApplication level buffer (Output Buffer Size, Output packet size),  0=no buffer\nAffects bandwidth utilization, prevents bitrate changes and puts the sending process to a separate thread.\n\n\n\n\nAdvanced Settings:\n\n\n\n\nLive Mode:\n\n\nTurns on/off blocking of input pins.  (should be off by default)\n\n\n\n\n\n\nTCP No Delay:\n\n\nActivates the TCP_NODELAY option for TCP transmission (\nNagle Algorithm\n)\n\n\n\n\n\n\nTimecode Options:\n\n\nSends Time Code in RTMP Meta Data\n\n\n\n\n\n\nAllow B Frames:\n\n\nshould be on\n\n\n\n\n\n\nReduces the buffer/delay in H.264 Main Profile without B Frames. No effect in Baseline Mode.\n\n\nTimecode Options:\n\n\nsend Time Code in RTMP Meta Data\n\n\n\n\n\n\n\n\nConnection Status Notification\n\n\nThere are two possibilities to get the status of the connection to the server:\n\n\n\n\nEvent messages are sent via IMediaEventSink with the event code EC_NANO_RTMP_WRITER_STATUS  declared in RTMPWriterOptions.h (#define EC_NANO_RTMP_WRITER_STATUS EC_USER+181).  A message is sent when the connection state changes. The different states are represented by (also declared in RTMPWriterOptions.h):\n\n\nRTMPWriterConnected=0\n\n\nRTMPWriterDisconnected=1\n\n\nRTMPWriterReconnecting=2\n\n\nUsing a callback function, which is called when the connection state changes:\n\n\nQuery for the interface IRTMPStatusNotify\n\n\nSet the callback function via SetStatusNotifyHandler()\n\n\n\n\nRtmp Writer Filter crashes when using SetStatusNotifyHandler()\n\n\nThis problem is probably caused by calling a function declared with one calling convention with a function pointer declared with a different calling convention. Here is pretty good explanation of the problem:\n  * \nhttp://stackoverflow.com/questions/301655/c-visual-studio-runtime-error\n\n  * \nhttp://stackoverflow.com/questions/10079625/c-run-time-check-failure-0-the-value-of-esp-was-not-properly-saved-across-a\n\n\nConclusion: Make sure you use __stdcall in your declaration.\n\n\nLog / Debug Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\ nRtmpRenderer.ax\n\n\nFile name\n\n\n\n\nSets the output file name. The folder must exist.\n\n\nValue name:     LogToFile\n\n\nValue type:     REG_SZ / String\n\n\nValid values:   a valid output file name to enable file logging or an empty string\n\n\n\n\nLogging level\n\n\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed.\n\n\nValue name:     TRACE\n\n\nValue type:     REG_DWORD\n\n\nValid values:\n\n\n0 - minimal logging\n\n\n\u2026\n\n\n9 - maximal logging\n\n\n\n\n\n\n\n\nContact\n\n\n//Please contact us for further information, extended services are available upon request.//\n\n\nhttp://www.nanocosmos.de\n\n\ninfo@nanocosmos.de\n\n\n(c) 2009-2012, nanocosmos gmbh", 
            "title": "RTMP Writer"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#rtmp_network_renderer_writer", 
            "text": "", 
            "title": "RTMP Network Renderer &amp; Writer"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#purpose", 
            "text": "Writing RTMP compatible video/audio streams over a network connection  DirectShow filter for streaming to Wowza and Flash Media Servers   Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server  Supported Formats: H.264 + AAC", 
            "title": "Purpose"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#module_version", 
            "text": "nanocosmos RTMP Network Writer \\\nnRtmpRenderer.ax  Version 3.0.3.1", 
            "title": "Module / Version"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#directshow_connectivity", 
            "text": "The RTMP Writer is implemented as a  Renderer Filter , which means it only has 2 input pins for compressed video and audio and no output pin.\\\nThe input is accepting connections matching the following media types:   Pin 1 Media Types:  MEDIATYPE_Video    Pin 1 Media Subtypes:  FourCCs: H264, h264    Pin 1 Formats:  FORMAT_MPEG2_VIDEO,  FORMAT_NONE    Pin 2 Major Media Types:  MEDIATYPE_Audio    Pin 2 Media Subtypes:  MEDIASUBTYPE_AAC,  FourCC: 0x000000FF    Pin 2 Formats:  FORMAT_WaveFormatEx,  FORMAT_NONE", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#configuration", 
            "text": "The configuration may be set by using either the property page or the COM-Interface IRTMPOptions as declared in header file RTMPWriterOptions.h.  // Filter Guids\n// {B4FB59C5-983B-4d96-9204-F8B0E46704EE}\nDEFINE_GUID(CLSID_NANO_RTMP_WRITER,  0xb4fb59c5, 0x983b, 0x4d96, 0x92, 0x4, 0xf8, 0xb0, 0xe4, 0x67, 0x4, 0xee);\n\n// Property Page GUID\n// {EFC673DE-E20E-4699-8331-9522C5DF7A6D}\nDEFINE_GUID(CLSID_NANO_RTMP_WRITER_PROPPAGE, 0xefc673de, 0xe20e, 0x4699, 0x83, 0x31, 0x95, 0x22, 0xc5, 0xdf, 0x7a, 0x6d);\n\n// Configuration Interface GUID\n// IID_IRTMPOptions interface\n// {B8AF4593-BE31-449c-8485-3E6D65CBC1FE}\nDEFINE_GUID(IID_IRTMPOptions, 0xb8af4593, 0xbe31, 0x449c, 0x84, 0x85, 0x3e, 0x6d, 0x65, 0xcb, 0xc1, 0xfe)  The streaming url can be set by using standard DirectShow interface IFileSinkFilter .", 
            "title": "Configuration"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#configuration_with_directshow_filter_property_page", 
            "text": "The filter s property page offers a subset of encoding parameters, containing the most important options.  URL formatting:\\\nrtmp:// [hostname / IP address]/[application]+[stream name]  for example:\\\nrtmp://127.0.0.1/live+myStream  with:\\\nIP address: 127.0.0.1\\\nApplication name: live,   Stream name: myStream", 
            "title": "Configuration with DirectShow filter property page"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#connection_test", 
            "text": "Connect/Disconnect buttons. Allows to connect before starting the graph and disconnect during the streaming (this stops the running graph).", 
            "title": "Connection Test"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#rtmp_authentication", 
            "text": "RTMP Authentication expects a user name and a password for unlocking access to the Media Server.\nThis has been verified with Flash Media Server (3.x and 4) and Wowza Media Server (2.x).\nCDNs are supported on a case-by-case basis.\nSpecial tuning as been made for some CDN access\n(e.g. Limelight).", 
            "title": "RTMP Authentication"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#automatic_reconnection", 
            "text": "Attempts to restore network connection after n seconds to the server in case of network interrupts. During the reconnect attempts the graph still playing. 0 means no attempts to reconnect to server.", 
            "title": "Automatic Reconnection:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#advanced_configuration_options", 
            "text": "The advanced options should be handled carefully. They can severely affect network and streaming performance. Contact support if you want to fine tune any settings.  // Buffering: //  Data Flow:  RTMP multiplexed data -  application buffer -  socket buffer -  network.  There are 2 buffer types:\n  * Socket level buffer\nSize of the network socket buffer, much dependent on the underlying network architecture   Application level buffer (Output Buffer Size, Output packet size),  0=no buffer\nAffects bandwidth utilization, prevents bitrate changes and puts the sending process to a separate thread.", 
            "title": "Advanced Configuration Options"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#advanced_settings", 
            "text": "Live Mode:  Turns on/off blocking of input pins.  (should be off by default)    TCP No Delay:  Activates the TCP_NODELAY option for TCP transmission ( Nagle Algorithm )    Timecode Options:  Sends Time Code in RTMP Meta Data    Allow B Frames:  should be on    Reduces the buffer/delay in H.264 Main Profile without B Frames. No effect in Baseline Mode.  Timecode Options:  send Time Code in RTMP Meta Data", 
            "title": "Advanced Settings:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#connection_status_notification", 
            "text": "There are two possibilities to get the status of the connection to the server:   Event messages are sent via IMediaEventSink with the event code EC_NANO_RTMP_WRITER_STATUS  declared in RTMPWriterOptions.h (#define EC_NANO_RTMP_WRITER_STATUS EC_USER+181).  A message is sent when the connection state changes. The different states are represented by (also declared in RTMPWriterOptions.h):  RTMPWriterConnected=0  RTMPWriterDisconnected=1  RTMPWriterReconnecting=2  Using a callback function, which is called when the connection state changes:  Query for the interface IRTMPStatusNotify  Set the callback function via SetStatusNotifyHandler()", 
            "title": "Connection Status Notification"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#rtmp_writer_filter_crashes_when_using_setstatusnotifyhandler", 
            "text": "This problem is probably caused by calling a function declared with one calling convention with a function pointer declared with a different calling convention. Here is pretty good explanation of the problem:\n  *  http://stackoverflow.com/questions/301655/c-visual-studio-runtime-error \n  *  http://stackoverflow.com/questions/10079625/c-run-time-check-failure-0-the-value-of-esp-was-not-properly-saved-across-a  Conclusion: Make sure you use __stdcall in your declaration.", 
            "title": "Rtmp Writer Filter crashes when using SetStatusNotifyHandler()"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#log_debug_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\ nRtmpRenderer.ax", 
            "title": "Log / Debug Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#file_name", 
            "text": "Sets the output file name. The folder must exist.  Value name:     LogToFile  Value type:     REG_SZ / String  Valid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed.  Value name:     TRACE  Value type:     REG_DWORD  Valid values:  0 - minimal logging  \u2026  9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_writer/#contact", 
            "text": "//Please contact us for further information, extended services are available upon request.//  http://www.nanocosmos.de  info@nanocosmos.de  (c) 2009-2012, nanocosmos gmbh", 
            "title": "Contact"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/", 
            "text": "RTMP DirectShow Events\n\n\nRTMP Writer filter provides statistics and information about the current streaming status as DirectShow events.\n\n\nAll types are declared in RTMPWriterOptions.h.\n\n\nRTMP Event Codes\n\n\n// EC_USER is defined in Windows SDK\\include\\evcode.h\n// EC_USER                             0x8000\n\n// RTMP Statistics Event Code\n#define EC_NANO_RTMP_WRITER_STATS   EC_USER+179\n\n// RTMP Status Event Code\n#define EC_NANO_RTMP_WRITER_STATUS  EC_USER+181\n\n\n\n\nRTMP Statistics Event Parameters\n\n\n// RTMP Statistics Event Parameters\n// EventCode: (long)EC_NANO_RTMP_WRITER_STATS\n// EventParam1: (LONG_PTR)rtmp_writer_stats_t* pStatistics\n// EventParam2: (LONG_PTR)(char**)ppRTMPUrl or NULL\n// The parameter pointers MUST NOT be deleted or released\n\n\n\n\nRTMP Status Event Parameters\n\n\n// RTMP Status Event Parameters\n// EventCode: (long)EC_NANO_RTMP_WRITER_STATUS\n// EventParam1: (LONG_PTR)(int*)pRtmpWriterStatus\n// EventParam2: (LONG_PTR))(char**)ppRTMPUrl or NULL\n// The parameter pointers MUST NOT be deleted or released\n\n\n\n\nRTMP Status Values\n\n\nenum RtmpWriterStatus\n{\n    RTMPWriterConnected = 0,     // RTMP Writer is connected\n    RTMPWriterDisconnected = 1,  // RTMP Writer is disconnected\n    RTMPWriterReconnecting = 2   // RTMP Writer is trying to reconnect\n};\n\n\n\n\nRTMP Statistics Data Structure\n\n\nstruct rtmp_writer_stats_t\n{\n    int output_buffer_size; // Available buffer size in bytes\n    int output_buffer_fillness; // Current buffer fillness in bytes\n\n    __int64 output_bitrate; // Data rate sent through network in bits/s\n    __int64 output_bitrate2;    // Deprecated - works only with Windows XP\n    __int64 output_bitrate3;    // Deprecated - works only with Windows XP\n\n    DWORD packetsRtt;       // Deprecated - works only with Windows XP\n    unsigned int clientBytesReceived;   // Experimental - Bytes received /\n                                        // acknowledged by client\n\n    size_t audio_packets_buffered; // Number of audio packets/frames buffered\n    size_t video_packets_buffered; // Number of video packets/frames buffered\n\n    int audio_bitrate;      // Input audio bitrate in bits/s\n    int video_bitrate;      // Input video bitrate in bits/s\n\n    int audio_packets_sent; // Number of audio packets/frames sent\n    int video_packets_sent; // Number of video packets/frames sent\n};", 
            "title": "RTMP Status & Statistics"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/#rtmp_directshow_events", 
            "text": "RTMP Writer filter provides statistics and information about the current streaming status as DirectShow events.  All types are declared in RTMPWriterOptions.h.", 
            "title": "RTMP DirectShow Events"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/#rtmp_event_codes", 
            "text": "// EC_USER is defined in Windows SDK\\include\\evcode.h\n// EC_USER                             0x8000\n\n// RTMP Statistics Event Code\n#define EC_NANO_RTMP_WRITER_STATS   EC_USER+179\n\n// RTMP Status Event Code\n#define EC_NANO_RTMP_WRITER_STATUS  EC_USER+181", 
            "title": "RTMP Event Codes"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/#rtmp_statistics_event_parameters", 
            "text": "// RTMP Statistics Event Parameters\n// EventCode: (long)EC_NANO_RTMP_WRITER_STATS\n// EventParam1: (LONG_PTR)rtmp_writer_stats_t* pStatistics\n// EventParam2: (LONG_PTR)(char**)ppRTMPUrl or NULL\n// The parameter pointers MUST NOT be deleted or released", 
            "title": "RTMP Statistics Event Parameters"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/#rtmp_status_event_parameters", 
            "text": "// RTMP Status Event Parameters\n// EventCode: (long)EC_NANO_RTMP_WRITER_STATUS\n// EventParam1: (LONG_PTR)(int*)pRtmpWriterStatus\n// EventParam2: (LONG_PTR))(char**)ppRTMPUrl or NULL\n// The parameter pointers MUST NOT be deleted or released", 
            "title": "RTMP Status Event Parameters"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/#rtmp_status_values", 
            "text": "enum RtmpWriterStatus\n{\n    RTMPWriterConnected = 0,     // RTMP Writer is connected\n    RTMPWriterDisconnected = 1,  // RTMP Writer is disconnected\n    RTMPWriterReconnecting = 2   // RTMP Writer is trying to reconnect\n};", 
            "title": "RTMP Status Values"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtmp_status_statistics/#rtmp_statistics_data_structure", 
            "text": "struct rtmp_writer_stats_t\n{\n    int output_buffer_size; // Available buffer size in bytes\n    int output_buffer_fillness; // Current buffer fillness in bytes\n\n    __int64 output_bitrate; // Data rate sent through network in bits/s\n    __int64 output_bitrate2;    // Deprecated - works only with Windows XP\n    __int64 output_bitrate3;    // Deprecated - works only with Windows XP\n\n    DWORD packetsRtt;       // Deprecated - works only with Windows XP\n    unsigned int clientBytesReceived;   // Experimental - Bytes received /\n                                        // acknowledged by client\n\n    size_t audio_packets_buffered; // Number of audio packets/frames buffered\n    size_t video_packets_buffered; // Number of video packets/frames buffered\n\n    int audio_bitrate;      // Input audio bitrate in bits/s\n    int video_bitrate;      // Input video bitrate in bits/s\n\n    int audio_packets_sent; // Number of audio packets/frames sent\n    int video_packets_sent; // Number of video packets/frames sent\n};", 
            "title": "RTMP Statistics Data Structure"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/", 
            "text": "nanocosmos RTSP Sink Filter\n\n\nModule / Version\n\n\nnanocosmos RTSP Sink \\\nnRTSPSink.ax  Version 1.1.1.0\n\n\nnanocosmos RTSP Sink\n\n\n\n\nDirectShow filter for RTSP Streaming\n\n\nSupported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n\n\nSupported Formats: H.264 + AAC\n\n\n\n\nDirectShow Connectivity\n\n\nThe input is accepting connections matching the following media types:\n  * Major types:\n    * MEDIATYPE_Video\n  * Subtypes:\n    * FourCCs: H264, h264\n  * Formats:\n    * FORMAT_MPEG2_VIDEO,\n    * FORMAT_NONE\n\n\n\n\nMajor types:\n\n\nMEDIATYPE_Audio\n\n\n\n\n\n\nSubtypes:\n\n\nMEDIASUBTYPE_AAC,  FourCC: 0x000000FF\n\n\n\n\n\n\nFormats:\n\n\nFORMAT_WaveFormatEx,\n\n\nFORMAT_NONE\n\n\n\n\n\n\n\n\nConfiguration\n\n\nThe filter configuration may be set by using either the property page or the COM Interface IRTSPSink and as declared in header file RTSPWriterOptions.h . The streaming url can be set by using standard DirectShow interface IFileSinkFilter .\n\n\n// Filter GUID\n// {2ECDA33B-81FB-4467-96C9-BD53A9ED975F}\nDEFINE_GUID(CLSID_NANO_RTSP_WRITER, 0x2ecda33b, 0x81fb, 0x4467, 0x96, 0xc9, 0xbd, 0x53, 0xa9, 0xed, 0x97, 0x5f);\n\n// Property Page GUID\n// {F387B72B-05AA-4016-8EC8-D6DA5DB36D23}\nDEFINE_GUID(CLSID_NANO_RTSP_WRITER_PROPPAGE, 0xf387b72b, 0x5aa, 0x4016, 0x8e, 0xc8, 0xd6, 0xda, 0x5d, 0xb3, 0x6d, 0x23);\n\n// Configuration Interface GUID\n// IRTSPSink\n// {F79C7B6E-E89E-415e-B3C7-A8E8BFA0278D}\nDEFINE_GUID(IID_IRTSPSink, 0xf79c7b6e, 0xe89e, 0x415e, 0xb3, 0xc7, 0xa8, 0xe8, 0xbf, 0xa0, 0x27, 0x8d);\n\n\n\n\nConfiguration through DirectShow filter property page\n\n\nThe filter\ns property page offers a subset of parameters, containing the most important options.\n\n\n\n\nURL format:\\\nrtsp:%%//%%127.0.0.1:8554/streaming\\\nrtsp:%%//%%[ IP:port ]/[ stream name]\\\n\n\nDebug-Log Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\nRTSPSink.ax  \n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "RTSP Sink"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#nanocosmos_rtsp_sink_filter", 
            "text": "", 
            "title": "nanocosmos RTSP Sink Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#module_version", 
            "text": "nanocosmos RTSP Sink \\\nnRTSPSink.ax  Version 1.1.1.0", 
            "title": "Module / Version"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#nanocosmos_rtsp_sink", 
            "text": "DirectShow filter for RTSP Streaming  Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server  Supported Formats: H.264 + AAC", 
            "title": "nanocosmos RTSP Sink"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#directshow_connectivity", 
            "text": "The input is accepting connections matching the following media types:\n  * Major types:\n    * MEDIATYPE_Video\n  * Subtypes:\n    * FourCCs: H264, h264\n  * Formats:\n    * FORMAT_MPEG2_VIDEO,\n    * FORMAT_NONE   Major types:  MEDIATYPE_Audio    Subtypes:  MEDIASUBTYPE_AAC,  FourCC: 0x000000FF    Formats:  FORMAT_WaveFormatEx,  FORMAT_NONE", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#configuration", 
            "text": "The filter configuration may be set by using either the property page or the COM Interface IRTSPSink and as declared in header file RTSPWriterOptions.h . The streaming url can be set by using standard DirectShow interface IFileSinkFilter .  // Filter GUID\n// {2ECDA33B-81FB-4467-96C9-BD53A9ED975F}\nDEFINE_GUID(CLSID_NANO_RTSP_WRITER, 0x2ecda33b, 0x81fb, 0x4467, 0x96, 0xc9, 0xbd, 0x53, 0xa9, 0xed, 0x97, 0x5f);\n\n// Property Page GUID\n// {F387B72B-05AA-4016-8EC8-D6DA5DB36D23}\nDEFINE_GUID(CLSID_NANO_RTSP_WRITER_PROPPAGE, 0xf387b72b, 0x5aa, 0x4016, 0x8e, 0xc8, 0xd6, 0xda, 0x5d, 0xb3, 0x6d, 0x23);\n\n// Configuration Interface GUID\n// IRTSPSink\n// {F79C7B6E-E89E-415e-B3C7-A8E8BFA0278D}\nDEFINE_GUID(IID_IRTSPSink, 0xf79c7b6e, 0xe89e, 0x415e, 0xb3, 0xc7, 0xa8, 0xe8, 0xbf, 0xa0, 0x27, 0x8d);", 
            "title": "Configuration"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#configuration_through_directshow_filter_property_page", 
            "text": "The filter s property page offers a subset of parameters, containing the most important options.   URL format:\\\nrtsp:%%//%%127.0.0.1:8554/streaming\\\nrtsp:%%//%%[ IP:port ]/[ stream name]\\", 
            "title": "Configuration through DirectShow filter property page"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#debug-log_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\nRTSPSink.ax", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_sink/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/", 
            "text": "nanocosmos RTSP Source Filter\n\n\nModule / Version\n\n\nnanocosmos RTSP Source \\\nnRTSPSource.ax  Version 1.2.1.0\n\n\nnanocosmos RTSP Source\n\n\nDirectShow filter for RTSP Streaming\n  * Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n  * Supported Formats: H.264 + AAC\n\n\nDirectShow Connectivity\n\n\nThe output is accepting connections matching the following media types:\n\n\n\n\nMajor types:\n\n\nMEDIATYPE_Video\n\n\n\n\n\n\nSubtypes:\n\n\nFourCCs: H264, h264\n\n\n\n\n\n\n\n\nFormats:\n\n\n\n\nFORMAT_MPEG2_VIDEO,\n\n\nFORMAT_NONE\n\n\n\n\n\n\n\n\nMajor types:\n\n\n\n\nMEDIATYPE_Audio\n\n\n\n\n\n\nSubtypes:\n\n\nMEDIASUBTYPE_AAC,  FourCC: 0x000000FF\n\n\n\n\n\n\nFormats:\n\n\nFORMAT_WaveFormatEx,\n\n\nFORMAT_NONE\n\n\n\n\n\n\n\n\nConfiguration\n\n\nThe filter configuration may be set by using either the property page or the COM Interface IRTSPSource and as declared in header file RTSPSourceOptions.h . The streaming url can be set by using standard DirectShow interface IFileSourceFilter .\n\n\n// Filter GUID\n// {99709313-5825-42ab-82ED-A7AD88ACBF4A}\nDEFINE_GUID(CLSID_NANO_RTSP_SOURCE, 0x99709313, 0x5825, 0x42ab, 0x82, 0xed, 0xa7, 0xad, 0x88, 0xac, 0xbf, 0x4a);\n\n// Property Page GUID\n// {D3BE0AA6-A8E2-45a8-9414-385FFD94B816}\nDEFINE_GUID(CLSID_NANO_RTSP_SOURCE_PROPPAGE, 0xd3be0aa6, 0xa8e2, 0x45a8, 0x94, 0x14, 0x38, 0x5f, 0xfd, 0x94, 0xb8, 0x16);\n\n// Configuration Interface GUID\n// IRTSPSource interface\n// {C39F308A-D27B-4c17-B01E-469F00248981}\nDEFINE_GUID(IID_IRTSPSource, 0xc39f308a, 0xd27b, 0x4c17, 0xb0, 0x1e, 0x46, 0x9f, 0x0, 0x24, 0x89, 0x81);\n\n\n\n\nBuffer statistics can be retrieved using IRTSPSourceBufferStats interface.\n\n\n// IRTSPSourceBufferStats interface\n// {655D499B-C9E0-4134-9DC4-6431FEEB5EB0}\nDEFINE_GUID(IID_IRTSPSourceBufferStats, 0x655d499b, 0xc9e0, 0x4134, 0x9d, 0xc4, 0x64, 0x31, 0xfe, 0xeb, 0x5e, 0xb0);\n\n\n\n\nUse standard DirectShow interface ICodecAPI to get/set these parameters:\n\n\n// ICodecAPI GUID\n// get/set receive timeout in seconds\n// VARIANT_TYPE: VT_I4, VARIANT::intVal\n// default value: 2\n// {33759D2A-3B7D-45ac-A8BF-C2477915C03B}\nDEFINE_GUID(PROPID_nanoRTSPSourceConnectionTimeout, 0x33759d2a, 0x3b7d, 0x45ac, 0xa8, 0xbf, 0xc2, 0x47, 0x79, 0x15, 0xc0, 0x3b);\n\n\n\n\nConfiguration through DirectShow filter property page\n\n\nThe filter\ns property page offers a subset of parameters, containing the most important options.\n{{ :nanortsp_netsrcprop.png?nolink |}}\nURL format:\\\nrtsp:%%//%%127.0.0.1:8554/streaming\\\nrtsp:%%//%% [ IP:port ]/[ stream name]\n\n\nDebug-Log Configuration Registry Settings\n\n\nKey: HKEY_CURRENT_USER\\Software\\DebugNano\\ nRTSPSource.ax  \n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "RTSP Source"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#nanocosmos_rtsp_source_filter", 
            "text": "", 
            "title": "nanocosmos RTSP Source Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#module_version", 
            "text": "nanocosmos RTSP Source \\\nnRTSPSource.ax  Version 1.2.1.0", 
            "title": "Module / Version"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#nanocosmos_rtsp_source", 
            "text": "DirectShow filter for RTSP Streaming\n  * Supported Architectures: Microsoft DirectShow, Windows XP, Vista, 7, Server\n  * Supported Formats: H.264 + AAC", 
            "title": "nanocosmos RTSP Source"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#directshow_connectivity", 
            "text": "The output is accepting connections matching the following media types:   Major types:  MEDIATYPE_Video    Subtypes:  FourCCs: H264, h264     Formats:   FORMAT_MPEG2_VIDEO,  FORMAT_NONE     Major types:   MEDIATYPE_Audio    Subtypes:  MEDIASUBTYPE_AAC,  FourCC: 0x000000FF    Formats:  FORMAT_WaveFormatEx,  FORMAT_NONE", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#configuration", 
            "text": "The filter configuration may be set by using either the property page or the COM Interface IRTSPSource and as declared in header file RTSPSourceOptions.h . The streaming url can be set by using standard DirectShow interface IFileSourceFilter .  // Filter GUID\n// {99709313-5825-42ab-82ED-A7AD88ACBF4A}\nDEFINE_GUID(CLSID_NANO_RTSP_SOURCE, 0x99709313, 0x5825, 0x42ab, 0x82, 0xed, 0xa7, 0xad, 0x88, 0xac, 0xbf, 0x4a);\n\n// Property Page GUID\n// {D3BE0AA6-A8E2-45a8-9414-385FFD94B816}\nDEFINE_GUID(CLSID_NANO_RTSP_SOURCE_PROPPAGE, 0xd3be0aa6, 0xa8e2, 0x45a8, 0x94, 0x14, 0x38, 0x5f, 0xfd, 0x94, 0xb8, 0x16);\n\n// Configuration Interface GUID\n// IRTSPSource interface\n// {C39F308A-D27B-4c17-B01E-469F00248981}\nDEFINE_GUID(IID_IRTSPSource, 0xc39f308a, 0xd27b, 0x4c17, 0xb0, 0x1e, 0x46, 0x9f, 0x0, 0x24, 0x89, 0x81);", 
            "title": "Configuration"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#buffer_statistics_can_be_retrieved_using_irtspsourcebufferstats_interface", 
            "text": "// IRTSPSourceBufferStats interface\n// {655D499B-C9E0-4134-9DC4-6431FEEB5EB0}\nDEFINE_GUID(IID_IRTSPSourceBufferStats, 0x655d499b, 0xc9e0, 0x4134, 0x9d, 0xc4, 0x64, 0x31, 0xfe, 0xeb, 0x5e, 0xb0);", 
            "title": "Buffer statistics can be retrieved using IRTSPSourceBufferStats interface."
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#use_standard_directshow_interface_icodecapi_to_getset_these_parameters", 
            "text": "// ICodecAPI GUID\n// get/set receive timeout in seconds\n// VARIANT_TYPE: VT_I4, VARIANT::intVal\n// default value: 2\n// {33759D2A-3B7D-45ac-A8BF-C2477915C03B}\nDEFINE_GUID(PROPID_nanoRTSPSourceConnectionTimeout, 0x33759d2a, 0x3b7d, 0x45ac, 0xa8, 0xbf, 0xc2, 0x47, 0x79, 0x15, 0xc0, 0x3b);", 
            "title": "Use standard DirectShow interface ICodecAPI to get/set these parameters:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#configuration_through_directshow_filter_property_page", 
            "text": "The filter s property page offers a subset of parameters, containing the most important options.\n{{ :nanortsp_netsrcprop.png?nolink |}}\nURL format:\\\nrtsp:%%//%%127.0.0.1:8554/streaming\\\nrtsp:%%//%% [ IP:port ]/[ stream name]", 
            "title": "Configuration through DirectShow filter property page"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#debug-log_configuration_registry_settings", 
            "text": "Key: HKEY_CURRENT_USER\\Software\\DebugNano\\ nRTSPSource.ax", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_rtsp_source/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/", 
            "text": "nanocosmos UDP/TS Network Writer and Reader Filter\n\n\nIntroduction\n\n\nDirectShow filters for UDP/TS Streaming\n  * Supported Architectures: Microsoft DirectShow, Vista, 7, 8, 10, Server\n  * Supported Protocols: UDP Unicast and Multicast\n  * Supported Video Codecs: H.264 and MPEG-2 Video\n  * Supported Audio Codecs: AAC and MPEG Audio\n  * Supported Payload: MPEG Transport Stream (A/V Interleaved) or Video Elementary Stream (Video only)\n\n\nModules\n\n\nUDP Network Source Filter: nanoNetSource.ax     \\\nUDP Network Writer Filter: nanoNetSink.ax   \\\n\n\nDirectShow Connectivity\n\n\nThe DirectShow pins are accepting connections matching the following media types:\n\n\nVideo Major Types:\n\n    MEDIATYPE_Video\n\n  Subtypes:\n\n    H.264: MEDIASUBTYPE_H264,  FourCC: 0x34363248\n\n    H.264: MEDIASUBTYPE_h264,  FourCC: 0x34363268\n\n    MPEG-2: MEDIASUBTYPE_MPEG2_VIDEO\n\n  Formats:\n\n    FORMAT_MPEG2_VIDEO\n\n    FORMAT_NONE\n\n\nAudio Major Types:\n\n    MEDIATYPE_Audio\n\n  Subtypes:\n\n    AAC: MEDIASUBTYPE_AAC,  FourCC: 0x000000FF\n\n    MPEG-1 Audio: MEDIASUBTYPE_MPEG1AudioPayload\n\n    MPEG-2 Audio: MEDIASUBTYPE_MPEG2_AUDIO\n\n  Formats:\n  AAC, MPEG Audio:  FORMAT_WaveFormatEx  \n\n\nConfiguration\n\n\nConfiguration through the Property Page\n\n\n\n\nInterface\n: Desired network interface or Any\n\n\nAddress\n: Local IP address or 0.0.0.0\n\n\nPort\n: Network port number\n\n\nMode\n: Transport Stream (default) or Elementary Stream\n\n\nStream State\n: Indicates the current stream state (online/offline)\n\n\nInput Stream Mediatype\n: Display of the current video format if online\n\n\n\n\nInterface\n: Desired network interface or Any\n\n\nAddress\n: Hostname or IP address of the receiving machine or multicast address\n\n\nPort\n: Network port number\n\n\nMode\n: Transport Stream (default) or Elementary Stream\n\n\nUDP Packet Size\n: Should not exceed MTU size. By default 1316 bytes (7 TS packets)\n\n\nConfiguration through COM Interface\n\n\nHeader Files\n\n\nNetwork Source Filter:\n\n- NetSourceGuids.h\n\n- NetSourceOptions.h\n\n- bsMediaParams.h\n\n- ICodecProp.h\n\n- CommonProps.h  \n\n\nNetwork Writer Filter:\n\n- NetWriterGuids.h  \n\n- NetWriterOptions.h\n\n- ICodecProp.h\n\n- CommonProps.h  \n\n\nCOM Interfaces\n\n\nNetwork Source Filter:\n\n- INetSource\n\n- ICodecProp\n\n- IFileSourceFilter\n\n- ICodecAPI\n\n- IBaseFilter\n\n- ISpecifyPropertyPages  \n\n\nNetwork Writer Filter:\n\n- INetSink\n\n- ICodecProp\n\n- IFileSinkFilter\n\n- ICodecAPI\n\n- IBaseFilter\n\n- ISpecifyPropertyPages  \n\n\nSetting up the stream URL\n\n\nThe streaming url can be set by using standard DirectShow interfaces //\nIFileSourceFilter\n// (Reader) and //\nIFileSinkFilter\n// (Writer)\n\nor the custom interfaces //\nINetSource\n// (Reader) and //\nINetSink\n// (Writer).\n\n\nURL Format: udp:%%//%% [ hostnameorIP:port ]\\\n\n\nExamples:  \n\n\nGiven two machines with different IP addresses, the sender 192.168.1.51 and the receiver 192.168.1.52.  \n\n\nFor a \nUDP unicast\n stream the Network Writer needs to be set up\nto the destination IP address of the receiver, udp:%%//%%192.168.1.52:1234.  \n\nOn the receiver side the Network Source is set up to the local IP address,\nudp:%%//%%192.168.1.52:1234 or udp:%%//%%0.0.0.0:1234.  \n\n\nFor a \nUDP multicast\n stream the sender and receiver are set up to the same multicast address, e.g. udp:%%//%%225.0.0.40:1234.  \n\n\nSetting the license to unlock the filter\n\n\nThe filter can be unlocked either through a license key entry in the windows registry or by setting the license key through COM interface ICodecProp::SetProperty with the property IID_nanoPeg_LicenseString as first parameter. The second license parameter has to be a wide/unicode string!\n\n\n#include \nICodecProp.h\n // ICodecProp interface\n#include \nCommonProps.h\n // IID_nanoPeg_LicenseString property id\n\nconst wchar_t* strwLicense = L\nnlic:....\n;\n\n// Query ICodeProp interface from IBaseFilter instance\nCComQIPtr \nICodecProp\n pCodecProp = m_pBaseFilter;\n\nif (pCodecProp)\n{\n    pCodecProp-\nSetProperty(\nIID_nanoPeg_LicenseString, strwLicense);\n}\nelse\n{\n    // Handle error\n}\n\n\n\n\nINetSource and INetSink Interfaces\n\n\nThe INetSource and INetSink interfaces provide additional functions for getting and setting configuration properties like network interface, hostname, port, operational mode (Transport Stream or Elementary Stream) and the current streaming state.  \n\n\n// Interface declared in NetSourceOptions.h  \n// IID defined in NetSourceGuids.h  \n// {7899B7E7-F8D4-4076-BE9D-D03D51413756}  \ninterface INetSource : public IUnknown\n{\n    virtual STDMETHODIMP SetPort(int port) = 0;\n    virtual STDMETHODIMP SetNetworkInterface(const wchar_t* net_interface) = 0;\n    virtual STDMETHODIMP SetServerAddress(const wchar_t* address) = 0;\n    virtual STDMETHODIMP GetPort(int* port) = 0;\n    virtual STDMETHODIMP GetNetworkInterface(BSTR* net_interface) = 0;\n    virtual STDMETHODIMP GetServerAddress(wchar_t* address, int size) = 0;\n    virtual STDMETHODIMP GetMode(net_source_mode_t* mode) = 0;\n    virtual STDMETHODIMP SetMode(net_source_mode_t mode) = 0;\n    virtual STDMETHODIMP GetStreamingState(net_source_state_t* state) = 0;\n    virtual STDMETHODIMP GetElemetaryStreamProperties(BS::params_t* params, int pin) = 0;\n    virtual STDMETHODIMP GetNumOfAvailableInterface(int* count) = 0;\n    virtual STDMETHODIMP GetAvailableInterface(BSTR* nif, int n) = 0;\n    virtual STDMETHODIMP InitInput() = 0;\n};\n\n\n\n\n// Interface declared in NetWriterOptions.h  \n// IID defined in NetWriterGuids.h  \n// {A4F3C2AC-18F7-4113-92FD-4042BD7279AC}\ninterface INetSink : public IUnknown\n{\n    virtual STDMETHODIMP SetDest(const wchar_t* dest, int port) = 0;\n    virtual STDMETHODIMP SetMode(net_sink_mode_t mode) = 0;\n    virtual STDMETHODIMP GetDest(const wchar_t* dest, int size, int* port) = 0;\n    virtual STDMETHODIMP GetMode(net_sink_mode_t* mode) = 0;\n    virtual STDMETHODIMP GetNumOfAvailableInterface(int* count) = 0;\n    virtual STDMETHODIMP GetAvailableInterface(BSTR* nif, int n) = 0;\n    virtual STDMETHODIMP GetNetInterface(BSTR* nif) = 0;\n    virtual STDMETHODIMP SetNetInterface(BSTR nif) = 0;\n};\n\n\n\n\nNetwork Source Filter Timeout Settings\n\n\nTimeout settings can be configured through the standard DirectShow COM interface ICodecAPI or in the Windows Registry.  \n\n\n\n\nLoad Timeout\n in ms\n\nThe load timeout leads to loading being aborted after the configured  timespan if no stream input was received during IFileSourceFilter::Load.  \n\n\n\n\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: TimeoutLoad  \nValue Type: REG_DWORD  \nDefault Value: 10000  \n\nICodecAPI interface parameter defined in NetSourceGuids.h  \nGet/Set input timeout during load in ms  \nVARIANT_TYPE: VT_I4, VARIANT::intVal  \ndefault value: 10000 ms  \n{CDC0C5AF-1666-4b46-8C7A-48EFF1C7E965}  \nDEFINE_GUID(PROPID_nanoNSTimeoutLoad,  \n0xcdc0c5af, 0x1666, 0x4b46, 0x8c, 0x7a, 0x48, 0xef, 0xf1, 0xc7, 0xe9, 0x65);  \n\n\n\n\n\n\nInput Timeout\n in ms\n\nThe input timeout leads to the filtergraph being stopped if no stream input was received for the configured time, e.g. because the stream was stopped at the sender.  \n\n\n\n\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: TimeoutInput  \nValue Type: REG_DWORD  \nDefault Value: 5000  \n\nICodecAPI interface parameter defined in NetSourceGuids.h  \nGet/Set input timeout during streaming in ms  \nVARIANT_TYPE: VT_I4, VARIANT::intVal  \ndefault value: 5000 ms  \n{454B2E50-C50F-41f6-BF96-BF84016780C6}  \nDEFINE_GUID(PROPID_nanoNSTimeoutInput,  \n0x454b2e50, 0xc50f, 0x41f6, 0xbf, 0x96, 0xbf, 0x84, 0x1, 0x67, 0x80, 0xc6);  \n\n\n\n\n\n\nOutput Timeout\n in ms\n\nThe output timeout leads to the filtergraph being stopped if no MediaSamples were delivered for the configured time.  \n\n\n\n\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: TimeoutOutput  \nValue Type: REG_DWORD  \nDefault Value: 5000  \n\nICodecAPI interface parameter defined in NetSourceGuids.h  \nGet/Set output timeout during streaming in ms  \nVARIANT_TYPE: VT_I4, VARIANT::intVal  \ndefault value: 5000 ms  \n{D75ED01E-D608-436d-BCE7-DBC4AC71A29D}  \nDEFINE_GUID(PROPID_nanoNSTimeoutOutput,  \n0xd75ed01e, 0xd608, 0x436d, 0xbc, 0xe7, 0xdb, 0xc4, 0xac, 0x71, 0xa2, 0x9d);  \n\n\n\n\nNetwork Source Filter File Dump Settings\n\n\nThe file dump allows to record the udp input stream to a file.\n\nIt is intended to be used for diagnosis purposes only.\n\nIt is supported for a single Network Source Filter instance only.\n\nSettings can be configured through the Windows Registry.\n\nRegistry settings are loaded at creation time of an instance.\n\nThe file dump is started and stopped when the filtergraph is started and stopped.  \n\n\n\n\nEnable File Dump\n\nEnable/disable dump file writing\n\n\n\n\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: FileDumpEnable\nValue Type: REG_DWORD  \nValid Values:   0 - disable, 1 - enable\nDefault Value: 0 - disable  \n\n\n\n\n\n\nDump File Name\n\nFull file path to the output file.\n\nThe destination folder must already exist.\n\n\n\n\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name:     FileDumpFilename  \nValue Type:     REG_SZ / String  \nValid Values:   A valid output file name  \n\n\n\n\nDebug-Log Configuration Registry Settings\n\n\nKeys:\n\n\nHKEY_CURRENT_USER\\Software\\DebugNano\\nanoNetSource.ax\n\n  HKEY_CURRENT_USER\\Software\\DebugNano\\nanoNetSink.ax  \n\n\nFile name\n\n\nSets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string\n\n\nLogging level\n\n\nA higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "UDP/TS Streaming"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#nanocosmos_udpts_network_writer_and_reader_filter", 
            "text": "", 
            "title": "nanocosmos UDP/TS Network Writer and Reader Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#introduction", 
            "text": "DirectShow filters for UDP/TS Streaming\n  * Supported Architectures: Microsoft DirectShow, Vista, 7, 8, 10, Server\n  * Supported Protocols: UDP Unicast and Multicast\n  * Supported Video Codecs: H.264 and MPEG-2 Video\n  * Supported Audio Codecs: AAC and MPEG Audio\n  * Supported Payload: MPEG Transport Stream (A/V Interleaved) or Video Elementary Stream (Video only)", 
            "title": "Introduction"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#modules", 
            "text": "UDP Network Source Filter: nanoNetSource.ax     \\\nUDP Network Writer Filter: nanoNetSink.ax   \\", 
            "title": "Modules"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#directshow_connectivity", 
            "text": "The DirectShow pins are accepting connections matching the following media types:  Video Major Types: \n    MEDIATYPE_Video \n  Subtypes: \n    H.264: MEDIASUBTYPE_H264,  FourCC: 0x34363248 \n    H.264: MEDIASUBTYPE_h264,  FourCC: 0x34363268 \n    MPEG-2: MEDIASUBTYPE_MPEG2_VIDEO \n  Formats: \n    FORMAT_MPEG2_VIDEO \n    FORMAT_NONE  Audio Major Types: \n    MEDIATYPE_Audio \n  Subtypes: \n    AAC: MEDIASUBTYPE_AAC,  FourCC: 0x000000FF \n    MPEG-1 Audio: MEDIASUBTYPE_MPEG1AudioPayload \n    MPEG-2 Audio: MEDIASUBTYPE_MPEG2_AUDIO \n  Formats:\n  AAC, MPEG Audio:  FORMAT_WaveFormatEx", 
            "title": "DirectShow Connectivity"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#configuration", 
            "text": "", 
            "title": "Configuration"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#configuration_through_the_property_page", 
            "text": "Interface : Desired network interface or Any  Address : Local IP address or 0.0.0.0  Port : Network port number  Mode : Transport Stream (default) or Elementary Stream  Stream State : Indicates the current stream state (online/offline)  Input Stream Mediatype : Display of the current video format if online   Interface : Desired network interface or Any  Address : Hostname or IP address of the receiving machine or multicast address  Port : Network port number  Mode : Transport Stream (default) or Elementary Stream  UDP Packet Size : Should not exceed MTU size. By default 1316 bytes (7 TS packets)", 
            "title": "Configuration through the Property Page"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#configuration_through_com_interface", 
            "text": "", 
            "title": "Configuration through COM Interface"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#header_files", 
            "text": "Network Source Filter: \n- NetSourceGuids.h \n- NetSourceOptions.h \n- bsMediaParams.h \n- ICodecProp.h \n- CommonProps.h    Network Writer Filter: \n- NetWriterGuids.h   \n- NetWriterOptions.h \n- ICodecProp.h \n- CommonProps.h", 
            "title": "Header Files"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#com_interfaces", 
            "text": "Network Source Filter: \n- INetSource \n- ICodecProp \n- IFileSourceFilter \n- ICodecAPI \n- IBaseFilter \n- ISpecifyPropertyPages    Network Writer Filter: \n- INetSink \n- ICodecProp \n- IFileSinkFilter \n- ICodecAPI \n- IBaseFilter \n- ISpecifyPropertyPages", 
            "title": "COM Interfaces"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#setting_up_the_stream_url", 
            "text": "The streaming url can be set by using standard DirectShow interfaces // IFileSourceFilter // (Reader) and // IFileSinkFilter // (Writer) \nor the custom interfaces // INetSource // (Reader) and // INetSink // (Writer).  URL Format: udp:%%//%% [ hostnameorIP:port ]\\  Examples:    Given two machines with different IP addresses, the sender 192.168.1.51 and the receiver 192.168.1.52.    For a  UDP unicast  stream the Network Writer needs to be set up\nto the destination IP address of the receiver, udp:%%//%%192.168.1.52:1234.   \nOn the receiver side the Network Source is set up to the local IP address,\nudp:%%//%%192.168.1.52:1234 or udp:%%//%%0.0.0.0:1234.    For a  UDP multicast  stream the sender and receiver are set up to the same multicast address, e.g. udp:%%//%%225.0.0.40:1234.", 
            "title": "Setting up the stream URL"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#setting_the_license_to_unlock_the_filter", 
            "text": "The filter can be unlocked either through a license key entry in the windows registry or by setting the license key through COM interface ICodecProp::SetProperty with the property IID_nanoPeg_LicenseString as first parameter. The second license parameter has to be a wide/unicode string!  #include  ICodecProp.h  // ICodecProp interface\n#include  CommonProps.h  // IID_nanoPeg_LicenseString property id\n\nconst wchar_t* strwLicense = L nlic:.... ;\n\n// Query ICodeProp interface from IBaseFilter instance\nCComQIPtr  ICodecProp  pCodecProp = m_pBaseFilter;\n\nif (pCodecProp)\n{\n    pCodecProp- SetProperty( IID_nanoPeg_LicenseString, strwLicense);\n}\nelse\n{\n    // Handle error\n}", 
            "title": "Setting the license to unlock the filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#inetsource_and_inetsink_interfaces", 
            "text": "The INetSource and INetSink interfaces provide additional functions for getting and setting configuration properties like network interface, hostname, port, operational mode (Transport Stream or Elementary Stream) and the current streaming state.    // Interface declared in NetSourceOptions.h  \n// IID defined in NetSourceGuids.h  \n// {7899B7E7-F8D4-4076-BE9D-D03D51413756}  \ninterface INetSource : public IUnknown\n{\n    virtual STDMETHODIMP SetPort(int port) = 0;\n    virtual STDMETHODIMP SetNetworkInterface(const wchar_t* net_interface) = 0;\n    virtual STDMETHODIMP SetServerAddress(const wchar_t* address) = 0;\n    virtual STDMETHODIMP GetPort(int* port) = 0;\n    virtual STDMETHODIMP GetNetworkInterface(BSTR* net_interface) = 0;\n    virtual STDMETHODIMP GetServerAddress(wchar_t* address, int size) = 0;\n    virtual STDMETHODIMP GetMode(net_source_mode_t* mode) = 0;\n    virtual STDMETHODIMP SetMode(net_source_mode_t mode) = 0;\n    virtual STDMETHODIMP GetStreamingState(net_source_state_t* state) = 0;\n    virtual STDMETHODIMP GetElemetaryStreamProperties(BS::params_t* params, int pin) = 0;\n    virtual STDMETHODIMP GetNumOfAvailableInterface(int* count) = 0;\n    virtual STDMETHODIMP GetAvailableInterface(BSTR* nif, int n) = 0;\n    virtual STDMETHODIMP InitInput() = 0;\n};  // Interface declared in NetWriterOptions.h  \n// IID defined in NetWriterGuids.h  \n// {A4F3C2AC-18F7-4113-92FD-4042BD7279AC}\ninterface INetSink : public IUnknown\n{\n    virtual STDMETHODIMP SetDest(const wchar_t* dest, int port) = 0;\n    virtual STDMETHODIMP SetMode(net_sink_mode_t mode) = 0;\n    virtual STDMETHODIMP GetDest(const wchar_t* dest, int size, int* port) = 0;\n    virtual STDMETHODIMP GetMode(net_sink_mode_t* mode) = 0;\n    virtual STDMETHODIMP GetNumOfAvailableInterface(int* count) = 0;\n    virtual STDMETHODIMP GetAvailableInterface(BSTR* nif, int n) = 0;\n    virtual STDMETHODIMP GetNetInterface(BSTR* nif) = 0;\n    virtual STDMETHODIMP SetNetInterface(BSTR nif) = 0;\n};", 
            "title": "INetSource and INetSink Interfaces"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#network_source_filter_timeout_settings", 
            "text": "Timeout settings can be configured through the standard DirectShow COM interface ICodecAPI or in the Windows Registry.     Load Timeout  in ms \nThe load timeout leads to loading being aborted after the configured  timespan if no stream input was received during IFileSourceFilter::Load.     Registry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: TimeoutLoad  \nValue Type: REG_DWORD  \nDefault Value: 10000  \n\nICodecAPI interface parameter defined in NetSourceGuids.h  \nGet/Set input timeout during load in ms  \nVARIANT_TYPE: VT_I4, VARIANT::intVal  \ndefault value: 10000 ms  \n{CDC0C5AF-1666-4b46-8C7A-48EFF1C7E965}  \nDEFINE_GUID(PROPID_nanoNSTimeoutLoad,  \n0xcdc0c5af, 0x1666, 0x4b46, 0x8c, 0x7a, 0x48, 0xef, 0xf1, 0xc7, 0xe9, 0x65);     Input Timeout  in ms \nThe input timeout leads to the filtergraph being stopped if no stream input was received for the configured time, e.g. because the stream was stopped at the sender.     Registry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: TimeoutInput  \nValue Type: REG_DWORD  \nDefault Value: 5000  \n\nICodecAPI interface parameter defined in NetSourceGuids.h  \nGet/Set input timeout during streaming in ms  \nVARIANT_TYPE: VT_I4, VARIANT::intVal  \ndefault value: 5000 ms  \n{454B2E50-C50F-41f6-BF96-BF84016780C6}  \nDEFINE_GUID(PROPID_nanoNSTimeoutInput,  \n0x454b2e50, 0xc50f, 0x41f6, 0xbf, 0x96, 0xbf, 0x84, 0x1, 0x67, 0x80, 0xc6);     Output Timeout  in ms \nThe output timeout leads to the filtergraph being stopped if no MediaSamples were delivered for the configured time.     Registry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: TimeoutOutput  \nValue Type: REG_DWORD  \nDefault Value: 5000  \n\nICodecAPI interface parameter defined in NetSourceGuids.h  \nGet/Set output timeout during streaming in ms  \nVARIANT_TYPE: VT_I4, VARIANT::intVal  \ndefault value: 5000 ms  \n{D75ED01E-D608-436d-BCE7-DBC4AC71A29D}  \nDEFINE_GUID(PROPID_nanoNSTimeoutOutput,  \n0xd75ed01e, 0xd608, 0x436d, 0xbc, 0xe7, 0xdb, 0xc4, 0xac, 0x71, 0xa2, 0x9d);", 
            "title": "Network Source Filter Timeout Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#network_source_filter_file_dump_settings", 
            "text": "The file dump allows to record the udp input stream to a file. \nIt is intended to be used for diagnosis purposes only. \nIt is supported for a single Network Source Filter instance only. \nSettings can be configured through the Windows Registry. \nRegistry settings are loaded at creation time of an instance. \nThe file dump is started and stopped when the filtergraph is started and stopped.     Enable File Dump \nEnable/disable dump file writing   Registry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name: FileDumpEnable\nValue Type: REG_DWORD  \nValid Values:   0 - disable, 1 - enable\nDefault Value: 0 - disable     Dump File Name \nFull file path to the output file. \nThe destination folder must already exist.   Registry Key: HKCU\\SOFTWARE\\nanocosmos\\nNetSource  \nValue Name:     FileDumpFilename  \nValue Type:     REG_SZ / String  \nValid Values:   A valid output file name", 
            "title": "Network Source Filter File Dump Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#debug-log_configuration_registry_settings", 
            "text": "", 
            "title": "Debug-Log Configuration Registry Settings"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#keys", 
            "text": "HKEY_CURRENT_USER\\Software\\DebugNano\\nanoNetSource.ax \n  HKEY_CURRENT_USER\\Software\\DebugNano\\nanoNetSink.ax", 
            "title": "Keys:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#file_name", 
            "text": "Sets the output file name. The folder must already exist.\\\nValue name:     LogToFile\\\nValue type:     REG_SZ / String\\\nValid values:   a valid output file name to enable file logging or an empty string", 
            "title": "File name"
        }, 
        {
            "location": "/nanostream/directshow/directshow_udp_ts_streaming/#logging_level", 
            "text": "A higher value increases the amount of logging messages sent, and messages get more detailed. \\\nValue name:     TRACE\\\nValue type:     REG_DWORD\\\nValid values:\n  * 0 - minimal logging\n  * \u2026\n  * 9 - maximal logging", 
            "title": "Logging level"
        }, 
        {
            "location": "/nanostream/directshow/directshow_screen_capture_filter/", 
            "text": "How to use the Screen Capture DirectShow filter\n\n\nCapture Modes\n\n\n\n\nMouse Follow\n\n\nRegion\n\n\nScreen\n\n\nWindow Handle\n\n\n\n\nScreen Capture - Single Window\n\n\nIt is possible to capture a single window instead of the entire screen. The content of the window is captured even if the window is partially or completely in the background. You need to enter the Window handle or Window class name into the field.\n\n\nAt the moment there are two modes for capturing a single window:\n  * Auto Size: adjusts the output size depending on the size of the window to capture, before the directshow graph is started\n\n\n\n  * Fullscreen: the output size is equivalent to the screen size, the window size is not scaled, the window can be resized while the graph is running and one can see the whole window at all times\n\n\n\n\n\n\nScaling example: if you need to downscale a full screen capture, use the additional \nResize/Scale\n functionality in the encoder or add a resizer/scaler filter to the DirectShow filter graph\n\n\n\n\nRegion Capture\n\n\nIf the output of the region area seems to be different from the specified region, check if Windows display zoom is enabled:", 
            "title": "Screen Capture Filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_screen_capture_filter/#how_to_use_the_screen_capture_directshow_filter", 
            "text": "", 
            "title": "How to use the Screen Capture DirectShow filter"
        }, 
        {
            "location": "/nanostream/directshow/directshow_screen_capture_filter/#capture_modes", 
            "text": "Mouse Follow  Region  Screen  Window Handle", 
            "title": "Capture Modes"
        }, 
        {
            "location": "/nanostream/directshow/directshow_screen_capture_filter/#screen_capture_-_single_window", 
            "text": "It is possible to capture a single window instead of the entire screen. The content of the window is captured even if the window is partially or completely in the background. You need to enter the Window handle or Window class name into the field.  At the moment there are two modes for capturing a single window:\n  * Auto Size: adjusts the output size depending on the size of the window to capture, before the directshow graph is started  \n  * Fullscreen: the output size is equivalent to the screen size, the window size is not scaled, the window can be resized while the graph is running and one can see the whole window at all times    Scaling example: if you need to downscale a full screen capture, use the additional  Resize/Scale  functionality in the encoder or add a resizer/scaler filter to the DirectShow filter graph", 
            "title": "Screen Capture - Single Window"
        }, 
        {
            "location": "/nanostream/directshow/directshow_screen_capture_filter/#region_capture", 
            "text": "If the output of the region area seems to be different from the specified region, check if Windows display zoom is enabled:", 
            "title": "Region Capture"
        }, 
        {
            "location": "/nanostream/directshow/directshow_video_mixer/", 
            "text": "Video Mixer / Picture-in-Picture\n\n\nThis document describes the DirectShow filter configuration for the nanocosmos Video Mixer 2.\n\n\nSee also the [[live_video_encoder_-_overlay_mixing|nanoStream API for the VideoMixer]]\n\n\nRequirements:\n\n\n\n\nDirectShow architecture / C++\n\n\nNanocosmos Video Mixer 2 Filter\n\n\n\n\nPicture-in-picture mode for 2 video inputs\n\n\nThis short C++ example code shows how to configure the Video Mixer to show video 2 in the right top corner of video 1.\n\n\n// {0ED06AB0-B2F3-421b-BA63-2E591C932802}\nstatic const GUID CLSID_nanoVideoMixer2 = { 0xed06ab0, 0xb2f3, 0x421b, { 0xba, 0x63, 0x2e, 0x59, 0x1c, 0x93, 0x28, 0x2 } };\n\n// {2140722A-9F1E-4ac7-8A81-CF77CA6DD683}\nstatic const GUID IID_IVideoPlacement = { 0x2140722a, 0x9f1e, 0x4ac7, { 0x8a, 0x81, 0xcf, 0x77, 0xca, 0x6d, 0xd6, 0x83 } };\n\nCComPtr\nIBaseFilter\n m_pVideoMixer;\nm_pVideoMixer.CoCreateInstance(CLSID_nanoVideoMixer2);\n\n// target area picture-in-picture: right top corner of picture 1\nRECT rcTarget = {m_VideoWidth * 7/10, m_VideoHeight*1/20,\nm_VideoWidth * 9/20, m_VideoHeight * 3/10};\n\nCComQIPtr \nIVideoPlacement\n api = m_pVideoMixer;        \nif (api){\n    api-\nSetVideoFrameDuration( (REFERENCE_TIME)(10000000LL / m_VideoFrameRate) );\n    api-\nSetOutputSize(m_VideoWidth, m_VideoHeight);\n    RECT rc = {0,0, m_VideoWidth, m_VideoHeight};\n    api-\nSetVideoPosition(0, \nrc);\n    api-\nSetVideoPosition(1, \nrcTarget);\n    return 0;\n}", 
            "title": "Video Mixer PiP"
        }, 
        {
            "location": "/nanostream/directshow/directshow_video_mixer/#video_mixer_picture-in-picture", 
            "text": "This document describes the DirectShow filter configuration for the nanocosmos Video Mixer 2.  See also the [[live_video_encoder_-_overlay_mixing|nanoStream API for the VideoMixer]]", 
            "title": "Video Mixer / Picture-in-Picture"
        }, 
        {
            "location": "/nanostream/directshow/directshow_video_mixer/#requirements", 
            "text": "DirectShow architecture / C++  Nanocosmos Video Mixer 2 Filter", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_video_mixer/#picture-in-picture_mode_for_2_video_inputs", 
            "text": "This short C++ example code shows how to configure the Video Mixer to show video 2 in the right top corner of video 1.  // {0ED06AB0-B2F3-421b-BA63-2E591C932802}\nstatic const GUID CLSID_nanoVideoMixer2 = { 0xed06ab0, 0xb2f3, 0x421b, { 0xba, 0x63, 0x2e, 0x59, 0x1c, 0x93, 0x28, 0x2 } };\n\n// {2140722A-9F1E-4ac7-8A81-CF77CA6DD683}\nstatic const GUID IID_IVideoPlacement = { 0x2140722a, 0x9f1e, 0x4ac7, { 0x8a, 0x81, 0xcf, 0x77, 0xca, 0x6d, 0xd6, 0x83 } };\n\nCComPtr IBaseFilter  m_pVideoMixer;\nm_pVideoMixer.CoCreateInstance(CLSID_nanoVideoMixer2);\n\n// target area picture-in-picture: right top corner of picture 1\nRECT rcTarget = {m_VideoWidth * 7/10, m_VideoHeight*1/20,\nm_VideoWidth * 9/20, m_VideoHeight * 3/10};\n\nCComQIPtr  IVideoPlacement  api = m_pVideoMixer;        \nif (api){\n    api- SetVideoFrameDuration( (REFERENCE_TIME)(10000000LL / m_VideoFrameRate) );\n    api- SetOutputSize(m_VideoWidth, m_VideoHeight);\n    RECT rc = {0,0, m_VideoWidth, m_VideoHeight};\n    api- SetVideoPosition(0,  rc);\n    api- SetVideoPosition(1,  rcTarget);\n    return 0;\n}", 
            "title": "Picture-in-picture mode for 2 video inputs"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/", 
            "text": "nanocosmos Video Mixer / Overlay\n\n\nGeneral Information\n\n\nnanoStream 2.0 supports a video mixing of 2 input video signals and text and bitmap overlay functions. Both functions can be used from within nanoStream plugin applications or by using DirectShow filter setups.\n\n\nRequirements:\n\n\n\n\nNanocosmos Video Mixer DirectShow Filter (for video mixing)\n\n\nNanocosmos Text/Bitmap Overlay Filter (for text or image overlay)\n\n\nnanoStream Plugins (optional)\n\n\nVideo mixing and text/image overlay can be used independently.\n\n\n\n\nUsage of Video Mixer:\n\n\nUse the IVideoPlacement Interface of the VideoMixer 2 filter:\n\n\nPicture-in-Picture: This example shows how to display one video source within another video source.\n\n\n// specify how both capture sources should be mixed\nCComPtr\nIVideoPlacement\n api ;\nm_pVideoMixer-\nQueryInterface(IID_IVideoPlacement, reinterpret_cast\nvoid**\n(\napi));\nif (api) {\n    api-\nSetVideoFrameDuration((REFERENCE_TIME)(10000000LL / m_VideoFrameRate) );\n    api-\nSetOutputSize(width, height);\n    RECT rc = {0,0, width, height};\n    api-\nSetVideoPosition(0, \nrc);            // specify display area for first capture source\n    // target area picture-in-picture: right top corner of picture 1\n    RECT rcTarget = {width * 7/10, height*1/20, width * 9/20, height * 3/10};\n    api-\nSetVideoPosition(1, \nrcTarget);     // specify display area for second capture source\n}\n\n\n\n\nLeft/Right: Example showing how to mix two video sources side by side (left/right)\n\n\n// specify how both capture sources should be mixed\nCComPtr\nIVideoPlacement\n api ;\nm_pVideoMixer-\nQueryInterface(IID_IVideoPlacement, reinterpret_cast\nvoid**\n(\napi));\nif (api) {\n    api-\nSetVideoFrameDuration((REFERENCE_TIME)(10000000LL / videoFrameRate));\n    api-\nSetOutputSize(videoWidth, videoHeight);\n    RECT left = {0, 0, videoWidth / 2, videoHeight};\n    api-\nSetVideoPosition(0, \nleft);    // specify display area for first capture source\n    RECT right = {videoWidth / 2, 0, videoWidth, videoHeight};\n    api-\nSetVideoPosition(1, \nright);   // specify display area for second capture source\n}\n\n\n\n\nUsage of Text/Bitmap Overlay:\n\n\nText Overlay:\n\n\nThe text to overlay can either be copied directly to the item text buffer or can be specified by the path to a file, containing the overlay text. The text within that file is then loaded by the overlay filter.\n\n\nUse the INanoTextOverlay interface of the overlay filter:\n\n\nCComQIPtr\nINanoTextOverlay, \nIID_INanoTextOverlay\n m_pTextOverlay;\nm_pTextOverlay = m_pOverlayFilter;\nif(m_pTextOverlay) {\n    // you can add more than one item to the overlay filter, for the sake of simplicity we add only one item here\n    overlay_item_t item;\n    // if we draw text text overlay filter uses only top/left coords.\n    // width/height of the text it determined from font params\n    item.output_rect.left       = videoWidth * 1/20;\n    item.output_rect.top       = videoHeight * 1/20;\n    item.output_rect.bottom = videoHeight * 19/20;\n    item.output_rect.right     = videoWidth * 19/20;\n    item.back_color                 = COLORREF(0x00000000);\n    item.text_color             = COLORREF(0x000099FF);\n    item.alpha                  = 0.5;           // the opacity of the overlay text\n    // (if skip color is equal to back_color then text will be drawn without background color)\n    item.skip_color = COLORREF(0x00000000);\n\n    CString text = _T(\nText Overlay\n);  // the text that should be overlayed\n    item.use_filename = false;                  // assign true, if text specifies a path to a file,\n                                                                // containing text\n    wcscpy(item.text, text.GetBuffer());\n    item.speed                  = -2.0; //speed of string moving\n\n    // set font properties\n    item.font.lfHeight      = -8;\n    item.font.lfWidth               = 0;\n    item.font.lfEscapement  = 0;\n    item.font.lfOrientation = 0;\n    item.font.lfWeight      = FW_BOLD;\n    item.font.lfItalic              = 0;\n    item.font.lfUnderline       = 0;\n    item.font.lfStrikeOut       = 0;\n    item.font.lfCharSet     = 0;\n    item.font.lfOutPrecision    = 3;\n    item.font.lfClipPrecision   = 2;\n    item.font.lfQuality     = DEFAULT_QUALITY;\n    item.font.lfPitchAndFamily  = DEFAULT_PITCH|FF_DONTCARE;\n\n    TCHAR fontName[100] = _T(\nArial\n);\n    _tccpy(item.font.lfFaceName, fontName);         // face name of the font\n\n    m_pTextOverlay-\nAddItem(\nitem, NULL);       // add the item to the overlay filter\n}\n\n\n\n\nPicture Overlay:\n\n\nThe image to overlay is not loaded by the overlay filter. The image data has to be loaded beforehand. In this example the class CImage is used.\n\n\nUse the INanoTextOverlay interface of the overlay filter:\n\n\nCComQIPtr\nINanoTextOverlay, \nIID_INanoTextOverlay\n m_pPicOverlay;\nm_pPicOverlay = m_pOverlayFilter;\nif(m_pPicOverlay) {\n    overlay_item_t item;\n    item.output_rect.left       = videoWidth * 1/20;\n    item.output_rect.top       = videoHeight * 1/20;\n    item.output_rect.bottom = videoHeight * 19/20;\n    item.output_rect.right     = videoWidth * 19/20;\n    item.alpha                  = 0.5;\n\n    CString imagePath = _T(\nC:\\temp\\my_image.bmp\n); // path to the image - .png and .jpg\n                                                                                        // is also possible\n    CImage image;\n    m_Image.Load(imagePath .GetBuffer());\n    item.image.data          = m_Image.GetBits();\n    item.image.width     = m_Image.GetWidth();\n    item.image.height    = m_Image.GetHeight();\n    item.image.pitch             = m_Image.GetPitch();\n    item.use_image       = true;\n    item.use_image_alpha = false; // assign true for using the alpha value of png images\n\n    m_pPicOverlay-\nAddItem(\nitem, NULL);    // add the item to the overlay filter\n}\n\n\n\n\nIf the alpha values of a png picture should be used \nitem.use_image_alpha\n has to be set to true.", 
            "title": "Video Mixer Overlay"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#nanocosmos_video_mixer_overlay", 
            "text": "", 
            "title": "nanocosmos Video Mixer / Overlay"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#general_information", 
            "text": "nanoStream 2.0 supports a video mixing of 2 input video signals and text and bitmap overlay functions. Both functions can be used from within nanoStream plugin applications or by using DirectShow filter setups.", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#requirements", 
            "text": "Nanocosmos Video Mixer DirectShow Filter (for video mixing)  Nanocosmos Text/Bitmap Overlay Filter (for text or image overlay)  nanoStream Plugins (optional)  Video mixing and text/image overlay can be used independently.", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#usage_of_video_mixer", 
            "text": "Use the IVideoPlacement Interface of the VideoMixer 2 filter:", 
            "title": "Usage of Video Mixer:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#picture-in-picture_this_example_shows_how_to_display_one_video_source_within_another_video_source", 
            "text": "// specify how both capture sources should be mixed\nCComPtr IVideoPlacement  api ;\nm_pVideoMixer- QueryInterface(IID_IVideoPlacement, reinterpret_cast void** ( api));\nif (api) {\n    api- SetVideoFrameDuration((REFERENCE_TIME)(10000000LL / m_VideoFrameRate) );\n    api- SetOutputSize(width, height);\n    RECT rc = {0,0, width, height};\n    api- SetVideoPosition(0,  rc);            // specify display area for first capture source\n    // target area picture-in-picture: right top corner of picture 1\n    RECT rcTarget = {width * 7/10, height*1/20, width * 9/20, height * 3/10};\n    api- SetVideoPosition(1,  rcTarget);     // specify display area for second capture source\n}", 
            "title": "Picture-in-Picture: This example shows how to display one video source within another video source."
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#leftright_example_showing_how_to_mix_two_video_sources_side_by_side_leftright", 
            "text": "// specify how both capture sources should be mixed\nCComPtr IVideoPlacement  api ;\nm_pVideoMixer- QueryInterface(IID_IVideoPlacement, reinterpret_cast void** ( api));\nif (api) {\n    api- SetVideoFrameDuration((REFERENCE_TIME)(10000000LL / videoFrameRate));\n    api- SetOutputSize(videoWidth, videoHeight);\n    RECT left = {0, 0, videoWidth / 2, videoHeight};\n    api- SetVideoPosition(0,  left);    // specify display area for first capture source\n    RECT right = {videoWidth / 2, 0, videoWidth, videoHeight};\n    api- SetVideoPosition(1,  right);   // specify display area for second capture source\n}", 
            "title": "Left/Right: Example showing how to mix two video sources side by side (left/right)"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#usage_of_textbitmap_overlay", 
            "text": "", 
            "title": "Usage of Text/Bitmap Overlay:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#text_overlay", 
            "text": "The text to overlay can either be copied directly to the item text buffer or can be specified by the path to a file, containing the overlay text. The text within that file is then loaded by the overlay filter.  Use the INanoTextOverlay interface of the overlay filter:  CComQIPtr INanoTextOverlay,  IID_INanoTextOverlay  m_pTextOverlay;\nm_pTextOverlay = m_pOverlayFilter;\nif(m_pTextOverlay) {\n    // you can add more than one item to the overlay filter, for the sake of simplicity we add only one item here\n    overlay_item_t item;\n    // if we draw text text overlay filter uses only top/left coords.\n    // width/height of the text it determined from font params\n    item.output_rect.left       = videoWidth * 1/20;\n    item.output_rect.top       = videoHeight * 1/20;\n    item.output_rect.bottom = videoHeight * 19/20;\n    item.output_rect.right     = videoWidth * 19/20;\n    item.back_color                 = COLORREF(0x00000000);\n    item.text_color             = COLORREF(0x000099FF);\n    item.alpha                  = 0.5;           // the opacity of the overlay text\n    // (if skip color is equal to back_color then text will be drawn without background color)\n    item.skip_color = COLORREF(0x00000000);\n\n    CString text = _T( Text Overlay );  // the text that should be overlayed\n    item.use_filename = false;                  // assign true, if text specifies a path to a file,\n                                                                // containing text\n    wcscpy(item.text, text.GetBuffer());\n    item.speed                  = -2.0; //speed of string moving\n\n    // set font properties\n    item.font.lfHeight      = -8;\n    item.font.lfWidth               = 0;\n    item.font.lfEscapement  = 0;\n    item.font.lfOrientation = 0;\n    item.font.lfWeight      = FW_BOLD;\n    item.font.lfItalic              = 0;\n    item.font.lfUnderline       = 0;\n    item.font.lfStrikeOut       = 0;\n    item.font.lfCharSet     = 0;\n    item.font.lfOutPrecision    = 3;\n    item.font.lfClipPrecision   = 2;\n    item.font.lfQuality     = DEFAULT_QUALITY;\n    item.font.lfPitchAndFamily  = DEFAULT_PITCH|FF_DONTCARE;\n\n    TCHAR fontName[100] = _T( Arial );\n    _tccpy(item.font.lfFaceName, fontName);         // face name of the font\n\n    m_pTextOverlay- AddItem( item, NULL);       // add the item to the overlay filter\n}", 
            "title": "Text Overlay:"
        }, 
        {
            "location": "/nanostream/directshow/directshow_overlay_mixing/#picture_overlay", 
            "text": "The image to overlay is not loaded by the overlay filter. The image data has to be loaded beforehand. In this example the class CImage is used.  Use the INanoTextOverlay interface of the overlay filter:  CComQIPtr INanoTextOverlay,  IID_INanoTextOverlay  m_pPicOverlay;\nm_pPicOverlay = m_pOverlayFilter;\nif(m_pPicOverlay) {\n    overlay_item_t item;\n    item.output_rect.left       = videoWidth * 1/20;\n    item.output_rect.top       = videoHeight * 1/20;\n    item.output_rect.bottom = videoHeight * 19/20;\n    item.output_rect.right     = videoWidth * 19/20;\n    item.alpha                  = 0.5;\n\n    CString imagePath = _T( C:\\temp\\my_image.bmp ); // path to the image - .png and .jpg\n                                                                                        // is also possible\n    CImage image;\n    m_Image.Load(imagePath .GetBuffer());\n    item.image.data          = m_Image.GetBits();\n    item.image.width     = m_Image.GetWidth();\n    item.image.height    = m_Image.GetHeight();\n    item.image.pitch             = m_Image.GetPitch();\n    item.use_image       = true;\n    item.use_image_alpha = false; // assign true for using the alpha value of png images\n\n    m_pPicOverlay- AddItem( item, NULL);    // add the item to the overlay filter\n}  If the alpha values of a png picture should be used  item.use_image_alpha  has to be set to true.", 
            "title": "Picture Overlay:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/", 
            "text": "Live Video Encoder - Acoustic Echo Cancellation (AEC)\n\n\nThis document describes recommended settings for Acoustic Echo Cancellation in a video streaming/video chat application.\n\n\nRequirements:\n\n\nnanoStream Live Video Encoder running on Windows Vista or Windows 7\n  \nRTMP Server (Wowza recommended)\n  \nFlash Media Player or other client\n  \nMicrophone and Loudspeaker setup to let echo cancellation work (no headset)\n\n\nNOTE:\n\n\nThese settings are dependent on overall system configurations and may vary between different version releases of encoder, server and client components.\n\n\nGeneral Description\n\n\nWhen using microphone and speaker setups for audio/video communication, a known acoustic \necho\n effect is sometimes leading to disturbing feedback loops. To remove these echoes, a special technique called \nAcoustic Echo Cancellation (AEC)\n may be used.\n\n\nNanocosmos AEC works by installing a special audio driver called \nVoiceCaptureDriver\n.\n\n\nThere are 2 operation modes of this driver:\n\n\n*usage within nanoStream Live Video Encoder\nSwitching on AEC in Live Video Encoder automatically uses the VoiceCaptureDriver\n\n\n*usage within DirectShow or other applications\nThe VoiceCapture driver may be directly used as an audio recording source; \\  additionally the original audio source needs to be configured in the driver properties.\n\n\nNotes:\n\n\nAll effects are dependent on hardware and software system setup, microphone and loudspeaker positions.\n  \nThis driver uses the Microsoft \nVoice Capture DSP\n driver available only with Windows Vista and 7.\n\n\nSample / Test Setup\n\n\nThe nanoStream.html sample web page contains a sample implementation to show how to use the AEC feature within Live Video Encoder. Switch on \nAEC\n in the \nAdvanced Options\n area.\n\n\nPlugin / ActiveX Configuration\n\n\nSwitch on AEC\n\n\nTo switch on AEC, use the SetConfig method of the Plugin Interface:\n\n\n    SetConfig(\nAcousticEchoCancelation\n,\n1\n);\n\n\n\n\n//The AEC mode supports some additional configuration settings to fine tune AEC behavior. See nanoEncoder.js for sample code.//\n\n\nEcho Supression\n\n\n//Specifies how many times the Voice Capture performs acoustic echo suppression (AES) on the residual signal.//\n\n\n    SetConfig(\nAEC:AesTimes\n, 2);\n\n\n\n\nPossible Values:\n\n\n    0, 1, 2 (default=0)\n\n\n\n\nMS Property:\n\n\n    MFPKEY_WMAAECMA_FEATR_AES\n\n\n\n\nGain control\n\n\n//Specifies whether the Voice Capture DSP performs automatic gain control.//\n\n\n    SetConfig(\nAEC:Agc\n, 1);\n\n\n\n\nPossible Values:\n\n\n    0,1 (default=0)\n\n\n\n\nMS Property:\n\n\n    MFPKEY_WMAAECMA_FEATR_AGC\n\n\n\n\nAcoustic Echo Cancellation\n\n\n//Specifies the duration of echo that the acoustic echo cancellation (AEC) algorithm can handle, in milliseconds.//\n\n\n    SetConfig(\nAEC:AecEchoLength\n, 1024);\n\n\n\n\nPossible Values:\n\n\n    128, 256, 512, 1024 (default=256)\n\n\n\n\nMS Property:\n\n\n    MFPKEY_WMAAECMA_FEATR_ECHO_LENGTH\n\n\n\n\nAdditional Information:\n\n\nMicrosoft Notes on Windows XP:\n\n\nhttp://support.microsoft.com/kb/310507\n\n\nMicrosoft Voice Capture:\n\n\nhttp://msdn.microsoft.com/en-us/library/ff819492(v=vs.85).aspx\n\n\nhttp://msdn.microsoft.com/en-us/library/ff819411(v=vs.85).aspx\n\n\nContact\n\n\n//Please contact us for further information, extended services are available upon request.//\n\n\nhttp://www.nanocosmos.de\n\n\ninfo@nanocosmos.de\n\n\n(c) 2009-2012, nanocosmos gmbh", 
            "title": "Acoustic Echo Cancellation"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#live_video_encoder_-_acoustic_echo_cancellation_aec", 
            "text": "This document describes recommended settings for Acoustic Echo Cancellation in a video streaming/video chat application.", 
            "title": "Live Video Encoder - Acoustic Echo Cancellation (AEC)"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#requirements", 
            "text": "nanoStream Live Video Encoder running on Windows Vista or Windows 7\n   RTMP Server (Wowza recommended)\n   Flash Media Player or other client\n   Microphone and Loudspeaker setup to let echo cancellation work (no headset)", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#note", 
            "text": "These settings are dependent on overall system configurations and may vary between different version releases of encoder, server and client components.", 
            "title": "NOTE:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#general_description", 
            "text": "When using microphone and speaker setups for audio/video communication, a known acoustic  echo  effect is sometimes leading to disturbing feedback loops. To remove these echoes, a special technique called  Acoustic Echo Cancellation (AEC)  may be used.  Nanocosmos AEC works by installing a special audio driver called  VoiceCaptureDriver .  There are 2 operation modes of this driver:  *usage within nanoStream Live Video Encoder\nSwitching on AEC in Live Video Encoder automatically uses the VoiceCaptureDriver  *usage within DirectShow or other applications\nThe VoiceCapture driver may be directly used as an audio recording source; \\  additionally the original audio source needs to be configured in the driver properties.", 
            "title": "General Description"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#notes", 
            "text": "All effects are dependent on hardware and software system setup, microphone and loudspeaker positions.\n   This driver uses the Microsoft  Voice Capture DSP  driver available only with Windows Vista and 7.", 
            "title": "Notes:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#sample_test_setup", 
            "text": "The nanoStream.html sample web page contains a sample implementation to show how to use the AEC feature within Live Video Encoder. Switch on  AEC  in the  Advanced Options  area.", 
            "title": "Sample / Test Setup"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#plugin_activex_configuration", 
            "text": "", 
            "title": "Plugin / ActiveX Configuration"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#switch_on_aec", 
            "text": "To switch on AEC, use the SetConfig method of the Plugin Interface:      SetConfig( AcousticEchoCancelation , 1 );  //The AEC mode supports some additional configuration settings to fine tune AEC behavior. See nanoEncoder.js for sample code.//", 
            "title": "Switch on AEC"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#echo_supression", 
            "text": "//Specifies how many times the Voice Capture performs acoustic echo suppression (AES) on the residual signal.//      SetConfig( AEC:AesTimes , 2);", 
            "title": "Echo Supression"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#possible_values", 
            "text": "0, 1, 2 (default=0)", 
            "title": "Possible Values:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#ms_property", 
            "text": "MFPKEY_WMAAECMA_FEATR_AES", 
            "title": "MS Property:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#gain_control", 
            "text": "//Specifies whether the Voice Capture DSP performs automatic gain control.//      SetConfig( AEC:Agc , 1);", 
            "title": "Gain control"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#possible_values_1", 
            "text": "0,1 (default=0)", 
            "title": "Possible Values:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#ms_property_1", 
            "text": "MFPKEY_WMAAECMA_FEATR_AGC", 
            "title": "MS Property:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#acoustic_echo_cancellation", 
            "text": "//Specifies the duration of echo that the acoustic echo cancellation (AEC) algorithm can handle, in milliseconds.//      SetConfig( AEC:AecEchoLength , 1024);", 
            "title": "Acoustic Echo Cancellation"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#possible_values_2", 
            "text": "128, 256, 512, 1024 (default=256)", 
            "title": "Possible Values:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#ms_property_2", 
            "text": "MFPKEY_WMAAECMA_FEATR_ECHO_LENGTH", 
            "title": "MS Property:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#additional_information", 
            "text": "Microsoft Notes on Windows XP:  http://support.microsoft.com/kb/310507  Microsoft Voice Capture:  http://msdn.microsoft.com/en-us/library/ff819492(v=vs.85).aspx  http://msdn.microsoft.com/en-us/library/ff819411(v=vs.85).aspx", 
            "title": "Additional Information:"
        }, 
        {
            "location": "/nanostream/support/nanostream_aec/#contact", 
            "text": "//Please contact us for further information, extended services are available upon request.//  http://www.nanocosmos.de  info@nanocosmos.de  (c) 2009-2012, nanocosmos gmbh", 
            "title": "Contact"
        }, 
        {
            "location": "/nanostream/support/nanostream_audio_levels/", 
            "text": "nanoStream Audio Levels\n\n\nThe current audio level can be queried with the method \nGetAudioLevel(int channel)\n. Valid parameters are \n0\n for the left respectively \n1\n for the right channel. Note that the plugin method gives back audio level values (\nmin value\n is \n0\n, \nmax value\n is \n32767\n) after \nStartPreview\n or \nStartBroadcast\n was invoked; before that the method will just return the current audio volume (most of the time that will be the value \n100\n).\n\n\nSimple sample code for java script:\nFirst create a variable:\n\n\nvar liveTimer = {};\n\n\n\n\n\n\nThen in the handler function for the button \nStartPreview\n or \nStartBroadcast\n method assign a function which should be called every \nx\n milliseconds (here \n100 ms\n)\n\n\nliveTimer = window.setInterval(audioLevelHandler, 100);\n\n\n\n\n\n\nThe function itself:\n\n\nfunction audioLevelHandler() {\nvar v = liveObj.GetAudioLevel(channel); // channel can be 0 for left channel or 1 for right channel\nvar percent = Math.round(v*100.0/32767.0);\n//... do something with the values\n}```\nAfter the preview or broadcast is stopped you can stop the audio level handler:\n```javascript\nwindow.clearInterval(liveTimer);\n\n\n\n\n\n\nMore frequent update of audio level values\n\nTo get the audio level data more frequently from the plugin you can use following setting:\n\n\npluginObj.SetConfig(_T(\nAudioLatency\n), _T(\n100\n)); // the 2\u00b0 value is time in ms\n\n\n\n\nThe default value for most cameras for the audio latency is 500 ms, so the audio level display can be quite delayed. You can also try to set 50ms for the AudioLatency, but 100ms should be sufficient.", 
            "title": "Audio Level"
        }, 
        {
            "location": "/nanostream/support/nanostream_audio_levels/#nanostream_audio_levels", 
            "text": "The current audio level can be queried with the method  GetAudioLevel(int channel) . Valid parameters are  0  for the left respectively  1  for the right channel. Note that the plugin method gives back audio level values ( min value  is  0 ,  max value  is  32767 ) after  StartPreview  or  StartBroadcast  was invoked; before that the method will just return the current audio volume (most of the time that will be the value  100 ).  Simple sample code for java script:\nFirst create a variable:  var liveTimer = {};   Then in the handler function for the button  StartPreview  or  StartBroadcast  method assign a function which should be called every  x  milliseconds (here  100 ms )  liveTimer = window.setInterval(audioLevelHandler, 100);   The function itself:  function audioLevelHandler() {\nvar v = liveObj.GetAudioLevel(channel); // channel can be 0 for left channel or 1 for right channel\nvar percent = Math.round(v*100.0/32767.0);\n//... do something with the values\n}```\nAfter the preview or broadcast is stopped you can stop the audio level handler:\n```javascript\nwindow.clearInterval(liveTimer);   More frequent update of audio level values \nTo get the audio level data more frequently from the plugin you can use following setting:  pluginObj.SetConfig(_T( AudioLatency ), _T( 100 )); // the 2\u00b0 value is time in ms  The default value for most cameras for the audio latency is 500 ms, so the audio level display can be quite delayed. You can also try to set 50ms for the AudioLatency, but 100ms should be sufficient.", 
            "title": "nanoStream Audio Levels"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/", 
            "text": "Auto-Adjust Bitrate \n Statistics for RTMP\n\n\nGeneral Information\n\n\nnanoStream 2.0 supports an \u201cAuto Adjust\u201d mode to control the encoded video bitrate to avoid network congestion.\nThe following modes are available:\n- Automatic Bandwidth Checker to initially set a recommended video bitrate\n- Dynamic/Adaptive Bitrate Control (ABC) during streaming\n- The ABC can be controlled automatically by an internal algorithm, or customized by using the plugin \nOnEvent\n. Event statistics are gathered by monitoring the tcp traffic on the sender side.\n\n\nBandwidth Checker / Get Recommended Bitrate\n\n\nThe bandwidth checker estimates the highest possible bitrate for your bandwidth.\nNote: please ensure that you have a stable internet connection during the bandwidth tests.\n\n\nAdaptive Bitrate Control\n\n\nAdaptive Bitrate Control additionally compensates dynamic bandwidth changes during streaming.\n- Applications - GUI and browser plugin\nThere is a checkbox \u201cAdaptive\u201d, respectively \u201cAdaptive Bitrate\u201d, available in both GUI and browser page, which enables the automatic adjustment of the bitrate.\n\n\nHow to use Adaptive Bitrate Control\n\n\n\n\nSelect the target bitrate, that is, the bitrate you want to achieve in the best (optimal) possible case (the maximum permitted bitrate)\n\n\nSet the minimum bitrate. The default of 150kB can be changed (see \nAdvanced Configuration Options\n below).\n\n\nMake sure the checkbox \u201cAdaptive Bitrate\u201d is checked\n\n\nStart broadcasting\n\n\n\n\nImportant\n\nThe bitrate will be adjusted every five seconds if necessary.\nTo achieve the best possible control of the bitrate, start the GUI or the browser plugin as administrator or as an user with administrative permissions. Otherwise the TCP traffic cannot be monitored and the actual bitrate, which is received on the client side, has to be estimated.\n\n\nConnection Status and Network Statistics send via OnEvent\n\n\nEvent notifications sent via \nOnEvent\n consist of the event type and a set of key/value pairs containing the event information. Currently there are two types of notifications send via \nOnEvent\n: RTMP Connection Status and Network Statistics.\n\n\nRTMP Connection Status Event\n\n\nType Id: 11\nThe connection status has three possible states, Key/Values: connectionStatus/connected, disconnected, reconnecting.\nReconnecting means that the plugin/rtmp client is currently trying to reestablish the connection to the server.\n\n\nRTMP Network Statistics Event\n\n\nType Id: 10\nThe tcp traffic statistics are sent as a JSON-Object.\nKeys/Values:\n\n\n{\noutputBufferSize\n : intVal, \noutputBufferFillness\n : intVal, \noutputBitrateDefault\n : intVal, \noutputBitrateFallback\n : intVal, \nvideoBitrate\n : intVal, \nroundTripTime\n : intVal}\n\n\n\n\n\n\n\n\n\n\nOption (Key)\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\noutputBufferSize\n\n\nthe maximum available buffer (in bytes)\n\n\n\n\n\n\noutputBufferFillness\n\n\nhow much if the buffer is used (in bytes)\n\n\n\n\n\n\noutputBitrateDefault\n\n\nthe estimated bitrate with which the packets are sent to the stream URL, this value is estimated by using tcp packet statistics gathered with a tcp sniffer. Only available when running as admin\n\n\n\n\n\n\noutputBitrateFallback\n\n\nlike outputBitrateDefault, but not as accurate; does not use a tcp sniffer, but is always available\n\n\n\n\n\n\nvideoBitrate\n\n\nthe bitrate used by the video encoder at the moment\n\n\n\n\n\n\nroundTripTime\n\n\nthe average time in ms, which is needed to receive an acknowledgement for a sent packet\n\n\n\n\n\n\n\n\nNote\n: If you only want the statistics but no automatic control of the bitrate make sure to uncheck the checkbox \u201cAdpative Bitrate\u201d and check the checkbox \u201cTcp Sniffing \u201d. \u201cAdaptive Bitrate\u201d and \u201cTcp Sniffing\u201d can be activated/deactivated via SetConfig(Option, Value) with the parameters \u201cAutoApplyAdaptiveBitrate\u201d, respectively \u201cUseTcpSniffing\u201d for \nOption\n and 0 (off) or 1 (on) for \nValue\n.\nFor more information about how to use the statistics, see the Javascript API and nanoStream.html sample for an example implementation.\n\n\nAdvanced Configuration Options\n\n\nThe internal algorithm for ABC can be adjusted by following variables, changed via \nSetConfig(Option, Value)\n:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNumberOfSamplesToUse\n\n\nhow many samples from the statistics should be used for adjusting the bitrate, the default value is 5\n\n\n\n\n\n\nBufferFillnessLimitIncBitrate\n\n\nthe maximum allowed buffer fillness percentage for increasing the bitrate. The default value is five percent (0.05), this value should be smaller than or equal to BufferFillnessLimitDecBitrate\n\n\n\n\n\n\nBufferFillnessLimitDecBitrate\n\n\nThe minimum buffer fillness percentage, in which case the bitrate is decreased. The default value is ten percent (0.1), this value should be bigger than or equal to BufferFillnessLimitIncBitrate\n\n\n\n\n\n\nDesiredBufferFillness\n\n\nThe desired buffer fillness percentage, the default value is 7.5 percent (0.075). This value should be between BufferFillnessLimitIncBitrate and BufferFillnessLimitDecBitrate\n\n\n\n\n\n\nMinimumBitrate\n\n\nThis value is the lower limit for the bitrate, the default value is 50Kb (50000)\n\n\n\n\n\n\nStartBitrate\n\n\nThe bitrate used at the start of the broadcast, the default value is 150Kb (150000)\n\n\n\n\n\n\nRTTLimitFactor\n\n\nthe bitrate is only increased, for the round trip\n\n\n\n\n\n\n\n\nHow ABC works\n\n\nWhen broadcasting starts the bitrate is set to the value \nStartBitrate\n. The bitrate will be checked and possibly adjusted every few seconds - the number of seconds is specified by the value NumberOfSamplesToUse (if set to five, every five seconds). Depending on the conditions at the moment of ckecking, the bitrate will either be increased, decreased or not changed at all. The bitrate value will neither be changed to a value higher than target bitrate (selected by the user) nor lower than the \nMinimumBitrate\n. If an event lowers the available bandwidth, the bitrate will be decreased accordingly. Vice versa, the bitrate will be increased if there is more bandwidth available. It can take a few minutes to reach the maximum bitrate depending on the size of the gap between the user selected target bitrate and the current bitrate.\n\n\nAdaptive Bitrate on iOS and Android\n\n\nThe ABC for iOS and Android works in a similar way to ABC on Windows.\nThe stream is started with the user selected target bitrate, which is also the maximum bitrate the ABC will use. Depending on the network conditions the bitrate will be decreased or increased. To determine the network conditions the ABC uses internal buffer and bandwidth measurements. Because encoding segments are used on iOS, the adjustment of the bitrate can take longer than on Windows or Android.\nFollowing settings are available:\n- \nminimumBitrate\n: the minimum bitrate the ABC should use as lowest bitrate setting, default is 50000 (~50 kb)\n- \nmaxPercentBitrateChange\n: it does not mean that the bitrate change will be limited to a maximum percent, but that the stream is restarted internally if the bitrate change is greater than the \nmaxPercentBitrateChange\n value. A low value will lead to many stream restarts, which in turn will lead to dropouts in the stream, default: 50 (50%).\nBoth, iOS and Android, also allow to adjust the framerate depending on the network conditions. There is an additional setting available for this mode:\n- \nminimumFramerate\n: the minimum framerate the ABC should use as lowest framerate settings, default is 15 fps\n\n\n\nABC Modes\n\n\nThere are two modes available to control the bitrate in case of low bandwidth:\n\n\nQuality Degrade - AdaptiveBitrateControlModeQualityDegrade\n\n\nUses properties:\n- minimumBitrate\n- maxPercentBitrateChange\n\n\nIn case of not enough bandwidth the ABC will decrease the bitrate incrementally. The bitrate will not be reduced under the minimum bitrate value. The framerate remains at the initially set value.\nIf the bitrate is reduced during one step by an amount larger than the maxPercentBitrateChange value, all buffered data, which was not sent yet, will be discarded. This forces the encoder to continue the stream with new data and prevents it from being stuck with processing old data. This mechanism also prevents the latency from increasing further.\n\nAdvantages\n: keeps framerate at initially set value and supports the smoothness of the video playback.\n\nDisadvantage\n: the video quality is reduced when the bitrate is reduced\n\n\nFrame Drop - AdaptiveBitrateControlModeFrameDrop.\n\n\nUses properties:\n- minimumBitrate\n- minimumFramerate\n- maxPercentBitrateChange\n\n\nLow bandwidth will be compensated by decreasing the framerate. When the bandwidth is too low the framerate will be reduced incrementally by dropping some frames. The bitrate will be reduced as well to fit the adjusted output framerate. The framerate and bitrate will be set lower than the minimum famerate and bitrate. This mechanism is designed to maintain the video image quality by reducing the smoothness of the video playback.\nThe maxPercentBitrateChange algorithm works exactly the same as described above for AdativBitrateControlModeQualityDegrade.\n\nAdvantage\n: maintains video image quality even with lower bandwidth.\n\nDisadvantage\n: framerate is reduced for low bandwidth conditions, which leads to a reduced smoothness of the video playback.", 
            "title": "Bitrate Control & Statistics"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#auto-adjust_bitrate_statistics_for_rtmp", 
            "text": "", 
            "title": "Auto-Adjust Bitrate &amp; Statistics for RTMP"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#general_information", 
            "text": "nanoStream 2.0 supports an \u201cAuto Adjust\u201d mode to control the encoded video bitrate to avoid network congestion.\nThe following modes are available:\n- Automatic Bandwidth Checker to initially set a recommended video bitrate\n- Dynamic/Adaptive Bitrate Control (ABC) during streaming\n- The ABC can be controlled automatically by an internal algorithm, or customized by using the plugin  OnEvent . Event statistics are gathered by monitoring the tcp traffic on the sender side.", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#bandwidth_checker_get_recommended_bitrate", 
            "text": "The bandwidth checker estimates the highest possible bitrate for your bandwidth.\nNote: please ensure that you have a stable internet connection during the bandwidth tests.", 
            "title": "Bandwidth Checker / Get Recommended Bitrate"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#adaptive_bitrate_control", 
            "text": "Adaptive Bitrate Control additionally compensates dynamic bandwidth changes during streaming.\n- Applications - GUI and browser plugin\nThere is a checkbox \u201cAdaptive\u201d, respectively \u201cAdaptive Bitrate\u201d, available in both GUI and browser page, which enables the automatic adjustment of the bitrate.", 
            "title": "Adaptive Bitrate Control"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#how_to_use_adaptive_bitrate_control", 
            "text": "Select the target bitrate, that is, the bitrate you want to achieve in the best (optimal) possible case (the maximum permitted bitrate)  Set the minimum bitrate. The default of 150kB can be changed (see  Advanced Configuration Options  below).  Make sure the checkbox \u201cAdaptive Bitrate\u201d is checked  Start broadcasting   Important \nThe bitrate will be adjusted every five seconds if necessary.\nTo achieve the best possible control of the bitrate, start the GUI or the browser plugin as administrator or as an user with administrative permissions. Otherwise the TCP traffic cannot be monitored and the actual bitrate, which is received on the client side, has to be estimated.", 
            "title": "How to use Adaptive Bitrate Control"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#connection_status_and_network_statistics_send_via_onevent", 
            "text": "Event notifications sent via  OnEvent  consist of the event type and a set of key/value pairs containing the event information. Currently there are two types of notifications send via  OnEvent : RTMP Connection Status and Network Statistics.", 
            "title": "Connection Status and Network Statistics send via OnEvent"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#rtmp_connection_status_event", 
            "text": "Type Id: 11\nThe connection status has three possible states, Key/Values: connectionStatus/connected, disconnected, reconnecting.\nReconnecting means that the plugin/rtmp client is currently trying to reestablish the connection to the server.", 
            "title": "RTMP Connection Status Event"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#rtmp_network_statistics_event", 
            "text": "Type Id: 10\nThe tcp traffic statistics are sent as a JSON-Object.\nKeys/Values:  { outputBufferSize  : intVal,  outputBufferFillness  : intVal,  outputBitrateDefault  : intVal,  outputBitrateFallback  : intVal,  videoBitrate  : intVal,  roundTripTime  : intVal}     Option (Key)  Description      outputBufferSize  the maximum available buffer (in bytes)    outputBufferFillness  how much if the buffer is used (in bytes)    outputBitrateDefault  the estimated bitrate with which the packets are sent to the stream URL, this value is estimated by using tcp packet statistics gathered with a tcp sniffer. Only available when running as admin    outputBitrateFallback  like outputBitrateDefault, but not as accurate; does not use a tcp sniffer, but is always available    videoBitrate  the bitrate used by the video encoder at the moment    roundTripTime  the average time in ms, which is needed to receive an acknowledgement for a sent packet     Note : If you only want the statistics but no automatic control of the bitrate make sure to uncheck the checkbox \u201cAdpative Bitrate\u201d and check the checkbox \u201cTcp Sniffing \u201d. \u201cAdaptive Bitrate\u201d and \u201cTcp Sniffing\u201d can be activated/deactivated via SetConfig(Option, Value) with the parameters \u201cAutoApplyAdaptiveBitrate\u201d, respectively \u201cUseTcpSniffing\u201d for  Option  and 0 (off) or 1 (on) for  Value .\nFor more information about how to use the statistics, see the Javascript API and nanoStream.html sample for an example implementation.", 
            "title": "RTMP Network Statistics Event"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#advanced_configuration_options", 
            "text": "The internal algorithm for ABC can be adjusted by following variables, changed via  SetConfig(Option, Value) :     Option  Description      NumberOfSamplesToUse  how many samples from the statistics should be used for adjusting the bitrate, the default value is 5    BufferFillnessLimitIncBitrate  the maximum allowed buffer fillness percentage for increasing the bitrate. The default value is five percent (0.05), this value should be smaller than or equal to BufferFillnessLimitDecBitrate    BufferFillnessLimitDecBitrate  The minimum buffer fillness percentage, in which case the bitrate is decreased. The default value is ten percent (0.1), this value should be bigger than or equal to BufferFillnessLimitIncBitrate    DesiredBufferFillness  The desired buffer fillness percentage, the default value is 7.5 percent (0.075). This value should be between BufferFillnessLimitIncBitrate and BufferFillnessLimitDecBitrate    MinimumBitrate  This value is the lower limit for the bitrate, the default value is 50Kb (50000)    StartBitrate  The bitrate used at the start of the broadcast, the default value is 150Kb (150000)    RTTLimitFactor  the bitrate is only increased, for the round trip", 
            "title": "Advanced Configuration Options"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#how_abc_works", 
            "text": "When broadcasting starts the bitrate is set to the value  StartBitrate . The bitrate will be checked and possibly adjusted every few seconds - the number of seconds is specified by the value NumberOfSamplesToUse (if set to five, every five seconds). Depending on the conditions at the moment of ckecking, the bitrate will either be increased, decreased or not changed at all. The bitrate value will neither be changed to a value higher than target bitrate (selected by the user) nor lower than the  MinimumBitrate . If an event lowers the available bandwidth, the bitrate will be decreased accordingly. Vice versa, the bitrate will be increased if there is more bandwidth available. It can take a few minutes to reach the maximum bitrate depending on the size of the gap between the user selected target bitrate and the current bitrate.", 
            "title": "How ABC works"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#adaptive_bitrate_on_ios_and_android", 
            "text": "The ABC for iOS and Android works in a similar way to ABC on Windows.\nThe stream is started with the user selected target bitrate, which is also the maximum bitrate the ABC will use. Depending on the network conditions the bitrate will be decreased or increased. To determine the network conditions the ABC uses internal buffer and bandwidth measurements. Because encoding segments are used on iOS, the adjustment of the bitrate can take longer than on Windows or Android.\nFollowing settings are available:\n-  minimumBitrate : the minimum bitrate the ABC should use as lowest bitrate setting, default is 50000 (~50 kb)\n-  maxPercentBitrateChange : it does not mean that the bitrate change will be limited to a maximum percent, but that the stream is restarted internally if the bitrate change is greater than the  maxPercentBitrateChange  value. A low value will lead to many stream restarts, which in turn will lead to dropouts in the stream, default: 50 (50%).\nBoth, iOS and Android, also allow to adjust the framerate depending on the network conditions. There is an additional setting available for this mode:\n-  minimumFramerate : the minimum framerate the ABC should use as lowest framerate settings, default is 15 fps", 
            "title": "Adaptive Bitrate on iOS and Android"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#abc_modes", 
            "text": "There are two modes available to control the bitrate in case of low bandwidth:", 
            "title": "ABC Modes"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#quality_degrade_-_adaptivebitratecontrolmodequalitydegrade", 
            "text": "Uses properties:\n- minimumBitrate\n- maxPercentBitrateChange  In case of not enough bandwidth the ABC will decrease the bitrate incrementally. The bitrate will not be reduced under the minimum bitrate value. The framerate remains at the initially set value.\nIf the bitrate is reduced during one step by an amount larger than the maxPercentBitrateChange value, all buffered data, which was not sent yet, will be discarded. This forces the encoder to continue the stream with new data and prevents it from being stuck with processing old data. This mechanism also prevents the latency from increasing further. Advantages : keeps framerate at initially set value and supports the smoothness of the video playback. Disadvantage : the video quality is reduced when the bitrate is reduced", 
            "title": "Quality Degrade - AdaptiveBitrateControlModeQualityDegrade"
        }, 
        {
            "location": "/nanostream/support/nanostream_bitrate_control_statistics/#frame_drop_-_adaptivebitratecontrolmodeframedrop", 
            "text": "Uses properties:\n- minimumBitrate\n- minimumFramerate\n- maxPercentBitrateChange  Low bandwidth will be compensated by decreasing the framerate. When the bandwidth is too low the framerate will be reduced incrementally by dropping some frames. The bitrate will be reduced as well to fit the adjusted output framerate. The framerate and bitrate will be set lower than the minimum famerate and bitrate. This mechanism is designed to maintain the video image quality by reducing the smoothness of the video playback.\nThe maxPercentBitrateChange algorithm works exactly the same as described above for AdativBitrateControlModeQualityDegrade. Advantage : maintains video image quality even with lower bandwidth. Disadvantage : framerate is reduced for low bandwidth conditions, which leads to a reduced smoothness of the video playback.", 
            "title": "Frame Drop - AdaptiveBitrateControlModeFrameDrop."
        }, 
        {
            "location": "/nanostream/support/nanostream_latency/", 
            "text": "nanoStream - Latency\n\n\nThe latency for a stream depends on the protocol, which is used to view the stream, and also on the buffer size for the player. RTMP allows a lower latency than HLS. Common latency values for RTMP are 2 to 5 seconds. Whereas latency values for HLS are often between 20 to 30 seconds.\nNotice that RTMP servers, like Wowza, allow to transcode a RTMP stream to HLS.\n\n\nHow is the stream viewed on the receiver side\n\n\n\n\nWith Flash-Player in a browser or RTMP source player (available in the SDK downloads for iOS and Android - and also available on Windows)\n\n\nNative playback on mobile devices use in general HLS, so the latency will be significantly higher.\n\n\n\n\nHLS settings for Wowza\n\n\nThe latency for HLS depends on the chunk size (for wowza: cupertinoChunkDurationTarget), as described here:\n- \nHLS from Live Camera\n\n- \nCupertino Streaming Segmenter\n\n- \nMinimizing HLS Latency\n\n\nBasically, \u201ccupertinoChunkDurationTarget\u201d has to be modified to achive a lower latency for HLS. For example, using:\n\ncupertinoChunkDurationTarget=2000 (in milliseconds)\n should lead to a lower latency (less than 10 seconds).\n\n\nPlatform specific latency settings\n\n\niOS\n\n\nNotice\n: Following descriptions assume that HLS is not used.\nThere are two encoding modes:\n1. NSXEncodingModeAdvancedInMemory (default): available since version 4.0.0.0, requires at least iOS 8. This mode allows low latency from 0.5 to 2 seconds. The buffer setting on the player side is the main factor for the latency.\n2. NSXEncodingModeLegacy: backwards compatible for iOS 7.\n\n\nFor this mode, the latency is around 2 to 4 seconds. By changing the settings for the parameters \u201cframerate\u201d and \u201ckeyFramerate\u201d it is possible to influence the latency. Using the standard settings: framerate=30fps and keyFramerate=60 - the latency should be around 2 to 3 seconds.", 
            "title": "Latency"
        }, 
        {
            "location": "/nanostream/support/nanostream_latency/#nanostream_-_latency", 
            "text": "The latency for a stream depends on the protocol, which is used to view the stream, and also on the buffer size for the player. RTMP allows a lower latency than HLS. Common latency values for RTMP are 2 to 5 seconds. Whereas latency values for HLS are often between 20 to 30 seconds.\nNotice that RTMP servers, like Wowza, allow to transcode a RTMP stream to HLS.", 
            "title": "nanoStream - Latency"
        }, 
        {
            "location": "/nanostream/support/nanostream_latency/#how_is_the_stream_viewed_on_the_receiver_side", 
            "text": "With Flash-Player in a browser or RTMP source player (available in the SDK downloads for iOS and Android - and also available on Windows)  Native playback on mobile devices use in general HLS, so the latency will be significantly higher.", 
            "title": "How is the stream viewed on the receiver side"
        }, 
        {
            "location": "/nanostream/support/nanostream_latency/#hls_settings_for_wowza", 
            "text": "The latency for HLS depends on the chunk size (for wowza: cupertinoChunkDurationTarget), as described here:\n-  HLS from Live Camera \n-  Cupertino Streaming Segmenter \n-  Minimizing HLS Latency  Basically, \u201ccupertinoChunkDurationTarget\u201d has to be modified to achive a lower latency for HLS. For example, using: cupertinoChunkDurationTarget=2000 (in milliseconds)  should lead to a lower latency (less than 10 seconds).", 
            "title": "HLS settings for Wowza"
        }, 
        {
            "location": "/nanostream/support/nanostream_latency/#platform_specific_latency_settings", 
            "text": "", 
            "title": "Platform specific latency settings"
        }, 
        {
            "location": "/nanostream/support/nanostream_latency/#ios", 
            "text": "Notice : Following descriptions assume that HLS is not used.\nThere are two encoding modes:\n1. NSXEncodingModeAdvancedInMemory (default): available since version 4.0.0.0, requires at least iOS 8. This mode allows low latency from 0.5 to 2 seconds. The buffer setting on the player side is the main factor for the latency.\n2. NSXEncodingModeLegacy: backwards compatible for iOS 7.  For this mode, the latency is around 2 to 4 seconds. By changing the settings for the parameters \u201cframerate\u201d and \u201ckeyFramerate\u201d it is possible to influence the latency. Using the standard settings: framerate=30fps and keyFramerate=60 - the latency should be around 2 to 3 seconds.", 
            "title": "iOS"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/", 
            "text": "Live Video Encoder - Low Latency Streaming\n\n\nOverview:\n\n\nThis document describes recommended settings to reduce overall end-to-end delay/latency in a video streaming/video chat application.\nLatency is primarily based on stream buffers. The lower the buffers, the lower is the latency.\nBuffers can happen on all parts of a stream, encoder, streamer, server, CDN and player.\n\n\n//NOTE: These settings are dependent on overall system configurations and may vary between different version releases of encoder, server and client components.//\n\n\nChoosing the right stream protocol\n\n\nLowest latency for client-server based streaming can be reached with RTMP.\nWith additional fine tuning, you can reach end-to-end-latency values below 1 second.\nFor local area networks, UDP-TS has the lowest latency.\nHLS, HDS, Smooth Streaming and MPEG DASH have high buffers by default and are not suitable for low latency applications.\n\n\nEncoder Configuration\n\n\nOn Application/API level, nanoStream provides some functions to decrease end-to-end latency.\n\n\nnanoStream Encoder Configuration\n\n\nnanoStream supports some external and internal settings which may affect latency.\n\n\nUsage of Baseline profile is recommended if suitable\nregarding the quality/bitrate scenario.\nFramerates should be as high as possible (20-25-30 fps).\nLower than 15 fps might \nincrease\n the\noverall latency, due to frame buffering.\n\n\nBaseline Profile\n\n\nHighest compatibility, low cpu/system requirements, low latency\\\nApplications: Standard web streaming configuration for up to SD resolution, 15-30 fps and 0.1-1.5 Mbit video bitrate:\n\n\nnanoStream.SetConfig(\nH264Profile\n, \nBaseline\n);            // Baseline Profile supported by most devices and players\nnanoStream.SetConfig(\nH264IFrameDistance\n, \n50\n);       // Moderate GOP length\nnanoStream.SetConfig(\nH264PFrameDistance\n, \n1\n);        // No B-frames\n\n\n\n\nMain Profile\n\n\nCompatibility to most devices, low latency\\\nApplications: Standard web streaming configuration for up to SD resolution, 15-30 fps and 0.1-1.5 Mbit video bitrate:\n\n\nnanoStream.SetConfig(\nH264Profile\n, \nMain\n);                 // Main Profile\nnanoStream.SetConfig(\nH264IFrameDistance\n, \n50\n);      // Moderate GOP length\nnanoStream.SetConfig(\nH264PFrameDistance\n, \n1\n);       // No B-frames\n//nanoStream.SetConfig(\nH264PFrameDistance\n, \n3\n);       // Optional: 2 B-frames (better quality, slightly higher latency)\n\n\n\n\nPerformance settings\n\n\nnanoStream.SetConfig(\nH264VlcMode\n, \n1\n);                    // CAVLC entropy coding mode\nnanoStream.SetConfig(\nRateControl\n, \n1\n);                       // Strict constant bitrate\nnanoStream.SetConfig(\nH264Quality\n, \n1\n);                      // Moderate quality, lower cpu requirements\n\n\n\n\nAdditional low-latency settings\n\n\nThe Plugin Interface supports one function \nLowDelayOn\n which sets some internal buffer settings to achieve lower latency:\n\n\n  LowDelayOn() {\n  SetConfig(\nTcpNoDelay\n,\n0\n);\n  SetConfig(\nOutBufferSize\n,\n0\n);\n  SetConfig(\nSocketBufferSize\n,\n524288\n);\n  }\n\n\n\n\nRTMP Writer\n\n\nWe recommend connecting to the server before starting the stream.\nOn Windows, use StartConnect or IRTMPOptions::ConnectServer\nto establish the server connection before the stream\nis started (this is done automatically when using the plugin).\n\n\nTCP/IP Networking\n\n\nOn the network level we recommend to use\nIRTMPOptions::SetTcpNoDelay(true) which\ndisables the use of the nagle algorithm to\ndecrease latency. For the plugin this can be set with the option \nTcpNoDelay\n for SetConfig().\n\n\nCapture devices\n\n\nIt is important that the latency/sample buffer size\nis not too big for the audio capture device pin.\nBy default audio devices might use 500ms-1s.\nWe recommend buffer sizes/audio latencies\nbetween 50ms-100ms.\nFor Windows, this can be configured for the plugin using the option \nAudioLatency\n for SetConfig() or on DirectShow level with IAMBufferNegotiation::SuggestAllocatorProperties.\n\n\nPlayer Configuration\n\n\nThe Player buffers have a high impact on latency.\nFlash Player net stream buffer should be set to a low value or 0:\n(e.g. jwplayer or others)\n\n\nNetStream buffer = 0.1   or    0  \n\n\nWowza Server Configuration\n\n\nTo improve delay, one server based config can be changed on Wowza:\\\nchangeing\n\n\nStreamType\nlive\n/StreamType\n\n\n\n\n\nto\n\n\nStreamType\nlive-lowlatency\n/StreamType\n\n\n\n\n\nFor low latency chat applications, it is best to use smaller socket buffer sizes (16000 bytes for read and write). The socket buffer sizes are configured in \n[install-dir]/conf/VHost.xml:\n\n\nCode:\n\n\nReceiveBufferSize\n16000\n/ReceiveBufferSize\n\n\nSendBufferSize\n16000\n/SendBufferSize\n\n\n\n\n\nFurther information:\n\n\nhttp://www.wowzamedia.com/forums_46\n\n\nhttp://www.wowzamedia.com/forums_8\n\n\nPlease contact us for further information, additional support and consulting services are available upon request.\n\n\nhttp://www.nanocosmos.de\n\n\ninfo@nanocosmos.de\n\n\n(c) 2009-2015, nanocosmos gmbh", 
            "title": "Low Latency"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#live_video_encoder_-_low_latency_streaming", 
            "text": "", 
            "title": "Live Video Encoder - Low Latency Streaming"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#overview", 
            "text": "This document describes recommended settings to reduce overall end-to-end delay/latency in a video streaming/video chat application.\nLatency is primarily based on stream buffers. The lower the buffers, the lower is the latency.\nBuffers can happen on all parts of a stream, encoder, streamer, server, CDN and player.  //NOTE: These settings are dependent on overall system configurations and may vary between different version releases of encoder, server and client components.//", 
            "title": "Overview:"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#choosing_the_right_stream_protocol", 
            "text": "Lowest latency for client-server based streaming can be reached with RTMP.\nWith additional fine tuning, you can reach end-to-end-latency values below 1 second.\nFor local area networks, UDP-TS has the lowest latency.\nHLS, HDS, Smooth Streaming and MPEG DASH have high buffers by default and are not suitable for low latency applications.", 
            "title": "Choosing the right stream protocol"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#encoder_configuration", 
            "text": "On Application/API level, nanoStream provides some functions to decrease end-to-end latency.", 
            "title": "Encoder Configuration"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#nanostream_encoder_configuration", 
            "text": "nanoStream supports some external and internal settings which may affect latency.  Usage of Baseline profile is recommended if suitable\nregarding the quality/bitrate scenario.\nFramerates should be as high as possible (20-25-30 fps).\nLower than 15 fps might  increase  the\noverall latency, due to frame buffering.", 
            "title": "nanoStream Encoder Configuration"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#baseline_profile", 
            "text": "Highest compatibility, low cpu/system requirements, low latency\\\nApplications: Standard web streaming configuration for up to SD resolution, 15-30 fps and 0.1-1.5 Mbit video bitrate:  nanoStream.SetConfig( H264Profile ,  Baseline );            // Baseline Profile supported by most devices and players\nnanoStream.SetConfig( H264IFrameDistance ,  50 );       // Moderate GOP length\nnanoStream.SetConfig( H264PFrameDistance ,  1 );        // No B-frames", 
            "title": "Baseline Profile"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#main_profile", 
            "text": "Compatibility to most devices, low latency\\\nApplications: Standard web streaming configuration for up to SD resolution, 15-30 fps and 0.1-1.5 Mbit video bitrate:  nanoStream.SetConfig( H264Profile ,  Main );                 // Main Profile\nnanoStream.SetConfig( H264IFrameDistance ,  50 );      // Moderate GOP length\nnanoStream.SetConfig( H264PFrameDistance ,  1 );       // No B-frames\n//nanoStream.SetConfig( H264PFrameDistance ,  3 );       // Optional: 2 B-frames (better quality, slightly higher latency)  Performance settings  nanoStream.SetConfig( H264VlcMode ,  1 );                    // CAVLC entropy coding mode\nnanoStream.SetConfig( RateControl ,  1 );                       // Strict constant bitrate\nnanoStream.SetConfig( H264Quality ,  1 );                      // Moderate quality, lower cpu requirements", 
            "title": "Main Profile"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#additional_low-latency_settings", 
            "text": "The Plugin Interface supports one function  LowDelayOn  which sets some internal buffer settings to achieve lower latency:    LowDelayOn() {\n  SetConfig( TcpNoDelay , 0 );\n  SetConfig( OutBufferSize , 0 );\n  SetConfig( SocketBufferSize , 524288 );\n  }  RTMP Writer  We recommend connecting to the server before starting the stream.\nOn Windows, use StartConnect or IRTMPOptions::ConnectServer\nto establish the server connection before the stream\nis started (this is done automatically when using the plugin).  TCP/IP Networking  On the network level we recommend to use\nIRTMPOptions::SetTcpNoDelay(true) which\ndisables the use of the nagle algorithm to\ndecrease latency. For the plugin this can be set with the option  TcpNoDelay  for SetConfig().  Capture devices  It is important that the latency/sample buffer size\nis not too big for the audio capture device pin.\nBy default audio devices might use 500ms-1s.\nWe recommend buffer sizes/audio latencies\nbetween 50ms-100ms.\nFor Windows, this can be configured for the plugin using the option  AudioLatency  for SetConfig() or on DirectShow level with IAMBufferNegotiation::SuggestAllocatorProperties.", 
            "title": "Additional low-latency settings"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#player_configuration", 
            "text": "The Player buffers have a high impact on latency.\nFlash Player net stream buffer should be set to a low value or 0:\n(e.g. jwplayer or others)  NetStream buffer = 0.1   or    0", 
            "title": "Player Configuration"
        }, 
        {
            "location": "/nanostream/support/nanostream_low_latency/#wowza_server_configuration", 
            "text": "To improve delay, one server based config can be changed on Wowza:\\\nchangeing  StreamType live /StreamType   to  StreamType live-lowlatency /StreamType   For low latency chat applications, it is best to use smaller socket buffer sizes (16000 bytes for read and write). The socket buffer sizes are configured in  [install-dir]/conf/VHost.xml:  Code:  ReceiveBufferSize 16000 /ReceiveBufferSize  SendBufferSize 16000 /SendBufferSize   Further information:  http://www.wowzamedia.com/forums_46  http://www.wowzamedia.com/forums_8  Please contact us for further information, additional support and consulting services are available upon request.  http://www.nanocosmos.de  info@nanocosmos.de  (c) 2009-2015, nanocosmos gmbh", 
            "title": "Wowza Server Configuration"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/", 
            "text": "nanoStream Live Video Encoder Mixer / Overlay\n\n\nLive Video Encoder supports several enhancements to video source mixing and overlays. Video mixing of 2 input video signals Text and bitmap overlay Region based capture\nAll functions can be used from within nanoStream plugin applications or by using DirectShow filter setups.\n\n\nRequirements:\n\n\n\n\nNanocosmos Live Video Encoder Web Plugins\n\n\nNanocosmos Video Mixer DirectShow Filter (for video mixing)\n\n\nNanocosmos Text/Bitmap Overlay Filter (for text or image overlay)\n\n\nVideo mixing and text/image overlay can be used independently.\n\n\n\n\nUsage\n\n\nUsage of Video Mixer:\n\n\nSelect 2 video sources:\n- Unordered List ItemUsage for nanovid plugin: Set the \nVideoSource\n and \nVideoSource2\n properties\n- Use for \nnanoEncoder.js\n: call \nSetVideoSource\n and \nSetVideoSource2\n\nThe parameters to the properties are the index numbers of the video capture device (0..n)\nSelect Video Mixing Mode: 0=off, 16+1=left/right, 16+2=left/right narrow, 16+7 \u2026 picture-in-picture\n\n\nUsage of Text/Bitmap Overlay:\n\n\nAn overlay can either be a text or an image. If the specified string contains an extension, like \n.txt, .bmp, .jpg or .png\n , the encoder tries to load the file from the given path. If no file extension is found the encoder assumes that the text in the string should be displayed directly.\nSet the \nTextOverlayText\n Property to the text or file name\nSet the \nVideoEffect\n Property: 0=off, 1=left top, 2=right top, 3=left bottom, 4=left top, 5=user defined position\n\n\nSetting the overlay position\n\n\nOnly possible when \nVideoEffect\n Property is set to 5.\n1. via the Windows Registry (search for regedit in the Windows Start Menu):\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nanoStream\n\nKey\n: \u201cOverlayLeft\u201d \nDefault Value\n: VideoWidth1/20\n\nKey\n: \u201cOverlayTop\u201d \nDefault Value\n: VideoHeight1/20\n2. via \nSetConfig()\n:\n\nSetConfig(\u201cOverlayOrigin\u201d, \u201c0,$left,$top\u201d)\n: left and top coordiantes can be specified; right and bottom coordinates are determined automatically, the first value is the index of the overlay (always 0, if only one overlay is used)\n\nSetConfig(\u201cOverlayRect\u201d, \u201c0,$left,$top,$right,$bottom\u201d)\n: all coordinates are specified, the image or text is resized if necessary\n\n\nUsing more than one Overlay\n\n\nTo use more than one overlay the \nVideoEffect\n property has to be set to 5 (free positioning)! To add a new overlay apply following steps:\n1. \nSetConfig(\u201cAddOverlay\u201d, text)\n, where \ntext\n can be a path to a file or simple text.\n2. Get the index of the overlay: \nnanovideo.GetIndexOfOverlay(text)\n, \ntext\n has to be same as in the previous step.\n3. Use either \nSetConfig(\u201cOverlayOrigin\u201d, \u201c$index,$left,$top\u201d)\n or \nSetConfig(\u201cOverlayRect\u201d, \u201c$index,$left,$top,$right,$bottom\u201d)\n\n\nOverlay Options\n\n\nOptions can be set with \nSetConfig\n and apply for all overlays used.\n- \nOverlayTextColor\n: foreground color for text overlays\n- \nOverlayBackgroundColor\n: background color\n- \nOverlaySkipColor\n: color which should be not rendered, if the same as background color, no background is being drawn\n- \nOverlayAlpha\n: the opaqueness of the overlay - from invisble (0.0) to fully opaque (1.0)\n\n\nColors are supplied as strings containing a COLORREF (RGB macro can be used), e.g. \u201c0x00FF0000\u201d.\nRegistry Keys:\n\nKey\n: \u201cOverlayBackColor\u201d \nDefault Value\n: 0\n\nKey\n: \u201cOverlayTextColor\u201d \nDefault Value\n: 0x000099FF\n\n\nUsage of Region Capture:\n\n\nTo capture a region of the input video, use the \nCaptureRegion\n configuration values or call the \nSetCaptureRegion\n Javascript Function.\n\n\nnanovideo.SetConfig(\nCaptureRegion\n,\nleft,right,top,bottom\n)\nnanovideo.SetConfig(\nCaptureRegion\n,100,420,50,290)\n\n\n\n\nDuring Encoding/Streaming, the CaptureRegion may be changed to follow a region object on the screen. For simpler usage of moving the origin of the region, the SetRegion method may be used:\n\n\nSetRegion(left, top)\n\n\n\n\nSee example implementation in \nnanoStream.html", 
            "title": "Overlay Mixer"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#nanostream_live_video_encoder_mixer_overlay", 
            "text": "Live Video Encoder supports several enhancements to video source mixing and overlays. Video mixing of 2 input video signals Text and bitmap overlay Region based capture\nAll functions can be used from within nanoStream plugin applications or by using DirectShow filter setups.", 
            "title": "nanoStream Live Video Encoder Mixer / Overlay"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#requirements", 
            "text": "Nanocosmos Live Video Encoder Web Plugins  Nanocosmos Video Mixer DirectShow Filter (for video mixing)  Nanocosmos Text/Bitmap Overlay Filter (for text or image overlay)  Video mixing and text/image overlay can be used independently.", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#usage", 
            "text": "", 
            "title": "Usage"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#usage_of_video_mixer", 
            "text": "Select 2 video sources:\n- Unordered List ItemUsage for nanovid plugin: Set the  VideoSource  and  VideoSource2  properties\n- Use for  nanoEncoder.js : call  SetVideoSource  and  SetVideoSource2 \nThe parameters to the properties are the index numbers of the video capture device (0..n)\nSelect Video Mixing Mode: 0=off, 16+1=left/right, 16+2=left/right narrow, 16+7 \u2026 picture-in-picture", 
            "title": "Usage of Video Mixer:"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#usage_of_textbitmap_overlay", 
            "text": "An overlay can either be a text or an image. If the specified string contains an extension, like  .txt, .bmp, .jpg or .png  , the encoder tries to load the file from the given path. If no file extension is found the encoder assumes that the text in the string should be displayed directly.\nSet the  TextOverlayText  Property to the text or file name\nSet the  VideoEffect  Property: 0=off, 1=left top, 2=right top, 3=left bottom, 4=left top, 5=user defined position", 
            "title": "Usage of Text/Bitmap Overlay:"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#setting_the_overlay_position", 
            "text": "Only possible when  VideoEffect  Property is set to 5.\n1. via the Windows Registry (search for regedit in the Windows Start Menu):\nRegistry Key: HKCU\\SOFTWARE\\nanocosmos\\nanoStream Key : \u201cOverlayLeft\u201d  Default Value : VideoWidth1/20 Key : \u201cOverlayTop\u201d  Default Value : VideoHeight1/20\n2. via  SetConfig() : SetConfig(\u201cOverlayOrigin\u201d, \u201c0,$left,$top\u201d) : left and top coordiantes can be specified; right and bottom coordinates are determined automatically, the first value is the index of the overlay (always 0, if only one overlay is used) SetConfig(\u201cOverlayRect\u201d, \u201c0,$left,$top,$right,$bottom\u201d) : all coordinates are specified, the image or text is resized if necessary", 
            "title": "Setting the overlay position"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#using_more_than_one_overlay", 
            "text": "To use more than one overlay the  VideoEffect  property has to be set to 5 (free positioning)! To add a new overlay apply following steps:\n1.  SetConfig(\u201cAddOverlay\u201d, text) , where  text  can be a path to a file or simple text.\n2. Get the index of the overlay:  nanovideo.GetIndexOfOverlay(text) ,  text  has to be same as in the previous step.\n3. Use either  SetConfig(\u201cOverlayOrigin\u201d, \u201c$index,$left,$top\u201d)  or  SetConfig(\u201cOverlayRect\u201d, \u201c$index,$left,$top,$right,$bottom\u201d)", 
            "title": "Using more than one Overlay"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#overlay_options", 
            "text": "Options can be set with  SetConfig  and apply for all overlays used.\n-  OverlayTextColor : foreground color for text overlays\n-  OverlayBackgroundColor : background color\n-  OverlaySkipColor : color which should be not rendered, if the same as background color, no background is being drawn\n-  OverlayAlpha : the opaqueness of the overlay - from invisble (0.0) to fully opaque (1.0)  Colors are supplied as strings containing a COLORREF (RGB macro can be used), e.g. \u201c0x00FF0000\u201d.\nRegistry Keys: Key : \u201cOverlayBackColor\u201d  Default Value : 0 Key : \u201cOverlayTextColor\u201d  Default Value : 0x000099FF", 
            "title": "Overlay Options"
        }, 
        {
            "location": "/nanostream/support/nanostream_mixer_overlay/#usage_of_region_capture", 
            "text": "To capture a region of the input video, use the  CaptureRegion  configuration values or call the  SetCaptureRegion  Javascript Function.  nanovideo.SetConfig( CaptureRegion , left,right,top,bottom )\nnanovideo.SetConfig( CaptureRegion ,100,420,50,290)  During Encoding/Streaming, the CaptureRegion may be changed to follow a region object on the screen. For simpler usage of moving the origin of the region, the SetRegion method may be used:  SetRegion(left, top)  See example implementation in  nanoStream.html", 
            "title": "Usage of Region Capture:"
        }, 
        {
            "location": "/nanostream/support/nanostream_mp4_recording/", 
            "text": "Mp4 Recording on the fly\n\n\nIt is possible to start and stop the local file recording while a broadcast is running. To use this feature, the SetConfig option \nMp4RecordOnTheFly\n has to be enabled, before the broadcast is started. With a second SetConfig option (\nMp4RecordOnTheFlyControl\n) a recording can be started and stopped while the broadcast is running.\n\n\nThe mp4 file name will be the same for every recording started and stopped during a broadcast. If a previous recording exists, it will be renamed.\nFor example if the file name is \ntest.mp4\n and three recording were made during the broadcast, following files will exist:\n  - test.mp4\n  - test_1.mp4\n  - test_2.mp4\n\n\nSee [[live_video_encoder_-_plugin_integration_api#mp4_recording|here]] for further information about the SetConfig options.", 
            "title": "MP4 Recording"
        }, 
        {
            "location": "/nanostream/support/nanostream_mp4_recording/#mp4_recording_on_the_fly", 
            "text": "It is possible to start and stop the local file recording while a broadcast is running. To use this feature, the SetConfig option  Mp4RecordOnTheFly  has to be enabled, before the broadcast is started. With a second SetConfig option ( Mp4RecordOnTheFlyControl ) a recording can be started and stopped while the broadcast is running.  The mp4 file name will be the same for every recording started and stopped during a broadcast. If a previous recording exists, it will be renamed.\nFor example if the file name is  test.mp4  and three recording were made during the broadcast, following files will exist:\n  - test.mp4\n  - test_1.mp4\n  - test_2.mp4  See [[live_video_encoder_-_plugin_integration_api#mp4_recording|here]] for further information about the SetConfig options.", 
            "title": "Mp4 Recording on the fly"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/", 
            "text": "nanoStream Remote Server Recording\n\n\nRecording on demand on Flash Media Server\n\n\nGeneral Information\n\n\nnanoStream 2.0 supports a \nRemote Server Record\n mode to enable server based video recording functionality. Currently this works only with Flash Media Server. See Wowza section for how to record on demand to Wowza Media Server.\n\n\nRequirements:\n\n\n\n\nFlash Media Server 3/4 or higher\n\n\nThe application must support recording. Some preinstalled applications (live on FMS4) dont. To test recording, you have to create a new application folder in FMS_DIR\\applications, and copy the files from FMS_DIR\\samples\\applications\\live into it.\n\n\nStreams containing H.264/AVC video data have to be named matching the \nmp4:streamname\n scheme, otherwise recording will fail. Sample stream URL: \nrtmp://localhost/liverec+mp4:samplerec.mp4\n\n\nThe recorded file can be found in the directory specified with LIVE_DIR in the config file FMS_DIR\\conf\\fms.ini\n\n\n\n\nUsage:\n\n\n\n\nSet the publish mode with a call to \nSetRTMPPublishMode\n before calling \nStartBroadcast()\n - if you use the RTMP filter directly use the property \nPROPID_nanoRTMPPublishMode\n\n\nValid Values are:\n\n\n0 - live(no recording),\n\n\n1 - record(rewrite file),\n\n\n2 - append(append to file)\n\n\n\n\n\n\nJavascript API:\n\n\ncall the function SetRTMPPublishMode()to configure publish mode\n\n\n\n\n\n\nPlugin API / ActiveX / C/C++:\n\n\nCall the API function setConfig with parameter name \nRTMPPublishMode\n:\n\n\nnanoStream.setConfig(\nRTMPPublishMode\n,\n1\n);\n\n\n\n\n\n\n\n\nSample Web Application:\n\n\nSee the HTML web page in the folder web/liveEncoder/nanoStream.html\\\nThe feature is implemented there under \nAdvanced Options\n.\\\nSee the function code for SetRTMPPublishMode  in nanoEncoder.js for how it is implemented in Javascript.\\\n\n\nRecording on demand on Wowza Media Server\n\n\nGeneral Information\n\n\nnanoStream 2.0 supports a \nRemote Server Record\n mode to enable server based video recording functionality. Currently this works only with Wowza Media Server and an additional server plugin.\n\n\nWowza Streaming Engine\n\n\n\n\nEdit the file Application.xml at: [install-dir]/conf/[application]/\n\n\nEdit the \nStreamType\n to: \nlive-record\n\n\n\n\nOlder Versions\n\n\nRequirements:\n\n\n\n\nWowza Media Server 2.0.0.4 or higher.\n\n\nWowza Plugin Module \nLiveStreamRecord: Module for recording a live stream on demand.\n\n\n\n\nDownload Link: \nWowza LiveStreamRecord 2.0\n\n\nInstallation:\n\n\n\n\nUnpack the ZIP file and copy the jar files wms-plugin-into the Wowza installation folder: [install-dir]/lib\n\n\nEdit the file Application.xml at: [install-dir]/conf/[application]/\n\n\nAdd this \n at the end of the \n list:\n\n\n\n\nModule\n\n    \nName\nModuleLiveStreamRecord\n/Name\n\n    \nDescription\nModuleLiveStreamRecord\n/Description\n\n    \nClass\ncom.wowza.wms.plugin.livestreamrecord.ModuleLiveStreamRecord\n/Class\n\n\n/Module\n\n\n\n\n\nUsage:\n\n\n\n\nRecording requires a running encoder start with \nStartBroadcast()\n\n\nJavascript API:\n\n\ncall the function \nStartServerRecording()\nto advise the server to record the stream\n\n\n\n\n\n\nPlugin API / ActiveX / C/C++:\n\n\nCall the API function \nsendCommandObject\n - if you use the RTMP filter directly the interface \nIRTMPMetadataSink\n has to be used (see [[can_i_add_meta_data_to_the_live_stream|here]] for a description):\n\n\nnanoStream.sendCommandObject(myStreamName,\nstartRecording\n,cmd);\n\n\nmyStreamName is the current RTMP Stream Name (e.g. \nlivestream1\n)\n\n\ncmd is a command object, or NULL (please contact us for sample code for C++)\n\n\nSample JavaScript Code:\n\n\n\n\n\n\n\n\n\n\n\n\nvar myStreamName = \nYourStreamName\n; // replace with your stream name\nvar cmd = {};\ncmd.streamName = myStreamName;   // rtmp stream name\ncmd.cmd2 = {};\n\ncmd.cmd2.format = \nmp4\n;        // video format - mp4 recommended\ncmd.cmd2.append = false;         // append files or write new files\ncmd.cmd2.startOnKeyFrame = true; // start recording on a video key frame\ncmd.cmd2.recordData = false;\ncmd.cmd2.versionFile = true;     // start recorded\n\npluginObj.SendRtmpCommand(myStreamName, \nstartRecording\n, cmd);\n\n\n\n\nSample Web Application:\n\n\nSee the HTML web page in the folder web/liveEncoder/nanoStream.html\\\nThe feature is implemented there under \nAdvanced Options\n.\\\nSee the function code for //StartServerRecording// in nanoEncoder.js for how it is implemented in Javascript.\n\n\nContact\n\n\nPlease contact us for further information, additional support and consulting services are available upon request.\n\n\nhttp://www.nanocosmos.de\n\n\ninfo@nanocosmos.de\n\n\n(c) 2009-2015, nanocosmos gmbh", 
            "title": "Remote Server Recording"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#nanostream_remote_server_recording", 
            "text": "", 
            "title": "nanoStream Remote Server Recording"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#recording_on_demand_on_flash_media_server", 
            "text": "", 
            "title": "Recording on demand on Flash Media Server"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#general_information", 
            "text": "nanoStream 2.0 supports a  Remote Server Record  mode to enable server based video recording functionality. Currently this works only with Flash Media Server. See Wowza section for how to record on demand to Wowza Media Server.", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#requirements", 
            "text": "Flash Media Server 3/4 or higher  The application must support recording. Some preinstalled applications (live on FMS4) dont. To test recording, you have to create a new application folder in FMS_DIR\\applications, and copy the files from FMS_DIR\\samples\\applications\\live into it.  Streams containing H.264/AVC video data have to be named matching the  mp4:streamname  scheme, otherwise recording will fail. Sample stream URL:  rtmp://localhost/liverec+mp4:samplerec.mp4  The recorded file can be found in the directory specified with LIVE_DIR in the config file FMS_DIR\\conf\\fms.ini", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#usage", 
            "text": "Set the publish mode with a call to  SetRTMPPublishMode  before calling  StartBroadcast()  - if you use the RTMP filter directly use the property  PROPID_nanoRTMPPublishMode  Valid Values are:  0 - live(no recording),  1 - record(rewrite file),  2 - append(append to file)    Javascript API:  call the function SetRTMPPublishMode()to configure publish mode    Plugin API / ActiveX / C/C++:  Call the API function setConfig with parameter name  RTMPPublishMode :  nanoStream.setConfig( RTMPPublishMode , 1 );", 
            "title": "Usage:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#sample_web_application", 
            "text": "See the HTML web page in the folder web/liveEncoder/nanoStream.html\\\nThe feature is implemented there under  Advanced Options .\\\nSee the function code for SetRTMPPublishMode  in nanoEncoder.js for how it is implemented in Javascript.\\", 
            "title": "Sample Web Application:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#recording_on_demand_on_wowza_media_server", 
            "text": "", 
            "title": "Recording on demand on Wowza Media Server"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#general_information_1", 
            "text": "nanoStream 2.0 supports a  Remote Server Record  mode to enable server based video recording functionality. Currently this works only with Wowza Media Server and an additional server plugin.", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#wowza_streaming_engine", 
            "text": "Edit the file Application.xml at: [install-dir]/conf/[application]/  Edit the  StreamType  to:  live-record", 
            "title": "Wowza Streaming Engine"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#older_versions", 
            "text": "", 
            "title": "Older Versions"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#requirements_1", 
            "text": "Wowza Media Server 2.0.0.4 or higher.  Wowza Plugin Module  LiveStreamRecord: Module for recording a live stream on demand.   Download Link:  Wowza LiveStreamRecord 2.0", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#installation", 
            "text": "Unpack the ZIP file and copy the jar files wms-plugin-into the Wowza installation folder: [install-dir]/lib  Edit the file Application.xml at: [install-dir]/conf/[application]/  Add this   at the end of the   list:   Module \n     Name ModuleLiveStreamRecord /Name \n     Description ModuleLiveStreamRecord /Description \n     Class com.wowza.wms.plugin.livestreamrecord.ModuleLiveStreamRecord /Class  /Module", 
            "title": "Installation:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#usage_1", 
            "text": "Recording requires a running encoder start with  StartBroadcast()  Javascript API:  call the function  StartServerRecording() to advise the server to record the stream    Plugin API / ActiveX / C/C++:  Call the API function  sendCommandObject  - if you use the RTMP filter directly the interface  IRTMPMetadataSink  has to be used (see [[can_i_add_meta_data_to_the_live_stream|here]] for a description):  nanoStream.sendCommandObject(myStreamName, startRecording ,cmd);  myStreamName is the current RTMP Stream Name (e.g.  livestream1 )  cmd is a command object, or NULL (please contact us for sample code for C++)  Sample JavaScript Code:       var myStreamName =  YourStreamName ; // replace with your stream name\nvar cmd = {};\ncmd.streamName = myStreamName;   // rtmp stream name\ncmd.cmd2 = {};\n\ncmd.cmd2.format =  mp4 ;        // video format - mp4 recommended\ncmd.cmd2.append = false;         // append files or write new files\ncmd.cmd2.startOnKeyFrame = true; // start recording on a video key frame\ncmd.cmd2.recordData = false;\ncmd.cmd2.versionFile = true;     // start recorded\n\npluginObj.SendRtmpCommand(myStreamName,  startRecording , cmd);", 
            "title": "Usage:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#sample_web_application_1", 
            "text": "See the HTML web page in the folder web/liveEncoder/nanoStream.html\\\nThe feature is implemented there under  Advanced Options .\\\nSee the function code for //StartServerRecording// in nanoEncoder.js for how it is implemented in Javascript.", 
            "title": "Sample Web Application:"
        }, 
        {
            "location": "/nanostream/support/nanostream_remote_server_recording/#contact", 
            "text": "Please contact us for further information, additional support and consulting services are available upon request.  http://www.nanocosmos.de  info@nanocosmos.de  (c) 2009-2015, nanocosmos gmbh", 
            "title": "Contact"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/", 
            "text": "nanoStream UDP-TS Live Streaming\n\n\nGeneral Information\n\n\nnanoStream 2.0 supports TS Live Streaming Modules for encoding and playback.\n\n\nRequirements:\n\n\nnanoStream Live Video Encoder\n\n\nDirectShow Usage\n\n\nTS Encoder, based on H.264/AAC and UDP-TS\\\nDirectShow Filters used:\n  * Nanocosmos H.264 Video Encoder\n  * Nanocosmos AAC Audio Encoder\n  * Nanocosmos Net UDP Sink\n\n\nConfiguration set the ts url as \nudp://server/1.ts\n\n\n\n\n\n\nDirectShow Decoding/Playback\n\n\nDirectShow Filters used:\n  * Nanocosmos H.264 Video Decoder\n  * Nanocosmos AAC Audio Decoder\n  * Nanocosmos Net Source\n\n\n\n\nURL Formats:\n\n\nExample IP Numbers, use your own IP range\n  * Unicast/Point-to-point:\n    * udp://192.168.1.123:1234/1.ts\n  * Broadcast:\n    * udp://192.168.1.255:1234/1.ts\n  * Multicast:\n    * udp://224.0.0.1:1234/1.ts\n\n\nNetSource and NetSink filters should run in TransportStream mode,indicated by \n1.ts\n part of the url.\\\n\nThis mode can be selected through the PropertyPage or COM-Interface.\\\nIt is recommended to do H.264 encoding in Baseline Profile.\\\n\nH.264 Encoder options can be set through the PropertyPage or COM-Interface.\n\n\nPlayback URL Formats:\n\n\nUsually you can use the same URLs as above, without the 1.ts\nNote: For VLC player, you need to add a @ sign before the host.\n\n\nVLC Examples\n  * Unicast/Point-to-point:\n    * udp://@192.168.1.123:1234\n  * Broadcast:\n    * udp://@192.168.1.255:1234\n  * Multicast:\n    * udp://@224.0.0.1:1234\n\n\nContact\n\n\nPlease contact us for further information, additional support and consulting services are available upon request.\n\n\nhttp://www.nanocosmos.de\n\n\ninfo@nanocosmos.de\n\n\n(c) 2009-2015, nanocosmos gmbh", 
            "title": "UDP/TS Streaming"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#nanostream_udp-ts_live_streaming", 
            "text": "", 
            "title": "nanoStream UDP-TS Live Streaming"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#general_information", 
            "text": "nanoStream 2.0 supports TS Live Streaming Modules for encoding and playback.", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#requirements", 
            "text": "nanoStream Live Video Encoder", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#directshow_usage", 
            "text": "TS Encoder, based on H.264/AAC and UDP-TS\\\nDirectShow Filters used:\n  * Nanocosmos H.264 Video Encoder\n  * Nanocosmos AAC Audio Encoder\n  * Nanocosmos Net UDP Sink  Configuration set the ts url as  udp://server/1.ts", 
            "title": "DirectShow Usage"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#directshow_decodingplayback", 
            "text": "DirectShow Filters used:\n  * Nanocosmos H.264 Video Decoder\n  * Nanocosmos AAC Audio Decoder\n  * Nanocosmos Net Source", 
            "title": "DirectShow Decoding/Playback"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#url_formats", 
            "text": "Example IP Numbers, use your own IP range\n  * Unicast/Point-to-point:\n    * udp://192.168.1.123:1234/1.ts\n  * Broadcast:\n    * udp://192.168.1.255:1234/1.ts\n  * Multicast:\n    * udp://224.0.0.1:1234/1.ts  NetSource and NetSink filters should run in TransportStream mode,indicated by  1.ts  part of the url.\\ \nThis mode can be selected through the PropertyPage or COM-Interface.\\\nIt is recommended to do H.264 encoding in Baseline Profile.\\ \nH.264 Encoder options can be set through the PropertyPage or COM-Interface.", 
            "title": "URL Formats:"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#playback_url_formats", 
            "text": "Usually you can use the same URLs as above, without the 1.ts\nNote: For VLC player, you need to add a @ sign before the host.  VLC Examples\n  * Unicast/Point-to-point:\n    * udp://@192.168.1.123:1234\n  * Broadcast:\n    * udp://@192.168.1.255:1234\n  * Multicast:\n    * udp://@224.0.0.1:1234", 
            "title": "Playback URL Formats:"
        }, 
        {
            "location": "/nanostream/support/nanostream_udp_ts_streaming/#contact", 
            "text": "Please contact us for further information, additional support and consulting services are available upon request.  http://www.nanocosmos.de  info@nanocosmos.de  (c) 2009-2015, nanocosmos gmbh", 
            "title": "Contact"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/", 
            "text": "RTMP Knowledge Base\n\n\nnanoStream RTMP Authentication\n\n\nGeneral Information\n\n\nThis document describes the nanoStream 2.0 \u201cRTMP Authentication\u201d interface.\n\n\nRequirements:\n\n\n\n\nWowza Media Server 2.0 or higher\n\n\nWowza Plugin Module \u201cMedia Security\u201d\n\n\nWowza Media Security Link/Description\n\nor\n\n\nFMS 3.5 or higher\n\n\nFMS authentication addin\n\n\nFlash Media Authentication\n\n\n\n\nInstallation:\n\n\nInstallation for Wowza:\n\n\n\n\nsince version 3.5 the module is included in the server, see \nHow-To enable username/password\n\n\nFollow the download and unpack instructions from the download link\n\n\nEdit the file Application.xml at [install-dir]/conf/[application]/\n\n\nAdd this \nModule\n\u00a0 at the end of the \nModules\n list:\n\n\n\n\nlt;Module\ngt;\n\nlt;Name\ngt;ModuleRTMPAuthenticate\nlt;/Name\ngt;\n\nlt;Description\ngt;ModuleRTMPAuthenticate\nlt;/Description\ngt;\n\nlt;Class\ngt;com.wowza.wms.plugin.security.ModuleRTMPAuthenticate\nlt;/Class\ngt;\n\nlt;/Module\ngt;\n\n\n\n\n\n\nCreate a text file in the \n[install-dir]/conf\n folder named \nconnect.password\n, then add a line with a username and password separate with a space for each user:\n\n[install-dir]/conf/connect.password:\n\n\nuser1 pass1\n\n\nuser2 pass2\n\n\n\n\nInstallation for Flash Media Server\n\n\n\n\ninstall the addin\n\n\nopen \ncmd.ex\n as admin and go to \nFMSINSTALLDIR\\conf\n\n\ncreate \nuser\n with users.exe add -u\u00a0[username] -p [password]\n\n\n\n\nUsage\n\n\nPass the user name and password to the nanoStream API with:\n\n\nnanostream.SetConfig(\nAuth\n,\nuser:password\n);\n\n\n\n\nStart Streaming with\n\n\nStartBroadcast();\n\n\n\n\nSample Web Application:\n\n\nSee the HTML web page in the folder \nweb/liveEncoder/nanoStream.html\n\nThe feature is implemented there under \nOptions\n.\n\n\nRTMP Connect Data\n\n\nnanoStream supports sending a user defined amf data object included in the RTMP connect call. The data can be handled in the \nonConnect()\n handler of the RTMP server. Common applications are custom authentication and transmission of additional user/setup information. If set, the data will be included in the next connect call.\n\n\nThe function \nSetConnectInfo\n is supported on Windows/MacOS/iOS/Android.\nParameters are \nstring jsonValues\n, JSON object string.\nRestrictions\n- Top-level object must be an object.\n- Cannot contain arrays or other objects.\n- May only contain key-value pairs.\n\n\nExample JSON showing a string, number and boolean value:\n\n\n{\n  \nkey1\n : \nvalue1\n,\n  \nkey2\n : 7.5,\n  \nkey3\n : false\n}\n\n\n\n\nLine breaks are only used for clarity, JSON will more look like this:\n\n\n{\nkey1\n:\nvalue1\n,\nkey2\n:7.5,\nkey3\n:false}\n\n\n\n\n\n\nRTMP Metadata\n\n\nnanoStream supports sending user defined RTMP metadata during the stream. Common applications are the calls to onMetaData and onCuePoint handlers.\nFunction Name: \nSendMetadata\n\n\nSupported Platforms: Windows/MacOS/iOS/Android\n\nParameters:\n- \nstring handlerName\n, Name of the handler, e.g. \nonMetaData\n,\nonCuePoint\n or a custom handler name \nonMyHandler\n\n- \nstring jsonValues\n, JSON object string, see example below\n- \nstring type\n, reserved, leave empty \n\n- \nboolean live\n, Send metadata live/in-stream or non live which means that the metadata is aggregated at the server and sent at stream start of a player. Should be true in most cases.\n\nRestrictions\n:\n- Top-level object must be an object.\n- Top-level object can contain objects and key/value pairs.\n- Second-level objects cannot contain further nested objects.\n- Cannot contain arrays.\n\n\nExample JSON for \nonMetaData\n handler\n\n\n{\n  \nkey\n : \nvalue\n,\n  \nnextkey\n : \nnextvalue\n,\n  \nanotherkey\n : 14.0,\n   \nlastkey\n : false\n}\n// Line breaks are only used for clarity.\n// The real JSON string will more look like this:\n{\nkey\n : \nvalue\n, \nnextkey\n : \nnextvalue\n, \nanotherkey\n : 14.0, \nlastkey\n : false}\n\n\n\n\n\n\nExample JSON for \nonCuePoint\n handler\n\n\n{\n  \nname\n : \nchapter1\n,\n  \ntype\n : \nevent\n,\n  \ntime\n : 14.0,\n  \nparameters\n :\n  {\n    \nparameter1\n : \nvalue1\n,\n    \nparameter2\n : 0,\n    \nparameter3\n : false\n  }\n}\n\n\n\n\n// Line breaks are only used for clarity.\n// The real JSON string will more look like this:\n\n\n{\nname\n:\nchapter1\n,\ntype\n:\nevent\n,\ntime\n:14.0,\nparameters\n:{\nparameter1\n:\nvalue1\n,\nparameter2\n:0,\nparameter3\n:false}}\n\n\n\n\n\n\nMore information\n\n\nMore information about RTMP metadata and cue points can be found here:\n\n \nAdobe Using cue points and metadata\n\n\n \nAdobe Use cue points\n\n\nRTMP Streaming Automatic Reconnect\n\n\nGeneral Information\n\n\nNanocosmos Rtmp streaming can be configured to try to reconnect after connection to the streaming server failed (for example due to unstable internet connection).\n\n\na id=\nreconnect_settings\n\n\nAvailable Reconnection Settings (for use with Plugin or directly with RTMP Writer)\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\nValues\n\n\n\n\n\n\n\n\n\n\nReconnectAttempts\n\n\nhow often a reconnection should be attempted\n\n\n0-max(int32). Default: 5\n\n\n\n\n\n\nUseUnlimitedReconnect (\nplugin\n); PROPID_nanoRTMPUnlimitedReconnect(\nrtmp-writer\n)\n\n\nunlimited reconnection attempts (filter graph is not stopped). Overrides ReconnectAttempts\n\n\n0: disable, 1: enable\n\n\n\n\n\n\nReconnectPeriod\n\n\ntime to wait before a new reconnection attempt is made\n\n\n100 ms - max(int32)ms. Values \n 100 ms disable Auto-reconnect. Default 5000 ms\n\n\n\n\n\n\nUseInternalReconnect\n\n\nif enabled, the filter graph is not restarted when trying to reconnect: local encoding and recording continues despite absent internet connection\n\n\n0: disabled (reconnection is done by stopping and starting the filter graph), 1: enabled (use internal reconnect of rtmp-writer)\n\n\n\n\n\n\n\n\nIf all reconnection attempts were unsuccessful, streaming will be stopped, except when \nUseUnlimitedReconnect\n is used.\n\nImportant\n\nIf a reconnection attempt was successful the internal reconnection counter is reset. For following disconnections, the rtmp writer tries again to reconnect the given number of reconnect attempts before stopping the encoder.\n\n\nUsing Reconnection with the browser plugin\n\n\nTo use the reconnection ability of the rtmp writer \nSetConfig(Option, Value)\n can be used, see \nTable Above\n for available options and corresponding values.\n\n\nUsing Reconnection with the RTMP Writer\n\n\nReconnection can be configured via the interface IRTMPOptions:\n\n\nCComQIPtr\nlt;IRTMPOptions, \namp;IID_IRTMPOptions\ngt; optRtmp = pSink;\nif (optRtmp)\n{\noptRtmp-\ngt;SetReconnectInterval(reconnectPeriodValue);\noptRtmp-\ngt;SetReconnectAttempts(reconnectAttemptsValue);\n}\n\n\n\n\nFurther options are available via ICodecApi:\n\n\nCComQIPtr api = pSink;\nif(SUCCEEDED(api-\ngt;IsSupported(\namp;PROPID_nanoRTMPUnlimitedReconnect)))\n{\nVARIANT vt;\nVariantInit(\namp;vt);\nvt.vt = VT_BOOL;\nvt.boolVal = VARIANT_TRUE; // or VARIANT_FALSE\napi-\ngt;SetValue(\namp;PROPID_nanoRTMPUnlimitedReconnect, \namp;vt);\n}\n\n\n\n\nUsing Reconnection with XML\n\n\nSee Also: \nLiveVideoEncoder-XML-Config\n\n\nlt;reconnectinterval\ngt;\n\nlt;attempts\ngt;5\nlt;/attempts\ngt;\n\nlt;interval\ngt;5000\nlt;/interval\ngt;\n\nlt;restartgraph\ngt;false\nlt;/restartgraph\ngt; \nlt;!-- false: internal reconnect of the rtmp writer will be used--\ngt;\n\nlt;unlimitedattempts\ngt;true\nlt;/unlimitedattempts\ngt; \nlt;!-- overrides attempts (5 in this example) --\ngt;\n\nlt;/reconnectinterval\ngt;\n\n\n\n\n\n\nrestartgraph\n and \nUseInternalReconnect\n have reversed meaning:\n\nrestartgraph\n set to \nfalse\n enables usage of the rtmp-writer\ns internal reconnect, whereas \nUseInternalReconnect\n set to \n0\n disables usage of rtmp-writer\ns internal reconnect (reconnection is done by stopping and starting the filter graph).\n\n\nUsing Reconnection to keep the encoder running\n\n\nIf the rtmp writer is disconnected from the streaming server URL, the whole encoder graph will be stopped. When a parallel stream to another destination is running, this recording will be stopped as well. This is especially important for the local mp4 file writer. To avoid this, you can use the option enable UseInternalReconnect (if the plugin is used) or SetReconnectAttempts, (if the RTMP Writer is used directly). The filter graph will then keep running until all reconnect attempts fail.\n\n\nExample\n\n\nreconnect attempts = 100\n\n\nreconnect period = 6000 ms\n\nHere, the encoder will keep running for ten minutes if all reconnection attempts failed. If you use the option \nUseUnlimitedReconnect\n, resp. \nPROPID_nanoRTMPUnlimitedReconnect\n the graph will never be stopped by the rtmp filter - a reconnection attempt is made every \nx\n ms (depending on the specified value).\n\n\nRTMP statistics\n\n\nThe following pseudocode, shows how to query the connection status and the statistics of the RTMP Writer (\nm_pMediaEventEx\n is of type \nIMediaEventEx\n):\n\n\nwhile (SUCCEEDED(m_pMediaEventEx-\ngt;GetEvent(\namp;nEvCode, \namp;param1, \namp;param2, 0))) {\nswitch (nEvCode) {\ncase EC_NANO_RTMP_WRITER_STATUS:\n{\nRtmpWriterStatus *status = (RtmpWriterStatus*)param1;\nswitch(*status)\n{\ncase RTMPWriterConnected: //...\ncase RTMPWriterDisconnected: //...\ncase RTMPWriterReconnecting: //...\n}\n}\n\ncase EC_NANO_RTMP_WRITER_STATS:\n{\nrtmp_writer_stats_t* stats = (rtmp_writer_stats_t*)param1;\n//...\n// if you use multiple rtmp writer you can identify which rtmp writer did send\n// the statistics by using the second parameter (it contains the url, to which\n// the rtmp writer is streaming\nchar* urlId = (char*)param2;\n//...\n}\n}\n}\n\n\n\n\nExplanation of \nrtmp_writer_stats_t\n:\n- \noutput_buffer_size\n = max. available buffer in bytes\n- \noutput_buffer_fillness\n = how much bytes of the buffer are used\n- \noutput_bitrate\n = estimated bitrate of the stream\n- \noutput_bitrate2\n = similar to ouput_bitrate, but another (more accurate) method is used (only available if tcp sniffing is enabled - works only with win xp)\n- \noutput_bitrate3\n = similar to ouput_bitrate, but another method is used (only available if tcp sniffing is enabled - works only with win xp)\n- \npacketsRtt\n = rount trip time (RTT) in ms\n- \nclientBytesReceived\n = amount of received bytes\n- \naudio_buffered_samples\n = amount of buffered samples for audio\n- \nvideo_buffered_samples\n = amount of buffered samples for video\n- \naudio_bitrate\n = current audio bitrate of the encoder\n- \nvideo_bitrate\n = current video bitrate of the encoder", 
            "title": "RTMP"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#nanostream_rtmp_authentication", 
            "text": "", 
            "title": "nanoStream RTMP Authentication"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#general_information", 
            "text": "This document describes the nanoStream 2.0 \u201cRTMP Authentication\u201d interface.", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#requirements", 
            "text": "Wowza Media Server 2.0 or higher  Wowza Plugin Module \u201cMedia Security\u201d  Wowza Media Security Link/Description \nor  FMS 3.5 or higher  FMS authentication addin  Flash Media Authentication", 
            "title": "Requirements:"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#installation", 
            "text": "", 
            "title": "Installation:"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#installation_for_wowza", 
            "text": "since version 3.5 the module is included in the server, see  How-To enable username/password  Follow the download and unpack instructions from the download link  Edit the file Application.xml at [install-dir]/conf/[application]/  Add this  Module \u00a0 at the end of the  Modules  list:   lt;Module gt; lt;Name gt;ModuleRTMPAuthenticate lt;/Name gt; lt;Description gt;ModuleRTMPAuthenticate lt;/Description gt; lt;Class gt;com.wowza.wms.plugin.security.ModuleRTMPAuthenticate lt;/Class gt; lt;/Module gt;   Create a text file in the  [install-dir]/conf  folder named  connect.password , then add a line with a username and password separate with a space for each user: [install-dir]/conf/connect.password:  user1 pass1  user2 pass2", 
            "title": "Installation for Wowza:"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#installation_for_flash_media_server", 
            "text": "install the addin  open  cmd.ex  as admin and go to  FMSINSTALLDIR\\conf  create  user  with users.exe add -u\u00a0[username] -p [password]", 
            "title": "Installation for Flash Media Server"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#usage", 
            "text": "Pass the user name and password to the nanoStream API with:  nanostream.SetConfig( Auth , user:password );  Start Streaming with  StartBroadcast();", 
            "title": "Usage"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#sample_web_application", 
            "text": "See the HTML web page in the folder  web/liveEncoder/nanoStream.html \nThe feature is implemented there under  Options .", 
            "title": "Sample Web Application:"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#rtmp_connect_data", 
            "text": "nanoStream supports sending a user defined amf data object included in the RTMP connect call. The data can be handled in the  onConnect()  handler of the RTMP server. Common applications are custom authentication and transmission of additional user/setup information. If set, the data will be included in the next connect call.  The function  SetConnectInfo  is supported on Windows/MacOS/iOS/Android.\nParameters are  string jsonValues , JSON object string.\nRestrictions\n- Top-level object must be an object.\n- Cannot contain arrays or other objects.\n- May only contain key-value pairs.  Example JSON showing a string, number and boolean value:  {\n   key1  :  value1 ,\n   key2  : 7.5,\n   key3  : false\n}  Line breaks are only used for clarity, JSON will more look like this:  { key1 : value1 , key2 :7.5, key3 :false}", 
            "title": "RTMP Connect Data"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#rtmp_metadata", 
            "text": "nanoStream supports sending user defined RTMP metadata during the stream. Common applications are the calls to onMetaData and onCuePoint handlers.\nFunction Name:  SendMetadata  Supported Platforms: Windows/MacOS/iOS/Android \nParameters:\n-  string handlerName , Name of the handler, e.g.  onMetaData , onCuePoint  or a custom handler name  onMyHandler \n-  string jsonValues , JSON object string, see example below\n-  string type , reserved, leave empty  \n-  boolean live , Send metadata live/in-stream or non live which means that the metadata is aggregated at the server and sent at stream start of a player. Should be true in most cases. Restrictions :\n- Top-level object must be an object.\n- Top-level object can contain objects and key/value pairs.\n- Second-level objects cannot contain further nested objects.\n- Cannot contain arrays.", 
            "title": "RTMP Metadata"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#example_json_for_onmetadata_handler", 
            "text": "{\n   key  :  value ,\n   nextkey  :  nextvalue ,\n   anotherkey  : 14.0,\n    lastkey  : false\n}\n// Line breaks are only used for clarity.\n// The real JSON string will more look like this:\n{ key  :  value ,  nextkey  :  nextvalue ,  anotherkey  : 14.0,  lastkey  : false}", 
            "title": "Example JSON for \"onMetaData\" handler"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#example_json_for_oncuepoint_handler", 
            "text": "{\n   name  :  chapter1 ,\n   type  :  event ,\n   time  : 14.0,\n   parameters  :\n  {\n     parameter1  :  value1 ,\n     parameter2  : 0,\n     parameter3  : false\n  }\n}  // Line breaks are only used for clarity.\n// The real JSON string will more look like this:  { name : chapter1 , type : event , time :14.0, parameters :{ parameter1 : value1 , parameter2 :0, parameter3 :false}}", 
            "title": "Example JSON for \"onCuePoint\" handler"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#more_information", 
            "text": "More information about RTMP metadata and cue points can be found here:   Adobe Using cue points and metadata    Adobe Use cue points", 
            "title": "More information"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#rtmp_streaming_automatic_reconnect", 
            "text": "", 
            "title": "RTMP Streaming Automatic Reconnect"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#general_information_1", 
            "text": "Nanocosmos Rtmp streaming can be configured to try to reconnect after connection to the streaming server failed (for example due to unstable internet connection).  a id= reconnect_settings", 
            "title": "General Information"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#available_reconnection_settings_for_use_with_plugin_or_directly_with_rtmp_writer", 
            "text": "Option  Description  Values      ReconnectAttempts  how often a reconnection should be attempted  0-max(int32). Default: 5    UseUnlimitedReconnect ( plugin ); PROPID_nanoRTMPUnlimitedReconnect( rtmp-writer )  unlimited reconnection attempts (filter graph is not stopped). Overrides ReconnectAttempts  0: disable, 1: enable    ReconnectPeriod  time to wait before a new reconnection attempt is made  100 ms - max(int32)ms. Values   100 ms disable Auto-reconnect. Default 5000 ms    UseInternalReconnect  if enabled, the filter graph is not restarted when trying to reconnect: local encoding and recording continues despite absent internet connection  0: disabled (reconnection is done by stopping and starting the filter graph), 1: enabled (use internal reconnect of rtmp-writer)     If all reconnection attempts were unsuccessful, streaming will be stopped, except when  UseUnlimitedReconnect  is used. Important \nIf a reconnection attempt was successful the internal reconnection counter is reset. For following disconnections, the rtmp writer tries again to reconnect the given number of reconnect attempts before stopping the encoder.", 
            "title": "Available Reconnection Settings (for use with Plugin or directly with RTMP Writer)"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#using_reconnection_with_the_browser_plugin", 
            "text": "To use the reconnection ability of the rtmp writer  SetConfig(Option, Value)  can be used, see  Table Above  for available options and corresponding values.", 
            "title": "Using Reconnection with the browser plugin"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#using_reconnection_with_the_rtmp_writer", 
            "text": "Reconnection can be configured via the interface IRTMPOptions:  CComQIPtr lt;IRTMPOptions,  amp;IID_IRTMPOptions gt; optRtmp = pSink;\nif (optRtmp)\n{\noptRtmp- gt;SetReconnectInterval(reconnectPeriodValue);\noptRtmp- gt;SetReconnectAttempts(reconnectAttemptsValue);\n}  Further options are available via ICodecApi:  CComQIPtr api = pSink;\nif(SUCCEEDED(api- gt;IsSupported( amp;PROPID_nanoRTMPUnlimitedReconnect)))\n{\nVARIANT vt;\nVariantInit( amp;vt);\nvt.vt = VT_BOOL;\nvt.boolVal = VARIANT_TRUE; // or VARIANT_FALSE\napi- gt;SetValue( amp;PROPID_nanoRTMPUnlimitedReconnect,  amp;vt);\n}", 
            "title": "Using Reconnection with the RTMP Writer"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#using_reconnection_with_xml", 
            "text": "See Also:  LiveVideoEncoder-XML-Config  lt;reconnectinterval gt; lt;attempts gt;5 lt;/attempts gt; lt;interval gt;5000 lt;/interval gt; lt;restartgraph gt;false lt;/restartgraph gt;  lt;!-- false: internal reconnect of the rtmp writer will be used-- gt; lt;unlimitedattempts gt;true lt;/unlimitedattempts gt;  lt;!-- overrides attempts (5 in this example) -- gt; lt;/reconnectinterval gt;   restartgraph  and  UseInternalReconnect  have reversed meaning: restartgraph  set to  false  enables usage of the rtmp-writer s internal reconnect, whereas  UseInternalReconnect  set to  0  disables usage of rtmp-writer s internal reconnect (reconnection is done by stopping and starting the filter graph).", 
            "title": "Using Reconnection with XML"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#using_reconnection_to_keep_the_encoder_running", 
            "text": "If the rtmp writer is disconnected from the streaming server URL, the whole encoder graph will be stopped. When a parallel stream to another destination is running, this recording will be stopped as well. This is especially important for the local mp4 file writer. To avoid this, you can use the option enable UseInternalReconnect (if the plugin is used) or SetReconnectAttempts, (if the RTMP Writer is used directly). The filter graph will then keep running until all reconnect attempts fail.  Example  reconnect attempts = 100  reconnect period = 6000 ms \nHere, the encoder will keep running for ten minutes if all reconnection attempts failed. If you use the option  UseUnlimitedReconnect , resp.  PROPID_nanoRTMPUnlimitedReconnect  the graph will never be stopped by the rtmp filter - a reconnection attempt is made every  x  ms (depending on the specified value).", 
            "title": "Using Reconnection to keep the encoder running"
        }, 
        {
            "location": "/nanostream/support/nanostream_rtmp_all/#rtmp_statistics", 
            "text": "The following pseudocode, shows how to query the connection status and the statistics of the RTMP Writer ( m_pMediaEventEx  is of type  IMediaEventEx ):  while (SUCCEEDED(m_pMediaEventEx- gt;GetEvent( amp;nEvCode,  amp;param1,  amp;param2, 0))) {\nswitch (nEvCode) {\ncase EC_NANO_RTMP_WRITER_STATUS:\n{\nRtmpWriterStatus *status = (RtmpWriterStatus*)param1;\nswitch(*status)\n{\ncase RTMPWriterConnected: //...\ncase RTMPWriterDisconnected: //...\ncase RTMPWriterReconnecting: //...\n}\n}\n\ncase EC_NANO_RTMP_WRITER_STATS:\n{\nrtmp_writer_stats_t* stats = (rtmp_writer_stats_t*)param1;\n//...\n// if you use multiple rtmp writer you can identify which rtmp writer did send\n// the statistics by using the second parameter (it contains the url, to which\n// the rtmp writer is streaming\nchar* urlId = (char*)param2;\n//...\n}\n}\n}  Explanation of  rtmp_writer_stats_t :\n-  output_buffer_size  = max. available buffer in bytes\n-  output_buffer_fillness  = how much bytes of the buffer are used\n-  output_bitrate  = estimated bitrate of the stream\n-  output_bitrate2  = similar to ouput_bitrate, but another (more accurate) method is used (only available if tcp sniffing is enabled - works only with win xp)\n-  output_bitrate3  = similar to ouput_bitrate, but another method is used (only available if tcp sniffing is enabled - works only with win xp)\n-  packetsRtt  = rount trip time (RTT) in ms\n-  clientBytesReceived  = amount of received bytes\n-  audio_buffered_samples  = amount of buffered samples for audio\n-  video_buffered_samples  = amount of buffered samples for video\n-  audio_bitrate  = current audio bitrate of the encoder\n-  video_bitrate  = current video bitrate of the encoder", 
            "title": "RTMP statistics"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/", 
            "text": "bintu.live client SDK for Android\n\n\n\u00a9 2016 nanocosmos gmbh \nhttp://www.nanocosmos.de\n\n\nVersion 0.1.1\n\n\nThe bintu.live client SDK is used to generate and access live stream URLs from the bintu.live service to be used in combination with the nanoStream SDKs for live video encoding and broadcast.\n\n\nLegal Notice\n\n\nThis material is subject to the terms and conditions defined in separate license conditions (\nLICENSE.txt\n) All information contained herein is, and remains the property of nanocosmos GmbH and its suppliers if any. The intellectual and technical concepts contained herein are proprietary to nanocosmos GmbH, and are protected by trade secret or copyright law. Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from nanocosmos.\n\n\nProject setup\n\n\nAndroid Studio\n\n\nTo use the bintu.live SDK in your Android Studio project you need to include the bintu android archive as a module. In order to do this copy the android archive (bintu-sdk.aar) to your drive and open the \nCreate Module\n menu in Android Studio (via File -\n New -\n Create Module). On the \nCreate New Module\n menu select \nImport .JAR/.AAR Package\n, as shown below, and click on \nNext\n.\n\n\n\nAfterwards select the location of the bintu.live sdk archive file and enter a name for this module (e.g. \nBintuSDK\n).\nAfter finishing the bintu.live sdk is included in your project and ready to use.\n\n\nEclipse ADT\n\n\nbintu.live platform connection\n\n\nOur bintu.live connection component (bintu-sdk.aar) consists of an entry point API client class BintuSDK (net.nanocosmos.bintu.bintusdk.BintuSDK) which you use to make calls to our streaming platform. There are other classes, like StreamInfo (net.nanocosmos.bintu.bintusdk.stream.StreamInfo) and RtmpIngest  (net.nanocosmos.bintu.bintusdk.stream.RtmpIngest), which mainly hold the configuration you receive from the BintuSDK.\n\n\nIn general, if you want to interface with our streaming platform, you construct an instance of the BintuSDK with its main constructor:\n\n\nBintuSDK bintuSDK = new BintuSDK(apiKey);\n\n\n\n\nOnce you have an instance, you can create new streams with it, receive information about a previously created stream or list all streams that are present on your account.\n\n\nLets step through these in detail:\n\n\nWith the createStream call you create a new stream. You would use this in your broadcaster app. As argument you pass an instace of an implementation of the StreamInfoResponseHandler interface to the createStream call. This interface represents callback classes to handle the result of the create stream call. It contains two method declarations. One to handle the success result, called \nhandle\n, and one to handle errors, called \nonError\n. One of these will be executed as result of the createStream call. When the \nhandle\n-method is executed it is passed the result data of the createStream call as a StreamInfo object.\n\n\nbintu.createStream(new StreamInfoResponseHandler() {\n                @Override\n                public void handle(StreamInfo streamInfo) {\n                    //TODO Handle the Result\n                }\n\n                @Override\n                public void onError(Throwable error) {\n                    //TODO Handle the Error\n                }\n\n            });\n\n\n\n\nWith the getStream call you can receive information about a previously created stream, by passing its id to the call. In most cases, you would take the stream ID you get while creating a stream and store it on your own server somewhere. If anyone wants to view a stream, you send that ID to the player app. Then you can receive that stream\ns playout information. For example, if you want to play the stream via RTMP:\n\n\nbintuSDK.getStream(streamID, new StreamInfoResponseHandler() {\n            @Override\n            public void handle(StreamInfo streamInfo) {\n                RtmpPlayout rtmpPlayout = streamInfo.getRtmpPlayouts().get(0);\n                String rtmpURL = rtmpPlayout.getUrl();\n                String streamName = rtmpPlayout.getStreamName();\n                //TODO Play the stream\n            }\n\n            @Override\n            public void onError(Throwable error) {\n                //TODO Handle the Error\n            }\n        });\n\n\n\n\nYou can also list all streams on your account with the getStreams call. For example, you can bypass your server, get all streams on the player and let the user select the one they want to see. Or you just play the first one that is live, like shown below:\n\n\nbintuSDK.getStreams(new StreamInfoListResponseHandler() {\n               @Override\n               public void handle(List\nStreamInfo\n result) {\n                 for(StreamInfo info : result){\n                       if (info.getState() == State.LIVE){\n                           //TODO Play this stream\n                           break;\n                       }\n                   }\n               }\n\n               @Override\n               public void onError(Throwable e) {\n                   //TODO Handle the Error\n               }\n           });\n\n\n\n\nBut this example can be made simpler. There is also the getStreams call (added in version 0.?.? of the bintu-sdk.aar) which allows you filter the streams by state directly on the server, resulting in quicker load times. The above example can be implemented like this:\n\n\nbintuSDK.getStreams(State.LIVE, new StreamInfoListResponseHandler() {\n                @Override\n                public void handle(List\nStreamInfo\n result) {\n                    try {\n                        StreamInfo info = result.get(0);\n                        //TODO Play stream\n                    }catch (Exception ex){\n                        //TODO Handle the Error    \n                    }\n                }\n\n                @Override\n                public void onError(Throwable e) {\n                    //TODO Handle the Error\n                }\n            });\n\n\n\n\nThat was a basic overview of our bintu.live component.", 
            "title": "Android SDK"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#bintulive_client_sdk_for_android", 
            "text": "\u00a9 2016 nanocosmos gmbh  http://www.nanocosmos.de  Version 0.1.1  The bintu.live client SDK is used to generate and access live stream URLs from the bintu.live service to be used in combination with the nanoStream SDKs for live video encoding and broadcast.", 
            "title": "bintu.live client SDK for Android"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#legal_notice", 
            "text": "This material is subject to the terms and conditions defined in separate license conditions ( LICENSE.txt ) All information contained herein is, and remains the property of nanocosmos GmbH and its suppliers if any. The intellectual and technical concepts contained herein are proprietary to nanocosmos GmbH, and are protected by trade secret or copyright law. Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from nanocosmos.", 
            "title": "Legal Notice"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#project_setup", 
            "text": "", 
            "title": "Project setup"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#android_studio", 
            "text": "To use the bintu.live SDK in your Android Studio project you need to include the bintu android archive as a module. In order to do this copy the android archive (bintu-sdk.aar) to your drive and open the  Create Module  menu in Android Studio (via File -  New -  Create Module). On the  Create New Module  menu select  Import .JAR/.AAR Package , as shown below, and click on  Next .  Afterwards select the location of the bintu.live sdk archive file and enter a name for this module (e.g.  BintuSDK ).\nAfter finishing the bintu.live sdk is included in your project and ready to use.", 
            "title": "Android Studio"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#eclipse_adt", 
            "text": "", 
            "title": "Eclipse ADT"
        }, 
        {
            "location": "/bintu/android/bintu-android-sdk/#bintulive_platform_connection", 
            "text": "Our bintu.live connection component (bintu-sdk.aar) consists of an entry point API client class BintuSDK (net.nanocosmos.bintu.bintusdk.BintuSDK) which you use to make calls to our streaming platform. There are other classes, like StreamInfo (net.nanocosmos.bintu.bintusdk.stream.StreamInfo) and RtmpIngest  (net.nanocosmos.bintu.bintusdk.stream.RtmpIngest), which mainly hold the configuration you receive from the BintuSDK.  In general, if you want to interface with our streaming platform, you construct an instance of the BintuSDK with its main constructor:  BintuSDK bintuSDK = new BintuSDK(apiKey);  Once you have an instance, you can create new streams with it, receive information about a previously created stream or list all streams that are present on your account.  Lets step through these in detail:  With the createStream call you create a new stream. You would use this in your broadcaster app. As argument you pass an instace of an implementation of the StreamInfoResponseHandler interface to the createStream call. This interface represents callback classes to handle the result of the create stream call. It contains two method declarations. One to handle the success result, called  handle , and one to handle errors, called  onError . One of these will be executed as result of the createStream call. When the  handle -method is executed it is passed the result data of the createStream call as a StreamInfo object.  bintu.createStream(new StreamInfoResponseHandler() {\n                @Override\n                public void handle(StreamInfo streamInfo) {\n                    //TODO Handle the Result\n                }\n\n                @Override\n                public void onError(Throwable error) {\n                    //TODO Handle the Error\n                }\n\n            });  With the getStream call you can receive information about a previously created stream, by passing its id to the call. In most cases, you would take the stream ID you get while creating a stream and store it on your own server somewhere. If anyone wants to view a stream, you send that ID to the player app. Then you can receive that stream s playout information. For example, if you want to play the stream via RTMP:  bintuSDK.getStream(streamID, new StreamInfoResponseHandler() {\n            @Override\n            public void handle(StreamInfo streamInfo) {\n                RtmpPlayout rtmpPlayout = streamInfo.getRtmpPlayouts().get(0);\n                String rtmpURL = rtmpPlayout.getUrl();\n                String streamName = rtmpPlayout.getStreamName();\n                //TODO Play the stream\n            }\n\n            @Override\n            public void onError(Throwable error) {\n                //TODO Handle the Error\n            }\n        });  You can also list all streams on your account with the getStreams call. For example, you can bypass your server, get all streams on the player and let the user select the one they want to see. Or you just play the first one that is live, like shown below:  bintuSDK.getStreams(new StreamInfoListResponseHandler() {\n               @Override\n               public void handle(List StreamInfo  result) {\n                 for(StreamInfo info : result){\n                       if (info.getState() == State.LIVE){\n                           //TODO Play this stream\n                           break;\n                       }\n                   }\n               }\n\n               @Override\n               public void onError(Throwable e) {\n                   //TODO Handle the Error\n               }\n           });  But this example can be made simpler. There is also the getStreams call (added in version 0.?.? of the bintu-sdk.aar) which allows you filter the streams by state directly on the server, resulting in quicker load times. The above example can be implemented like this:  bintuSDK.getStreams(State.LIVE, new StreamInfoListResponseHandler() {\n                @Override\n                public void handle(List StreamInfo  result) {\n                    try {\n                        StreamInfo info = result.get(0);\n                        //TODO Play stream\n                    }catch (Exception ex){\n                        //TODO Handle the Error    \n                    }\n                }\n\n                @Override\n                public void onError(Throwable e) {\n                    //TODO Handle the Error\n                }\n            });  That was a basic overview of our bintu.live component.", 
            "title": "bintu.live platform connection"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sdk/", 
            "text": "bintu.live client SDK\n\n\n(c) 2016 nanocosmos gmbh\nhttp://www.nanocosmos.de\n\n\nVersion 0.2.1\n\n\nThe bintu.live client SDK is used to generate and access live stream URLs from the bintu.live service\nto be used in combination with the nanoStream SDKs for live video encoding and broadcast.\n\n\nLEGAL NOTICE\n\n\nThis material is subject to the terms and conditions defined in\nseparate license conditions (\nLICENSE.txt\n)\nAll information contained herein is, and remains the property\nof nanocosmos GmbH and its suppliers if any. The intellectual and technical concepts\ncontained herein are proprietary to nanocosmos GmbH, and are protected by trade secret\nor copyright law. Dissemination of this information or reproduction of this material\nis strictly forbidden unless prior written permission is obtained from nanocosmos.\n\n\nImporting the Bintu.framework\n\n\nOpen your Xcode project and go to the \nGeneral\n tab of your application target. Drag the \nBintu.framework\n file to the section \nEmbedded Binaries\n of your application target. Check \nCopy items if needed\n when asked.\n\n\nAfter embedding and linking it, you can import the SDK anywhere you need it with the following line:\n\n\n#import \nBintu/Bintu.h\n\n\n\n\n\nBintu.live platform connection\n\n\nOur Bintu.live connection component (Bintu.framework) consists of an entry point API client class \nBNTAPIClient\n which you use to make calls to our streaming platform. There are other class, like \nBNTStreamInfo\n and \nBNTRTMPInfo\n which mainly hold the configuration you receive from the \nBNTAPIClient\n.\n\n\nIn general, if you want to interface with our streaming platform, you construct an instance of the \nBNTAPIClient\n with its main constructor:\n\n\nBNTAPIClient *client = [BNTAPIClient initWithAPIKey:apiKey];\n\n\n\nOnce you have an instance, you can create new streams with it, receive information about a previously created stream or list all streams that are present on your account.\n\n\nLets step through these in detail:\n\n\nWith the \ncreateStream\n call you create a new stream. You would use this in your broadcaster app. In the completion block of this method, you get an instance of \nBNTStreamInfo\n which exposes an instance of \nBNTRTMPIngest\n which holds the configuration you need to stream to bintu.live.\n\n\n[client createStreamWithCompletion:^(BNTStreamInfo *stream, NSError *err) {\n    self.streamID = stream.id;\n    self.streamURL = stream.ingest.rtmpInfo.url;\n    self.streamName = stream.ingest.rtmpInfo.streamName;\n}];\n\n\n\nWith the\ngetStreamWithID\n call you can receive information about a previously created stream. In most cases, you would take the stream ID you get while creating a stream and store it on your own server somewhere. If anyone wants to view a stream, you send that ID to the player app. Then you can receive that stream\ns playout information.\nFor example, if you want to play the stream via HLS:\n\n\n[client getStreamWithID:@\"\na long id\n\" andCompletion:^(BNTStreamInfo *stream, NSError *err) {\n    BNTHLSPlayout *playout = [stream.hlsPlayouts firstObject];\n    self.hlsURL = playout.url;\n}];\n\n\n\nYou can also list all streams on your account with the \ngetStreams\n call. For example, you can bypass your server, get all streams on the player and let the user select the one they want to see. Or you just play the first one that is live, like shown below:\n\n\n[client getStreamsWithCompletion:^(NSArray *streams, NSError *err) {\n    for (BNTStreamInfo *stream in streams) {\n        if (stream.state == BNTStreamStateLive) {\n            // play stream!\n        }\n    }\n}];\n\n\n\nBut this example can be made simpler. There is also the \ngetStreamsWithState\n call (added in version 0.2.0 of the Bintu.framework) which allows you filter the streams by state directly on the server, resulting in quicker load times. The above example can be implemented like this:\n\n\n[client getStreamsWithState:BNTStreamStateLive completion:^(NSArray *streams, NSError *err) {\n    // all objects in streams have state = live\n    BNTStreamInfo *stream = [streams firstObject];\n    if (stream) {\n        // play stream!\n    }  \n}];\n\n\n\nThat was a basic overview of our bintu.live component.\n\n\nStrip simulator architectur slices\n\n\nXcode 6 and sometimes higher versions contain a bug where an app containing an embedded framework cannot be submitted to the app store when the framework contains simulator architectures (see \nhttp://www.openradar.me/radar?id=6409498411401216\n).\n\n\nOn the other hand, including the simulator architectures in the framework is necessary for anyone that wants to test their app (and also the bintu.live connector) on the simulator.\n\n\nThe workaround is that Bintu.framework contains a script (\nstrip-frameworks.sh\n) which removes the simulator architectures from the framework just before submitting to the app store.\n\n\nFor this to work correctly, you need to add a \nRun Script Phase\n to your Xcode app target. This phase has to come after the \nEmbed Frameworks\n phase otherwise it will not work.\n\n\nThe \nRun Script\n phase should contain following line:\n\n\nbash \n${BUILT_PRODUCTS_DIR}/${FRAMEWORKS_FOLDER_PATH}/Bintu.framework/strip-frameworks.sh\n\n\n\n\n\nThis should be all that is needed to work around the Xcode bug.", 
            "title": "SDK Documentation"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sdk/#bintulive_client_sdk", 
            "text": "(c) 2016 nanocosmos gmbh\nhttp://www.nanocosmos.de  Version 0.2.1  The bintu.live client SDK is used to generate and access live stream URLs from the bintu.live service\nto be used in combination with the nanoStream SDKs for live video encoding and broadcast.", 
            "title": "bintu.live client SDK"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sdk/#legal_notice", 
            "text": "This material is subject to the terms and conditions defined in\nseparate license conditions ( LICENSE.txt )\nAll information contained herein is, and remains the property\nof nanocosmos GmbH and its suppliers if any. The intellectual and technical concepts\ncontained herein are proprietary to nanocosmos GmbH, and are protected by trade secret\nor copyright law. Dissemination of this information or reproduction of this material\nis strictly forbidden unless prior written permission is obtained from nanocosmos.", 
            "title": "LEGAL NOTICE"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sdk/#importing_the_bintuframework", 
            "text": "Open your Xcode project and go to the  General  tab of your application target. Drag the  Bintu.framework  file to the section  Embedded Binaries  of your application target. Check  Copy items if needed  when asked.  After embedding and linking it, you can import the SDK anywhere you need it with the following line:  #import  Bintu/Bintu.h", 
            "title": "Importing the Bintu.framework"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sdk/#bintulive_platform_connection", 
            "text": "Our Bintu.live connection component (Bintu.framework) consists of an entry point API client class  BNTAPIClient  which you use to make calls to our streaming platform. There are other class, like  BNTStreamInfo  and  BNTRTMPInfo  which mainly hold the configuration you receive from the  BNTAPIClient .  In general, if you want to interface with our streaming platform, you construct an instance of the  BNTAPIClient  with its main constructor:  BNTAPIClient *client = [BNTAPIClient initWithAPIKey:apiKey];  Once you have an instance, you can create new streams with it, receive information about a previously created stream or list all streams that are present on your account.  Lets step through these in detail:  With the  createStream  call you create a new stream. You would use this in your broadcaster app. In the completion block of this method, you get an instance of  BNTStreamInfo  which exposes an instance of  BNTRTMPIngest  which holds the configuration you need to stream to bintu.live.  [client createStreamWithCompletion:^(BNTStreamInfo *stream, NSError *err) {\n    self.streamID = stream.id;\n    self.streamURL = stream.ingest.rtmpInfo.url;\n    self.streamName = stream.ingest.rtmpInfo.streamName;\n}];  With the getStreamWithID  call you can receive information about a previously created stream. In most cases, you would take the stream ID you get while creating a stream and store it on your own server somewhere. If anyone wants to view a stream, you send that ID to the player app. Then you can receive that stream s playout information.\nFor example, if you want to play the stream via HLS:  [client getStreamWithID:@\" a long id \" andCompletion:^(BNTStreamInfo *stream, NSError *err) {\n    BNTHLSPlayout *playout = [stream.hlsPlayouts firstObject];\n    self.hlsURL = playout.url;\n}];  You can also list all streams on your account with the  getStreams  call. For example, you can bypass your server, get all streams on the player and let the user select the one they want to see. Or you just play the first one that is live, like shown below:  [client getStreamsWithCompletion:^(NSArray *streams, NSError *err) {\n    for (BNTStreamInfo *stream in streams) {\n        if (stream.state == BNTStreamStateLive) {\n            // play stream!\n        }\n    }\n}];  But this example can be made simpler. There is also the  getStreamsWithState  call (added in version 0.2.0 of the Bintu.framework) which allows you filter the streams by state directly on the server, resulting in quicker load times. The above example can be implemented like this:  [client getStreamsWithState:BNTStreamStateLive completion:^(NSArray *streams, NSError *err) {\n    // all objects in streams have state = live\n    BNTStreamInfo *stream = [streams firstObject];\n    if (stream) {\n        // play stream!\n    }  \n}];  That was a basic overview of our bintu.live component.", 
            "title": "Bintu.live platform connection"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sdk/#strip_simulator_architectur_slices", 
            "text": "Xcode 6 and sometimes higher versions contain a bug where an app containing an embedded framework cannot be submitted to the app store when the framework contains simulator architectures (see  http://www.openradar.me/radar?id=6409498411401216 ).  On the other hand, including the simulator architectures in the framework is necessary for anyone that wants to test their app (and also the bintu.live connector) on the simulator.  The workaround is that Bintu.framework contains a script ( strip-frameworks.sh ) which removes the simulator architectures from the framework just before submitting to the app store.  For this to work correctly, you need to add a  Run Script Phase  to your Xcode app target. This phase has to come after the  Embed Frameworks  phase otherwise it will not work.  The  Run Script  phase should contain following line:  bash  ${BUILT_PRODUCTS_DIR}/${FRAMEWORKS_FOLDER_PATH}/Bintu.framework/strip-frameworks.sh   This should be all that is needed to work around the Xcode bug.", 
            "title": "Strip simulator architectur slices"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/", 
            "text": "Create your own live streaming app with nanoStream SDK for iOS in 5 minutes!\n\n\nThis guide will show you how you can get a head start on your competition for your end-to-end streaming platform by leveraging tried and true nanoStream technology.\n\n\nSummary\n\n\nWith this guide, you will be able to create a live video broadcaster and player app with nanoStream SDK, connected to the bintu.live streaming platform. You do not need to install your own server, just stream to the URL you get from bintu!\nYou will still be able to use your own server.\n\n\nRequirements\n\n\n\n\nnanoStream SDK 4.5.5 or later\n\n\na nanoStream SDK license for iOS (valid for publish \n playback)\n\n\na valid bintu.live API key\n\n\nXCode 7.2 or later on Mac OS 10.10 or later\n\n\nbintu.live connector requires at least iOS 8.0\n\n\n\n\nBroadcast (Publisher) App\n\n\n\n\n\n\nOpen the project \nStreamingExample\n from the SDK samples folder in Xcode.\n\n\n\n\n\n\nAdd the license and API keys\n\n\n\n\n\n\nOpen \nnanoLicenseConfig.h\n.\n\n\n\n\ninsert your License and API keys.\n\n\n\n\nmyLicenseKey = @\nnlic:1.2:...\n\nmyApiKey  = @\n12773-...\n\n\n\n\n\n\n\n\nBuild and run the application.\n\n\n\n\nHow to use the broadcaster\n\n\n\n\nRun the app\n\n\nEnter your API key if not hardcoded\n\n\nWait for the bandwidth check to finish or just skip to use defaults\n\n\nTap the \nstart broadcast\n button\n\n\n\n\nYou should see the result logged to the console: \nYou are live!\n.\nThe streamer automatically gets a stream URL from bintu.live and starts streaming.\nThe stream URL is logged as well.\n\n\nIn case of error please check the error message in the console log, your API key and your account. Contact us for help.\n\n\n{{::run_bandwith_check.png?200|}}\n\n\n{{::anzeige_bandwidth_in_stream.png?200|}}\n\n\nPlayer App\n\n\n\n\nOpen the project \nPlayingExample\n from the SDK samples folder in Xcode.\n\n\nBuild and run the application.\n(your license and API keys should be used from the same file as the broadcaster app)\n\n\n\n\nIf you tap the play button, you should see your live video sent from the broacaster device!\nIn case of error, please check the debug console. The error message should tell you something about the error. Check your API and license keys. Contact us for help.\n\n\nAll Together\n\n\nCongratulations! You now have everything you need for your own streaming platform.\n\n\nYou can now run the broadcaster app on one device and the player app on another. You can start a stream in the broadcaster app (via \nStart\n button) and can play it directly in the player app (via \nPlay\n button). The player app assumes that you want to play the latest stream on your account that is live.\n\n\nNext steps\n\n\nFrom here on you would probably want to integrate the live streaming function into your own backend.\nIf you want to know more how these sample apps were created and how you can set up your own ones, visit this \nstep-by-step tutorial\n.\n\n\nThese samples are pretty basic for better understanding what is going on. For a more complete sample on how to use nanoStream and bintu.live, see the samples \nBintuEncoder\n and \nBintuPlayer\n in the SDK \nsamples\n folder.\n\n\nGetting help\n\n\nContact us for additional help, or additional functions, full-feature apps and consulting services!", 
            "title": "Sample Documentation"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#create_your_own_live_streaming_app_with_nanostream_sdk_for_ios_in_5_minutes", 
            "text": "This guide will show you how you can get a head start on your competition for your end-to-end streaming platform by leveraging tried and true nanoStream technology.", 
            "title": "Create your own live streaming app with nanoStream SDK for iOS in 5 minutes!"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#summary", 
            "text": "With this guide, you will be able to create a live video broadcaster and player app with nanoStream SDK, connected to the bintu.live streaming platform. You do not need to install your own server, just stream to the URL you get from bintu!\nYou will still be able to use your own server.", 
            "title": "Summary"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#requirements", 
            "text": "nanoStream SDK 4.5.5 or later  a nanoStream SDK license for iOS (valid for publish   playback)  a valid bintu.live API key  XCode 7.2 or later on Mac OS 10.10 or later  bintu.live connector requires at least iOS 8.0", 
            "title": "Requirements"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#broadcast_publisher_app", 
            "text": "Open the project  StreamingExample  from the SDK samples folder in Xcode.    Add the license and API keys    Open  nanoLicenseConfig.h .   insert your License and API keys.   myLicenseKey = @ nlic:1.2:... \nmyApiKey  = @ 12773-...    Build and run the application.", 
            "title": "Broadcast (Publisher) App"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#how_to_use_the_broadcaster", 
            "text": "Run the app  Enter your API key if not hardcoded  Wait for the bandwidth check to finish or just skip to use defaults  Tap the  start broadcast  button   You should see the result logged to the console:  You are live! .\nThe streamer automatically gets a stream URL from bintu.live and starts streaming.\nThe stream URL is logged as well.  In case of error please check the error message in the console log, your API key and your account. Contact us for help.  {{::run_bandwith_check.png?200|}}  {{::anzeige_bandwidth_in_stream.png?200|}}", 
            "title": "How to use the broadcaster"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#player_app", 
            "text": "Open the project  PlayingExample  from the SDK samples folder in Xcode.  Build and run the application.\n(your license and API keys should be used from the same file as the broadcaster app)   If you tap the play button, you should see your live video sent from the broacaster device!\nIn case of error, please check the debug console. The error message should tell you something about the error. Check your API and license keys. Contact us for help.", 
            "title": "Player App"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#all_together", 
            "text": "Congratulations! You now have everything you need for your own streaming platform.  You can now run the broadcaster app on one device and the player app on another. You can start a stream in the broadcaster app (via  Start  button) and can play it directly in the player app (via  Play  button). The player app assumes that you want to play the latest stream on your account that is live.", 
            "title": "All Together"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#next_steps", 
            "text": "From here on you would probably want to integrate the live streaming function into your own backend.\nIf you want to know more how these sample apps were created and how you can set up your own ones, visit this  step-by-step tutorial .  These samples are pretty basic for better understanding what is going on. For a more complete sample on how to use nanoStream and bintu.live, see the samples  BintuEncoder  and  BintuPlayer  in the SDK  samples  folder.", 
            "title": "Next steps"
        }, 
        {
            "location": "/bintu/ios/bintu_ios_sample/#getting_help", 
            "text": "Contact us for additional help, or additional functions, full-feature apps and consulting services!", 
            "title": "Getting help"
        }, 
        {
            "location": "/about/", 
            "text": "About nanocosmos", 
            "title": "About"
        }
    ]
}